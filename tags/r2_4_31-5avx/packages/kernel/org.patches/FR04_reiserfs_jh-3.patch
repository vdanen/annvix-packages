diff -Nru a/fs/buffer.c b/fs/buffer.c
--- a/fs/buffer.c	Fri Jul 11 17:05:43 2003
+++ b/fs/buffer.c	Fri Jul 11 17:05:43 2003
@@ -617,20 +617,6 @@
 	spin_unlock(&lru_list_lock);
 }
 
-void buffer_insert_list_journal_head(struct buffer_head *bh, 
-                                     struct list_head *list,
-				     void *journal_head)
-{
-	spin_lock(&lru_list_lock);
-	if (buffer_attached(bh))
-		list_del(&bh->b_inode_buffers);
-	set_buffer_attached(bh);
-	list_add(&bh->b_inode_buffers, list);
-	bh->b_journal_head = journal_head;
-	spin_unlock(&lru_list_lock);
-}
-EXPORT_SYMBOL(buffer_insert_list_journal_head);
-
 /*
  * The caller must have the lru_list lock before calling the 
  * remove_inode_queue functions.
@@ -1362,8 +1348,11 @@
 		goto try_to_free;
 	if (!page->mapping->a_ops->releasepage)
 		goto try_to_free;
-	if (page->mapping->a_ops->releasepage(page, gfp_mask))
+	if (page->mapping->a_ops->releasepage(page, gfp_mask)) {
+		if (!page->buffers)
+			return 1;
 		goto try_to_free;
+	}
 	/*
 	 * We couldn't release buffer metadata; don't even bother trying
 	 * to release buffers.
diff -Nru a/fs/reiserfs/inode.c b/fs/reiserfs/inode.c
--- a/fs/reiserfs/inode.c	Fri Jul 11 17:05:43 2003
+++ b/fs/reiserfs/inode.c	Fri Jul 11 17:05:43 2003
@@ -107,16 +107,6 @@
     put_ih_entry_count( ih, entry_count );
 }
 
-static void add_to_flushlist(struct inode *inode, struct buffer_head *bh) {
-    struct reiserfs_journal_list *jl = SB_JOURNAL(inode->i_sb)->j_current_jl;
-    buffer_insert_list_journal_head(bh, &jl->j_ordered_bh_list, jl);
-}
-
-static void add_to_tail_list(struct inode *inode, struct buffer_head *bh) {
-    struct reiserfs_journal_list *jl = SB_JOURNAL(inode->i_sb)->j_current_jl;
-    buffer_insert_list_journal_head(bh, &jl->j_tail_bh_list, jl);
-}
-
 //
 // FIXME: we might cache recently accessed indirect item
 
@@ -862,7 +852,8 @@
 		    */
 		    __mark_buffer_dirty(unbh) ;
 		    /* note, this covers the data=ordered case too */
-		    add_to_tail_list(inode, unbh) ;
+		    reiserfs_add_tail_list(inode, unbh) ;
+		    buffer_insert_inode_data_queue(unbh, inode);
 		}
 	    }
 
@@ -1960,12 +1951,12 @@
 		    if (!atomic_set_buffer_dirty(bh)) {
 			set_buffer_flushtime(bh);
 			refile_buffer(bh);
-			buffer_insert_inode_data_queue(bh, p_s_inode);
 			need_balance_dirty = 1;
 
 			if (reiserfs_data_ordered(p_s_inode->i_sb)) {
-			    add_to_flushlist(p_s_inode, bh) ;
+			    reiserfs_add_flush_list(p_s_inode, bh) ;
 			}
+			buffer_insert_inode_data_queue(bh, p_s_inode);
 		    }
 		}
 	    }
@@ -2104,7 +2095,8 @@
 			__mark_buffer_dirty(bh_result) ;
 			mark_buffer_uptodate(bh_result, 1);
 			/* no need to update the inode trans, already done */
-			add_to_flushlist(inode, bh_result) ;
+			reiserfs_add_flush_list(inode, bh_result) ;
+			buffer_insert_inode_data_queue(bh_result, inode);
 		    }
 		    reiserfs_update_sd(hole_th, inode) ;
 		    journal_end(hole_th, hole_th->t_super, 
@@ -2334,6 +2326,7 @@
     unsigned blocksize;
     struct buffer_head *bh, *head;
     int logbh = 0 ;
+    loff_t pos = ((loff_t)page->index << PAGE_CACHE_SHIFT) + to;
 
     blocksize = 1 << inode->i_blkbits;
     if (reiserfs_file_data_log(inode)) {
@@ -2360,18 +2353,26 @@
 		journal_mark_dirty (th, inode->i_sb, bh);
 		unlock_kernel() ;
 	    } else if (!atomic_set_buffer_dirty(bh)) {
+		/* the buffer was clean, so we know any pending ordered
+		 * writes have been done.  If it has b_journal_head set,
+		 * and we don't need a new ordered write, reset it.
+		 *
+		 * We only trigger ordered writes for buffers that are new,
+		 * or ones with data past i_size.
+		 */
 		__mark_dirty(bh);
-		if (reiserfs_data_ordered(inode->i_sb)) {
+		if (reiserfs_data_ordered(inode->i_sb) && 
+		   (buffer_new(bh) || pos > inode->i_size))
+		{
 		    lock_kernel();
-		    add_to_flushlist(inode, bh);
-		    /* if we don't update the inode trans information,
-		     * an fsync(fd) might not catch these data blocks
-		     */
-		    reiserfs_update_inode_transaction(inode);
+		    reiserfs_add_flush_list(inode, bh); 
+		    unlock_kernel();
+		} else if (bh->b_journal_head && !buffer_locked(bh)) {
+		    lock_kernel();
+		    reiserfs_free_jh(bh);
 		    unlock_kernel();
-		} else {
-		    buffer_insert_inode_data_queue(bh, inode);
 		}
+		buffer_insert_inode_data_queue(bh, inode);
 		*balance = 1;
 	    }
 	}
@@ -2461,9 +2462,9 @@
 static int flushpage_can_drop(struct inode *inode, struct buffer_head *bh) {
     int ret = 1 ;
     
-    if (!buffer_mapped(bh)) {
-        return 1 ;
-    }
+    if (!buffer_mapped(bh))
+    	goto free_jh;
+
     if (reiserfs_file_data_log(inode)) {
 	lock_kernel() ;
 	/* very conservative, leave the buffer pinned if anyone might need it.
@@ -2477,13 +2478,15 @@
     }
     if (reiserfs_data_ordered(inode->i_sb)) {
         if (buffer_dirty(bh) && bh->b_journal_head) {
+	    struct reiserfs_jh *jh = NULL;
 	    struct reiserfs_journal_list *jl = NULL;
 	    lock_kernel();
 
-	    /* we can race against fsync_inode_buffers if we aren't careful */
-	    if (buffer_attached(bh) && buffer_dirty(bh))
-		jl = bh->b_journal_head;
-
+	    /* retest after schedule in lock_kernel */
+	    if (buffer_dirty(bh) && bh->b_journal_head) {
+		jh = bh->b_journal_head;
+		jl = jh->jl;
+	    }
 	    /* why is this safe?
 	     * reiserfs_setattr updates i_size in the on disk
 	     * stat data before allowing vmtruncate to be called.
@@ -2497,12 +2500,21 @@
 	     * if the buffer was put onto the ordered list for an older
 	     * transaction, we need to leave it around
 	     */
-	    if (jl != SB_JOURNAL(inode->i_sb)->j_current_jl) {
+	    if (jl && jl != SB_JOURNAL(inode->i_sb)->j_current_jl) {
 	        ret = 0;
 	    } 
 	    unlock_kernel();
 	}
     }
+free_jh:
+    /* only discard the b_journal_head when code above declared it safe
+     * to drop the page
+     */
+    if (ret && bh->b_journal_head) {
+	lock_kernel();
+        reiserfs_free_jh(bh);
+	unlock_kernel();
+    }
     return ret ;
 }
 
@@ -2554,6 +2566,36 @@
     return ret ;
 }
 
+static int reiserfs_releasepage(struct page *page, int gfp_mask) {
+    struct buffer_head *bh, *head;
+    int dirty_jh = 0;
+    int try_to_free_run = 0;
+
+restart:
+    if (page && page->buffers) {
+	head = page->buffers;
+	bh = head;
+	do {
+	    if (bh->b_journal_head) {
+	        if (!buffer_dirty(bh) && !buffer_locked(bh)) {
+		    lock_kernel();
+		    reiserfs_free_jh(bh);
+		    unlock_kernel();
+	        } else {
+		    dirty_jh = 1;    
+		}
+	    }
+	    bh = bh->b_this_page;
+	} while (bh != head) ;
+    }
+    if (dirty_jh && !try_to_free_run) {
+        try_to_free_run = 1;
+	try_to_free_buffers(page, gfp_mask);
+	goto restart;
+    }
+    return 1;
+}
+
 void sd_attrs_to_i_attrs( __u16 sd_attrs, struct inode *inode )
 {
 	if( reiserfs_attrs( inode -> i_sb ) ) {
@@ -2602,12 +2644,8 @@
                               struct kiobuf *iobuf, unsigned long blocknr,
 			      int blocksize) 
 {
-    if (reiserfs_data_ordered(inode->i_sb) || reiserfs_file_data_log(inode)) {
+    if (reiserfs_file_data_log(inode))
 	return -EINVAL;
-    }
-    lock_kernel();
-    reiserfs_commit_for_tail(inode);
-    unlock_kernel();
     return generic_direct_IO(rw, inode, iobuf, blocknr, blocksize,
                              reiserfs_get_block_direct_io) ;
 }
@@ -2621,4 +2659,6 @@
     bmap: reiserfs_aop_bmap,
     direct_IO: reiserfs_direct_io,
     flushpage: reiserfs_flushpage,
+    releasepage: reiserfs_releasepage,
 } ;
+
diff -Nru a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
--- a/fs/reiserfs/journal.c	Fri Jul 11 17:05:43 2003
+++ b/fs/reiserfs/journal.c	Fri Jul 11 17:05:43 2003
@@ -79,6 +79,9 @@
 static DECLARE_WAIT_QUEUE_HEAD(reiserfs_commit_thread_done) ;
 DECLARE_MUTEX(kreiserfsd_sem) ;
 
+static kmem_cache_t *reiserfs_jh_cache;
+static atomic_t nr_reiserfs_jh = ATOMIC_INIT(0);
+
 #define JOURNAL_TRANS_HALF 1018   /* must be correct to keep the desc and commit
 				     structs at 4k */
 #define BUFNR 64 /*read ahead */
@@ -697,6 +700,143 @@
     return 0;
 }
 
+#define CHUNK_SIZE 32
+struct buffer_chunk {
+    struct buffer_head *bh[CHUNK_SIZE];
+    int nr;
+};
+
+static void end_log_buffer_io_sync(struct buffer_head *bh, int uptodate) {
+    if (buffer_journaled(bh)) {
+        reiserfs_warning(NULL, "clm-2084: pinned buffer %lu:%s sent to disk\n",
+	                 bh->b_blocknr, kdevname(bh->b_dev)) ;
+    }
+    mark_buffer_uptodate(bh, uptodate) ;
+    unlock_buffer(bh) ;
+    put_bh(bh) ;
+}
+
+/* yes, there's a very tiny difference between this and 
+ * end_log_buffer_io_sync, but in data=ordered mode, this function get
+ * run a lot, so saving a little cpu is a good thing
+ */
+static void end_ordered_buffer_io_sync(struct buffer_head *bh, int uptodate) {
+    mark_buffer_uptodate(bh, uptodate) ;
+    unlock_buffer(bh) ;
+    put_bh(bh) ;
+}
+
+static void submit_logged_buffer(struct buffer_head *bh) {
+    get_bh(bh) ;
+    bh->b_end_io = end_log_buffer_io_sync ;
+    mark_buffer_notjournal_new(bh) ;
+    clear_bit(BH_Dirty, &bh->b_state) ;
+    if (!buffer_uptodate(bh))
+        BUG();
+    submit_bh(WRITE, bh) ;
+}
+
+static void submit_ordered_buffer(struct buffer_head *bh) {
+    get_bh(bh) ;
+    bh->b_end_io = end_ordered_buffer_io_sync ;
+    clear_bit(BH_Dirty, &bh->b_state) ;
+    if (!buffer_uptodate(bh))
+        BUG();
+    submit_bh(WRITE, bh) ;
+}
+
+static void write_chunk(struct buffer_chunk *chunk) {
+    int i;
+    unlock_kernel();
+    for (i = 0; i < chunk->nr ; i++) {
+	submit_logged_buffer(chunk->bh[i]) ;
+    }
+    lock_kernel();
+    chunk->nr = 0;
+}
+static void write_ordered_chunk(struct buffer_chunk *chunk) {
+    int i;
+    unlock_kernel();
+    for (i = 0; i < chunk->nr ; i++) {
+	submit_ordered_buffer(chunk->bh[i]) ;
+    }
+    if (current->need_resched)
+        schedule() ;
+    lock_kernel();
+    chunk->nr = 0;
+}
+static void add_to_chunk(struct buffer_chunk *chunk, 
+                         struct buffer_head *bh,
+			 void (fn)(struct buffer_chunk *)) 
+{
+    if (chunk->nr >= CHUNK_SIZE)
+        BUG();
+    chunk->bh[chunk->nr++] = bh;
+    if (chunk->nr >= CHUNK_SIZE)
+        fn(chunk);
+}
+
+#define JH_ENTRY(l) list_entry((l), struct reiserfs_jh, list)
+static int write_ordered_buffers(struct list_head *list, struct list_head *wl)
+{
+    struct buffer_head *bh;
+    struct reiserfs_jh *jh;
+    int ret = 0;
+    int nr = 0;
+    int nr_dirty = 0;
+    struct buffer_chunk chunk;
+    chunk.nr = 0;
+
+    while(!list_empty(list)) {
+	nr++;
+        jh = JH_ENTRY(list->next);
+	bh = jh->bh;
+	if (buffer_dirty(bh) || buffer_locked(bh)) {
+	    list_del_init(&jh->list);
+	    list_add(&jh->list, wl);
+	    get_bh(bh);
+	    if (buffer_dirty(bh)) {
+		lock_buffer(bh);
+		add_to_chunk(&chunk, bh, write_ordered_chunk);
+		nr_dirty++;
+	    }
+	    put_bh(bh);
+	} else {
+	    reiserfs_free_jh(bh);
+	}
+        if (current->need_resched)
+            schedule() ;
+    }
+    if (chunk.nr)
+        write_ordered_chunk(&chunk);
+    while(!list_empty(wl)) {
+        jh = JH_ENTRY(wl->next);
+	bh = jh->bh;
+	get_bh(bh);
+	wait_on_buffer(bh);
+	if (!buffer_uptodate(bh))
+	    ret = -EIO;
+        reiserfs_free_jh(bh);
+	put_bh(bh);
+        if (current->need_resched)
+            schedule() ;
+    }
+    return ret;
+}
+
+static inline void get_journal_list(struct reiserfs_journal_list *jl)
+{
+    jl->j_refcount++;
+}
+
+static inline void put_journal_list(struct super_block *s,
+                                   struct reiserfs_journal_list *jl)
+{
+    if (--jl->j_refcount == 0)
+        reiserfs_kfree(jl, sizeof(struct reiserfs_journal_list), s);
+
+}
+
 /*
 ** if this journal list still has commit blocks unflushed, send them to disk.
 **
@@ -732,10 +872,15 @@
   if (trans_id == SB_JOURNAL(s)->j_trans_id)
       BUG();
 
+  get_journal_list(jl);
+
+  /* write any buffers that must hit disk before the commit is done */
+  write_ordered_buffers(&jl->j_ordered_bh_list, &jl->j_wait_bh_list);
+
   if (flushall) {
     if (flush_older_commits(s, jl) == 1) {
         /* list disappeared during flush_older_commits.  return */
-        return 0;
+        goto put_jl;
     }
   }
 
@@ -745,11 +890,13 @@
   down(&jl->j_commit_lock);
   if (!journal_list_still_alive(s, trans_id)) {
       up(&jl->j_commit_lock);
-      return 0;
+      goto put_jl;
   }
   if (jl->j_trans_id == 0)
       BUG();
   
+  if (jl->j_refcount < 2)
+      BUG();
   /* this commit is done, exit */
   if (atomic_read(&(jl->j_commit_left)) <= 0) {
     if (flushall) {
@@ -760,18 +907,12 @@
     if (!list_empty(&jl->j_tail_bh_list))
         BUG();
     up(&jl->j_commit_lock);
-    return 0 ;
+    goto put_jl;
   }
 
-  /* write any buffers that must hit disk before the commit is done */
-  while(!list_empty(&jl->j_ordered_bh_list)) {
-      unlock_kernel();
-      fsync_buffers_list(&jl->j_ordered_bh_list);
-      lock_kernel();
-  }
   if (jl->j_len > SB_JOURNAL_TRANS_MAX(s)) {
     reiserfs_panic(s, "journal-512: flush_commit_list: length is %lu, trans_id %lu\n", jl->j_len, jl->j_trans_id) ;
-    return 0 ;
+    goto put_jl;
   }
 
   orig_commit_left = atomic_read(&(jl->j_commit_left)) ; 
@@ -860,6 +1001,8 @@
   }
   up(&jl->j_commit_lock);
 
+put_jl:
+  put_journal_list(s, jl);
   return 0 ;
 }
 
@@ -981,25 +1124,6 @@
     return 0 ;
 }
 
-static void reiserfs_end_buffer_io_sync(struct buffer_head *bh, int uptodate) {
-    if (buffer_journaled(bh)) {
-        reiserfs_warning(NULL, "clm-2084: pinned buffer %lu:%s sent to disk\n",
-	                 bh->b_blocknr, kdevname(bh->b_dev)) ;
-    }
-    mark_buffer_uptodate(bh, uptodate) ;
-    unlock_buffer(bh) ;
-    put_bh(bh) ;
-}
-static void submit_logged_buffer(struct buffer_head *bh) {
-    get_bh(bh) ;
-    bh->b_end_io = reiserfs_end_buffer_io_sync ;
-    mark_buffer_notjournal_new(bh) ;
-    clear_bit(BH_Dirty, &bh->b_state) ;
-    if (!buffer_uptodate(bh))
-        BUG();
-    submit_bh(WRITE, bh) ;
-}
-
 static void del_from_work_list(struct super_block *s, 
                                struct reiserfs_journal_list *jl) {
     if (!list_empty(&jl->j_working_list)) {
@@ -1255,37 +1379,13 @@
   if (!list_empty(&jl->j_tail_bh_list))
       BUG();
 
-  // kmem_cache_free(journal_list_cachep, jl);
-  reiserfs_kfree(jl, sizeof(struct reiserfs_journal_list), s);
+  put_journal_list(s, jl);
 
   if (flushall)
       up(&SB_JOURNAL(s)->j_flush_sem);
   return 0 ;
 } 
 
-
-#define CHUNK_SIZE 32
-struct buffer_chunk {
-    struct buffer_head *bh[CHUNK_SIZE];
-    int nr;
-};
-
-static void write_chunk(struct buffer_chunk *chunk) {
-    int i;
-    for (i = 0; i < chunk->nr ; i++) {
-	submit_logged_buffer(chunk->bh[i]) ;
-    }
-    chunk->nr = 0;
-}
-
-static void add_to_chunk(struct buffer_chunk *chunk, struct buffer_head *bh) {
-    if (chunk->nr >= CHUNK_SIZE)
-        BUG();
-    chunk->bh[chunk->nr++] = bh;
-    if (chunk->nr >= CHUNK_SIZE)
-        write_chunk(chunk);
-}
-
 static int write_one_transaction(struct super_block *s,
                                  struct reiserfs_journal_list *jl,
 				 struct buffer_chunk *chunk) 
@@ -1328,7 +1428,7 @@
 		if (cn->bh && buffer_journal_dirty(tmp_bh) && 
 		    !test_bit(BH_JPrepared, &tmp_bh->b_state)) 
 		{
-		    add_to_chunk(chunk, tmp_bh);
+		    add_to_chunk(chunk, tmp_bh, write_chunk);
 		    ret++;
 		} else {
 		    /* note, cn->bh might be null now */
@@ -1695,7 +1795,6 @@
   sleep_on(&reiserfs_commit_thread_done) ;
 
   free_journal_ram(p_s_sb) ;
-
   return 0 ;
 }
 
@@ -2278,9 +2377,11 @@
     INIT_LIST_HEAD(&jl->j_list);
     INIT_LIST_HEAD(&jl->j_working_list);
     INIT_LIST_HEAD(&jl->j_ordered_bh_list);
+    INIT_LIST_HEAD(&jl->j_wait_bh_list);
     INIT_LIST_HEAD(&jl->j_tail_bh_list);
     sema_init(&jl->j_commit_lock, 1);
     SB_JOURNAL(s)->j_num_lists++;
+    get_journal_list(jl);
     return jl;
 }
 
@@ -3412,12 +3513,6 @@
   inode->u.reiserfs_i.i_trans_id = SB_JOURNAL(inode->i_sb)->j_trans_id ;
 }
 
-void reiserfs_update_tail_transaction(struct inode *inode) {
-  
-  inode->u.reiserfs_i.i_tail_jl = SB_JOURNAL(inode->i_sb)->j_current_jl;
-  inode->u.reiserfs_i.i_tail_trans_id = SB_JOURNAL(inode->i_sb)->j_trans_id ;
-}
-
 static void __commit_trans_jl(struct inode *inode, unsigned long id,
                                  struct reiserfs_journal_list *jl) 
 {
@@ -3457,14 +3552,6 @@
     }
     /* otherwise the list is gone, and long since committed */
 }
-void reiserfs_commit_for_tail(struct inode *inode) {
-    unsigned long id = inode->u.reiserfs_i.i_tail_trans_id;
-    struct reiserfs_journal_list *jl = inode->u.reiserfs_i.i_tail_jl;
-
-    /* for tails, if this info is unset there's nothing to commit */
-    if (id && jl)
-	__commit_trans_jl(inode, id, jl);
-}
 void reiserfs_commit_for_inode(struct inode *inode) {
     unsigned long id = inode->u.reiserfs_i.i_trans_id;
     struct reiserfs_journal_list *jl = inode->u.reiserfs_i.i_jl;
@@ -3545,6 +3632,65 @@
 	}
     }
 }
+
+static struct reiserfs_jh *alloc_jh(void) {
+    struct reiserfs_jh *jh;
+    while(1) {
+	jh = kmem_cache_alloc(reiserfs_jh_cache, GFP_NOFS);
+	if (jh) {
+	    atomic_inc(&nr_reiserfs_jh);
+	    return jh;
+	}
+        yield();
+    }
+}
+
+void reiserfs_free_jh(struct buffer_head *bh) {
+    struct reiserfs_jh *jh;
+
+    reiserfs_check_lock_depth("free_jh");
+    jh = bh->b_journal_head;
+    if (jh) {
+	bh->b_journal_head = NULL;
+	jh->bh = NULL;
+	list_del_init(&jh->list);
+	kmem_cache_free(reiserfs_jh_cache, jh);
+	if (atomic_read(&nr_reiserfs_jh) <= 0)
+	    BUG();
+	atomic_dec(&nr_reiserfs_jh);
+	put_bh(bh);
+    }
+}
+
+static inline int __add_jh(struct inode *inode, struct buffer_head *bh,
+			   struct reiserfs_journal_list *jl,
+                           struct list_head *list) 
+{
+    struct reiserfs_jh *jh;
+
+    reiserfs_check_lock_depth("add_jh");
+    if (bh->b_journal_head) {
+        jh = bh->b_journal_head;
+	list_del_init(&jh->list);
+    } else {
+	get_bh(bh);
+	jh = alloc_jh();
+	jh->bh = bh;
+	bh->b_journal_head = jh;
+    }
+    jh->jl = jl;
+    list_add_tail(&jh->list, list);
+    return 0;
+}
+
+int reiserfs_add_flush_list(struct inode *inode, struct buffer_head *bh) {
+    struct reiserfs_journal_list *jl = SB_JOURNAL(inode->i_sb)->j_current_jl;
+    return __add_jh(inode, bh, jl, &jl->j_ordered_bh_list);
+}
+int reiserfs_add_tail_list(struct inode *inode, struct buffer_head *bh) {
+    struct reiserfs_journal_list *jl = SB_JOURNAL(inode->i_sb)->j_current_jl;
+    return __add_jh(inode, bh, jl, &jl->j_tail_bh_list);
+}
 /* 
 ** long and ugly.  If flush, will not return until all commit
 ** blocks and all real buffers in the trans are on disk.
@@ -3788,11 +3934,7 @@
    * clean, if we crash before the later transaction commits, the data block
    * is lost.
    */
-  while(!list_empty(&jl->j_tail_bh_list)) {
-      unlock_kernel();
-      fsync_buffers_list(&jl->j_tail_bh_list);
-      lock_kernel();
-  }
+  write_ordered_buffers(&jl->j_tail_bh_list, &jl->j_wait_bh_list);
   up(&jl->j_commit_lock);
 
   /* honor the flush wishes from the caller, simple commits can
@@ -3888,6 +4030,22 @@
   return 0 ;
 }
 
-int __init reiserfs_journal_cache_init(void) {
+int reiserfs_journal_cache_init(void) {
+    int ret = 0;
+
+    reiserfs_jh_cache = kmem_cache_create("reiserfs_jh", 
+                                          sizeof(struct reiserfs_jh),
+					  0, 0, NULL, NULL);
+    if (!reiserfs_jh_cache) {
+        ret = -ENOMEM;
+	printk("failed to initialize reiserfs journal head cache\n");
+    }
+    printk("reiserfs journal head cache initialized\n");
+    return ret;
+}
+
+int reiserfs_journal_cache_destroy(void) {
+    kmem_cache_destroy(reiserfs_jh_cache);
+    reiserfs_jh_cache = NULL;
     return 0;
 }
diff -Nru a/fs/reiserfs/tail_conversion.c b/fs/reiserfs/tail_conversion.c
--- a/fs/reiserfs/tail_conversion.c	Fri Jul 11 17:05:43 2003
+++ b/fs/reiserfs/tail_conversion.c	Fri Jul 11 17:05:43 2003
@@ -132,7 +132,6 @@
 
     inode->u.reiserfs_i.i_first_direct_byte = U32_MAX;
 
-    reiserfs_update_tail_transaction(inode);
     return 0;
 }
 
diff -Nru a/include/linux/reiserfs_fs.h b/include/linux/reiserfs_fs.h
--- a/include/linux/reiserfs_fs.h	Fri Jul 11 17:05:43 2003
+++ b/include/linux/reiserfs_fs.h	Fri Jul 11 17:05:43 2003
@@ -1686,6 +1686,15 @@
   				   block should be displaced from others */
 } ;
 
+/* used to keep track of ordered and tail writes, attached to the buffer
+ * head through b_journal_head.
+ */
+struct reiserfs_jh {
+    struct reiserfs_journal_list *jl;
+    struct buffer_head *bh;
+    struct list_head list;
+};
+
 static inline int
 reiserfs_dangling_handle(struct reiserfs_transaction_handle *th) {
     return (th && (th->t_flags & REISERFS_DANGLING_HANDLE)) ;
@@ -1772,6 +1781,10 @@
 #define JOURNAL_BUFFER(j,n) ((j)->j_ap_blocks[((j)->j_start + (n)) % JOURNAL_BLOCK_COUNT])
 
 int reiserfs_journal_cache_init(void);
+int reiserfs_journal_cache_destroy(void);
+void reiserfs_free_jh(struct buffer_head *);
+int reiserfs_add_flush_list(struct inode *, struct buffer_head *);
+int reiserfs_add_tail_list(struct inode *, struct buffer_head *);
 int reiserfs_flush_old_commits(struct super_block *);
 void reiserfs_commit_for_inode(struct inode *) ;
 void reiserfs_commit_for_tail(struct inode *) ;
diff -Nru a/include/linux/reiserfs_fs_i.h b/include/linux/reiserfs_fs_i.h
--- a/include/linux/reiserfs_fs_i.h	Fri Jul 11 17:05:43 2003
+++ b/include/linux/reiserfs_fs_i.h	Fri Jul 11 17:05:43 2003
@@ -57,13 +57,6 @@
     ** flushed */
     unsigned long i_trans_id ;
     struct reiserfs_journal_list *i_jl;
-
-    /* direct io needs to make sure the tail is on disk to avoid
-     * buffer alias problems.  This records the transaction last
-     * involved in a direct->indirect conversion for this file
-     */
-    unsigned long i_tail_trans_id;
-    struct reiserfs_journal_list *i_tail_jl;
 };
 
 #endif
diff -Nru a/include/linux/reiserfs_fs_sb.h b/include/linux/reiserfs_fs_sb.h
--- a/include/linux/reiserfs_fs_sb.h	Fri Jul 11 17:05:43 2003
+++ b/include/linux/reiserfs_fs_sb.h	Fri Jul 11 17:05:43 2003
@@ -222,6 +222,13 @@
    * need their own list
    */
   struct list_head j_tail_bh_list;
+
+  /* ordered and tail writes go onto this list so multiple procs can 
+   * safely write and wait on them at once
+   */
+  struct list_head j_wait_bh_list;
+
+  int j_refcount;
 } ;
 
 struct reiserfs_page_list  ; /* defined in reiserfs_fs.h */
