diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/Documentation/Configure.help linux-2.4.23-pre1/Documentation/Configure.help
--- linux-2.4.22/Documentation/Configure.help	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/Documentation/Configure.help	2003-08-27 14:41:42.000000000 +0000
@@ -137,6 +137,15 @@
 
   If you don't know what to do here, say N.
 
+Maximum number of CPUs
+CONFIG_NR_CPUS
+  This allows you to specify the maximum number of CPUs which this
+  kernel will support.  The maximum supported value is 32 and the
+  mimimum value which makes sense is 2.
+
+  This is purely to save memory - each supported CPU adds
+  approximately eight kilobytes to the kernel image.
+
 Intel or compatible 80x86 processor
 CONFIG_X86
   This is Linux's home port.  Linux was originally native to the Intel
@@ -3217,6 +3226,190 @@
   If you want to compile it as a module, say M here and read
   <file:Documentation/modules.txt>.  If unsure, say `N'.
 
+IP: virtual server support
+CONFIG_IP_VS
+  IP Virtual Server support will let you build a high-performance
+  virtual server based on cluster of two or more real servers. This
+  option must be enabled for at least one of the clustered computers
+  that will take care of intercepting incomming connections to a
+  single IP address and scheduling them to real servers.
+
+  Three request dispatching techniques are implemented, they are
+  virtual server via NAT, virtual server via tunneling and virtual
+  server via direct routing. The several scheduling algorithms can
+  be used to choose which server the connection is directed to,
+  thus load balancing can be achieved among the servers.  For more
+  information and its administration program, please visit the
+  following URL:
+	http://www.linuxvirtualserver.org/
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IP virtual server debugging
+CONFIG_IP_VS_DEBUG
+  Say Y here if you want to get additional messages useful in
+  debugging the IP virtual server code. You can change the debug
+  level in /proc/sys/net/ipv4/vs/debug_level
+
+IPVS connection hash table size (the Nth power of 2)
+CONFIG_IP_VS_TAB_BITS
+  The IPVS connection hash table uses the chaining scheme to handle
+  hash collisions. Using a big IPVS connection hash table will greatly
+  reduce conflicts when there are hundreds of thousands of connections
+  in the hash table.
+
+  Note the table size must be power of 2. The table size will be the
+  value of 2 to the your input number power. The number to choose is
+  from 8 to 20, the default number is 12, which means the table size
+  is 4096. Don't input the number too small, otherwise you will lose
+  performance on it. You can adapt the table size yourself, according
+  to your virtual server application. It is good to set the table size
+  not far less than the number of connections per second multiplying
+  average lasting time of connection in the table.  For example, your
+  virtual server gets 200 connections per second, the connection lasts
+  for 200 seconds in average in the connection table, the table size
+  should be not far less than 200x200, it is good to set the table
+  size 32768 (2**15).
+
+  Another note that each connection occupies 128 bytes effectively and
+  each hash entry uses 8 bytes, so you can estimate how much memory is
+  needed for your box.
+
+IPVS: round-robin scheduling
+CONFIG_IP_VS_RR
+  The robin-robin scheduling algorithm simply directs network
+  connections to different real servers in a round-robin manner.
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IPVS: weighted round-robin scheduling
+CONFIG_IP_VS_WRR
+  The weighted robin-robin scheduling algorithm directs network
+  connections to different real servers based on server weights
+  in a round-robin manner. Servers with higher weights receive
+  new connections first than those with less weights, and servers
+  with higher weights get more connections than those with less
+  weights and servers with equal weights get equal connections.
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IPVS: least-connection scheduling
+CONFIG_IP_VS_LC
+  The least-connection scheduling algorithm directs network
+  connections to the server with the least number of active 
+  connections.
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IPVS: weighted least-connection scheduling
+CONFIG_IP_VS_WLC
+  The weighted least-connection scheduling algorithm directs network
+  connections to the server with the least active connections
+  normalized by the server weight.
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IPVS: locality-based least-connection scheduling
+CONFIG_IP_VS_LBLC
+  The locality-based least-connection scheduling algorithm is for
+  destination IP load balancing. It is usually used in cache cluster.
+  This algorithm usually directs packet destined for an IP address to
+  its server if the server is alive and under load. If the server is
+  overloaded (its active connection numbers is larger than its weight)
+  and there is a server in its half load, then allocate the weighted
+  least-connection server to this IP address.
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IPVS: locality-based least-connection with replication scheduling
+CONFIG_IP_VS_LBLCR
+  The locality-based least-connection with replication scheduling
+  algorithm is also for destination IP load balancing. It is 
+  usually used in cache cluster. It differs from the LBLC scheduling
+  as follows: the load balancer maintains mappings from a target
+  to a set of server nodes that can serve the target. Requests for
+  a target are assigned to the least-connection node in the target's
+  server set. If all the node in the server set are over loaded,
+  it picks up a least-connection node in the cluster and adds it
+  in the sever set for the target. If the server set has not been
+  modified for the specified time, the most loaded node is removed
+  from the server set, in order to avoid high degree of replication.
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IPVS: destination hashing scheduling
+CONFIG_IP_VS_DH
+  The destination hashing scheduling algorithm assigns network
+  connections to the servers through looking up a statically assigned
+  hash table by their destination IP addresses.
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IPVS: source hashing scheduling
+CONFIG_IP_VS_SH
+  The source hashing scheduling algorithm assigns network
+  connections to the servers through looking up a statically assigned
+  hash table by their source IP addresses.
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IPVS: shortest expected delay scheduling
+CONFIG_IP_VS_SED
+  The shortest expected delay scheduling algorithm assigns network
+  connections to the server with the shortest expected delay. The 
+  expected delay that the job will experience is (Ci + 1) / Ui if 
+  sent to the ith server, in which Ci is the number of connections
+  on the the ith server and Ui is the fixed service rate (weight)
+  of the ith server.
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IPVS: never queue scheduling
+CONFIG_IP_VS_NQ
+  The never queue scheduling algorithm adopts a two-speed model.
+  When there is an idle server available, the job will be sent to
+  the idle server, instead of waiting for a fast one. When there
+  is no idle server available, the job will be sent to the server
+  that minimize its expected delay (The Shortest Expected Delay
+  scheduling algorithm).
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
+IPVS: FTP protocol helper
+CONFIG_IP_VS_FTP
+  FTP is a protocol that transfers IP address and/or port number in
+  the payload. In the virtual server via Network Address Translation,
+  the IP address and port number of real servers cannot be sent to
+  clients in ftp connections directly, so FTP protocol helper is
+  required for tracking the connection and mangling it back to that of
+  virtual service.
+
+  If you want to compile it in kernel, say Y. If you want to compile
+  it as a module, say M here and read Documentation/modules.txt. If
+  unsure, say N.
+
 SYN flood protection
 CONFIG_SYN_COOKIES
   Normal TCP/IP networking is open to an attack known as "SYN
@@ -18921,6 +19114,21 @@
 
   If unsure, say N.
 
+Intel/AMD/VIA HW Random Number Generator support
+CONFIG_HW_RANDOM
+  This driver provides kernel-side support for the
+  Random Number Generator hardware found on Intel i8xx-based motherboards,
+  AMD 76x-based motherboards, and Via Nehemiah CPUs.
+
+  Provides a character driver, used to read() entropy data.
+
+  To compile this driver as a module ( = code which can be inserted in
+  and removed from the running kernel whenever you want), say M here
+  and read <file:Documentation/modules.txt>. The module will be called
+  hw_random.
+
+  If unsure, say N.
+
 Power Management support
 CONFIG_PM
   "Power Management" means that parts of your computer are shut
@@ -24894,6 +25102,19 @@
   output to the second serial port on these devices.  Saying N will
   cause the debug messages to appear on the first serial port.
 
+Kernel log buffer length shift
+CONFIG_LOG_BUF_SHIFT
+  The kernel log buffer has a fixed size of :
+      64 kB (2^16) on MULTIQUAD and IA64,
+     128 kB (2^17) on S390
+      32 kB (2^15) on SMP systems
+      16 kB (2^14) on UP systems
+
+  You have the ability to change this size with this paramter which
+  fixes the bit shift of to get the buffer length (which must be a
+  power of 2). Eg: a value of 16 sets the buffer to 64 kB (2^16).
+  The default value of 0 uses standard values above.
+
 Disable pgtable cache
 CONFIG_NO_PGT_CACHE
   Normally the kernel maintains a `quicklist' of preallocated
@@ -27478,6 +27699,12 @@
 
   See http://csrc.nist.gov/encryption/aes/ for more information.
 
+CONFIG_CRYPTO_CAST5
+  CAST5 (CAST-128) cipher algorithm.
+
+  The CAST5 encryption algorithm (synonymous with CAST-128) is
+  described in RFC2144.
+
 CONFIG_CRYPTO_DEFLATE
   This is the Deflate algorithm (RFC1951), specified for use in
   IPSec with the IPCOMP protocol (RFC3173, RFC2394).
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/Documentation/crypto/api-intro.txt linux-2.4.23-pre1/Documentation/crypto/api-intro.txt
--- linux-2.4.22/Documentation/crypto/api-intro.txt	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/Documentation/crypto/api-intro.txt	2003-08-27 14:41:59.000000000 +0000
@@ -186,7 +186,6 @@
   Dag Arne Osvik (Serpent)
   Brian Gladman (AES)
 
-
 SHA1 algorithm contributors:
   Jean-Francois Dive
   
@@ -214,6 +213,9 @@
   Kyle McMartin
   Adam J. Richter
 
+CAST5 algorithm contributors:
+  Kartikey Mahendra Bhatt (original developers unknown, FSF copyright).
+
 Generic scatterwalk code by Adam J. Richter <adam@yggdrasil.com>
 
 Please send any credits updates or corrections to:
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/Documentation/filesystems/jfs.txt linux-2.4.23-pre1/Documentation/filesystems/jfs.txt
--- linux-2.4.22/Documentation/filesystems/jfs.txt	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/Documentation/filesystems/jfs.txt	2003-08-27 14:40:39.000000000 +0000
@@ -23,6 +23,15 @@
 		read-write.  The resize keyword with no value will grow
 		the volume to the full size of the partition.
 
+nointegrity	Do not write to the journal.  The primary use of this option
+		is to allow for higher performance when restoring a volume
+		from backup media.  The integrity of the volume is not
+		guaranteed if the system abnormally abends.
+
+integrity	Default.  Commit metadata changes to the journal.  Use this
+		option to remount a volume where the nointegrity option was
+		previously specified in order to restore normal behavior.
+
 JFS TODO list:
 
 Plans for our near term development items
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/Documentation/hw_random.txt linux-2.4.23-pre1/Documentation/hw_random.txt
--- linux-2.4.22/Documentation/hw_random.txt	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/Documentation/hw_random.txt	2003-08-27 14:41:24.000000000 +0000
@@ -0,0 +1,138 @@
+	Hardware driver for Intel/AMD/VIA Random Number Generators (RNG)
+	Copyright 2000,2001 Jeff Garzik <jgarzik@pobox.com>
+	Copyright 2000,2001 Philipp Rumpf <prumpf@mandrakesoft.com>
+
+Introduction:
+
+	The hw_random device driver is software that makes use of a
+	special hardware feature on your CPU or motherboard,
+	a Random Number Generator (RNG).
+
+	In order to make effective use of this device driver, you
+	should download the support software as well.  Download the
+	latest version of the "rng-tools" package from the
+	hw_random driver's official Web site:
+
+		http://sourceforge.net/projects/gkernel/
+
+About the Intel RNG hardware, from the firmware hub datasheet:
+
+	The Firmware Hub integrates a Random Number Generator (RNG)
+	using thermal noise generated from inherently random quantum
+	mechanical properties of silicon. When not generating new random
+	bits the RNG circuitry will enter a low power state. Intel will
+	provide a binary software driver to give third party software
+	access to our RNG for use as a security feature. At this time,
+	the RNG is only to be used with a system in an OS-present state.
+
+Theory of operation:
+
+	Character driver.  Using the standard open()
+	and read() system calls, you can read random data from
+	the hardware RNG device.  This data is NOT CHECKED by any
+	fitness tests, and could potentially be bogus (if the
+	hardware is faulty or has been tampered with).  Data is only
+	output if the hardware "has-data" flag is set, but nevertheless
+	a security-conscious person would run fitness tests on the
+	data before assuming it is truly random.
+
+	/dev/hwrandom is char device major 10, minor 183.
+
+Driver notes:
+
+	* FIXME: support poll(2)
+
+	NOTE: request_mem_region was removed, for two reasons:
+	1) Only one RNG is supported by this driver, 2) The location
+	used by the RNG is a fixed location in MMIO-addressable memory,
+	3) users with properly working BIOS e820 handling will always
+	have the region in which the RNG is located reserved, so
+	request_mem_region calls always fail for proper setups.
+	However, for people who use mem=XX, BIOS e820 information is
+	-not- in /proc/iomem, and request_mem_region(RNG_ADDR) can
+	succeed.
+
+Driver details:
+
+	Based on:
+	Intel 82802AB/82802AC Firmware Hub (FWH) Datasheet
+		May 1999 Order Number: 290658-002 R
+
+	Intel 82802 Firmware Hub: Random Number Generator
+	Programmer's Reference Manual
+		December 1999 Order Number: 298029-001 R
+
+	Intel 82802 Firmware HUB Random Number Generator Driver
+	Copyright (c) 2000 Matt Sottek <msottek@quiknet.com>
+
+	Special thanks to Matt Sottek.  I did the "guts", he
+	did the "brains" and all the testing.
+
+Change history:
+
+	Version 1.0.0:
+	* Merge Intel, AMD, VIA RNG drivers into one.
+	  Further changelog in BitKeeper.
+
+	Version 0.9.8:
+	* Support other i8xx chipsets by adding 82801E detection
+	* 82801DB detection is the same as for 82801CA.
+
+	Version 0.9.7:
+	* Support other i8xx chipsets too (by adding 82801BA(M) and
+	  82801CA(M) detection)
+
+	Version 0.9.6:
+	* Internal driver cleanups, prep for 1.0.0 release.
+
+	Version 0.9.5:
+	* Rip out entropy injection via timer.  It never ever worked,
+	  and a better solution (rngd) is now available.
+
+	Version 0.9.4:
+	* Fix: Remove request_mem_region
+	* Fix: Horrible bugs in FIPS calculation and test execution
+
+	Version 0.9.3:
+	* Clean up rng_read a bit.
+	* Update i810_rng driver Web site URL.
+	* Increase default timer interval to 4 samples per second.
+	* Abort if mem region is not available.
+	* BSS zero-initialization cleanup.
+	* Call misc_register() from rng_init_one.
+	* Fix O_NONBLOCK to occur before we schedule.
+
+	Version 0.9.2:
+	* Simplify open blocking logic
+
+	Version 0.9.1:
+	* Support i815 chipsets too (Matt Sottek)
+	* Fix reference counting when statically compiled (prumpf)
+	* Rewrite rng_dev_read (prumpf)
+	* Make module races less likely (prumpf)
+	* Small miscellaneous bug fixes (prumpf)
+	* Use pci table for PCI id list
+
+	Version 0.9.0:
+	* Don't register a pci_driver, because we are really
+	  using PCI bridge vendor/device ids, and someone
+	  may want to register a driver for the bridge. (bug fix)
+	* Don't let the usage count go negative (bug fix)
+	* Clean up spinlocks (bug fix)
+	* Enable PCI device, if necessary (bug fix)
+	* iounmap on module unload (bug fix)
+	* If RNG chrdev is already in use when open(2) is called,
+	  sleep until it is available.
+	* Remove redundant globals rng_allocated, rng_use_count
+	* Convert numeric globals to unsigned
+	* Module unload cleanup
+
+	Version 0.6.2:
+	* Clean up spinlocks.  Since we don't have any interrupts
+	  to worry about, but we do have a timer to worry about,
+	  we use spin_lock_bh everywhere except the timer function
+	  itself.
+	* Fix module load/unload.
+	* Fix timer function and h/w enable/disable logic
+	* New timer interval sysctl
+	* Clean up sysctl names
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/Documentation/kernel-parameters.txt linux-2.4.23-pre1/Documentation/kernel-parameters.txt
--- linux-2.4.22/Documentation/kernel-parameters.txt	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/Documentation/kernel-parameters.txt	2003-08-27 14:40:34.000000000 +0000
@@ -278,6 +278,8 @@
 
 	keepinitrd	[HW, ARM]
 
+	lapic		[IA-32,APIC] Enable the local APIC even if BIOS disabled it.
+
 	load_ramdisk=	[RAM] List of ramdisks to load from floppy.
 
 	lockd.udpport=	[NFS]
@@ -414,6 +416,8 @@
 
 	nointroute	[IA-64]
  
+	nolapic		[IA-32,APIC] Do not enable or use the local APIC.
+
 	no-scroll	[VGA]
 
 	nosmp		[SMP] Tells an SMP kernel to act as a UP kernel.
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/Documentation/sonypi.txt linux-2.4.23-pre1/Documentation/sonypi.txt
--- linux-2.4.22/Documentation/sonypi.txt	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/Documentation/sonypi.txt	2003-08-27 14:39:14.000000000 +0000
@@ -8,7 +8,9 @@
 	Copyright (C) 2000 Andrew Tridgell <tridge@samba.org>
 
 This driver enables access to the Sony Programmable I/O Control Device which
-can be found in many (all ?) Sony Vaio laptops.
+can be found in many Sony Vaio laptops. Some newer Sony laptops (seems to be
+limited to new FX series laptops, at least the FX501 and the FX702) lack a
+sonypi device and are not supported at all by this driver.
 
 It will give access (through a user space utility) to some events those laptops
 generate, like:
@@ -96,6 +98,7 @@
 				SONYPI_THUMBPHRASE_MASK 	0x0200
 				SONYPI_MEYE_MASK		0x0400
 				SONYPI_MEMORYSTICK_MASK		0x0800
+				SONYPI_BATTERY_MASK		0x1000
 
 	useinput:	if set (which is the default) jogdial events are
 			forwarded to the input subsystem as mouse wheel
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/Documentation/video4linux/meye.txt linux-2.4.23-pre1/Documentation/video4linux/meye.txt
--- linux-2.4.22/Documentation/video4linux/meye.txt	2003-06-13 14:51:29.000000000 +0000
+++ linux-2.4.23-pre1/Documentation/video4linux/meye.txt	2003-08-27 14:39:44.000000000 +0000
@@ -16,6 +16,23 @@
 
 MJPEG hardware grabbing is supported via a private API (see below).
 
+Hardware supported:
+-------------------
+
+This driver supports the 'second' version of the MotionEye camera :)
+
+The first version was connected directly on the video bus of the Neomagic
+video card and is unsupported.
+
+The second one, made by Kawasaki Steel is fully supported by this 
+driver (PCI vendor/device is 0x136b/0xff01)
+
+The third one, present in recent (more or less last year) Picturebooks
+(C1M* models), is not supported. The manufacturer has given the specs
+to the developers under a NDA (which allows the develoment of a GPL
+driver however), but things are not moving very fast (see
+http://r-engine.sourceforge.net/) (PCI vendor/device is 0x10cf/0x2011).
+
 Driver options:
 ---------------
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/MAINTAINERS linux-2.4.23-pre1/MAINTAINERS
--- linux-2.4.22/MAINTAINERS	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/MAINTAINERS	2003-08-27 14:40:40.000000000 +0000
@@ -670,7 +670,7 @@
 ETHERNET BRIDGE
 P:	Stephen Hemminger
 M:	shemminger@osdl.org
-L:	bridge@math.leidenuniv.nl
+L:	bridge@osdl.org
 W:	http://bridge.sourceforge.net/
 S:	Maintained
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/Makefile linux-2.4.23-pre1/Makefile
--- linux-2.4.22/Makefile	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/Makefile	2003-08-27 14:39:26.000000000 +0000
@@ -1,7 +1,7 @@
 VERSION = 2
 PATCHLEVEL = 4
-SUBLEVEL = 22
-EXTRAVERSION =
+SUBLEVEL = 23
+EXTRAVERSION = pre1
 
 KERNELRELEASE=$(VERSION).$(PATCHLEVEL).$(SUBLEVEL)$(EXTRAVERSION)
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/alpha/config.in linux-2.4.23-pre1/arch/alpha/config.in
--- linux-2.4.22/arch/alpha/config.in	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/alpha/config.in	2003-08-27 14:39:48.000000000 +0000
@@ -269,6 +269,7 @@
 
 if [ "$CONFIG_SMP" = "y" ]; then
    define_bool CONFIG_HAVE_DEC_LOCK y
+   int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
 fi
 
 if [ "$CONFIG_ALPHA_GENERIC" = "y" -o "$CONFIG_ALPHA_SRM" = "y" ]; then
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/arm/mm/mm-armo.c linux-2.4.23-pre1/arch/arm/mm/mm-armo.c
--- linux-2.4.22/arch/arm/mm/mm-armo.c	2001-04-12 19:20:31.000000000 +0000
+++ linux-2.4.23-pre1/arch/arm/mm/mm-armo.c	2003-08-27 14:40:24.000000000 +0000
@@ -104,6 +104,7 @@
 no_pte:
 	spin_unlock(&mm->page_table_lock);
 	pmd_free(new_pmd);
+	check_pgt_cache();
 	free_pgd_slow(new_pgd);
 	return NULL;
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/arm/mm/mm-armv.c linux-2.4.23-pre1/arch/arm/mm/mm-armv.c
--- linux-2.4.22/arch/arm/mm/mm-armv.c	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/arm/mm/mm-armv.c	2003-08-27 14:40:45.000000000 +0000
@@ -123,6 +123,7 @@
 no_pte:
 	spin_unlock(&mm->page_table_lock);
 	pmd_free(new_pmd);
+	check_pgt_cache();
 	free_pages((unsigned long)new_pgd, 2);
 	return NULL;
 
@@ -157,6 +158,7 @@
 	pmd_clear(pmd);
 	pte_free(pte);
 	pmd_free(pmd);
+	check_pgt_cache();
 free:
 	free_pages((unsigned long) pgd, 2);
 }
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/config.in linux-2.4.23-pre1/arch/i386/config.in
--- linux-2.4.22/arch/i386/config.in	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/config.in	2003-08-27 14:40:01.000000000 +0000
@@ -231,6 +231,7 @@
       define_bool CONFIG_X86_IO_APIC y
    fi
 else
+   int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
    bool 'Multi-node NUMA system support' CONFIG_X86_NUMA
    if [ "$CONFIG_X86_NUMA" = "y" ]; then
       #Platform Choices
@@ -476,6 +477,8 @@
    bool '  Compile the kernel with frame pointers' CONFIG_FRAME_POINTER
 fi
 
+int 'Kernel messages buffer length shift (0 = default)' CONFIG_LOG_BUF_SHIFT 0
+
 endmenu
 
 source crypto/Config.in
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/defconfig linux-2.4.23-pre1/arch/i386/defconfig
--- linux-2.4.22/arch/i386/defconfig	2002-11-28 23:53:09.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/defconfig	2003-08-27 14:39:33.000000000 +0000
@@ -64,6 +64,7 @@
 CONFIG_SMP=y
 # CONFIG_MULTIQUAD is not set
 CONFIG_HAVE_DEC_LOCK=y
+CONFIG_NR_CPUS=32
 
 #
 # General setup
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/kernel/apic.c linux-2.4.23-pre1/arch/i386/kernel/apic.c
--- linux-2.4.22/arch/i386/kernel/apic.c	2003-06-13 14:51:29.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/kernel/apic.c	2003-08-27 14:42:00.000000000 +0000
@@ -38,6 +38,8 @@
 int prof_old_multiplier[NR_CPUS] = { 1, };
 int prof_counter[NR_CPUS] = { 1, };
 
+static int enabled_via_apicbase;
+
 int get_maxlvt(void)
 {
 	unsigned int v, ver, maxlvt;
@@ -142,6 +144,13 @@
 	value = apic_read(APIC_SPIV);
 	value &= ~APIC_SPIV_APIC_ENABLED;
 	apic_write_around(APIC_SPIV, value);
+
+	if (enabled_via_apicbase) {
+		unsigned int l, h;
+		rdmsr(MSR_IA32_APICBASE, l, h);
+		l &= ~MSR_IA32_APICBASE_ENABLE;
+		wrmsr(MSR_IA32_APICBASE, l, h);
+	}
 }
 
 /*
@@ -464,7 +473,6 @@
 
 static void apic_pm_suspend(void *data)
 {
-	unsigned int l, h;
 	unsigned long flags;
 
 	if (apic_pm_state.perfctr_pmdev)
@@ -484,9 +492,6 @@
 	__save_flags(flags);
 	__cli();
 	disable_local_APIC();
-	rdmsr(MSR_IA32_APICBASE, l, h);
-	l &= ~MSR_IA32_APICBASE_ENABLE;
-	wrmsr(MSR_IA32_APICBASE, l, h);
 	__restore_flags(flags);
 }
 
@@ -593,7 +598,26 @@
  * Detect and enable local APICs on non-SMP boards.
  * Original code written by Keir Fraser.
  */
-int dont_enable_local_apic __initdata = 0;
+
+/*
+ * Knob to control our willingness to enable the local APIC.
+ */
+int enable_local_apic __initdata = 0; /* -1=force-disable, +1=force-enable */
+
+static int __init lapic_disable(char *str)
+{
+	enable_local_apic = -1;
+	clear_bit(X86_FEATURE_APIC, boot_cpu_data.x86_capability);
+	return 0;
+}
+__setup("nolapic", lapic_disable);
+
+static int __init lapic_enable(char *str)
+{
+	enable_local_apic = 1;
+	return 0;
+}
+__setup("lapic", lapic_enable);
 
 static int __init detect_init_APIC (void)
 {
@@ -601,7 +625,7 @@
 	extern void get_cpu_vendor(struct cpuinfo_x86*);
 
 	/* Disabled by DMI scan or kernel option? */
-	if (dont_enable_local_apic)
+	if (enable_local_apic < 0)
 		return -1;
 
 	/* Workaround for us being called before identify_cpu(). */
@@ -616,7 +640,7 @@
 		goto no_apic;
 	case X86_VENDOR_INTEL:
 		if (boot_cpu_data.x86 == 6 ||
-		    (boot_cpu_data.x86 == 15 && cpu_has_apic) ||
+		    (boot_cpu_data.x86 == 15 && (cpu_has_apic || enable_local_apic > 0)) ||
 		    (boot_cpu_data.x86 == 5 && cpu_has_apic))
 			break;
 		goto no_apic;
@@ -636,6 +660,7 @@
 			l &= ~MSR_IA32_APICBASE_BASE;
 			l |= MSR_IA32_APICBASE_ENABLE | APIC_DEFAULT_PHYS_BASE;
 			wrmsr(MSR_IA32_APICBASE, l, h);
+			enabled_via_apicbase = 1;
 		}
 	}
 	/*
@@ -928,14 +953,8 @@
 
 static unsigned int calibration_result;
 
-int dont_use_local_apic_timer __initdata = 0;
-
 void __init setup_APIC_clocks (void)
 {
-	/* Disabled by DMI scan or kernel option? */
-	if (dont_use_local_apic_timer)
-		return;
-
 	printk("Using local APIC timer interrupts.\n");
 	using_apic_timer = 1;
 
@@ -1152,6 +1171,9 @@
  */
 int __init APIC_init_uniprocessor (void)
 {
+	if (enable_local_apic < 0)
+		clear_bit(X86_FEATURE_APIC, boot_cpu_data.x86_capability);
+
 	if (!smp_found_config && !cpu_has_apic)
 		return -1;
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/kernel/dmi_scan.c linux-2.4.23-pre1/arch/i386/kernel/dmi_scan.c
--- linux-2.4.22/arch/i386/kernel/dmi_scan.c	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/kernel/dmi_scan.c	2003-08-27 14:40:09.000000000 +0000
@@ -335,9 +335,9 @@
 static int __init local_apic_kills_bios(struct dmi_blacklist *d)
 {
 #ifdef CONFIG_X86_LOCAL_APIC
-	extern int dont_enable_local_apic;
-	if (!dont_enable_local_apic) {
-		dont_enable_local_apic = 1;
+	extern int enable_local_apic;
+	if (enable_local_apic == 0) {
+		enable_local_apic = -1;
 		printk(KERN_WARNING "%s with broken BIOS detected. "
 		       "Refusing to enable the local APIC.\n",
 		       d->ident);
@@ -347,43 +347,6 @@
 }
 
 /*
- * The Microstar 6163-2 (a.k.a Pro) mainboard will hang shortly after
- * resumes, and also at what appears to be asynchronous APM events,
- * if the local APIC is enabled.
- */
-static int __init apm_kills_local_apic(struct dmi_blacklist *d)
-{
-#ifdef CONFIG_X86_LOCAL_APIC
-	extern int dont_enable_local_apic;
-	if (apm_info.bios.version && !dont_enable_local_apic) {
-		dont_enable_local_apic = 1;
-		printk(KERN_WARNING "%s with broken BIOS detected. "
-		       "Refusing to enable the local APIC.\n",
-		       d->ident);
-	}
-#endif
-	return 0;
-}
-
-/*
- * The Intel AL440LX mainboard will hang randomly if the local APIC
- * timer is running and the APM BIOS hasn't been disabled.
- */
-static int __init apm_kills_local_apic_timer(struct dmi_blacklist *d)
-{
-#ifdef CONFIG_X86_LOCAL_APIC
-	extern int dont_use_local_apic_timer;
-	if (apm_info.bios.version && !dont_use_local_apic_timer) {
-		dont_use_local_apic_timer = 1;
-		printk(KERN_WARNING "%s with broken BIOS detected. "
-		       "The local APIC timer will not be used.\n",
-		       d->ident);
-	}
-#endif
-	return 0;
-}
-
-/*
  *  Check for clue free BIOS implementations who use
  *  the following QA technique
  *
@@ -861,16 +824,6 @@
 			NO_MATCH, NO_MATCH
 			} },
 
-	{ apm_kills_local_apic, "Microstar 6163", {
-			MATCH(DMI_BOARD_VENDOR, "MICRO-STAR INTERNATIONAL CO., LTD"),
-			MATCH(DMI_BOARD_NAME, "MS-6163"),
-			NO_MATCH, NO_MATCH } },
-
-	{ apm_kills_local_apic_timer, "Intel AL440LX", {
-			MATCH(DMI_BOARD_VENDOR, "Intel Corporation"),
-			MATCH(DMI_BOARD_NAME, "AL440LX"),
-			NO_MATCH, NO_MATCH } },
-
 	/* Problem Intel 440GX bioses */
 
 	{ broken_pirq, "SABR1 Bios", {			/* Bad $PIR */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/kernel/head.S linux-2.4.23-pre1/arch/i386/kernel/head.S
--- linux-2.4.22/arch/i386/kernel/head.S	2003-06-13 14:51:29.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/kernel/head.S	2003-08-27 14:39:25.000000000 +0000
@@ -34,7 +34,7 @@
 #define X86_HARD_MATH	CPU_PARAMS+6
 #define X86_CPUID	CPU_PARAMS+8
 #define X86_CAPABILITY	CPU_PARAMS+12
-#define X86_VENDOR_ID	CPU_PARAMS+28
+#define X86_VENDOR_ID	CPU_PARAMS+36	/* tied to NCAPINTS in cpufeature.h */
 
 /*
  * swapper_pg_dir is the main page directory, address 0x00101000
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/kernel/io_apic.c linux-2.4.23-pre1/arch/i386/kernel/io_apic.c
--- linux-2.4.22/arch/i386/kernel/io_apic.c	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/kernel/io_apic.c	2003-08-27 14:40:04.000000000 +0000
@@ -169,6 +169,14 @@
 {
 	struct IO_APIC_route_entry entry;
 	unsigned long flags;
+	
+	/* Check delivery_mode to be sure we're not clearing an SMI pin */
+	spin_lock_irqsave(&ioapic_lock, flags);
+	*(((int*)&entry) + 0) = io_apic_read(apic, 0x10 + 2 * pin);
+	*(((int*)&entry) + 1) = io_apic_read(apic, 0x11 + 2 * pin);
+	spin_unlock_irqrestore(&ioapic_lock, flags);
+	if (entry.delivery_mode == dest_SMI)
+		return;
 
 	/*
 	 * Disable it in the IO-APIC irq-routing table:
@@ -1365,6 +1373,13 @@
 static void set_ioapic_affinity (unsigned int irq, unsigned long mask)
 {
 	unsigned long flags;
+
+	/* pick a single cpu for clustered xapics */
+	if(clustered_apic_mode == CLUSTERED_APIC_XAPIC){
+		int cpu = ffs(mask)-1;
+		mask = cpu_to_physical_apicid(cpu);
+	}
+
 	/*
 	 * Only the first 8 bits are valid.
 	 */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/kernel/mpparse.c linux-2.4.23-pre1/arch/i386/kernel/mpparse.c
--- linux-2.4.22/arch/i386/kernel/mpparse.c	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/kernel/mpparse.c	2003-08-27 14:39:59.000000000 +0000
@@ -977,7 +977,14 @@
 
 	processor.mpc_type = MP_PROCESSOR;
 	processor.mpc_apicid = id;
-	processor.mpc_apicver = 0x10; /* TBD: lapic version */
+
+	/*
+	 * mp_register_lapic_address() which is called before the
+	 * current function does the fixmap of FIX_APIC_BASE.
+	 * Read in the correct APIC version from there
+	 */
+	processor.mpc_apicver = apic_read(APIC_LVR);
+
 	processor.mpc_cpuflag = (enabled ? CPU_ENABLED : 0);
 	processor.mpc_cpuflag |= (boot_cpu ? CPU_BOOTPROCESSOR : 0);
 	processor.mpc_cpufeature = (boot_cpu_data.x86 << 8) | 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/kernel/pci-pc.c linux-2.4.23-pre1/arch/i386/kernel/pci-pc.c
--- linux-2.4.22/arch/i386/kernel/pci-pc.c	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/kernel/pci-pc.c	2003-08-27 14:40:20.000000000 +0000
@@ -1016,7 +1016,8 @@
 		"xor %%ah, %%ah\n"
 		"1:"
 		: "=a" (ret),
-		  "=b" (map)
+		  "=b" (map),
+		  "+m" (opt)
 		: "0" (PCIBIOS_GET_ROUTING_OPTIONS),
 		  "1" (0),
 		  "D" ((long) &opt),
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/kernel/process.c linux-2.4.23-pre1/arch/i386/kernel/process.c
--- linux-2.4.22/arch/i386/kernel/process.c	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/kernel/process.c	2003-08-27 14:39:11.000000000 +0000
@@ -47,6 +47,7 @@
 #ifdef CONFIG_MATH_EMULATION
 #include <asm/math_emu.h>
 #endif
+#include <asm/apic.h>
 
 #include <linux/irq.h>
 
@@ -399,6 +400,14 @@
 	 * other OSs see a clean IRQ state.
 	 */
 	smp_send_stop();
+#elif CONFIG_X86_LOCAL_APIC
+	if (cpu_has_apic) {
+		__cli();
+		disable_local_APIC();
+		__sti();
+	}
+#endif
+#ifdef CONFIG_X86_IO_APIC
 	disable_IO_APIC();
 #endif
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/kernel/setup.c linux-2.4.23-pre1/arch/i386/kernel/setup.c
--- linux-2.4.22/arch/i386/kernel/setup.c	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/kernel/setup.c	2003-08-27 14:40:29.000000000 +0000
@@ -1976,6 +1976,37 @@
 	
 #endif
 
+static void __init init_c3(struct cpuinfo_x86 *c)
+{
+	u32  lo, hi;
+
+	/* Test for Centaur Extended Feature Flags presence */
+	if (cpuid_eax(0xC0000000) >= 0xC0000001) {
+		/* store Centaur Extended Feature Flags as
+		 * word 5 of the CPU capability bit array
+		 */
+		c->x86_capability[5] = cpuid_edx(0xC0000001);
+	}
+
+	switch (c->x86_model) {
+		case 6 ... 8:		/* Cyrix III family */
+			rdmsr (MSR_VIA_FCR, lo, hi);
+			lo |= (1<<1 | 1<<7);	/* Report CX8 & enable PGE */
+			wrmsr (MSR_VIA_FCR, lo, hi);
+
+			set_bit(X86_FEATURE_CX8, c->x86_capability);
+			set_bit(X86_FEATURE_3DNOW, c->x86_capability);
+
+			/* fall through */
+
+		case 9:	/* Nehemiah */
+		default:
+			get_model_name(c);
+			display_cacheinfo(c);
+			break;
+	}
+}
+
 static void __init init_centaur(struct cpuinfo_x86 *c)
 {
 	enum {
@@ -2114,23 +2145,7 @@
 			break;
 
 		case 6:
-			switch (c->x86_model) {
-				case 6 ... 8:		/* Cyrix III family */
-					rdmsr (MSR_VIA_FCR, lo, hi);
-					lo |= (1<<1 | 1<<7);	/* Report CX8 & enable PGE */
-					wrmsr (MSR_VIA_FCR, lo, hi);
-
-					set_bit(X86_FEATURE_CX8, &c->x86_capability);
-					set_bit(X86_FEATURE_3DNOW, &c->x86_capability);
-
-					/* fall through */
-
-				case 9: /* Nehemiah */
-				default:
-					get_model_name(c);
-					display_cacheinfo(c);
-					break;
-			}
+			init_c3(c);
 			break;
 	}
 }
@@ -2765,10 +2780,16 @@
 
 		/* Intel-defined flags: level 0x00000001 */
 		if ( c->cpuid_level >= 0x00000001 ) {
-			cpuid(0x00000001, &tfms, &junk, &junk,
-			      &c->x86_capability[0]);
+			u32 capability, excap;
+			cpuid(0x00000001, &tfms, &junk, &excap, &capability);
+			c->x86_capability[0] = capability;
+			c->x86_capability[4] = excap;
 			c->x86 = (tfms >> 8) & 15;
 			c->x86_model = (tfms >> 4) & 15;
+			if (c->x86 == 0xf) {
+				c->x86 += (tfms >> 20) & 0xff;
+				c->x86_model += ((tfms >> 16) & 0xF) << 4;
+			} 
 			c->x86_mask = tfms & 15;
 		} else {
 			/* Have CPUID level 0 only - unheard of */
@@ -2972,12 +2993,12 @@
 	        "fpu", "vme", "de", "pse", "tsc", "msr", "pae", "mce",
 	        "cx8", "apic", NULL, "sep", "mtrr", "pge", "mca", "cmov",
 	        "pat", "pse36", "pn", "clflush", NULL, "dts", "acpi", "mmx",
-	        "fxsr", "sse", "sse2", "ss", "ht", "tm", "ia64", NULL,
+	        "fxsr", "sse", "sse2", "ss", "ht", "tm", "ia64", "pbe",
 
 		/* AMD-defined */
 		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
 		NULL, NULL, NULL, "syscall", NULL, NULL, NULL, NULL,
-		NULL, NULL, NULL, NULL, NULL, NULL, "mmxext", NULL,
+		NULL, NULL, NULL, "mp", NULL, NULL, "mmxext", NULL,
 		NULL, NULL, NULL, NULL, NULL, "lm", "3dnowext", "3dnow",
 
 		/* Transmeta-defined */
@@ -2987,7 +3008,20 @@
 		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
 
 		/* Other (Linux-defined) */
-		"cxmmx", "k6_mtrr", "cyrix_arr", "centaur_mcr", NULL, NULL, NULL, NULL,
+		"cxmmx", "k6_mtrr", "cyrix_arr", "centaur_mcr",
+		NULL, NULL, NULL, NULL,
+		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
+		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
+		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
+
+		/* Intel-defined (#2) */
+		"pni", NULL, NULL, "monitor", "ds_cpl", NULL, NULL, "tm2",
+		"est", NULL, "cid", NULL, NULL, NULL, NULL, NULL,
+		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
+		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
+
+		/* VIA/Cyrix/Centaur-defined */
+		NULL, NULL, "xstore", NULL, NULL, NULL, NULL, NULL,
 		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
 		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
 		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/i386/kernel/smpboot.c linux-2.4.23-pre1/arch/i386/kernel/smpboot.c
--- linux-2.4.22/arch/i386/kernel/smpboot.c	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/i386/kernel/smpboot.c	2003-08-27 14:40:29.000000000 +0000
@@ -51,7 +51,7 @@
 static int smp_b_stepping;
 
 /* Setup configured maximum number of CPUs to activate */
-static int max_cpus = -1;
+static int max_cpus = NR_CPUS;
 
 /* Total count of live CPUs */
 int smp_num_cpus = 1;
@@ -1116,7 +1116,7 @@
 
 		if (!(phys_cpu_present_map & (1ul << bit)))
 			continue;
-		if ((max_cpus >= 0) && (max_cpus <= cpucount+1))
+		if (max_cpus <= cpucount+1)
 			continue;
 
 		do_boot_cpu(apicid);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/ia64/config.in linux-2.4.23-pre1/arch/ia64/config.in
--- linux-2.4.22/arch/ia64/config.in	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/ia64/config.in	2003-08-27 14:40:34.000000000 +0000
@@ -87,6 +87,10 @@
 define_bool CONFIG_KCORE_ELF y	# On IA-64, we always want an ELF /proc/kcore.
 
 bool 'SMP support' CONFIG_SMP
+if [ "$CONFIG_SMP" = "y" ]; then
+   int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
+fi
+
 tristate 'Support running of Linux/x86 binaries' CONFIG_IA32_SUPPORT
 bool 'Performance monitor support' CONFIG_PERFMON
 tristate '/proc/pal support' CONFIG_IA64_PALINFO
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/ia64/defconfig linux-2.4.23-pre1/arch/ia64/defconfig
--- linux-2.4.22/arch/ia64/defconfig	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/ia64/defconfig	2003-08-27 14:39:25.000000000 +0000
@@ -50,6 +50,7 @@
 # CONFIG_HUGETLB_PAGE_SIZE_1MB is not set
 # CONFIG_HUGETLB_PAGE_SIZE_256KB is not set
 CONFIG_SMP=y
+CONFIG_NR_CPUS=32
 CONFIG_IA32_SUPPORT=y
 CONFIG_PERFMON=y
 CONFIG_IA64_PALINFO=y
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/mips/config-shared.in linux-2.4.23-pre1/arch/mips/config-shared.in
--- linux-2.4.22/arch/mips/config-shared.in	2003-08-25 11:44:39.000000000 +0000
+++ linux-2.4.23-pre1/arch/mips/config-shared.in	2003-08-27 14:40:35.000000000 +0000
@@ -1039,6 +1039,8 @@
 bool 'Magic SysRq key' CONFIG_MAGIC_SYSRQ
 if [ "$CONFIG_SMP" != "y" ]; then
    bool 'Run uncached' CONFIG_MIPS_UNCACHED
+else
+   int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
 fi
 endmenu
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/mips64/defconfig linux-2.4.23-pre1/arch/mips64/defconfig
--- linux-2.4.22/arch/mips64/defconfig	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/mips64/defconfig	2003-08-27 14:39:44.000000000 +0000
@@ -102,6 +102,7 @@
 # CONFIG_CPU_RM7000 is not set
 # CONFIG_CPU_SB1 is not set
 CONFIG_SMP=y
+CONFIG_NR_CPUS=32
 # CONFIG_64BIT_PHYS_ADDR is not set
 # CONFIG_CPU_ADVANCED is not set
 CONFIG_CPU_HAS_LLSC=y
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/parisc/config.in linux-2.4.23-pre1/arch/parisc/config.in
--- linux-2.4.22/arch/parisc/config.in	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/parisc/config.in	2003-08-27 14:41:56.000000000 +0000
@@ -45,6 +45,10 @@
 comment 'General options'
 
 bool 'Symmetric multi-processing support' CONFIG_SMP
+if [ "$CONFIG_SMP" = "y" ]; then
+   int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
+fi
+
 bool 'Chassis LCD and LED support' CONFIG_CHASSIS_LCD_LED
 
 bool 'Kernel Debugger support' CONFIG_KWDB
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/ppc/config.in linux-2.4.23-pre1/arch/ppc/config.in
--- linux-2.4.22/arch/ppc/config.in	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/ppc/config.in	2003-08-27 14:40:36.000000000 +0000
@@ -123,6 +123,7 @@
 bool 'Symmetric multi-processing support' CONFIG_SMP
 if [ "$CONFIG_SMP" = "y" ]; then
   bool '  Distribute interrupts on all CPUs by default' CONFIG_IRQ_ALL_CPUS
+  int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
 fi
 
 if [ "$CONFIG_6xx" = "y" -a "$CONFIG_8260" = "n" ];then
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/ppc64/config.in linux-2.4.23-pre1/arch/ppc64/config.in
--- linux-2.4.22/arch/ppc64/config.in	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/ppc64/config.in	2003-08-27 14:39:49.000000000 +0000
@@ -29,6 +29,7 @@
 bool 'Symmetric multi-processing support' CONFIG_SMP
 if [ "$CONFIG_SMP" = "y" ]; then
   bool '  Distribute interrupts on all CPUs by default' CONFIG_IRQ_ALL_CPUS
+  int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
   if [ "$CONFIG_PPC_PSERIES" = "y" ]; then
     bool '  Hardware multithreading' CONFIG_HMT
   fi
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/ppc64/defconfig linux-2.4.23-pre1/arch/ppc64/defconfig
--- linux-2.4.22/arch/ppc64/defconfig	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/ppc64/defconfig	2003-08-27 14:40:27.000000000 +0000
@@ -22,6 +22,7 @@
 CONFIG_PPC_PSERIES=y
 # CONFIG_PPC_ISERIES is not set
 CONFIG_SMP=y
+CONFIG_NR_CPUS=32
 CONFIG_IRQ_ALL_CPUS=y
 # CONFIG_HMT is not set
 # CONFIG_MSCHUNKS is not set
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/s390/config.in linux-2.4.23-pre1/arch/s390/config.in
--- linux-2.4.22/arch/s390/config.in	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/s390/config.in	2003-08-27 14:41:23.000000000 +0000
@@ -32,6 +32,9 @@
 comment 'Processor type and features'
 bool 'Symmetric multi-processing support' CONFIG_SMP
 bool 'IEEE FPU emulation' CONFIG_MATHEMU
+if [ "$CONFIG_SMP" = "y" ]; then
+   int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
+fi
 endmenu
 
 mainmenu_option next_comment
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/s390/defconfig linux-2.4.23-pre1/arch/s390/defconfig
--- linux-2.4.22/arch/s390/defconfig	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/s390/defconfig	2003-08-27 14:41:31.000000000 +0000
@@ -27,6 +27,7 @@
 #
 CONFIG_SMP=y
 CONFIG_MATHEMU=y
+CONFIG_NR_CPUS=32
 
 #
 # General setup
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/s390x/config.in linux-2.4.23-pre1/arch/s390x/config.in
--- linux-2.4.22/arch/s390x/config.in	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/s390x/config.in	2003-08-27 14:39:25.000000000 +0000
@@ -22,6 +22,9 @@
 mainmenu_option next_comment
 comment 'Processor type and features'
 bool 'Symmetric multi-processing support' CONFIG_SMP
+if [ "$CONFIG_SMP" = "y" ]; then
+   int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
+fi
 bool 'Kernel support for 31 bit emulation' CONFIG_S390_SUPPORT
 if [ "$CONFIG_S390_SUPPORT" = "y" ]; then
   tristate 'Kernel support for 31 bit ELF binaries' CONFIG_BINFMT_ELF32 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/s390x/defconfig linux-2.4.23-pre1/arch/s390x/defconfig
--- linux-2.4.22/arch/s390x/defconfig	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/s390x/defconfig	2003-08-27 14:39:12.000000000 +0000
@@ -21,6 +21,7 @@
 CONFIG_SMP=y
 CONFIG_S390_SUPPORT=y
 CONFIG_BINFMT_ELF32=y
+CONFIG_NR_CPUS=32
 
 #
 # Loadable module support
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc/config.in linux-2.4.23-pre1/arch/sparc/config.in
--- linux-2.4.22/arch/sparc/config.in	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc/config.in	2003-08-27 14:39:23.000000000 +0000
@@ -29,6 +29,10 @@
 
 bool 'Symmetric multi-processing support (does not work on sun4/sun4c)' CONFIG_SMP
 
+if [ "$CONFIG_SMP" = "y" ]; then
+   int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
+fi
+
 # Identify this as a Sparc32 build
 define_bool CONFIG_SPARC32 y
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc/mm/srmmu.c linux-2.4.23-pre1/arch/sparc/mm/srmmu.c
--- linux-2.4.22/arch/sparc/mm/srmmu.c	2003-06-13 14:51:32.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc/mm/srmmu.c	2003-08-27 14:40:39.000000000 +0000
@@ -126,6 +126,9 @@
 
 #define SRMMU_NOCACHE_BITMAP_SHIFT (PAGE_SHIFT - 4)
 
+/* The context table is a nocache user with the biggest alignment needs. */
+#define SRMMU_NOCACHE_ALIGN_MAX (sizeof(ctxd_t)*SRMMU_MAX_CONTEXTS)
+
 void *srmmu_nocache_pool;
 void *srmmu_nocache_bitmap;
 int srmmu_nocache_low;
@@ -260,6 +263,7 @@
 
 	/* we align on physical address */
 	if (align) {
+		BUG_ON(align > SRMMU_NOCACHE_ALIGN_MAX);
 		va_tmp = (SRMMU_NOCACHE_VADDR + (offset << SRMMU_NOCACHE_BITMAP_SHIFT));
 		phys_tmp = (__nocache_pa(va_tmp) + align - 1) & ~(align - 1);
 		va_tmp = (unsigned long)__nocache_va(phys_tmp);
@@ -367,7 +371,8 @@
 	unsigned long paddr, vaddr;
 	unsigned long pteval;
 
-	srmmu_nocache_pool = __alloc_bootmem(srmmu_nocache_size, PAGE_SIZE, 0UL);
+	srmmu_nocache_pool = __alloc_bootmem(srmmu_nocache_size,
+		SRMMU_NOCACHE_ALIGN_MAX, 0UL);
 	memset(srmmu_nocache_pool, 0, srmmu_nocache_size);
 
 	srmmu_nocache_bitmap = __alloc_bootmem(srmmu_nocache_bitmap_size, SMP_CACHE_BYTES, 0UL);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/config.in linux-2.4.23-pre1/arch/sparc64/config.in
--- linux-2.4.22/arch/sparc64/config.in	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/config.in	2003-08-27 14:39:57.000000000 +0000
@@ -28,6 +28,10 @@
 
 bool 'Symmetric multi-processing support' CONFIG_SMP
 
+if [ "$CONFIG_SMP" = "y" ]; then
+   int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
+fi
+
 # Identify this as a Sparc64 build
 define_bool CONFIG_SPARC64 y
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/defconfig linux-2.4.23-pre1/arch/sparc64/defconfig
--- linux-2.4.22/arch/sparc64/defconfig	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/defconfig	2003-08-27 14:40:05.000000000 +0000
@@ -58,6 +58,7 @@
 CONFIG_BINFMT_MISC=m
 # CONFIG_SUNOS_EMUL is not set
 CONFIG_SOLARIS_EMUL=m
+CONFIG_NR_CPUS=32
 
 #
 # Parallel port support
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/cpu.c linux-2.4.23-pre1/arch/sparc64/kernel/cpu.c
--- linux-2.4.22/arch/sparc64/kernel/cpu.c	2002-11-28 23:53:12.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/cpu.c	2003-08-27 14:41:34.000000000 +0000
@@ -37,6 +37,7 @@
   { 0x17, 0x13, 0, "UltraSparc IIe integrated FPU"},
   { 0x3e, 0x14, 0, "UltraSparc III integrated FPU"},
   { 0x3e, 0x15, 0, "UltraSparc III+ integrated FPU"},
+  { 0x3e, 0x16, 0, "UltraSparc IIIi integrated FPU"},
 };
 
 #define NSPARCFPU  (sizeof(linux_sparc_fpu)/sizeof(struct cpu_fp_info))
@@ -45,31 +46,25 @@
   { 0x17, 0x10, "TI UltraSparc I   (SpitFire)"},
   { 0x22, 0x10, "TI UltraSparc I   (SpitFire)"},
   { 0x17, 0x11, "TI UltraSparc II  (BlackBird)"},
-  { 0x17, 0x12, "TI UltraSparc IIi"},
-  { 0x17, 0x13, "TI UltraSparc IIe"},
+  { 0x17, 0x12, "TI UltraSparc IIi (Sabre)"},
+  { 0x17, 0x13, "TI UltraSparc IIe (Hummingbird)"},
   { 0x3e, 0x14, "TI UltraSparc III (Cheetah)"},
   { 0x3e, 0x15, "TI UltraSparc III+ (Cheetah+)"},
+  { 0x3e, 0x16, "TI UltraSparc IIIi (Jalapeno)"},
 };
 
 #define NSPARCCHIPS  (sizeof(linux_sparc_chips)/sizeof(struct cpu_iu_info))
 
-#ifdef CONFIG_SMP
-char *sparc_cpu_type[64] = { "cpu-oops", "cpu-oops1", "cpu-oops2", "cpu-oops3" };
-char *sparc_fpu_type[64] = { "fpu-oops", "fpu-oops1", "fpu-oops2", "fpu-oops3" };
-#else
-char *sparc_cpu_type[64] = { "cpu-oops", };
-char *sparc_fpu_type[64] = { "fpu-oops", };
-#endif
+char *sparc_cpu_type = "cpu-oops";
+char *sparc_fpu_type = "fpu-oops";
 
 unsigned int fsr_storage;
 
 void __init cpu_probe(void)
 {
 	unsigned long ver, fpu_vers, manuf, impl, fprs;
-	int i, cpuid;
+	int i;
 	
-	cpuid = hard_smp_processor_id();
-
 	fprs = fprs_read();
 	fprs_write(FPRS_FEF);
 	__asm__ __volatile__ ("rdpr %%ver, %0; stx %%fsr, [%1]"
@@ -86,7 +81,7 @@
 	for (i = 0; i < NSPARCCHIPS; i++) {
 		if (linux_sparc_chips[i].manuf == manuf) {
 			if (linux_sparc_chips[i].impl == impl) {
-				sparc_cpu_type[cpuid]
+				sparc_cpu_type
 					= linux_sparc_chips[i].cpu_name;
 				break;
 			}
@@ -105,14 +100,14 @@
 			printk("DEBUG: manuf[%lx] impl[%lx]\n",
 			       manuf, impl);
 		}
-		sparc_cpu_type[cpuid] = "Unknown CPU";
+		sparc_cpu_type = "Unknown CPU";
 	}
 
 	for (i = 0; i < NSPARCFPU; i++) {
 		if (linux_sparc_fpu[i].manuf == manuf &&
 		    linux_sparc_fpu[i].impl == impl) {
 			if (linux_sparc_fpu[i].fpu_vers == fpu_vers) {
-				sparc_fpu_type[cpuid]
+				sparc_fpu_type
 					= linux_sparc_fpu[i].fp_name;
 				break;
 			}
@@ -122,6 +117,6 @@
 	if (i == NSPARCFPU) {
 		printk("DEBUG: manuf[%lx] impl[%lx] fsr.vers[%lx]\n",
 		       manuf, impl, fpu_vers);
-		sparc_fpu_type[cpuid] = "Unknown FPU";
+		sparc_fpu_type = "Unknown FPU";
 	}
 }
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/entry.S linux-2.4.23-pre1/arch/sparc64/kernel/entry.S
--- linux-2.4.22/arch/sparc64/kernel/entry.S	2003-06-13 14:51:32.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/entry.S	2003-08-27 14:39:12.000000000 +0000
@@ -911,10 +911,15 @@
 	sllx		%g1, 63, %g2;					\
 	or		%g4, %g2, %g4;					\
 	/* Get log entry pointer for this cpu at this trap level. */	\
+	BRANCH_IF_JALAPENO(g2,g3,50f)					\
 	ldxa		[%g0] ASI_SAFARI_CONFIG, %g2;			\
 	srlx		%g2, 17, %g2;					\
-	and		%g2, 0x3ff, %g2;				\
-	sllx		%g2, 9, %g2;					\
+	ba,pt		%xcc, 60f; 					\
+	 and		%g2, 0x3ff, %g2;				\
+50:	ldxa		[%g0] ASI_JBUS_CONFIG, %g2;			\
+	srlx		%g2, 17, %g2;					\
+	and		%g2, 0x1f, %g2;					\
+60:	sllx		%g2, 9, %g2;					\
 	sethi		%hi(cheetah_error_log), %g3;			\
 	ldx		[%g3 + %lo(cheetah_error_log)], %g3;		\
 	brz,pn		%g3, 80f;					\
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/head.S linux-2.4.23-pre1/arch/sparc64/kernel/head.S
--- linux-2.4.22/arch/sparc64/kernel/head.S	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/head.S	2003-08-27 14:40:10.000000000 +0000
@@ -647,11 +647,18 @@
 	 nop
 
 not_starfire:
+	BRANCH_IF_JALAPENO(g1,g5,is_jalapeno)
 	BRANCH_IF_ANY_CHEETAH(g1,g5,is_cheetah)
 
 	ba,pt	%xcc, not_cheetah
 	 nop
 
+is_jalapeno:
+	ldxa		[%g0] ASI_JBUS_CONFIG, %g1
+	srlx		%g1, 17, %g1
+	ba,pt		%xcc, set_worklist
+	 and		%g1, 0x1f, %g1		! 5bit JBUS ID
+
 is_cheetah:
 	ldxa		[%g0] ASI_SAFARI_CONFIG, %g1
 	srlx		%g1, 17, %g1
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/ioctl32.c linux-2.4.23-pre1/arch/sparc64/kernel/ioctl32.c
--- linux-2.4.22/arch/sparc64/kernel/ioctl32.c	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/ioctl32.c	2003-08-27 14:41:37.000000000 +0000
@@ -1920,8 +1920,8 @@
 	    __cgc_do_ptr((void **) &cgc->sense, &cgc32->sense))
 		return -EFAULT;
 
-	if (get_user(dir, &cgc->data_direction) ||
-	    put_user(dir, &cgc32->data_direction))
+	if (get_user(dir, &cgc32->data_direction) ||
+	    put_user(dir, &cgc->data_direction))
 		return -EFAULT;
 
 	if (copy_in_user(&cgc->quiet, &cgc32->quiet,
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/irq.c linux-2.4.23-pre1/arch/sparc64/kernel/irq.c
--- linux-2.4.22/arch/sparc64/kernel/irq.c	2003-06-13 14:51:32.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/irq.c	2003-08-27 14:40:18.000000000 +0000
@@ -148,12 +148,24 @@
 		return;
 
 	if (tlb_type == cheetah || tlb_type == cheetah_plus) {
-		/* We set it to our Safari AID. */
-		__asm__ __volatile__("ldxa [%%g0] %1, %0"
-				     : "=r" (tid)
-				     : "i" (ASI_SAFARI_CONFIG));
-		tid = ((tid & (0x3ffUL<<17)) << 9);
-		tid &= IMAP_AID_SAFARI;
+		unsigned long ver;
+
+		__asm__ ("rdpr %%ver, %0" : "=r" (ver));
+		if ((ver >> 32) == 0x003e0016) {
+			/* We set it to our JBUS ID. */
+			__asm__ __volatile__("ldxa [%%g0] %1, %0"
+					     : "=r" (tid)
+					     : "i" (ASI_JBUS_CONFIG));
+			tid = ((tid & (0x1fUL<<17)) << 9);
+			tid &= IMAP_TID_JBUS;
+		} else {
+			/* We set it to our Safari AID. */
+			__asm__ __volatile__("ldxa [%%g0] %1, %0"
+					     : "=r" (tid)
+					     : "i" (ASI_SAFARI_CONFIG));
+			tid = ((tid & (0x3ffUL<<17)) << 9);
+			tid &= IMAP_AID_SAFARI;
+		}
 	} else if (this_is_starfire == 0) {
 		/* We set it to our UPA MID. */
 		__asm__ __volatile__("ldxa [%%g0] %1, %0"
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/isa.c linux-2.4.23-pre1/arch/sparc64/kernel/isa.c
--- linux-2.4.22/arch/sparc64/kernel/isa.c	2001-11-13 17:16:05.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/isa.c	2003-08-27 14:40:00.000000000 +0000
@@ -20,22 +20,23 @@
 		printk(" [%s", isa_dev->prom_name);
 }
 
-static void __init isa_dev_get_resource(struct isa_device *isa_dev)
+static void __init isa_dev_get_resource(struct isa_device *isa_dev,
+					struct linux_prom_registers *pregs,
+					int pregs_size)
 {
-	struct linux_prom_registers regs[PROMREG_MAX];
 	unsigned long base, len;
 	int prop_len;
 
 	prop_len = prom_getproperty(isa_dev->prom_node, "reg",
-				    (char *) regs, sizeof(regs));
+				    (char *) pregs, pregs_size);
 
 	if (prop_len <= 0)
 		return;
 
 	/* Only the first one is interesting. */
-	len = regs[0].reg_size;
-	base = (((unsigned long)regs[0].which_io << 32) |
-		(unsigned long)regs[0].phys_addr);
+	len = pregs[0].reg_size;
+	base = (((unsigned long)pregs[0].which_io << 32) |
+		(unsigned long)pregs[0].phys_addr);
 	base += isa_dev->bus->parent->io_space.start;
 
 	isa_dev->resource.start = base;
@@ -53,6 +54,9 @@
  *
  * The P1275 standard for ISA devices seems to also have been
  * totally ignored.
+ *
+ * On later systems, an interrupt-map and interrupt-map-mask scheme
+ * akin to EBUS is used.
  */
 static struct {
 	int	obp_irq;
@@ -67,33 +71,72 @@
 	{ 0, 0x00 }	/* end of table */
 };
 
-static void __init isa_dev_get_irq(struct isa_device *isa_dev)
+static int __init isa_dev_get_irq_using_imap(struct isa_device *isa_dev,
+					     struct isa_bridge *isa_br,
+					     int *interrupt,
+					     struct linux_prom_registers *pregs)
+{
+	unsigned int hi, lo, irq;
+	int i;
+
+	hi = pregs->which_io & isa_br->isa_intmask.phys_hi;
+	lo = pregs->phys_addr & isa_br->isa_intmask.phys_lo;
+	irq = *interrupt & isa_br->isa_intmask.interrupt;
+	for (i = 0; i < isa_br->num_isa_intmap; i++) {
+		if ((isa_br->isa_intmap[i].phys_hi == hi) &&
+		    (isa_br->isa_intmap[i].phys_lo == lo) &&
+		    (isa_br->isa_intmap[i].interrupt == irq)) {
+			*interrupt = isa_br->isa_intmap[i].cinterrupt;
+			return 0;
+		}
+	}
+	return -1;
+}
+
+static void __init isa_dev_get_irq(struct isa_device *isa_dev,
+				   struct linux_prom_registers *pregs)
 {
 	int irq_prop;
 
 	irq_prop = prom_getintdefault(isa_dev->prom_node,
 				      "interrupts", -1);
 	if (irq_prop <= 0) {
-		isa_dev->irq = PCI_IRQ_NONE;
+		goto no_irq;
 	} else {
+		struct pci_controller_info *pcic;
+		struct pci_pbm_info *pbm;
 		int i;
 
+		if (isa_dev->bus->num_isa_intmap) {
+			if (!isa_dev_get_irq_using_imap(isa_dev,
+							isa_dev->bus,
+							&irq_prop,
+							pregs))
+				goto route_irq;
+		}
+
 		for (i = 0; grover_irq_table[i].obp_irq != 0; i++) {
 			if (grover_irq_table[i].obp_irq == irq_prop) {
-				struct pci_controller_info *pcic;
-				struct pci_pbm_info *pbm;
 				int ino = grover_irq_table[i].pci_ino;
 
-				if (ino == 0) {
-					isa_dev->irq = PCI_IRQ_NONE;
-				} else {
-					pbm = isa_dev->bus->parent;
-					pcic = pbm->parent;
-					isa_dev->irq = pcic->irq_build(pbm, NULL, ino);
-				}
+				if (ino == 0)
+					goto no_irq;
+
+				irq_prop = ino;
+				goto route_irq;
 			}
 		}
+		goto no_irq;
+
+route_irq:
+		pbm = isa_dev->bus->parent;
+		pcic = pbm->parent;
+		isa_dev->irq = pcic->irq_build(pbm, NULL, irq_prop);
+		return;
 	}
+
+no_irq:
+	isa_dev->irq = PCI_IRQ_NONE;
 }
 
 static void __init isa_fill_children(struct isa_device *parent_isa_dev)
@@ -105,6 +148,7 @@
 
 	printk(" ->");
 	while (node != 0) {
+		struct linux_prom_registers regs[PROMREG_MAX];
 		struct isa_device *isa_dev;
 		int prop_len;
 
@@ -138,8 +182,8 @@
 		if (prop_len <= 0)
 			isa_dev->compatible[0] = '\0';
 
-		isa_dev_get_resource(isa_dev);
-		isa_dev_get_irq(isa_dev);
+		isa_dev_get_resource(isa_dev, regs, sizeof(regs));
+		isa_dev_get_irq(isa_dev, regs);
 
 		report_dev(isa_dev, 1);
 
@@ -152,6 +196,7 @@
 	int node = prom_getchild(isa_br->prom_node);
 
 	while (node != 0) {
+		struct linux_prom_registers regs[PROMREG_MAX];
 		struct isa_device *isa_dev;
 		int prop_len;
 
@@ -194,8 +239,8 @@
 		if (prop_len <= 0)
 			isa_dev->compatible[0] = '\0';
 
-		isa_dev_get_resource(isa_dev);
-		isa_dev_get_irq(isa_dev);
+		isa_dev_get_resource(isa_dev, regs, sizeof(regs));
+		isa_dev_get_irq(isa_dev, regs);
 
 		report_dev(isa_dev, 0);
 
@@ -260,6 +305,21 @@
 			isa_br->num_isa_ranges =
 				(prop_len / sizeof(struct linux_prom_isa_ranges));
 
+		prop_len = prom_getproperty(isa_br->prom_node,
+					    "interrupt-map",
+					    (char *) isa_br->isa_intmap,
+					    sizeof(isa_br->isa_intmap));
+		if (prop_len <= 0)
+			isa_br->num_isa_intmap = 0;
+		else
+			isa_br->num_isa_intmap =
+				(prop_len / sizeof(struct linux_prom_isa_intmap));
+
+		prop_len = prom_getproperty(isa_br->prom_node,
+					    "interrupt-map-mask",
+					    (char *) &(isa_br->isa_intmask),
+					    sizeof(isa_br->isa_intmask));
+
 		printk("isa%d:", isa_br->index);
 
 		isa_fill_devices(isa_br);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/pci.c linux-2.4.23-pre1/arch/sparc64/kernel/pci.c
--- linux-2.4.22/arch/sparc64/kernel/pci.c	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/pci.c	2003-08-27 14:39:12.000000000 +0000
@@ -81,6 +81,8 @@
 extern void sabre_init(int, char *);
 extern void psycho_init(int, char *);
 extern void schizo_init(int, char *);
+extern void schizo_plus_init(int, char *);
+extern void tomatillo_init(int, char *);
 
 static struct {
 	char *model_name;
@@ -92,7 +94,11 @@
 	{ "SUNW,psycho", psycho_init },
 	{ "pci108e,8000", psycho_init },
 	{ "SUNW,schizo", schizo_init },
-	{ "pci108e,8001", schizo_init }
+	{ "pci108e,8001", schizo_init },
+	{ "SUNW,schizo+", schizo_plus_init },
+	{ "pci108e,8002", schizo_plus_init },
+	{ "SUNW,tomatillo", tomatillo_init },
+	{ "pci108e,a801", tomatillo_init },
 };
 #define PCI_NUM_CONTROLLER_TYPES (sizeof(pci_controller_table) / \
 				  sizeof(pci_controller_table[0]))
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/pci_common.c linux-2.4.23-pre1/arch/sparc64/kernel/pci_common.c
--- linux-2.4.22/arch/sparc64/kernel/pci_common.c	2002-08-03 00:39:43.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/pci_common.c	2003-08-27 14:39:50.000000000 +0000
@@ -54,6 +54,7 @@
 	    (pdev->vendor == PCI_VENDOR_ID_SUN) &&
 	    (pdev->device == PCI_DEVICE_ID_SUN_PBM ||
 	     pdev->device == PCI_DEVICE_ID_SUN_SCHIZO ||
+	     pdev->device == PCI_DEVICE_ID_SUN_TOMATILLO ||
 	     pdev->device == PCI_DEVICE_ID_SUN_SABRE ||
 	     pdev->device == PCI_DEVICE_ID_SUN_HUMMINGBIRD)) {
 		*nregs = 0;
@@ -699,7 +700,7 @@
 	struct pcidev_cookie *pcp = pdev->sysdata;
 	struct pci_pbm_info *pbm = pcp->pbm;
 	struct pci_controller_info *p = pbm->parent;
-	unsigned int portid = p->portid;
+	unsigned int portid = pbm->portid;
 	unsigned int prom_irq;
 	int prom_node = pcp->prom_node;
 	int err;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/pci_iommu.c linux-2.4.23-pre1/arch/sparc64/kernel/pci_iommu.c
--- linux-2.4.22/arch/sparc64/kernel/pci_iommu.c	2003-06-13 14:51:32.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/pci_iommu.c	2003-08-27 14:39:35.000000000 +0000
@@ -829,5 +829,8 @@
 		}
 	}
 
+	if (device_mask >= (1UL << 32UL))
+		return 0;
+
 	return (device_mask & dma_addr_mask) == dma_addr_mask;
 }
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/pci_psycho.c linux-2.4.23-pre1/arch/sparc64/kernel/pci_psycho.c
--- linux-2.4.22/arch/sparc64/kernel/pci_psycho.c	2002-08-03 00:39:43.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/pci_psycho.c	2003-08-27 14:40:39.000000000 +0000
@@ -388,7 +388,6 @@
 					    struct pci_dev *pdev,
 					    unsigned int ino)
 {
-	struct pci_controller_info *p = pbm->parent;
 	struct ino_bucket *bucket;
 	unsigned long imap, iclr;
 	unsigned long imap_off, iclr_off;
@@ -413,11 +412,11 @@
 	if (PIL_RESERVED(pil))
 		BUG();
 
-	imap = p->controller_regs + imap_off;
+	imap = pbm->controller_regs + imap_off;
 	imap += 4;
 
 	iclr_off = psycho_iclr_offset(ino);
-	iclr = p->controller_regs + iclr_off;
+	iclr = pbm->controller_regs + iclr_off;
 	iclr += 4;
 
 	if ((ino & 0x20) == 0)
@@ -484,7 +483,7 @@
 				   int is_pbm_a)
 {
 	struct pci_strbuf *strbuf = &pbm->stc;
-	unsigned long regbase = p->controller_regs;
+	unsigned long regbase = p->pbm_A.controller_regs;
 	unsigned long err_base, tag_base, line_base;
 	u64 control;
 	int i;
@@ -679,7 +678,7 @@
 		psycho_write(iommu->iommu_control,
 			     control | PSYCHO_IOMMU_CTRL_DENAB);
 		for (i = 0; i < 16; i++) {
-			unsigned long base = p->controller_regs;
+			unsigned long base = p->pbm_A.controller_regs;
 
 			iommu_tag[i] =
 				psycho_read(base + PSYCHO_IOMMU_TAG + (i * 8UL));
@@ -756,8 +755,8 @@
 static void psycho_ue_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
 	struct pci_controller_info *p = dev_id;
-	unsigned long afsr_reg = p->controller_regs + PSYCHO_UE_AFSR;
-	unsigned long afar_reg = p->controller_regs + PSYCHO_UE_AFAR;
+	unsigned long afsr_reg = p->pbm_A.controller_regs + PSYCHO_UE_AFSR;
+	unsigned long afar_reg = p->pbm_A.controller_regs + PSYCHO_UE_AFAR;
 	unsigned long afsr, afar, error_bits;
 	int reported;
 
@@ -831,8 +830,8 @@
 static void psycho_ce_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
 	struct pci_controller_info *p = dev_id;
-	unsigned long afsr_reg = p->controller_regs + PSYCHO_CE_AFSR;
-	unsigned long afar_reg = p->controller_regs + PSYCHO_CE_AFAR;
+	unsigned long afsr_reg = p->pbm_A.controller_regs + PSYCHO_CE_AFSR;
+	unsigned long afar_reg = p->pbm_A.controller_regs + PSYCHO_CE_AFAR;
 	unsigned long afsr, afar, error_bits;
 	int reported;
 
@@ -911,6 +910,42 @@
 #define PSYCHO_PCI_AFAR_A	0x2018UL
 #define PSYCHO_PCI_AFAR_B	0x4018UL
 
+static void psycho_pcierr_intr_other(struct pci_pbm_info *pbm, int is_pbm_a)
+{
+	unsigned long csr_reg, csr, csr_error_bits;
+	u16 stat;
+
+	if (is_pbm_a) {
+		csr_reg = pbm->controller_regs + PSYCHO_PCIA_CTRL;
+	} else {
+		csr_reg = pbm->controller_regs + PSYCHO_PCIB_CTRL;
+	}
+	csr = psycho_read(csr_reg);
+	csr_error_bits =
+		csr & (PSYCHO_PCICTRL_SBH_ERR | PSYCHO_PCICTRL_SERR);
+	if (csr_error_bits) {
+		/* Clear the errors.  */
+		psycho_write(csr_reg, csr);
+
+		/* Log 'em.  */
+		if (csr_error_bits & PSYCHO_PCICTRL_SBH_ERR)
+			printk("%s: PCI streaming byte hole error asserted.\n",
+			       pbm->name);
+		if (csr_error_bits & PSYCHO_PCICTRL_SERR)
+			printk("%s: PCI SERR signal asserted.\n", pbm->name);
+	}
+	pci_read_config_word(pbm->pci_bus->self, PCI_STATUS, &stat);
+	if (stat & (PCI_STATUS_PARITY |
+		    PCI_STATUS_SIG_TARGET_ABORT |
+		    PCI_STATUS_REC_TARGET_ABORT |
+		    PCI_STATUS_REC_MASTER_ABORT |
+		    PCI_STATUS_SIG_SYSTEM_ERROR)) {
+		printk("%s: PCI bus error, PCI_STATUS[%04x]\n",
+		       pbm->name, stat);
+		pci_write_config_word(pbm->pci_bus->self, PCI_STATUS, 0xffff);
+	}
+}
+
 static void psycho_pcierr_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
 	struct pci_pbm_info *pbm = dev_id;
@@ -921,11 +956,11 @@
 
 	is_pbm_a = (pbm == &pbm->parent->pbm_A);
 	if (is_pbm_a) {
-		afsr_reg = p->controller_regs + PSYCHO_PCI_AFSR_A;
-		afar_reg = p->controller_regs + PSYCHO_PCI_AFAR_A;
+		afsr_reg = p->pbm_A.controller_regs + PSYCHO_PCI_AFSR_A;
+		afar_reg = p->pbm_A.controller_regs + PSYCHO_PCI_AFAR_A;
 	} else {
-		afsr_reg = p->controller_regs + PSYCHO_PCI_AFSR_B;
-		afar_reg = p->controller_regs + PSYCHO_PCI_AFAR_B;
+		afsr_reg = p->pbm_A.controller_regs + PSYCHO_PCI_AFSR_B;
+		afar_reg = p->pbm_A.controller_regs + PSYCHO_PCI_AFAR_B;
 	}
 
 	/* Latch error status. */
@@ -939,7 +974,7 @@
 		 PSYCHO_PCIAFSR_SMA | PSYCHO_PCIAFSR_STA |
 		 PSYCHO_PCIAFSR_SRTRY | PSYCHO_PCIAFSR_SPERR);
 	if (!error_bits)
-		return;
+		return psycho_pcierr_intr_other(pbm, is_pbm_a);
 	psycho_write(afsr_reg, error_bits);
 
 	/* Log the error. */
@@ -1022,8 +1057,8 @@
 static void __init psycho_register_error_handlers(struct pci_controller_info *p)
 {
 	struct pci_pbm_info *pbm = &p->pbm_A; /* arbitrary */
-	unsigned long base = p->controller_regs;
-	unsigned int irq, portid = p->portid;
+	unsigned long base = p->pbm_A.controller_regs;
+	unsigned int irq, portid = pbm->portid;
 	u64 tmp;
 
 	/* Build IRQs and register handlers. */
@@ -1043,6 +1078,7 @@
 		prom_halt();
 	}
 
+	pbm = &p->pbm_A;
 	irq = psycho_irq_build(pbm, NULL, (portid << 6) | PSYCHO_PCIERR_A_INO);
 	if (request_irq(irq, psycho_pcierr_intr,
 			SA_SHIRQ, "PSYCHO PCIERR", &p->pbm_A) < 0) {
@@ -1051,6 +1087,7 @@
 		prom_halt();
 	}
 
+	pbm = &p->pbm_B;
 	irq = psycho_irq_build(pbm, NULL, (portid << 6) | PSYCHO_PCIERR_B_INO);
 	if (request_irq(irq, psycho_pcierr_intr,
 			SA_SHIRQ, "PSYCHO PCIERR", &p->pbm_B) < 0) {
@@ -1310,26 +1347,26 @@
 	iommu->iommu_cur_ctx = 0;
 
 	/* Register addresses. */
-	iommu->iommu_control  = p->controller_regs + PSYCHO_IOMMU_CONTROL;
-	iommu->iommu_tsbbase  = p->controller_regs + PSYCHO_IOMMU_TSBBASE;
-	iommu->iommu_flush    = p->controller_regs + PSYCHO_IOMMU_FLUSH;
+	iommu->iommu_control  = p->pbm_A.controller_regs + PSYCHO_IOMMU_CONTROL;
+	iommu->iommu_tsbbase  = p->pbm_A.controller_regs + PSYCHO_IOMMU_TSBBASE;
+	iommu->iommu_flush    = p->pbm_A.controller_regs + PSYCHO_IOMMU_FLUSH;
 	/* PSYCHO's IOMMU lacks ctx flushing. */
 	iommu->iommu_ctxflush = 0;
 
 	/* We use the main control register of PSYCHO as the write
 	 * completion register.
 	 */
-	iommu->write_complete_reg = p->controller_regs + PSYCHO_CONTROL;
+	iommu->write_complete_reg = p->pbm_A.controller_regs + PSYCHO_CONTROL;
 
 	/*
 	 * Invalidate TLB Entries.
 	 */
-	control = psycho_read(p->controller_regs + PSYCHO_IOMMU_CONTROL);
+	control = psycho_read(p->pbm_A.controller_regs + PSYCHO_IOMMU_CONTROL);
 	control |= PSYCHO_IOMMU_CTRL_DENAB;
-	psycho_write(p->controller_regs + PSYCHO_IOMMU_CONTROL, control);
+	psycho_write(p->pbm_A.controller_regs + PSYCHO_IOMMU_CONTROL, control);
 	for(i = 0; i < 16; i++) {
-		psycho_write(p->controller_regs + PSYCHO_IOMMU_TAG + (i * 8UL), 0);
-		psycho_write(p->controller_regs + PSYCHO_IOMMU_DATA + (i * 8UL), 0);
+		psycho_write(p->pbm_A.controller_regs + PSYCHO_IOMMU_TAG + (i * 8UL), 0);
+		psycho_write(p->pbm_A.controller_regs + PSYCHO_IOMMU_DATA + (i * 8UL), 0);
 	}
 
 	/* Leave diag mode enabled for full-flushing done
@@ -1360,16 +1397,16 @@
 		iommu->alloc_info[i].next = 0;
 	}
 
-	psycho_write(p->controller_regs + PSYCHO_IOMMU_TSBBASE, __pa(tsbbase));
+	psycho_write(p->pbm_A.controller_regs + PSYCHO_IOMMU_TSBBASE, __pa(tsbbase));
 
-	control = psycho_read(p->controller_regs + PSYCHO_IOMMU_CONTROL);
+	control = psycho_read(p->pbm_A.controller_regs + PSYCHO_IOMMU_CONTROL);
 	control &= ~(PSYCHO_IOMMU_CTRL_TSBSZ | PSYCHO_IOMMU_CTRL_TBWSZ);
 	control |= (PSYCHO_IOMMU_TSBSZ_128K | PSYCHO_IOMMU_CTRL_ENAB);
-	psycho_write(p->controller_regs + PSYCHO_IOMMU_CONTROL, control);
+	psycho_write(p->pbm_A.controller_regs + PSYCHO_IOMMU_CONTROL, control);
 
 	/* If necessary, hook us up for starfire IRQ translations. */
 	if(this_is_starfire)
-		p->starfire_cookie = starfire_hookup(p->portid);
+		p->starfire_cookie = starfire_hookup(p->pbm_A.portid);
 	else
 		p->starfire_cookie = NULL;
 }
@@ -1391,28 +1428,28 @@
 	u64 tmp;
 
 	/* PROM sets the IRQ retry value too low, increase it. */
-	psycho_write(p->controller_regs + PSYCHO_IRQ_RETRY, 0xff);
+	psycho_write(p->pbm_A.controller_regs + PSYCHO_IRQ_RETRY, 0xff);
 
 	/* Enable arbiter for all PCI slots. */
-	tmp = psycho_read(p->controller_regs + PSYCHO_PCIA_CTRL);
+	tmp = psycho_read(p->pbm_A.controller_regs + PSYCHO_PCIA_CTRL);
 	tmp |= PSYCHO_PCICTRL_AEN;
-	psycho_write(p->controller_regs + PSYCHO_PCIA_CTRL, tmp);
+	psycho_write(p->pbm_A.controller_regs + PSYCHO_PCIA_CTRL, tmp);
 
-	tmp = psycho_read(p->controller_regs + PSYCHO_PCIB_CTRL);
+	tmp = psycho_read(p->pbm_A.controller_regs + PSYCHO_PCIB_CTRL);
 	tmp |= PSYCHO_PCICTRL_AEN;
-	psycho_write(p->controller_regs + PSYCHO_PCIB_CTRL, tmp);
+	psycho_write(p->pbm_A.controller_regs + PSYCHO_PCIB_CTRL, tmp);
 
 	/* Disable DMA write / PIO read synchronization on
 	 * both PCI bus segments.
 	 * [ U2P Erratum 1243770, STP2223BGA data sheet ]
 	 */
-	tmp = psycho_read(p->controller_regs + PSYCHO_PCIA_DIAG);
+	tmp = psycho_read(p->pbm_A.controller_regs + PSYCHO_PCIA_DIAG);
 	tmp |= PSYCHO_PCIDIAG_DDWSYNC;
-	psycho_write(p->controller_regs + PSYCHO_PCIA_DIAG, tmp);
+	psycho_write(p->pbm_A.controller_regs + PSYCHO_PCIA_DIAG, tmp);
 
-	tmp = psycho_read(p->controller_regs + PSYCHO_PCIB_DIAG);
+	tmp = psycho_read(p->pbm_A.controller_regs + PSYCHO_PCIB_DIAG);
 	tmp |= PSYCHO_PCIDIAG_DDWSYNC;
-	psycho_write(p->controller_regs + PSYCHO_PCIB_DIAG, tmp);
+	psycho_write(p->pbm_A.controller_regs + PSYCHO_PCIB_DIAG, tmp);
 }
 
 static void __init pbm_register_toplevel_resources(struct pci_controller_info *p,
@@ -1435,7 +1472,7 @@
 				   struct pci_pbm_info *pbm,
 				   int is_pbm_a)
 {
-	unsigned long base = p->controller_regs;
+	unsigned long base = pbm->controller_regs;
 	u64 control;
 
 	if (is_pbm_a) {
@@ -1500,14 +1537,21 @@
 	if (is_pbm_a) {
 		pbm = &p->pbm_A;
 		pbm->pci_first_slot = 1;
-		pbm->io_space.start = p->controller_regs + PSYCHO_IOSPACE_A;
-		pbm->mem_space.start = p->controller_regs + PSYCHO_MEMSPACE_A;
+		pbm->io_space.start = pbm->controller_regs + PSYCHO_IOSPACE_A;
+		pbm->mem_space.start = pbm->controller_regs + PSYCHO_MEMSPACE_A;
 	} else {
 		pbm = &p->pbm_B;
 		pbm->pci_first_slot = 2;
-		pbm->io_space.start = p->controller_regs + PSYCHO_IOSPACE_B;
-		pbm->mem_space.start = p->controller_regs + PSYCHO_MEMSPACE_B;
+		pbm->io_space.start = pbm->controller_regs + PSYCHO_IOSPACE_B;
+		pbm->mem_space.start = pbm->controller_regs + PSYCHO_MEMSPACE_B;
 	}
+
+	pbm->chip_type = PBM_CHIP_TYPE_PSYCHO;
+	pbm->chip_version =
+		prom_getintdefault(prom_node, "version#", 0);
+	pbm->chip_revision =
+		prom_getintdefault(prom_node, "module-revision#", 0);
+
 	pbm->io_space.end = pbm->io_space.start + PSYCHO_IOSPACE_SIZE;
 	pbm->io_space.flags = IORESOURCE_IO;
 	pbm->mem_space.end = pbm->mem_space.start + PSYCHO_MEMSPACE_SIZE;
@@ -1575,7 +1619,7 @@
 
 	spin_lock_irqsave(&pci_controller_lock, flags);
 	for(p = pci_controller_root; p; p = p->next) {
-		if (p->portid == upa_portid) {
+		if (p->pbm_A.portid == upa_portid) {
 			spin_unlock_irqrestore(&pci_controller_lock, flags);
 			is_pbm_a = (p->pbm_A.prom_node == 0);
 			psycho_pbm_init(p, node, is_pbm_a);
@@ -1603,7 +1647,8 @@
 	pci_controller_root = p;
 	spin_unlock_irqrestore(&pci_controller_lock, flags);
 
-	p->portid = upa_portid;
+	p->pbm_A.portid = upa_portid;
+	p->pbm_B.portid = upa_portid;
 	p->index = pci_num_controllers++;
 	p->pbms_same_domain = 0;
 	p->scan_bus = psycho_scan_bus;
@@ -1620,9 +1665,10 @@
 		prom_halt();
 	}
 
-	p->controller_regs = pr_regs[2].phys_addr;
+	p->pbm_A.controller_regs = pr_regs[2].phys_addr;
+	p->pbm_B.controller_regs = pr_regs[2].phys_addr;
 	printk("PCI: Found PSYCHO, control regs at %016lx\n",
-	       p->controller_regs);
+	       p->pbm_A.controller_regs);
 
 	p->pbm_A.config_space = p->pbm_B.config_space =
 		(pr_regs[2].phys_addr + PSYCHO_CONFIGSPACE);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/pci_sabre.c linux-2.4.23-pre1/arch/sparc64/kernel/pci_sabre.c
--- linux-2.4.22/arch/sparc64/kernel/pci_sabre.c	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/pci_sabre.c	2003-08-27 14:40:25.000000000 +0000
@@ -219,6 +219,7 @@
 	 ((unsigned long)(REG)))
 
 static int hummingbird_p;
+static struct pci_bus *sabre_root_bus;
 
 static void *sabre_pci_config_mkaddr(struct pci_pbm_info *pbm,
 				     unsigned char bus,
@@ -630,7 +631,6 @@
 					   struct pci_dev *pdev,
 					   unsigned int ino)
 {
-	struct pci_controller_info *p = pbm->parent;
 	struct ino_bucket *bucket;
 	unsigned long imap, iclr;
 	unsigned long imap_off, iclr_off;
@@ -655,11 +655,11 @@
 	if (PIL_RESERVED(pil))
 		BUG();
 
-	imap = p->controller_regs + imap_off;
+	imap = pbm->controller_regs + imap_off;
 	imap += 4;
 
 	iclr_off = sabre_iclr_offset(ino);
-	iclr = p->controller_regs + iclr_off;
+	iclr = pbm->controller_regs + iclr_off;
 	iclr += 4;
 
 	if ((ino & 0x20) == 0)
@@ -737,7 +737,7 @@
 		sabre_write(iommu->iommu_control,
 			    (control | SABRE_IOMMUCTRL_DENAB));
 		for (i = 0; i < 16; i++) {
-			unsigned long base = p->controller_regs;
+			unsigned long base = p->pbm_A.controller_regs;
 
 			iommu_tag[i] =
 				sabre_read(base + SABRE_IOMMU_TAG + (i * 8UL));
@@ -786,8 +786,8 @@
 static void sabre_ue_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
 	struct pci_controller_info *p = dev_id;
-	unsigned long afsr_reg = p->controller_regs + SABRE_UE_AFSR;
-	unsigned long afar_reg = p->controller_regs + SABRE_UECE_AFAR;
+	unsigned long afsr_reg = p->pbm_A.controller_regs + SABRE_UE_AFSR;
+	unsigned long afar_reg = p->pbm_A.controller_regs + SABRE_UECE_AFAR;
 	unsigned long afsr, afar, error_bits;
 	int reported;
 
@@ -844,8 +844,8 @@
 static void sabre_ce_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
 	struct pci_controller_info *p = dev_id;
-	unsigned long afsr_reg = p->controller_regs + SABRE_CE_AFSR;
-	unsigned long afar_reg = p->controller_regs + SABRE_UECE_AFAR;
+	unsigned long afsr_reg = p->pbm_A.controller_regs + SABRE_CE_AFSR;
+	unsigned long afar_reg = p->pbm_A.controller_regs + SABRE_UECE_AFAR;
 	unsigned long afsr, afar, error_bits;
 	int reported;
 
@@ -895,6 +895,38 @@
 	printk("]\n");
 }
 
+static void sabre_pcierr_intr_other(struct pci_controller_info *p)
+{
+	unsigned long csr_reg, csr, csr_error_bits;
+	u16 stat;
+
+	csr_reg = p->pbm_A.controller_regs + SABRE_PCICTRL;
+	csr = sabre_read(csr_reg);
+	csr_error_bits =
+		csr & SABRE_PCICTRL_SERR;
+	if (csr_error_bits) {
+		/* Clear the errors.  */
+		sabre_write(csr_reg, csr);
+
+		/* Log 'em.  */
+		if (csr_error_bits & SABRE_PCICTRL_SERR)
+			printk("SABRE%d: PCI SERR signal asserted.\n",
+			       p->index);
+	}
+	pci_read_config_word(sabre_root_bus->self,
+			     PCI_STATUS, &stat);
+	if (stat & (PCI_STATUS_PARITY |
+		    PCI_STATUS_SIG_TARGET_ABORT |
+		    PCI_STATUS_REC_TARGET_ABORT |
+		    PCI_STATUS_REC_MASTER_ABORT |
+		    PCI_STATUS_SIG_SYSTEM_ERROR)) {
+		printk("SABRE%d: PCI bus error, PCI_STATUS[%04x]\n",
+		       p->index, stat);
+		pci_write_config_word(sabre_root_bus->self,
+				      PCI_STATUS, 0xffff);
+	}
+}
+
 static void sabre_pcierr_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
 	struct pci_controller_info *p = dev_id;
@@ -902,8 +934,8 @@
 	unsigned long afsr, afar, error_bits;
 	int reported;
 
-	afsr_reg = p->controller_regs + SABRE_PIOAFSR;
-	afar_reg = p->controller_regs + SABRE_PIOAFAR;
+	afsr_reg = p->pbm_A.controller_regs + SABRE_PIOAFSR;
+	afar_reg = p->pbm_A.controller_regs + SABRE_PIOAFAR;
 
 	/* Latch error status. */
 	afar = sabre_read(afar_reg);
@@ -916,7 +948,7 @@
 		 SABRE_PIOAFSR_SMA | SABRE_PIOAFSR_STA |
 		 SABRE_PIOAFSR_SRTRY | SABRE_PIOAFSR_SPERR);
 	if (!error_bits)
-		return;
+		return sabre_pcierr_intr_other(p);
 	sabre_write(afsr_reg, error_bits);
 
 	/* Log the error. */
@@ -995,8 +1027,8 @@
 static void __init sabre_register_error_handlers(struct pci_controller_info *p)
 {
 	struct pci_pbm_info *pbm = &p->pbm_A; /* arbitrary */
-	unsigned long base = p->controller_regs;
-	unsigned long irq, portid = p->portid;
+	unsigned long base = pbm->controller_regs;
+	unsigned long irq, portid = pbm->portid;
 	u64 tmp;
 
 	/* We clear the error bits in the appropriate AFSR before
@@ -1044,13 +1076,12 @@
 					 struct resource *root)
 {
 	struct pci_pbm_info *pbm = pci_bus2pbm[pdev->bus->number];
-	struct pci_controller_info *p = pbm->parent;
 	unsigned long base;
 
 	if (res->flags & IORESOURCE_IO)
-		base = p->controller_regs + SABRE_IOSPACE;
+		base = pbm->controller_regs + SABRE_IOSPACE;
 	else
-		base = p->controller_regs + SABRE_MEMSPACE;
+		base = pbm->controller_regs + SABRE_MEMSPACE;
 
 	res->start += base;
 	res->end += base;
@@ -1060,7 +1091,6 @@
 {
 	struct pcidev_cookie *pcp = pdev->sysdata;
 	struct pci_pbm_info *pbm = pcp->pbm;
-	struct pci_controller_info *p = pbm->parent;
 	struct resource *res;
 	unsigned long base;
 	u32 reg;
@@ -1078,9 +1108,9 @@
 
 	is_64bit = 0;
 	if (res->flags & IORESOURCE_IO)
-		base = p->controller_regs + SABRE_IOSPACE;
+		base = pbm->controller_regs + SABRE_IOSPACE;
 	else {
-		base = p->controller_regs + SABRE_MEMSPACE;
+		base = pbm->controller_regs + SABRE_MEMSPACE;
 		if ((res->flags & PCI_BASE_ADDRESS_MEM_TYPE_MASK)
 		    == PCI_BASE_ADDRESS_MEM_TYPE_64)
 			is_64bit = 1;
@@ -1197,6 +1227,8 @@
 	pci_fixup_host_bridge_self(sabre_bus);
 	sabre_bus->self->sysdata = cookie;
 
+	sabre_root_bus = sabre_bus;
+
 	apb_init(p, sabre_bus);
 
 	sabres_scanned = 0;
@@ -1256,21 +1288,21 @@
 	iommu->iommu_cur_ctx = 0;
 
 	/* Register addresses. */
-	iommu->iommu_control  = p->controller_regs + SABRE_IOMMU_CONTROL;
-	iommu->iommu_tsbbase  = p->controller_regs + SABRE_IOMMU_TSBBASE;
-	iommu->iommu_flush    = p->controller_regs + SABRE_IOMMU_FLUSH;
-	iommu->write_complete_reg = p->controller_regs + SABRE_WRSYNC;
+	iommu->iommu_control  = p->pbm_A.controller_regs + SABRE_IOMMU_CONTROL;
+	iommu->iommu_tsbbase  = p->pbm_A.controller_regs + SABRE_IOMMU_TSBBASE;
+	iommu->iommu_flush    = p->pbm_A.controller_regs + SABRE_IOMMU_FLUSH;
+	iommu->write_complete_reg = p->pbm_A.controller_regs + SABRE_WRSYNC;
 	/* Sabre's IOMMU lacks ctx flushing. */
 	iommu->iommu_ctxflush = 0;
                                         
 	/* Invalidate TLB Entries. */
-	control = sabre_read(p->controller_regs + SABRE_IOMMU_CONTROL);
+	control = sabre_read(p->pbm_A.controller_regs + SABRE_IOMMU_CONTROL);
 	control |= SABRE_IOMMUCTRL_DENAB;
-	sabre_write(p->controller_regs + SABRE_IOMMU_CONTROL, control);
+	sabre_write(p->pbm_A.controller_regs + SABRE_IOMMU_CONTROL, control);
 
 	for(i = 0; i < 16; i++) {
-		sabre_write(p->controller_regs + SABRE_IOMMU_TAG + (i * 8UL), 0);
-		sabre_write(p->controller_regs + SABRE_IOMMU_DATA + (i * 8UL), 0);
+		sabre_write(p->pbm_A.controller_regs + SABRE_IOMMU_TAG + (i * 8UL), 0);
+		sabre_write(p->pbm_A.controller_regs + SABRE_IOMMU_DATA + (i * 8UL), 0);
 	}
 
 	/* Leave diag mode enabled for full-flushing done
@@ -1287,9 +1319,9 @@
 	iommu->dma_addr_mask = dma_mask;
 	memset((char *)tsbbase, 0, PAGE_SIZE << order);
 
-	sabre_write(p->controller_regs + SABRE_IOMMU_TSBBASE, __pa(tsbbase));
+	sabre_write(p->pbm_A.controller_regs + SABRE_IOMMU_TSBBASE, __pa(tsbbase));
 
-	control = sabre_read(p->controller_regs + SABRE_IOMMU_CONTROL);
+	control = sabre_read(p->pbm_A.controller_regs + SABRE_IOMMU_CONTROL);
 	control &= ~(SABRE_IOMMUCTRL_TSBSZ | SABRE_IOMMUCTRL_TBWSZ);
 	control |= SABRE_IOMMUCTRL_ENAB;
 	switch(tsbsize) {
@@ -1306,7 +1338,7 @@
 		prom_halt();
 		break;
 	}
-	sabre_write(p->controller_regs + SABRE_IOMMU_CONTROL, control);
+	sabre_write(p->pbm_A.controller_regs + SABRE_IOMMU_CONTROL, control);
 
 	/* We start with no consistent mappings. */
 	iommu->lowest_consistent_map =
@@ -1322,8 +1354,8 @@
 						   struct pci_pbm_info *pbm)
 {
 	char *name = pbm->name;
-	unsigned long ibase = p->controller_regs + SABRE_IOSPACE;
-	unsigned long mbase = p->controller_regs + SABRE_MEMSPACE;
+	unsigned long ibase = p->pbm_A.controller_regs + SABRE_IOSPACE;
+	unsigned long mbase = p->pbm_A.controller_regs + SABRE_MEMSPACE;
 	unsigned int devfn;
 	unsigned long first, last, i;
 	u8 *addr, map;
@@ -1416,6 +1448,7 @@
 			pbm = &p->pbm_B;
 		else
 			pbm = &p->pbm_A;
+		pbm->chip_type = PBM_CHIP_TYPE_SABRE;
 		pbm->parent = p;
 		pbm->prom_node = node;
 		pbm->pci_first_slot = 1;
@@ -1511,11 +1544,11 @@
 		pbm->io_space.name = pbm->mem_space.name = pbm->name;
 
 		/* Hack up top-level resources. */
-		pbm->io_space.start = p->controller_regs + SABRE_IOSPACE;
+		pbm->io_space.start = p->pbm_A.controller_regs + SABRE_IOSPACE;
 		pbm->io_space.end   = pbm->io_space.start + (1UL << 24) - 1UL;
 		pbm->io_space.flags = IORESOURCE_IO;
 
-		pbm->mem_space.start = p->controller_regs + SABRE_MEMSPACE;
+		pbm->mem_space.start = p->pbm_A.controller_regs + SABRE_MEMSPACE;
 		pbm->mem_space.end   = pbm->mem_space.start + (unsigned long)dma_begin - 1UL;
 		pbm->mem_space.flags = IORESOURCE_MEM;
 
@@ -1591,7 +1624,8 @@
 	pci_controller_root = p;
 	spin_unlock_irqrestore(&pci_controller_lock, flags);
 
-	p->portid = upa_portid;
+	p->pbm_A.portid = upa_portid;
+	p->pbm_B.portid = upa_portid;
 	p->index = pci_num_controllers++;
 	p->pbms_same_domain = 1;
 	p->scan_bus = sabre_scan_bus;
@@ -1614,30 +1648,31 @@
 	/*
 	 * First REG in property is base of entire SABRE register space.
 	 */
-	p->controller_regs = pr_regs[0].phys_addr;
-	pci_dma_wsync = p->controller_regs + SABRE_WRSYNC;
+	p->pbm_A.controller_regs = pr_regs[0].phys_addr;
+	p->pbm_B.controller_regs = pr_regs[0].phys_addr;
+	pci_dma_wsync = p->pbm_A.controller_regs + SABRE_WRSYNC;
 
 	printk("PCI: Found SABRE, main regs at %016lx, wsync at %016lx\n",
-	       p->controller_regs, pci_dma_wsync);
+	       p->pbm_A.controller_regs, pci_dma_wsync);
 
 	/* Clear interrupts */
 
 	/* PCI first */
 	for (clear_irq = SABRE_ICLR_A_SLOT0; clear_irq < SABRE_ICLR_B_SLOT0 + 0x80; clear_irq += 8)
-		sabre_write(p->controller_regs + clear_irq, 0x0UL);
+		sabre_write(p->pbm_A.controller_regs + clear_irq, 0x0UL);
 
 	/* Then OBIO */
 	for (clear_irq = SABRE_ICLR_SCSI; clear_irq < SABRE_ICLR_SCSI + 0x80; clear_irq += 8)
-		sabre_write(p->controller_regs + clear_irq, 0x0UL);
+		sabre_write(p->pbm_A.controller_regs + clear_irq, 0x0UL);
 
 	/* Error interrupts are enabled later after the bus scan. */
-	sabre_write(p->controller_regs + SABRE_PCICTRL,
+	sabre_write(p->pbm_A.controller_regs + SABRE_PCICTRL,
 		    (SABRE_PCICTRL_MRLEN   | SABRE_PCICTRL_SERR |
 		     SABRE_PCICTRL_ARBPARK | SABRE_PCICTRL_AEN));
 
 	/* Now map in PCI config space for entire SABRE. */
 	p->pbm_A.config_space = p->pbm_B.config_space =
-		(p->controller_regs + SABRE_CONFIGSPACE);
+		(p->pbm_A.controller_regs + SABRE_CONFIGSPACE);
 	printk("SABRE: Shared PCI config space at %016lx\n",
 	       p->pbm_A.config_space);
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/pci_schizo.c linux-2.4.23-pre1/arch/sparc64/kernel/pci_schizo.c
--- linux-2.4.22/arch/sparc64/kernel/pci_schizo.c	2002-11-28 23:53:12.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/pci_schizo.c	2003-08-27 14:39:33.000000000 +0000
@@ -1,7 +1,7 @@
 /* $Id: pci_schizo.c,v 1.23.2.2 2002/03/11 07:55:24 davem Exp $
- * pci_schizo.c: SCHIZO specific PCI controller support.
+ * pci_schizo.c: SCHIZO/TOMATILLO specific PCI controller support.
  *
- * Copyright (C) 2001 David S. Miller (davem@redhat.com)
+ * Copyright (C) 2001, 2002, 2003 David S. Miller (davem@redhat.com)
  */
 
 #include <linux/kernel.h>
@@ -45,13 +45,7 @@
  * block requires more space in Schizo's address space than
  * they predicted, thus requiring an address space reorg when
  * the newer Schizo is taped out.
- *
- * These offsets look weird because I keep in p->controller_regs
- * the second PROM register property minus 0x10000 which is the
- * base of the Safari and UPA64S registers of SCHIZO.
  */
-#define SCHIZO_PBM_A_REGS_OFF	(0x600000UL - 0x400000UL)
-#define SCHIZO_PBM_B_REGS_OFF	(0x700000UL - 0x400000UL)
 
 /* Streaming buffer control register. */
 #define SCHIZO_STRBUF_CTRL_LPTR    0x00000000000000f0UL /* LRU Lock Pointer */
@@ -101,25 +95,21 @@
 {
 	if (!pbm)
 		return NULL;
+	bus -= pbm->pci_first_busno;
 	return (void *)
 		(SCHIZO_CONFIG_BASE(pbm) |
 		 SCHIZO_CONFIG_ENCODE(bus, devfn, where));
 }
 
-/* 4 slots on pbm A, and 6 slots on pbm B.  In both cases
- * slot 0 is the SCHIZO host bridge itself.
- */
+/* Just make sure the bus number is in range.  */
 static int schizo_out_of_range(struct pci_pbm_info *pbm,
 			       unsigned char bus,
 			       unsigned char devfn)
 {
-	return ((pbm->parent == 0) ||
-		((pbm == &pbm->parent->pbm_B) &&
-		 (bus == pbm->pci_first_busno) &&
-		 PCI_SLOT(devfn) > 6) ||
-		((pbm == &pbm->parent->pbm_A) &&
-		 (bus == pbm->pci_first_busno) &&
-		 PCI_SLOT(devfn) > 4));
+	if (bus < pbm->pci_first_busno ||
+	    bus > pbm->pci_last_busno)
+		return 1;
+	return 0;
 }
 
 /* SCHIZO PCI configuration space accessors. */
@@ -188,6 +178,15 @@
 	}
 
 	pci_config_read32(addr, value);
+	if (where == PCI_PRIMARY_BUS &&
+	    dev->hdr_type == PCI_HEADER_TYPE_BRIDGE &&
+	    *value != 0xffffffff) {
+		u8 *busp = ((u8 *) value) + 1;
+		int i;
+
+		for (i = 0; i < 3; i++)
+			busp[i] += pbm->pci_first_busno;
+	}
 	return PCIBIOS_SUCCESSFUL;
 }
 
@@ -251,6 +250,20 @@
 		       where);
 		return PCIBIOS_SUCCESSFUL;
 	}
+
+	if (where == PCI_PRIMARY_BUS &&
+	    dev->hdr_type == PCI_HEADER_TYPE_BRIDGE) {
+		u8 *busp = ((u8 *) &value) + 1;
+		int i;
+
+		for (i = 0; i < 3; i++) {
+			if (busp[i] >= pbm->pci_first_busno)
+				busp[i] += pbm->pci_first_busno;
+			else
+				busp[i] = 0;
+		}
+	}
+
 	pci_config_write32(addr, value);
 	return PCIBIOS_SUCCESSFUL;
 }
@@ -379,16 +392,10 @@
 					    struct pci_dev *pdev,
 					    unsigned int ino)
 {
-	struct pci_controller_info *p = pbm->parent;
 	struct ino_bucket *bucket;
-	unsigned long imap, iclr, pbm_off;
+	unsigned long imap, iclr;
 	unsigned long imap_off, iclr_off;
-	int pil;
-
-	if (pbm == &p->pbm_A)
-		pbm_off = SCHIZO_PBM_A_REGS_OFF;
-	else
-		pbm_off = SCHIZO_PBM_B_REGS_OFF;
+	int pil, ign_fixup;
 
 	ino &= PCI_IRQ_INO;
 	imap_off = schizo_imap_offset(ino);
@@ -399,11 +406,11 @@
 	if (PIL_RESERVED(pil))
 		BUG();
 
-	imap = p->controller_regs + pbm_off + imap_off;
+	imap = pbm->pbm_regs + imap_off;
 	imap += 4;
 
 	iclr_off = schizo_iclr_offset(ino);
-	iclr = p->controller_regs + pbm_off + iclr_off;
+	iclr = pbm->pbm_regs + iclr_off;
 	iclr += 4;
 
 	/* On Schizo, no inofixup occurs.  This is because each
@@ -411,8 +418,17 @@
 	 * there is only one IMAP register for each PCI slot even
 	 * though four different INOs can be generated by each
 	 * PCI slot.
+	 *
+	 * But, for JBUS variants (essentially, Tomatillo), we have
+	 * to fixup the lowest bit of the interrupt group number.
 	 */
-	bucket = __bucket(build_irq(pil, 0, iclr, imap));
+	ign_fixup = 0;
+	if (pbm->chip_type == PBM_CHIP_TYPE_TOMATILLO) {
+		if (pbm->portid & 1)
+			ign_fixup = (1 << 6);
+	}
+
+	bucket = __bucket(build_irq(pil, ign_fixup, iclr, imap));
 	bucket->flags |= IBF_PCI;
 
 	return __irq(bucket);
@@ -428,6 +444,13 @@
 static unsigned long stc_tag_buf[16];
 static unsigned long stc_line_buf[16];
 
+/* These offsets look weird because I keep in pbm->controller_regs
+ * the second PROM register property minus 0x10000 which is the
+ * base of the Safari and UPA64S registers of SCHIZO.
+ */
+#define SCHIZO_PBM_A_REGS_OFF	(0x600000UL - 0x400000UL)
+#define SCHIZO_PBM_B_REGS_OFF	(0x700000UL - 0x400000UL)
+
 static void schizo_clear_other_err_intr(int irq)
 {
 	struct ino_bucket *bucket = __bucket(irq);
@@ -459,19 +482,12 @@
 static void __schizo_check_stc_error_pbm(struct pci_pbm_info *pbm,
 					 enum schizo_error_type type)
 {
-	struct pci_controller_info *p = pbm->parent;
 	struct pci_strbuf *strbuf = &pbm->stc;
-	unsigned long regbase = p->controller_regs;
+	unsigned long regbase = pbm->pbm_regs;
 	unsigned long err_base, tag_base, line_base;
 	u64 control;
-	char pbm_name = (pbm == &p->pbm_A ? 'A' : 'B');
 	int i;
 
-	if (pbm == &p->pbm_A)
-		regbase += SCHIZO_PBM_A_REGS_OFF;
-	else
-		regbase += SCHIZO_PBM_B_REGS_OFF;
-
 	err_base = regbase + SCHIZO_STC_ERR;
 	tag_base = regbase + SCHIZO_STC_TAG;
 	line_base = regbase + SCHIZO_STC_LINE;
@@ -517,8 +533,8 @@
 			unsigned long errval = stc_error_buf[j];
 			if (errval != 0) {
 				saw_error++;
-				printk("SCHIZO%d: PBM-%c STC_ERR(%d)[wr(%d)rd(%d)]\n",
-				       p->index, pbm_name,
+				printk("%s: STC_ERR(%d)[wr(%d)rd(%d)]\n",
+				       pbm->name,
 				       j,
 				       (errval & SCHIZO_STCERR_WRITE) ? 1 : 0,
 				       (errval & SCHIZO_STCERR_READ) ? 1 : 0);
@@ -527,8 +543,8 @@
 		if (saw_error != 0) {
 			unsigned long tagval = stc_tag_buf[i];
 			unsigned long lineval = stc_line_buf[i];
-			printk("SCHIZO%d: PBM-%c STC_TAG(%d)[PA(%016lx)VA(%08lx)V(%d)R(%d)]\n",
-			       p->index, pbm_name,
+			printk("%s: STC_TAG(%d)[PA(%016lx)VA(%08lx)V(%d)R(%d)]\n",
+			       pbm->name,
 			       i,
 			       ((tagval & SCHIZO_STCTAG_PPN) >> 19UL),
 			       (tagval & SCHIZO_STCTAG_VPN),
@@ -536,9 +552,9 @@
 			       ((tagval & SCHIZO_STCTAG_READ) ? 1 : 0));
 
 			/* XXX Should spit out per-bank error information... -DaveM */
-			printk("SCHIZO%d: PBM-%c STC_LINE(%d)[LIDX(%lx)SP(%lx)LADDR(%lx)EP(%lx)"
+			printk("%s: STC_LINE(%d)[LIDX(%lx)SP(%lx)LADDR(%lx)EP(%lx)"
 			       "V(%d)FOFN(%d)]\n",
-			       p->index, pbm_name,
+			       pbm->name,
 			       i,
 			       ((lineval & SCHIZO_STCLINE_LINDX) >> 23UL),
 			       ((lineval & SCHIZO_STCLINE_SPTR) >> 13UL),
@@ -574,13 +590,11 @@
 static void schizo_check_iommu_error_pbm(struct pci_pbm_info *pbm,
 					 enum schizo_error_type type)
 {
-	struct pci_controller_info *p = pbm->parent;
 	struct pci_iommu *iommu = pbm->iommu;
 	unsigned long iommu_tag[16];
 	unsigned long iommu_data[16];
 	unsigned long flags;
 	u64 control;
-	char pbm_name = (pbm == &p->pbm_A ? 'A' : 'B');
 	int i;
 
 	spin_lock_irqsave(&iommu->lock, flags);
@@ -608,8 +622,8 @@
 			type_string = "ECC Error";
 			break;
 		};
-		printk("SCHIZO%d: PBM-%c IOMMU Error, type[%s]\n",
-		       p->index, pbm_name, type_string);
+		printk("%s: IOMMU Error, type[%s]\n",
+		       pbm->name, type_string);
 
 		/* Put the IOMMU into diagnostic mode and probe
 		 * it's TLB for entries with error status.
@@ -624,11 +638,7 @@
 		schizo_write(iommu->iommu_control,
 			     control | SCHIZO_IOMMU_CTRL_DENAB);
 
-		base = p->controller_regs;
-		if (pbm == &p->pbm_A)
-			base += SCHIZO_PBM_A_REGS_OFF;
-		else
-			base += SCHIZO_PBM_B_REGS_OFF;
+		base = pbm->pbm_regs;
 
 		for (i = 0; i < 16; i++) {
 			iommu_tag[i] =
@@ -667,22 +677,23 @@
 				type_string = "ECC Error";
 				break;
 			};
-			printk("SCHIZO%d: PBM-%c IOMMU TAG(%d)[error(%s) ctx(%x) wr(%d) str(%d) "
+			printk("%s: IOMMU TAG(%d)[error(%s) ctx(%x) wr(%d) str(%d) "
 			       "sz(%dK) vpg(%08lx)]\n",
-			       p->index, pbm_name, i, type_string,
+			       pbm->name, i, type_string,
 			       (int)((tag & SCHIZO_IOMMU_TAG_CTXT) >> 25UL),
 			       ((tag & SCHIZO_IOMMU_TAG_WRITE) ? 1 : 0),
 			       ((tag & SCHIZO_IOMMU_TAG_STREAM) ? 1 : 0),
 			       ((tag & SCHIZO_IOMMU_TAG_SIZE) ? 64 : 8),
 			       (tag & SCHIZO_IOMMU_TAG_VPAGE) << IOMMU_PAGE_SHIFT);
-			printk("SCHIZO%d: PBM-%c IOMMU DATA(%d)[valid(%d) cache(%d) ppg(%016lx)]\n",
-			       p->index, pbm_name, i,
+			printk("%s: IOMMU DATA(%d)[valid(%d) cache(%d) ppg(%016lx)]\n",
+			       pbm->name, i,
 			       ((data & SCHIZO_IOMMU_DATA_VALID) ? 1 : 0),
 			       ((data & SCHIZO_IOMMU_DATA_CACHE) ? 1 : 0),
 			       (data & SCHIZO_IOMMU_DATA_PPAGE) << IOMMU_PAGE_SHIFT);
 		}
 	}
-	__schizo_check_stc_error_pbm(pbm, type);
+	if (pbm->stc.strbuf_enabled)
+		__schizo_check_stc_error_pbm(pbm, type);
 	spin_unlock_irqrestore(&iommu->lock, flags);
 }
 
@@ -697,26 +708,26 @@
 #define SCHIZO_UE_AFSR	0x10030UL
 #define SCHIZO_UE_AFAR	0x10038UL
 
-#define SCHIZO_UEAFSR_PPIO	0x8000000000000000UL
-#define SCHIZO_UEAFSR_PDRD	0x4000000000000000UL
-#define SCHIZO_UEAFSR_PDWR	0x2000000000000000UL
-#define SCHIZO_UEAFSR_SPIO	0x1000000000000000UL
-#define SCHIZO_UEAFSR_SDMA	0x0800000000000000UL
-#define SCHIZO_UEAFSR_ERRPNDG	0x0300000000000000UL
-#define SCHIZO_UEAFSR_BMSK	0x000003ff00000000UL
-#define SCHIZO_UEAFSR_QOFF	0x00000000c0000000UL
-#define SCHIZO_UEAFSR_AID	0x000000001f000000UL
-#define SCHIZO_UEAFSR_PARTIAL	0x0000000000800000UL
-#define SCHIZO_UEAFSR_OWNEDIN	0x0000000000400000UL
-#define SCHIZO_UEAFSR_MTAGSYND	0x00000000000f0000UL
-#define SCHIZO_UEAFSR_MTAG	0x000000000000e000UL
-#define SCHIZO_UEAFSR_ECCSYND	0x00000000000001ffUL
+#define SCHIZO_UEAFSR_PPIO	0x8000000000000000UL /* Safari */
+#define SCHIZO_UEAFSR_PDRD	0x4000000000000000UL /* Safari/Tomatillo */
+#define SCHIZO_UEAFSR_PDWR	0x2000000000000000UL /* Safari */
+#define SCHIZO_UEAFSR_SPIO	0x1000000000000000UL /* Safari */
+#define SCHIZO_UEAFSR_SDMA	0x0800000000000000UL /* Safari/Tomatillo */
+#define SCHIZO_UEAFSR_ERRPNDG	0x0300000000000000UL /* Safari */
+#define SCHIZO_UEAFSR_BMSK	0x000003ff00000000UL /* Safari */
+#define SCHIZO_UEAFSR_QOFF	0x00000000c0000000UL /* Safari/Tomatillo */
+#define SCHIZO_UEAFSR_AID	0x000000001f000000UL /* Safari/Tomatillo */
+#define SCHIZO_UEAFSR_PARTIAL	0x0000000000800000UL /* Safari */
+#define SCHIZO_UEAFSR_OWNEDIN	0x0000000000400000UL /* Safari */
+#define SCHIZO_UEAFSR_MTAGSYND	0x00000000000f0000UL /* Safari */
+#define SCHIZO_UEAFSR_MTAG	0x000000000000e000UL /* Safari */
+#define SCHIZO_UEAFSR_ECCSYND	0x00000000000001ffUL /* Safari */
 
 static void schizo_ue_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
 	struct pci_controller_info *p = dev_id;
-	unsigned long afsr_reg = p->controller_regs + SCHIZO_UE_AFSR;
-	unsigned long afar_reg = p->controller_regs + SCHIZO_UE_AFAR;
+	unsigned long afsr_reg = p->pbm_B.controller_regs + SCHIZO_UE_AFSR;
+	unsigned long afar_reg = p->pbm_B.controller_regs + SCHIZO_UE_AFAR;
 	unsigned long afsr, afar, error_bits;
 	int reported, limit;
 
@@ -741,7 +752,7 @@
 	schizo_write(afsr_reg, error_bits);
 
 	/* Log the error. */
-	printk("SCHIZO%d: Uncorrectable Error, primary error type[%s]\n",
+	printk("PCI%d: Uncorrectable Error, primary error type[%s]\n",
 	       p->index,
 	       (((error_bits & SCHIZO_UEAFSR_PPIO) ?
 		 "PIO" :
@@ -749,20 +760,20 @@
 		  "DMA Read" :
 		  ((error_bits & SCHIZO_UEAFSR_PDWR) ?
 		   "DMA Write" : "???")))));
-	printk("SCHIZO%d: bytemask[%04lx] qword_offset[%lx] SAFARI_AID[%02lx]\n",
+	printk("PCI%d: bytemask[%04lx] qword_offset[%lx] SAFARI_AID[%02lx]\n",
 	       p->index,
 	       (afsr & SCHIZO_UEAFSR_BMSK) >> 32UL,
 	       (afsr & SCHIZO_UEAFSR_QOFF) >> 30UL,
 	       (afsr & SCHIZO_UEAFSR_AID) >> 24UL);
-	printk("SCHIZO%d: partial[%d] owned_in[%d] mtag[%lx] mtag_synd[%lx] ecc_sync[%lx]\n",
+	printk("PCI%d: partial[%d] owned_in[%d] mtag[%lx] mtag_synd[%lx] ecc_sync[%lx]\n",
 	       p->index,
 	       (afsr & SCHIZO_UEAFSR_PARTIAL) ? 1 : 0,
 	       (afsr & SCHIZO_UEAFSR_OWNEDIN) ? 1 : 0,
 	       (afsr & SCHIZO_UEAFSR_MTAG) >> 13UL,
 	       (afsr & SCHIZO_UEAFSR_MTAGSYND) >> 16UL,
 	       (afsr & SCHIZO_UEAFSR_ECCSYND) >> 0UL);
-	printk("SCHIZO%d: UE AFAR [%016lx]\n", p->index, afar);
-	printk("SCHIZO%d: UE Secondary errors [", p->index);
+	printk("PCI%d: UE AFAR [%016lx]\n", p->index, afar);
+	printk("PCI%d: UE Secondary errors [", p->index);
 	reported = 0;
 	if (afsr & SCHIZO_UEAFSR_SPIO) {
 		reported++;
@@ -803,8 +814,8 @@
 static void schizo_ce_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
 	struct pci_controller_info *p = dev_id;
-	unsigned long afsr_reg = p->controller_regs + SCHIZO_CE_AFSR;
-	unsigned long afar_reg = p->controller_regs + SCHIZO_CE_AFAR;
+	unsigned long afsr_reg = p->pbm_B.controller_regs + SCHIZO_CE_AFSR;
+	unsigned long afar_reg = p->pbm_B.controller_regs + SCHIZO_CE_AFAR;
 	unsigned long afsr, afar, error_bits;
 	int reported, limit;
 
@@ -829,7 +840,7 @@
 	schizo_write(afsr_reg, error_bits);
 
 	/* Log the error. */
-	printk("SCHIZO%d: Correctable Error, primary error type[%s]\n",
+	printk("PCI%d: Correctable Error, primary error type[%s]\n",
 	       p->index,
 	       (((error_bits & SCHIZO_CEAFSR_PPIO) ?
 		 "PIO" :
@@ -841,20 +852,20 @@
 	/* XXX Use syndrome and afar to print out module string just like
 	 * XXX UDB CE trap handler does... -DaveM
 	 */
-	printk("SCHIZO%d: bytemask[%04lx] qword_offset[%lx] SAFARI_AID[%02lx]\n",
+	printk("PCI%d: bytemask[%04lx] qword_offset[%lx] SAFARI_AID[%02lx]\n",
 	       p->index,
 	       (afsr & SCHIZO_UEAFSR_BMSK) >> 32UL,
 	       (afsr & SCHIZO_UEAFSR_QOFF) >> 30UL,
 	       (afsr & SCHIZO_UEAFSR_AID) >> 24UL);
-	printk("SCHIZO%d: partial[%d] owned_in[%d] mtag[%lx] mtag_synd[%lx] ecc_sync[%lx]\n",
+	printk("PCI%d: partial[%d] owned_in[%d] mtag[%lx] mtag_synd[%lx] ecc_sync[%lx]\n",
 	       p->index,
 	       (afsr & SCHIZO_UEAFSR_PARTIAL) ? 1 : 0,
 	       (afsr & SCHIZO_UEAFSR_OWNEDIN) ? 1 : 0,
 	       (afsr & SCHIZO_UEAFSR_MTAG) >> 13UL,
 	       (afsr & SCHIZO_UEAFSR_MTAGSYND) >> 16UL,
 	       (afsr & SCHIZO_UEAFSR_ECCSYND) >> 0UL);
-	printk("SCHIZO%d: CE AFAR [%016lx]\n", p->index, afar);
-	printk("SCHIZO%d: CE Secondary errors [", p->index);
+	printk("PCI%d: CE AFAR [%016lx]\n", p->index, afar);
+	printk("PCI%d: CE Secondary errors [", p->index);
 	reported = 0;
 	if (afsr & SCHIZO_CEAFSR_SPIO) {
 		reported++;
@@ -874,23 +885,101 @@
 #define SCHIZO_PCI_AFSR	0x2010UL
 #define SCHIZO_PCI_AFAR	0x2018UL
 
-#define SCHIZO_PCIAFSR_PMA	0x8000000000000000UL
-#define SCHIZO_PCIAFSR_PTA	0x4000000000000000UL
-#define SCHIZO_PCIAFSR_PRTRY	0x2000000000000000UL
-#define SCHIZO_PCIAFSR_PPERR	0x1000000000000000UL
-#define SCHIZO_PCIAFSR_PTTO	0x0800000000000000UL
-#define SCHIZO_PCIAFSR_PUNUS	0x0400000000000000UL
-#define SCHIZO_PCIAFSR_SMA	0x0200000000000000UL
-#define SCHIZO_PCIAFSR_STA	0x0100000000000000UL
-#define SCHIZO_PCIAFSR_SRTRY	0x0080000000000000UL
-#define SCHIZO_PCIAFSR_SPERR	0x0040000000000000UL
-#define SCHIZO_PCIAFSR_STTO	0x0020000000000000UL
-#define SCHIZO_PCIAFSR_SUNUS	0x0010000000000000UL
-#define SCHIZO_PCIAFSR_BMSK	0x000003ff00000000UL
-#define SCHIZO_PCIAFSR_BLK	0x0000000080000000UL
-#define SCHIZO_PCIAFSR_CFG	0x0000000040000000UL
-#define SCHIZO_PCIAFSR_MEM	0x0000000020000000UL
-#define SCHIZO_PCIAFSR_IO	0x0000000010000000UL
+#define SCHIZO_PCIAFSR_PMA	0x8000000000000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_PTA	0x4000000000000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_PRTRY	0x2000000000000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_PPERR	0x1000000000000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_PTTO	0x0800000000000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_PUNUS	0x0400000000000000UL /* Schizo */
+#define SCHIZO_PCIAFSR_SMA	0x0200000000000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_STA	0x0100000000000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_SRTRY	0x0080000000000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_SPERR	0x0040000000000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_STTO	0x0020000000000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_SUNUS	0x0010000000000000UL /* Schizo */
+#define SCHIZO_PCIAFSR_BMSK	0x000003ff00000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_BLK	0x0000000080000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_CFG	0x0000000040000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_MEM	0x0000000020000000UL /* Schizo/Tomatillo */
+#define SCHIZO_PCIAFSR_IO	0x0000000010000000UL /* Schizo/Tomatillo */
+
+#define SCHIZO_PCI_CTRL		(0x2000UL)
+#define SCHIZO_PCICTRL_BUS_UNUS	(1UL << 63UL) /* Safari */
+#define SCHIZO_PCICTRL_ARB_PRIO (0x1ff << 52UL) /* Tomatillo */
+#define SCHIZO_PCICTRL_ESLCK	(1UL << 51UL) /* Safari */
+#define SCHIZO_PCICTRL_ERRSLOT	(7UL << 48UL) /* Safari */
+#define SCHIZO_PCICTRL_TTO_ERR	(1UL << 38UL) /* Safari/Tomatillo */
+#define SCHIZO_PCICTRL_RTRY_ERR	(1UL << 37UL) /* Safari/Tomatillo */
+#define SCHIZO_PCICTRL_DTO_ERR	(1UL << 36UL) /* Safari/Tomatillo */
+#define SCHIZO_PCICTRL_SBH_ERR	(1UL << 35UL) /* Safari */
+#define SCHIZO_PCICTRL_SERR	(1UL << 34UL) /* Safari/Tomatillo */
+#define SCHIZO_PCICTRL_PCISPD	(1UL << 33UL) /* Safari */
+#define SCHIZO_PCICTRL_MRM_PREF	(1UL << 28UL) /* Tomatillo */
+#define SCHIZO_PCICTRL_RDO_PREF	(1UL << 27UL) /* Tomatillo */
+#define SCHIZO_PCICTRL_RDL_PREF	(1UL << 26UL) /* Tomatillo */
+#define SCHIZO_PCICTRL_PTO	(3UL << 24UL) /* Safari/Tomatillo */
+#define SCHIZO_PCICTRL_PTO_SHIFT 24UL
+#define SCHIZO_PCICTRL_TRWSW	(7UL << 21UL) /* Tomatillo */
+#define SCHIZO_PCICTRL_F_TGT_A	(1UL << 20UL) /* Tomatillo */
+#define SCHIZO_PCICTRL_S_DTO_INT (1UL << 19UL) /* Safari */
+#define SCHIZO_PCICTRL_F_TGT_RT	(1UL << 19UL) /* Tomatillo */
+#define SCHIZO_PCICTRL_SBH_INT	(1UL << 18UL) /* Safari */
+#define SCHIZO_PCICTRL_T_DTO_INT (1UL << 18UL) /* Tomatillo */
+#define SCHIZO_PCICTRL_EEN	(1UL << 17UL) /* Safari/Tomatillo */
+#define SCHIZO_PCICTRL_PARK	(1UL << 16UL) /* Safari/Tomatillo */
+#define SCHIZO_PCICTRL_PCIRST	(1UL <<  8UL) /* Safari */
+#define SCHIZO_PCICTRL_ARB_S	(0x3fUL << 0UL) /* Safari */
+#define SCHIZO_PCICTRL_ARB_T	(0xffUL << 0UL) /* Tomatillo */
+
+static void schizo_pcierr_intr_other(struct pci_pbm_info *pbm)
+{
+	unsigned long csr_reg, csr, csr_error_bits;
+	u16 stat;
+
+	csr_reg = pbm->pbm_regs + SCHIZO_PCI_CTRL;
+	csr = schizo_read(csr_reg);
+	csr_error_bits =
+		csr & (SCHIZO_PCICTRL_BUS_UNUS |
+		       SCHIZO_PCICTRL_TTO_ERR |
+		       SCHIZO_PCICTRL_RTRY_ERR |
+		       SCHIZO_PCICTRL_DTO_ERR |
+		       SCHIZO_PCICTRL_SBH_ERR |
+		       SCHIZO_PCICTRL_SERR);
+	if (csr_error_bits) {
+		/* Clear the errors.  */
+		schizo_write(csr_reg, csr);
+
+		/* Log 'em.  */
+		if (csr_error_bits & SCHIZO_PCICTRL_BUS_UNUS)
+			printk("%s: Bus unusable error asserted.\n",
+			       pbm->name);
+		if (csr_error_bits & SCHIZO_PCICTRL_TTO_ERR)
+			printk("%s: PCI TRDY# timeout error asserted.\n",
+			       pbm->name);
+		if (csr_error_bits & SCHIZO_PCICTRL_RTRY_ERR)
+			printk("%s: PCI excessive retry error asserted.\n",
+			       pbm->name);
+		if (csr_error_bits & SCHIZO_PCICTRL_DTO_ERR)
+			printk("%s: PCI discard timeout error asserted.\n",
+			       pbm->name);
+		if (csr_error_bits & SCHIZO_PCICTRL_SBH_ERR)
+			printk("%s: PCI streaming byte hole error asserted.\n",
+			       pbm->name);
+		if (csr_error_bits & SCHIZO_PCICTRL_SERR)
+			printk("%s: PCI SERR signal asserted.\n",
+			       pbm->name);
+	}
+	pci_read_config_word(pbm->pci_bus->self, PCI_STATUS, &stat);
+	if (stat & (PCI_STATUS_PARITY |
+		    PCI_STATUS_SIG_TARGET_ABORT |
+		    PCI_STATUS_REC_TARGET_ABORT |
+		    PCI_STATUS_REC_MASTER_ABORT |
+		    PCI_STATUS_SIG_SYSTEM_ERROR)) {
+		printk("%s: PCI bus error, PCI_STATUS[%04x]\n",
+		       pbm->name, stat);
+		pci_write_config_word(pbm->pci_bus->self, PCI_STATUS, 0xffff);
+	}
+}
 
 static void schizo_pcierr_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
@@ -899,16 +988,8 @@
 	unsigned long afsr_reg, afar_reg, base;
 	unsigned long afsr, afar, error_bits;
 	int reported;
-	char pbm_name;
 
-	base = p->controller_regs;
-	if (pbm == &pbm->parent->pbm_A) {
-		base += SCHIZO_PBM_A_REGS_OFF;
-		pbm_name = 'A';
-	} else {
-		base += SCHIZO_PBM_B_REGS_OFF;
-		pbm_name = 'B';
-	}
+	base = pbm->pbm_regs;
 
 	afsr_reg = base + SCHIZO_PCI_AFSR;
 	afar_reg = base + SCHIZO_PCI_AFAR;
@@ -926,12 +1007,12 @@
 		 SCHIZO_PCIAFSR_SRTRY | SCHIZO_PCIAFSR_SPERR |
 		 SCHIZO_PCIAFSR_STTO | SCHIZO_PCIAFSR_SUNUS);
 	if (!error_bits)
-		return;
+		return schizo_pcierr_intr_other(pbm);
 	schizo_write(afsr_reg, error_bits);
 
 	/* Log the error. */
-	printk("SCHIZO%d: PBM-%c PCI Error, primary error type[%s]\n",
-	       p->index, pbm_name,
+	printk("%s: PCI Error, primary error type[%s]\n",
+	       pbm->name,
 	       (((error_bits & SCHIZO_PCIAFSR_PMA) ?
 		 "Master Abort" :
 		 ((error_bits & SCHIZO_PCIAFSR_PTA) ?
@@ -944,8 +1025,8 @@
 		     "Timeout" :
 		     ((error_bits & SCHIZO_PCIAFSR_PUNUS) ?
 		      "Bus Unusable" : "???"))))))));
-	printk("SCHIZO%d: PBM-%c bytemask[%04lx] was_block(%d) space(%s)\n",
-	       p->index, pbm_name,
+	printk("%s: bytemask[%04lx] was_block(%d) space(%s)\n",
+	       pbm->name,
 	       (afsr & SCHIZO_PCIAFSR_BMSK) >> 32UL,
 	       (afsr & SCHIZO_PCIAFSR_BLK) ? 1 : 0,
 	       ((afsr & SCHIZO_PCIAFSR_CFG) ?
@@ -954,10 +1035,10 @@
 		 "Memory" :
 		 ((afsr & SCHIZO_PCIAFSR_IO) ?
 		  "I/O" : "???"))));
-	printk("SCHIZO%d: PBM-%c PCI AFAR [%016lx]\n",
-	       p->index, pbm_name, afar);
-	printk("SCHIZO%d: PBM-%c PCI Secondary errors [",
-	       p->index, pbm_name);
+	printk("%s: PCI AFAR [%016lx]\n",
+	       pbm->name, afar);
+	printk("%s: PCI Secondary errors [",
+	       pbm->name);
 	reported = 0;
 	if (afsr & SCHIZO_PCIAFSR_SMA) {
 		reported++;
@@ -1020,24 +1101,37 @@
 
 #define SAFARI_ERRLOG_ERROUT	0x8000000000000000UL
 
-#define SAFARI_ERROR_BADCMD	0x4000000000000000UL
-#define SAFARI_ERROR_SSMDIS	0x2000000000000000UL
-#define SAFARI_ERROR_BADMA	0x1000000000000000UL
-#define SAFARI_ERROR_BADMB	0x0800000000000000UL
-#define SAFARI_ERROR_BADMC	0x0400000000000000UL
-#define SAFARI_ERROR_CPU1PS	0x0000000000002000UL
-#define SAFARI_ERROR_CPU1PB	0x0000000000001000UL
-#define SAFARI_ERROR_CPU0PS	0x0000000000000800UL
-#define SAFARI_ERROR_CPU0PB	0x0000000000000400UL
-#define SAFARI_ERROR_CIQTO	0x0000000000000200UL
-#define SAFARI_ERROR_LPQTO	0x0000000000000100UL
-#define SAFARI_ERROR_SFPQTO	0x0000000000000080UL
-#define SAFARI_ERROR_UFPQTO	0x0000000000000040UL
-#define SAFARI_ERROR_APERR	0x0000000000000020UL
-#define SAFARI_ERROR_UNMAP	0x0000000000000010UL
-#define SAFARI_ERROR_BUSERR	0x0000000000000004UL
-#define SAFARI_ERROR_TIMEOUT	0x0000000000000002UL
-#define SAFARI_ERROR_ILL	0x0000000000000001UL
+#define BUS_ERROR_BADCMD	0x4000000000000000UL /* Schizo/Tomatillo */
+#define BUS_ERROR_SSMDIS	0x2000000000000000UL /* Safari */
+#define BUS_ERROR_BADMA		0x1000000000000000UL /* Safari */
+#define BUS_ERROR_BADMB		0x0800000000000000UL /* Safari */
+#define BUS_ERROR_BADMC		0x0400000000000000UL /* Safari */
+#define BUS_ERROR_SNOOP_GR	0x0000000000200000UL /* Tomatillo */
+#define BUS_ERROR_SNOOP_PCI	0x0000000000100000UL /* Tomatillo */
+#define BUS_ERROR_SNOOP_RD	0x0000000000080000UL /* Tomatillo */
+#define BUS_ERROR_SNOOP_RDS	0x0000000000020000UL /* Tomatillo */
+#define BUS_ERROR_SNOOP_RDSA	0x0000000000010000UL /* Tomatillo */
+#define BUS_ERROR_SNOOP_OWN	0x0000000000008000UL /* Tomatillo */
+#define BUS_ERROR_SNOOP_RDO	0x0000000000004000UL /* Tomatillo */
+#define BUS_ERROR_CPU1PS	0x0000000000002000UL /* Safari */
+#define BUS_ERROR_WDATA_PERR	0x0000000000002000UL /* Tomatillo */
+#define BUS_ERROR_CPU1PB	0x0000000000001000UL /* Safari */
+#define BUS_ERROR_CTRL_PERR	0x0000000000001000UL /* Tomatillo */
+#define BUS_ERROR_CPU0PS	0x0000000000000800UL /* Safari */
+#define BUS_ERROR_SNOOP_ERR	0x0000000000000800UL /* Tomatillo */
+#define BUS_ERROR_CPU0PB	0x0000000000000400UL /* Safari */
+#define BUS_ERROR_JBUS_ILL_B	0x0000000000000400UL /* Tomatillo */
+#define BUS_ERROR_CIQTO		0x0000000000000200UL /* Safari */
+#define BUS_ERROR_LPQTO		0x0000000000000100UL /* Safari */
+#define BUS_ERROR_JBUS_ILL_C	0x0000000000000100UL /* Tomatillo */
+#define BUS_ERROR_SFPQTO	0x0000000000000080UL /* Safari */
+#define BUS_ERROR_UFPQTO	0x0000000000000040UL /* Safari */
+#define BUS_ERROR_RD_PERR	0x0000000000000040UL /* Tomatillo */
+#define BUS_ERROR_APERR		0x0000000000000020UL /* Safari/Tomatillo */
+#define BUS_ERROR_UNMAP		0x0000000000000010UL /* Safari/Tomatillo */
+#define BUS_ERROR_BUSERR	0x0000000000000004UL /* Safari/Tomatillo */
+#define BUS_ERROR_TIMEOUT	0x0000000000000002UL /* Safari/Tomatillo */
+#define BUS_ERROR_ILL		0x0000000000000001UL /* Safari */
 
 /* We only expect UNMAP errors here.  The rest of the Safari errors
  * are marked fatal and thus cause a system reset.
@@ -1047,19 +1141,19 @@
 	struct pci_controller_info *p = dev_id;
 	u64 errlog;
 
-	errlog = schizo_read(p->controller_regs + SCHIZO_SAFARI_ERRLOG);
-	schizo_write(p->controller_regs + SCHIZO_SAFARI_ERRLOG,
+	errlog = schizo_read(p->pbm_B.controller_regs + SCHIZO_SAFARI_ERRLOG);
+	schizo_write(p->pbm_B.controller_regs + SCHIZO_SAFARI_ERRLOG,
 		     errlog & ~(SAFARI_ERRLOG_ERROUT));
 
-	if (!(errlog & SAFARI_ERROR_UNMAP)) {
-		printk("SCHIZO%d: Unexpected Safari error interrupt, errlog[%016lx]\n",
+	if (!(errlog & BUS_ERROR_UNMAP)) {
+		printk("PCI%d: Unexpected Safari/JBUS error interrupt, errlog[%016lx]\n",
 		       p->index, errlog);
 
 		schizo_clear_other_err_intr(irq);
 		return;
 	}
 
-	printk("SCHIZO%d: Safari interrupt, UNMAPPED error, interrogating IOMMUs.\n",
+	printk("PCI%d: Safari/JBUS interrupt, UNMAPPED error, interrogating IOMMUs.\n",
 	       p->index);
 	schizo_check_iommu_error(p, SAFARI_ERR);
 
@@ -1083,131 +1177,279 @@
 #define SCHIZO_PCIERR_B_INO	0x33 /* PBM B PCI bus error */
 #define SCHIZO_SERR_INO		0x34 /* Safari interface error */
 
-#define SCHIZO_PCIA_CTRL	(SCHIZO_PBM_A_REGS_OFF + 0x2000UL)
-#define SCHIZO_PCIB_CTRL	(SCHIZO_PBM_B_REGS_OFF + 0x2000UL)
-#define SCHIZO_PCICTRL_BUS_UNUS	(1UL << 63UL)
-#define SCHIZO_PCICTRL_ESLCK	(1UL << 51UL)
-#define SCHIZO_PCICTRL_ERRSLOT	(7UL << 48UL)
-#define SCHIZO_PCICTRL_TTO_ERR	(1UL << 38UL)
-#define SCHIZO_PCICTRL_RTRY_ERR	(1UL << 37UL)
-#define SCHIZO_PCICTRL_DTO_ERR	(1UL << 36UL)
-#define SCHIZO_PCICTRL_SBH_ERR	(1UL << 35UL)
-#define SCHIZO_PCICTRL_SERR	(1UL << 34UL)
-#define SCHIZO_PCICTRL_PCISPD	(1UL << 33UL)
-#define SCHIZO_PCICTRL_PTO	(3UL << 24UL)
-#define SCHIZO_PCICTRL_DTO_INT	(1UL << 19UL)
-#define SCHIZO_PCICTRL_SBH_INT	(1UL << 18UL)
-#define SCHIZO_PCICTRL_EEN	(1UL << 17UL)
-#define SCHIZO_PCICTRL_PARK	(1UL << 16UL)
-#define SCHIZO_PCICTRL_PCIRST	(1UL <<  8UL)
-#define SCHIZO_PCICTRL_ARB	(0x3fUL << 0UL)
+struct pci_pbm_info *pbm_for_ino(struct pci_controller_info *p, u32 ino)
+{
+	ino &= IMAP_INO;
+	if (p->pbm_A.ino_bitmap & (1UL << ino))
+		return &p->pbm_A;
+	if (p->pbm_B.ino_bitmap & (1UL << ino))
+		return &p->pbm_B;
+	prom_printf("TOMATILLO%d: No entry in ino bitmap for %d\n",
+		    p->index, ino);
+	prom_halt();
+	/* NOTREACHED */
+	return NULL;
+}
+
+/* How the Tomatillo IRQs are routed around is pure guesswork here.
+ *
+ * All the Tomatillo devices I see in prtconf dumps seem to have only
+ * a single PCI bus unit attached to it.  It would seem they are seperate
+ * devices because their PortID (ie. JBUS ID) values are all different
+ * and thus the registers are mapped to totally different locations.
+ *
+ * However, two Tomatillo's look "similar" in that the only difference
+ * in their PortID is the lowest bit.
+ *
+ * So if we were to ignore this lower bit, it certainly looks like two
+ * PCI bus units of the same Tomatillo.  I still have not really
+ * figured this out...
+ */
+static void __init tomatillo_register_error_handlers(struct pci_controller_info *p)
+{
+	struct pci_pbm_info *pbm;
+	unsigned int irq;
+	struct ino_bucket *bucket;
+	u64 tmp, err_mask, err_no_mask;
+
+	/* Build IRQs and register handlers. */
+	pbm = pbm_for_ino(p, SCHIZO_UE_INO);
+	irq = schizo_irq_build(pbm, NULL, (pbm->portid << 6) | SCHIZO_UE_INO);
+	if (request_irq(irq, schizo_ue_intr,
+			SA_SHIRQ, "TOMATILLO UE", p) < 0) {
+		prom_printf("%s: Cannot register UE interrupt.\n",
+			    pbm->name);
+		prom_halt();
+	}
+	bucket = __bucket(irq);
+	tmp = readl(bucket->imap);
+	upa_writel(tmp, (pbm->pbm_regs +
+			 schizo_imap_offset(SCHIZO_UE_INO) + 4));
+
+	pbm = pbm_for_ino(p, SCHIZO_CE_INO);
+	irq = schizo_irq_build(pbm, NULL, (pbm->portid << 6) | SCHIZO_CE_INO);
+	if (request_irq(irq, schizo_ce_intr,
+			SA_SHIRQ, "TOMATILLO CE", p) < 0) {
+		prom_printf("%s: Cannot register CE interrupt.\n",
+			    pbm->name);
+		prom_halt();
+	}
+	bucket = __bucket(irq);
+	tmp = upa_readl(bucket->imap);
+	upa_writel(tmp, (pbm->pbm_regs +
+			 schizo_imap_offset(SCHIZO_CE_INO) + 4));
+
+	pbm = pbm_for_ino(p, SCHIZO_PCIERR_A_INO);
+	irq = schizo_irq_build(pbm, NULL, ((pbm->portid << 6) |
+					   SCHIZO_PCIERR_A_INO));
+	if (request_irq(irq, schizo_pcierr_intr,
+			SA_SHIRQ, "TOMATILLO PCIERR", pbm) < 0) {
+		prom_printf("%s: Cannot register PBM A PciERR interrupt.\n",
+			    pbm->name);
+		prom_halt();
+	}
+	bucket = __bucket(irq);
+	tmp = upa_readl(bucket->imap);
+	upa_writel(tmp, (pbm->pbm_regs +
+			 schizo_imap_offset(SCHIZO_PCIERR_A_INO) + 4));
+
+	pbm = pbm_for_ino(p, SCHIZO_PCIERR_B_INO);
+	irq = schizo_irq_build(pbm, NULL, ((pbm->portid << 6) |
+					    SCHIZO_PCIERR_B_INO));
+	if (request_irq(irq, schizo_pcierr_intr,
+			SA_SHIRQ, "TOMATILLO PCIERR", pbm) < 0) {
+		prom_printf("%s: Cannot register PBM B PciERR interrupt.\n",
+			    pbm->name);
+		prom_halt();
+	}
+	bucket = __bucket(irq);
+	tmp = upa_readl(bucket->imap);
+	upa_writel(tmp, (pbm->pbm_regs +
+			 schizo_imap_offset(SCHIZO_PCIERR_B_INO) + 4));
+
+	pbm = pbm_for_ino(p, SCHIZO_SERR_INO);
+	irq = schizo_irq_build(pbm, NULL, (pbm->portid << 6) | SCHIZO_SERR_INO);
+	if (request_irq(irq, schizo_safarierr_intr,
+			SA_SHIRQ, "TOMATILLO SERR", p) < 0) {
+		prom_printf("%s: Cannot register SafariERR interrupt.\n",
+			    pbm->name);
+		prom_halt();
+	}
+	bucket = __bucket(irq);
+	tmp = upa_readl(bucket->imap);
+	upa_writel(tmp, (pbm->pbm_regs +
+			 schizo_imap_offset(SCHIZO_SERR_INO) + 4));
+
+	/* Enable UE and CE interrupts for controller. */
+	schizo_write(p->pbm_A.controller_regs + SCHIZO_ECC_CTRL,
+		     (SCHIZO_ECCCTRL_EE |
+		      SCHIZO_ECCCTRL_UE |
+		      SCHIZO_ECCCTRL_CE));
+
+	schizo_write(p->pbm_B.controller_regs + SCHIZO_ECC_CTRL,
+		     (SCHIZO_ECCCTRL_EE |
+		      SCHIZO_ECCCTRL_UE |
+		      SCHIZO_ECCCTRL_CE));
+
+	/* Enable PCI Error interrupts and clear error
+	 * bits.
+	 */
+	err_mask = (SCHIZO_PCICTRL_BUS_UNUS |
+		    SCHIZO_PCICTRL_TTO_ERR |
+		    SCHIZO_PCICTRL_RTRY_ERR |
+		    SCHIZO_PCICTRL_SERR |
+		    SCHIZO_PCICTRL_EEN);
+
+	err_no_mask = SCHIZO_PCICTRL_DTO_ERR;
+
+	tmp = schizo_read(p->pbm_A.pbm_regs + SCHIZO_PCI_CTRL);
+	tmp |= err_mask;
+	tmp &= ~err_no_mask;
+	schizo_write(p->pbm_A.pbm_regs + SCHIZO_PCI_CTRL, tmp);
+
+	tmp = schizo_read(p->pbm_B.pbm_regs + SCHIZO_PCI_CTRL);
+	tmp |= err_mask;
+	tmp &= ~err_no_mask;
+	schizo_write(p->pbm_B.pbm_regs + SCHIZO_PCI_CTRL, tmp);
+
+	err_mask = (SCHIZO_PCIAFSR_PMA | SCHIZO_PCIAFSR_PTA |
+		    SCHIZO_PCIAFSR_PRTRY | SCHIZO_PCIAFSR_PPERR |
+		    SCHIZO_PCIAFSR_PTTO |
+		    SCHIZO_PCIAFSR_SMA | SCHIZO_PCIAFSR_STA |
+		    SCHIZO_PCIAFSR_SRTRY | SCHIZO_PCIAFSR_SPERR |
+		    SCHIZO_PCIAFSR_STTO);
+
+	schizo_write(p->pbm_A.pbm_regs + SCHIZO_PCI_AFSR, err_mask);
+	schizo_write(p->pbm_B.pbm_regs + SCHIZO_PCI_AFSR, err_mask);
+
+	err_mask = (BUS_ERROR_BADCMD | BUS_ERROR_SNOOP_GR |
+		    BUS_ERROR_SNOOP_PCI | BUS_ERROR_SNOOP_RD |
+		    BUS_ERROR_SNOOP_RDS | BUS_ERROR_SNOOP_RDSA |
+		    BUS_ERROR_SNOOP_OWN | BUS_ERROR_SNOOP_RDO |
+		    BUS_ERROR_WDATA_PERR | BUS_ERROR_CTRL_PERR |
+		    BUS_ERROR_SNOOP_ERR | BUS_ERROR_JBUS_ILL_B |
+		    BUS_ERROR_JBUS_ILL_C | BUS_ERROR_RD_PERR |
+		    BUS_ERROR_APERR | BUS_ERROR_UNMAP |
+		    BUS_ERROR_BUSERR | BUS_ERROR_TIMEOUT);
+
+	schizo_write(p->pbm_A.controller_regs + SCHIZO_SAFARI_ERRCTRL,
+		     (SCHIZO_SAFERRCTRL_EN | err_mask));
+	schizo_write(p->pbm_B.controller_regs + SCHIZO_SAFARI_ERRCTRL,
+		     (SCHIZO_SAFERRCTRL_EN | err_mask));
+
+	schizo_write(p->pbm_A.controller_regs + SCHIZO_SAFARI_IRQCTRL,
+		     (SCHIZO_SAFIRQCTRL_EN | (BUS_ERROR_UNMAP)));
+	schizo_write(p->pbm_B.controller_regs + SCHIZO_SAFARI_IRQCTRL,
+		     (SCHIZO_SAFIRQCTRL_EN | (BUS_ERROR_UNMAP)));
+}
 
 static void __init schizo_register_error_handlers(struct pci_controller_info *p)
 {
-	struct pci_pbm_info *pbm_a = &p->pbm_A;
-	struct pci_pbm_info *pbm_b = &p->pbm_B;
-	unsigned long base = p->controller_regs;
-	unsigned int irq, portid = p->portid;
+	struct pci_pbm_info *pbm;
+	unsigned int irq;
 	struct ino_bucket *bucket;
-	u64 tmp;
+	u64 tmp, err_mask, err_no_mask;
 
 	/* Build IRQs and register handlers. */
-	irq = schizo_irq_build(pbm_b, NULL, (portid << 6) | SCHIZO_UE_INO);
+	pbm = pbm_for_ino(p, SCHIZO_UE_INO);
+	irq = schizo_irq_build(pbm, NULL, (pbm->portid << 6) | SCHIZO_UE_INO);
 	if (request_irq(irq, schizo_ue_intr,
 			SA_SHIRQ, "SCHIZO UE", p) < 0) {
-		prom_printf("SCHIZO%d: Cannot register UE interrupt.\n",
-			    p->index);
+		prom_printf("%s: Cannot register UE interrupt.\n",
+			    pbm->name);
 		prom_halt();
 	}
 	bucket = __bucket(irq);
 	tmp = readl(bucket->imap);
-	upa_writel(tmp, (base + SCHIZO_PBM_B_REGS_OFF + schizo_imap_offset(SCHIZO_UE_INO) + 4));
+	upa_writel(tmp, (pbm->pbm_regs + schizo_imap_offset(SCHIZO_UE_INO) + 4));
 
-	irq = schizo_irq_build(pbm_b, NULL, (portid << 6) | SCHIZO_CE_INO);
+	pbm = pbm_for_ino(p, SCHIZO_CE_INO);
+	irq = schizo_irq_build(pbm, NULL, (pbm->portid << 6) | SCHIZO_CE_INO);
 	if (request_irq(irq, schizo_ce_intr,
 			SA_SHIRQ, "SCHIZO CE", p) < 0) {
-		prom_printf("SCHIZO%d: Cannot register CE interrupt.\n",
-			    p->index);
+		prom_printf("%s: Cannot register CE interrupt.\n",
+			    pbm->name);
 		prom_halt();
 	}
 	bucket = __bucket(irq);
 	tmp = upa_readl(bucket->imap);
-	upa_writel(tmp, (base + SCHIZO_PBM_B_REGS_OFF + schizo_imap_offset(SCHIZO_CE_INO) + 4));
+	upa_writel(tmp, (pbm->pbm_regs + schizo_imap_offset(SCHIZO_CE_INO) + 4));
 
-	irq = schizo_irq_build(pbm_a, NULL, (portid << 6) | SCHIZO_PCIERR_A_INO);
+	pbm = pbm_for_ino(p, SCHIZO_PCIERR_A_INO);
+	irq = schizo_irq_build(pbm, NULL, (pbm->portid << 6) | SCHIZO_PCIERR_A_INO);
 	if (request_irq(irq, schizo_pcierr_intr,
-			SA_SHIRQ, "SCHIZO PCIERR", pbm_a) < 0) {
-		prom_printf("SCHIZO%d(PBMA): Cannot register PciERR interrupt.\n",
-			    p->index);
+			SA_SHIRQ, "SCHIZO PCIERR", pbm) < 0) {
+		prom_printf("%s: Cannot register PBM A PciERR interrupt.\n",
+			    pbm->name);
 		prom_halt();
 	}
 	bucket = __bucket(irq);
 	tmp = upa_readl(bucket->imap);
-	upa_writel(tmp, (base + SCHIZO_PBM_A_REGS_OFF + schizo_imap_offset(SCHIZO_PCIERR_A_INO) + 4));
+	upa_writel(tmp, (pbm->pbm_regs + schizo_imap_offset(SCHIZO_PCIERR_A_INO) + 4));
 
-	irq = schizo_irq_build(pbm_b, NULL, (portid << 6) | SCHIZO_PCIERR_B_INO);
+	pbm = pbm_for_ino(p, SCHIZO_PCIERR_B_INO);
+	irq = schizo_irq_build(pbm, NULL, (pbm->portid << 6) | SCHIZO_PCIERR_B_INO);
 	if (request_irq(irq, schizo_pcierr_intr,
-			SA_SHIRQ, "SCHIZO PCIERR", pbm_b) < 0) {
-		prom_printf("SCHIZO%d(PBMB): Cannot register PciERR interrupt.\n",
-			    p->index);
+			SA_SHIRQ, "SCHIZO PCIERR", &p->pbm_B) < 0) {
+		prom_printf("%s: Cannot register PBM B PciERR interrupt.\n",
+			    pbm->name);
 		prom_halt();
 	}
 	bucket = __bucket(irq);
 	tmp = upa_readl(bucket->imap);
-	upa_writel(tmp, (base + SCHIZO_PBM_B_REGS_OFF + schizo_imap_offset(SCHIZO_PCIERR_B_INO) + 4));
+	upa_writel(tmp, (pbm->pbm_regs + schizo_imap_offset(SCHIZO_PCIERR_B_INO) + 4));
 
-	irq = schizo_irq_build(pbm_b, NULL, (portid << 6) | SCHIZO_SERR_INO);
+	pbm = pbm_for_ino(p, SCHIZO_SERR_INO);
+	irq = schizo_irq_build(pbm, NULL, (pbm->portid << 6) | SCHIZO_SERR_INO);
 	if (request_irq(irq, schizo_safarierr_intr,
 			SA_SHIRQ, "SCHIZO SERR", p) < 0) {
-		prom_printf("SCHIZO%d(PBMB): Cannot register SafariERR interrupt.\n",
-			    p->index);
+		prom_printf("%s: Cannot register SafariERR interrupt.\n",
+			    pbm->name);
 		prom_halt();
 	}
 	bucket = __bucket(irq);
 	tmp = upa_readl(bucket->imap);
-	upa_writel(tmp, (base + SCHIZO_PBM_B_REGS_OFF + schizo_imap_offset(SCHIZO_SERR_INO) + 4));
+	upa_writel(tmp, (pbm->pbm_regs + schizo_imap_offset(SCHIZO_SERR_INO) + 4));
 
 	/* Enable UE and CE interrupts for controller. */
-	schizo_write(base + SCHIZO_ECC_CTRL,
+	schizo_write(p->pbm_A.controller_regs + SCHIZO_ECC_CTRL,
 		     (SCHIZO_ECCCTRL_EE |
 		      SCHIZO_ECCCTRL_UE |
 		      SCHIZO_ECCCTRL_CE));
 
+	err_mask = (SCHIZO_PCICTRL_BUS_UNUS |
+		    SCHIZO_PCICTRL_ESLCK |
+		    SCHIZO_PCICTRL_TTO_ERR |
+		    SCHIZO_PCICTRL_RTRY_ERR |
+		    SCHIZO_PCICTRL_SBH_ERR |
+		    SCHIZO_PCICTRL_SERR |
+		    SCHIZO_PCICTRL_SBH_INT |
+		    SCHIZO_PCICTRL_EEN);
+
+	err_no_mask = SCHIZO_PCICTRL_DTO_ERR;
+
 	/* Enable PCI Error interrupts and clear error
 	 * bits for each PBM.
 	 */
-	tmp = schizo_read(base + SCHIZO_PCIA_CTRL);
-	tmp |= (SCHIZO_PCICTRL_BUS_UNUS |
-		SCHIZO_PCICTRL_ESLCK |
-		SCHIZO_PCICTRL_TTO_ERR |
-		SCHIZO_PCICTRL_RTRY_ERR |
-		SCHIZO_PCICTRL_DTO_ERR |
-		SCHIZO_PCICTRL_SBH_ERR |
-		SCHIZO_PCICTRL_SERR |
-		SCHIZO_PCICTRL_SBH_INT |
-		SCHIZO_PCICTRL_EEN);
-	schizo_write(base + SCHIZO_PCIA_CTRL, tmp);
-
-	tmp = schizo_read(base + SCHIZO_PCIB_CTRL);
-	tmp |= (SCHIZO_PCICTRL_BUS_UNUS |
-		SCHIZO_PCICTRL_ESLCK |
-		SCHIZO_PCICTRL_TTO_ERR |
-		SCHIZO_PCICTRL_RTRY_ERR |
-		SCHIZO_PCICTRL_DTO_ERR |
-		SCHIZO_PCICTRL_SBH_ERR |
-		SCHIZO_PCICTRL_SERR |
-		SCHIZO_PCICTRL_SBH_INT |
-		SCHIZO_PCICTRL_EEN);
-	schizo_write(base + SCHIZO_PCIB_CTRL, tmp);
+	tmp = schizo_read(p->pbm_A.pbm_regs + SCHIZO_PCI_CTRL);
+	tmp |= err_mask;
+	tmp &= ~err_no_mask;
+	schizo_write(p->pbm_A.pbm_regs + SCHIZO_PCI_CTRL, tmp);
 
-	schizo_write(base + SCHIZO_PBM_A_REGS_OFF + SCHIZO_PCI_AFSR,
+	schizo_write(p->pbm_A.pbm_regs + SCHIZO_PCI_AFSR,
 		     (SCHIZO_PCIAFSR_PMA | SCHIZO_PCIAFSR_PTA |
 		      SCHIZO_PCIAFSR_PRTRY | SCHIZO_PCIAFSR_PPERR |
 		      SCHIZO_PCIAFSR_PTTO | SCHIZO_PCIAFSR_PUNUS |
 		      SCHIZO_PCIAFSR_SMA | SCHIZO_PCIAFSR_STA |
 		      SCHIZO_PCIAFSR_SRTRY | SCHIZO_PCIAFSR_SPERR |
 		      SCHIZO_PCIAFSR_STTO | SCHIZO_PCIAFSR_SUNUS));
-	schizo_write(base + SCHIZO_PBM_B_REGS_OFF + SCHIZO_PCI_AFSR,
+
+	tmp = schizo_read(p->pbm_B.pbm_regs + SCHIZO_PCI_CTRL);
+	tmp |= err_mask;
+	tmp &= ~err_no_mask;
+	schizo_write(p->pbm_B.pbm_regs + SCHIZO_PCI_CTRL, tmp);
+
+	schizo_write(p->pbm_B.pbm_regs + SCHIZO_PCI_AFSR,
 		     (SCHIZO_PCIAFSR_PMA | SCHIZO_PCIAFSR_PTA |
 		      SCHIZO_PCIAFSR_PRTRY | SCHIZO_PCIAFSR_PPERR |
 		      SCHIZO_PCIAFSR_PTTO | SCHIZO_PCIAFSR_PUNUS |
@@ -1215,9 +1457,19 @@
 		      SCHIZO_PCIAFSR_SRTRY | SCHIZO_PCIAFSR_SPERR |
 		      SCHIZO_PCIAFSR_STTO | SCHIZO_PCIAFSR_SUNUS));
 
-	/* Make all Safari error conditions fatal except unmapped errors
-	 * which we make generate interrupts.
+	/* Make all Safari error conditions fatal except unmapped
+	 * errors which we make generate interrupts.
 	 */
+	err_mask = (BUS_ERROR_BADCMD | BUS_ERROR_SSMDIS |
+		    BUS_ERROR_BADMA | BUS_ERROR_BADMB |
+		    BUS_ERROR_BADMC |
+		    BUS_ERROR_CPU1PS | BUS_ERROR_CPU1PB |
+		    BUS_ERROR_CPU0PS | BUS_ERROR_CPU0PB |
+		    BUS_ERROR_CIQTO |
+		    BUS_ERROR_LPQTO | BUS_ERROR_SFPQTO |
+		    BUS_ERROR_UFPQTO | BUS_ERROR_APERR |
+		    BUS_ERROR_BUSERR | BUS_ERROR_TIMEOUT |
+		    BUS_ERROR_ILL);
 #if 1
 	/* XXX Something wrong with some Excalibur systems
 	 * XXX Sun is shipping.  The behavior on a 2-cpu
@@ -1226,53 +1478,26 @@
 	 * XXX their error status bits are cleared.  Just
 	 * XXX ignore them for now.  -DaveM
 	 */
-	schizo_write(base + SCHIZO_SAFARI_ERRCTRL,
-		     (SCHIZO_SAFERRCTRL_EN |
-		      (SAFARI_ERROR_BADCMD | SAFARI_ERROR_SSMDIS |
-		       SAFARI_ERROR_BADMA | SAFARI_ERROR_BADMB |
-		       SAFARI_ERROR_BADMC |
-		       SAFARI_ERROR_CIQTO |
-		       SAFARI_ERROR_LPQTO | SAFARI_ERROR_SFPQTO |
-		       SAFARI_ERROR_UFPQTO | SAFARI_ERROR_APERR |
-		       SAFARI_ERROR_BUSERR | SAFARI_ERROR_TIMEOUT |
-		       SAFARI_ERROR_ILL)));
-#else
-	schizo_write(base + SCHIZO_SAFARI_ERRCTRL,
-		     (SCHIZO_SAFERRCTRL_EN |
-		      (SAFARI_ERROR_BADCMD | SAFARI_ERROR_SSMDIS |
-		       SAFARI_ERROR_BADMA | SAFARI_ERROR_BADMB |
-		       SAFARI_ERROR_BADMC |
-		       SAFARI_ERROR_CPU1PS | SAFARI_ERROR_CPU1PB |
-		       SAFARI_ERROR_CPU0PS | SAFARI_ERROR_CPU0PB |
-		       SAFARI_ERROR_CIQTO |
-		       SAFARI_ERROR_LPQTO | SAFARI_ERROR_SFPQTO |
-		       SAFARI_ERROR_UFPQTO | SAFARI_ERROR_APERR |
-		       SAFARI_ERROR_BUSERR | SAFARI_ERROR_TIMEOUT |
-		       SAFARI_ERROR_ILL)));
+	err_mask &= ~(BUS_ERROR_CPU1PS | BUS_ERROR_CPU1PB |
+		      BUS_ERROR_CPU0PS | BUS_ERROR_CPU0PB);
 #endif
 
-	schizo_write(base + SCHIZO_SAFARI_IRQCTRL,
-		     (SCHIZO_SAFIRQCTRL_EN | (SAFARI_ERROR_UNMAP)));
+	schizo_write(p->pbm_A.controller_regs + SCHIZO_SAFARI_ERRCTRL,
+		     (SCHIZO_SAFERRCTRL_EN | err_mask));
+
+	schizo_write(p->pbm_A.controller_regs + SCHIZO_SAFARI_IRQCTRL,
+		     (SCHIZO_SAFIRQCTRL_EN | (BUS_ERROR_UNMAP)));
 }
 
 /* We have to do the config space accesses by hand, thus... */
-#define PBM_BRIDGE_BUS		0x40
-#define PBM_BRIDGE_SUBORDINATE	0x41
 static void __init pbm_renumber(struct pci_pbm_info *pbm, u8 orig_busno)
 {
-	u8 *addr, busno;
+	u8 busno;
 	int nbus;
 
 	busno = pci_highest_busnum;
 	nbus = pbm->pci_last_busno - pbm->pci_first_busno;
 
-	addr = schizo_pci_config_mkaddr(pbm, orig_busno,
-					0, PBM_BRIDGE_BUS);
-	pci_config_write8(addr, busno);
-	addr = schizo_pci_config_mkaddr(pbm, busno,
-					0, PBM_BRIDGE_SUBORDINATE);
-	pci_config_write8(addr, busno + nbus);
-
 	pbm->pci_first_busno = busno;
 	pbm->pci_last_busno = busno + nbus;
 	pci_highest_busnum = busno + nbus + 1;
@@ -1282,75 +1507,8 @@
 	} while (nbus--);
 }
 
-/* We have to do the config space accesses by hand here since
- * the pci_bus2pbm array is not ready yet.
- */
-static void __init pbm_pci_bridge_renumber(struct pci_pbm_info *pbm,
-					   u8 busno)
-{
-	u32 devfn, l, class;
-	u8 hdr_type;
-	int is_multi = 0;
-
-	for(devfn = 0; devfn < 0xff; ++devfn) {
-		u32 *dwaddr;
-		u8 *baddr;
-
-		if (PCI_FUNC(devfn) != 0 && is_multi == 0)
-			continue;
-
-		/* Anything there? */
-		dwaddr = schizo_pci_config_mkaddr(pbm, busno, devfn, PCI_VENDOR_ID);
-		l = 0xffffffff;
-		pci_config_read32(dwaddr, &l);
-		if (l == 0xffffffff || l == 0x00000000 ||
-		    l == 0x0000ffff || l == 0xffff0000) {
-			is_multi = 0;
-			continue;
-		}
-
-		baddr = schizo_pci_config_mkaddr(pbm, busno, devfn, PCI_HEADER_TYPE);
-		pci_config_read8(baddr, &hdr_type);
-		if (PCI_FUNC(devfn) == 0)
-			is_multi = hdr_type & 0x80;
-
-		dwaddr = schizo_pci_config_mkaddr(pbm, busno, devfn, PCI_CLASS_REVISION);
-		class = 0xffffffff;
-		pci_config_read32(dwaddr, &class);
-		if ((class >> 16) == PCI_CLASS_BRIDGE_PCI) {
-			u32 buses = 0xffffffff;
-
-			dwaddr = schizo_pci_config_mkaddr(pbm, busno, devfn,
-							  PCI_PRIMARY_BUS);
-			pci_config_read32(dwaddr, &buses);
-			pbm_pci_bridge_renumber(pbm, (buses >> 8) & 0xff);
-			buses &= 0xff000000;
-			pci_config_write32(dwaddr, buses);
-		}
-	}
-}
-
 static void __init pbm_bridge_reconfigure(struct pci_controller_info *p)
 {
-	struct pci_pbm_info *pbm;
-	u8 *addr;
-
-	/* Clear out primary/secondary/subordinate bus numbers on
-	 * all PCI-to-PCI bridges under each PBM.  The generic bus
-	 * probing will fix them up.
-	 */
-	pbm_pci_bridge_renumber(&p->pbm_B, p->pbm_B.pci_first_busno);
-	pbm_pci_bridge_renumber(&p->pbm_A, p->pbm_A.pci_first_busno);
-
-	/* Move PBM A out of the way. */
-	pbm = &p->pbm_A;
-	addr = schizo_pci_config_mkaddr(pbm, pbm->pci_first_busno,
-					0, PBM_BRIDGE_BUS);
-	pci_config_write8(addr, 0xff);
-	addr = schizo_pci_config_mkaddr(pbm, 0xff,
-					0, PBM_BRIDGE_SUBORDINATE);
-	pci_config_write8(addr, 0xff);
-
 	/* Now we can safely renumber both PBMs. */
 	pbm_renumber(&p->pbm_B, p->pbm_B.pci_first_busno);
 	pbm_renumber(&p->pbm_A, 0xff);
@@ -1379,7 +1537,7 @@
 	struct pcidev_cookie *cookie = kmalloc(sizeof(*cookie), GFP_KERNEL);
 
 	if (!cookie) {
-		prom_printf("SCHIZO: Critical allocation failure.\n");
+		prom_printf("%s: Critical allocation failure.\n", pbm->name);
 		prom_halt();
 	}
 
@@ -1401,20 +1559,42 @@
 	pci_setup_busmastering(pbm, pbm->pci_bus);
 }
 
-static void __init schizo_scan_bus(struct pci_controller_info *p)
+static void __init __schizo_scan_bus(struct pci_controller_info *p,
+				     int chip_type)
 {
+	if (!p->pbm_B.prom_node || !p->pbm_A.prom_node) {
+		printk("PCI: Only one PCI bus module of controller found.\n");
+		printk("PCI: Ignoring entire controller.\n");
+		return;
+	}
+
 	pbm_bridge_reconfigure(p);
 	pbm_config_busmastering(&p->pbm_B);
-	p->pbm_B.is_66mhz_capable = 0;
+	p->pbm_B.is_66mhz_capable =
+		prom_getbool(p->pbm_B.prom_node, "66mhz-capable");
 	pbm_config_busmastering(&p->pbm_A);
-	p->pbm_A.is_66mhz_capable = 1;
+	p->pbm_A.is_66mhz_capable =
+		prom_getbool(p->pbm_A.prom_node, "66mhz-capable");
 	pbm_scan_bus(p, &p->pbm_B);
 	pbm_scan_bus(p, &p->pbm_A);
 
 	/* After the PCI bus scan is complete, we can register
 	 * the error interrupt handlers.
 	 */
-	schizo_register_error_handlers(p);
+	if (chip_type == PBM_CHIP_TYPE_TOMATILLO)
+		tomatillo_register_error_handlers(p);
+	else
+		schizo_register_error_handlers(p);
+}
+
+static void __init schizo_scan_bus(struct pci_controller_info *p)
+{
+	__schizo_scan_bus(p, PBM_CHIP_TYPE_SCHIZO);
+}
+
+static void __init tomatillo_scan_bus(struct pci_controller_info *p)
+{
+	__schizo_scan_bus(p, PBM_CHIP_TYPE_TOMATILLO);
 }
 
 static void __init schizo_base_address_update(struct pci_dev *pdev, int resource)
@@ -1470,68 +1650,72 @@
 	res->end += root->start;
 }
 
-/* Interrogate Safari match/mask registers to figure out where
- * PCI MEM, I/O, and Config space are for this PCI bus module.
+/* Use ranges property to determine where PCI MEM, I/O, and Config
+ * space are for this PCI bus module.
  */
+static void schizo_determine_mem_io_space(struct pci_pbm_info *pbm)
+{
+	int i, saw_cfg, saw_mem, saw_io;
 
-#define SCHIZO_PCI_A_MEM_MATCH		0x00040UL
-#define SCHIZO_PCI_A_MEM_MASK		0x00048UL
-#define SCHIZO_PCI_A_IO_MATCH		0x00050UL
-#define SCHIZO_PCI_A_IO_MASK		0x00058UL
-#define SCHIZO_PCI_B_MEM_MATCH		0x00060UL
-#define SCHIZO_PCI_B_MEM_MASK		0x00068UL
-#define SCHIZO_PCI_B_IO_MATCH		0x00070UL
-#define SCHIZO_PCI_B_IO_MASK		0x00078UL
-
-static void schizo_determine_mem_io_space(struct pci_pbm_info *pbm,
-					  int is_pbm_a, unsigned long reg_base)
-{
-	u64 mem_match, mem_mask;
-	u64 io_match;
-	u64 a;
-
-	if (is_pbm_a) {
-		mem_match = reg_base + SCHIZO_PCI_A_MEM_MATCH;
-		io_match = reg_base + SCHIZO_PCI_A_IO_MATCH;
-	} else {
-		mem_match = reg_base + SCHIZO_PCI_B_MEM_MATCH;
-		io_match = reg_base + SCHIZO_PCI_B_IO_MATCH;
-	}
-	mem_mask = mem_match + 0x8UL;
+	saw_cfg = saw_mem = saw_io = 0;
+	for (i = 0; i < pbm->num_pbm_ranges; i++) {
+		struct linux_prom_pci_ranges *pr = &pbm->pbm_ranges[i];
+		unsigned long a;
+		int type;
 
-	a = schizo_read(mem_match) & ~0x8000000000000000UL;
+		type = (pr->child_phys_hi >> 24) & 0x3;
+		a = (((unsigned long)pr->parent_phys_hi << 32UL) |
+		     ((unsigned long)pr->parent_phys_lo  <<  0UL));
 
-	/* It should be 2GB in size but the decode is set for the full
-	 * 4GB so we have to add the 2G by hand.
-	 */
-	pbm->mem_space.start = a;
-	pbm->mem_space.end = a + 0x80000000;
-	pbm->mem_space.flags = IORESOURCE_MEM;
+		switch (type) {
+		case 0:
+			/* PCI config space, 16MB */
+			pbm->config_space = a;
+			saw_cfg = 1;
+			break;
 
-	/* This 32MB area is divided into two pieces.  The first
-	 * 16MB is Config space, the next 16MB is I/O space.
-	 */
+		case 1:
+			/* 16-bit IO space, 16MB */
+			pbm->io_space.start = a;
+			pbm->io_space.end = a + ((16UL*1024UL*1024UL) - 1UL);
+			pbm->io_space.flags = IORESOURCE_IO;
+			saw_io = 1;
+			break;
 
-	a = schizo_read(io_match) & ~0x8000000000000000UL;
-	pbm->config_space = a;
-	printk("SCHIZO PBM%c: Local PCI config space at %016lx\n",
-	       (is_pbm_a ? 'A' : 'B'), pbm->config_space);
+		case 2:
+			/* 32-bit MEM space, 2GB */
+			pbm->mem_space.start = a;
+			pbm->mem_space.end = a + (0x80000000UL - 1UL);
+			pbm->mem_space.flags = IORESOURCE_MEM;
+			saw_mem = 1;
+			break;
+
+		default:
+			break;
+		};
+	}
 
-	a += (16UL * 1024UL * 1024UL);
-	pbm->io_space.start = a;
-	pbm->io_space.end = a + ((16UL * 1024UL * 1024UL) - 1UL);
-	pbm->io_space.flags = IORESOURCE_IO;
+	if (!saw_cfg || !saw_io || !saw_mem) {
+		prom_printf("%s: Fatal error, missing %s PBM range.\n",
+			    pbm->name,
+			    ((!saw_cfg ?
+			      "CFG" :
+			      (!saw_io ?
+			       "IO" : "MEM"))));
+		prom_halt();
+	}
+
+	printk("%s: PCI CFG[%lx] IO[%lx] MEM[%lx]\n",
+	       pbm->name,
+	       pbm->config_space,
+	       pbm->io_space.start,
+	       pbm->mem_space.start);
 }
 
 static void __init pbm_register_toplevel_resources(struct pci_controller_info *p,
 						   struct pci_pbm_info *pbm)
 {
-	char *name = pbm->name;
-
-	sprintf(name, "SCHIZO%d PBM%c",
-		p->index,
-		(pbm == &p->pbm_A ? 'A' : 'B'));
-	pbm->io_space.name = pbm->mem_space.name = name;
+	pbm->io_space.name = pbm->mem_space.name = pbm->name;
 
 	request_resource(&ioport_resource, &pbm->io_space);
 	request_resource(&iomem_resource, &pbm->mem_space);
@@ -1539,40 +1723,29 @@
 				    &pbm->mem_space);
 }
 
-#define SCHIZO_STRBUF_CONTROL_A		(SCHIZO_PBM_A_REGS_OFF + 0x02800UL)
-#define SCHIZO_STRBUF_FLUSH_A		(SCHIZO_PBM_A_REGS_OFF + 0x02808UL)
-#define SCHIZO_STRBUF_FSYNC_A		(SCHIZO_PBM_A_REGS_OFF + 0x02810UL)
-#define SCHIZO_STRBUF_CTXFLUSH_A	(SCHIZO_PBM_A_REGS_OFF + 0x02818UL)
-#define SCHIZO_STRBUF_CTXMATCH_A	(SCHIZO_PBM_A_REGS_OFF + 0x10000UL)
-
-#define SCHIZO_STRBUF_CONTROL_B		(SCHIZO_PBM_B_REGS_OFF + 0x02800UL)
-#define SCHIZO_STRBUF_FLUSH_B		(SCHIZO_PBM_B_REGS_OFF + 0x02808UL)
-#define SCHIZO_STRBUF_FSYNC_B		(SCHIZO_PBM_B_REGS_OFF + 0x02810UL)
-#define SCHIZO_STRBUF_CTXFLUSH_B	(SCHIZO_PBM_B_REGS_OFF + 0x02818UL)
-#define SCHIZO_STRBUF_CTXMATCH_B	(SCHIZO_PBM_B_REGS_OFF + 0x10000UL)
-
-static void schizo_pbm_strbuf_init(struct pci_controller_info *p,
-				   struct pci_pbm_info *pbm,
-				   int is_pbm_a)
+#define SCHIZO_STRBUF_CONTROL		(0x02800UL)
+#define SCHIZO_STRBUF_FLUSH		(0x02808UL)
+#define SCHIZO_STRBUF_FSYNC		(0x02810UL)
+#define SCHIZO_STRBUF_CTXFLUSH		(0x02818UL)
+#define SCHIZO_STRBUF_CTXMATCH		(0x10000UL)
+
+static void schizo_pbm_strbuf_init(struct pci_pbm_info *pbm)
 {
-	unsigned long base = p->controller_regs;
+	unsigned long base = pbm->pbm_regs;
 	u64 control;
 
-	/* SCHIZO has context flushing. */
-	if (is_pbm_a) {
-		pbm->stc.strbuf_control		= base + SCHIZO_STRBUF_CONTROL_A;
-		pbm->stc.strbuf_pflush		= base + SCHIZO_STRBUF_FLUSH_A;
-		pbm->stc.strbuf_fsync		= base + SCHIZO_STRBUF_FSYNC_A;
-		pbm->stc.strbuf_ctxflush	= base + SCHIZO_STRBUF_CTXFLUSH_A;
-		pbm->stc.strbuf_ctxmatch_base	= base + SCHIZO_STRBUF_CTXMATCH_A;
-	} else {
-		pbm->stc.strbuf_control		= base + SCHIZO_STRBUF_CONTROL_B;
-		pbm->stc.strbuf_pflush		= base + SCHIZO_STRBUF_FLUSH_B;
-		pbm->stc.strbuf_fsync		= base + SCHIZO_STRBUF_FSYNC_B;
-		pbm->stc.strbuf_ctxflush	= base + SCHIZO_STRBUF_CTXFLUSH_B;
-		pbm->stc.strbuf_ctxmatch_base	= base + SCHIZO_STRBUF_CTXMATCH_B;
+	if (pbm->chip_type == PBM_CHIP_TYPE_TOMATILLO) {
+		/* TOMATILLO lacks streaming cache.  */
+		return;
 	}
 
+	/* SCHIZO has context flushing. */
+	pbm->stc.strbuf_control		= base + SCHIZO_STRBUF_CONTROL;
+	pbm->stc.strbuf_pflush		= base + SCHIZO_STRBUF_FLUSH;
+	pbm->stc.strbuf_fsync		= base + SCHIZO_STRBUF_FSYNC;
+	pbm->stc.strbuf_ctxflush	= base + SCHIZO_STRBUF_CTXFLUSH;
+	pbm->stc.strbuf_ctxmatch_base	= base + SCHIZO_STRBUF_CTXMATCH;
+
 	pbm->stc.strbuf_flushflag = (volatile unsigned long *)
 		((((unsigned long)&pbm->stc.__flushflag_buf[0])
 		  + 63UL)
@@ -1594,48 +1767,63 @@
 	pbm->stc.strbuf_enabled = 1;
 }
 
-#define SCHIZO_IOMMU_CONTROL_A		(SCHIZO_PBM_A_REGS_OFF + 0x00200UL)
-#define SCHIZO_IOMMU_TSBBASE_A		(SCHIZO_PBM_A_REGS_OFF + 0x00208UL)
-#define SCHIZO_IOMMU_FLUSH_A		(SCHIZO_PBM_A_REGS_OFF + 0x00210UL)
-#define SCHIZO_IOMMU_CTXFLUSH_A		(SCHIZO_PBM_A_REGS_OFF + 0x00218UL)
-#define SCHIZO_IOMMU_TAG_A		(SCHIZO_PBM_A_REGS_OFF + 0x0a580UL)
-#define SCHIZO_IOMMU_DATA_A		(SCHIZO_PBM_A_REGS_OFF + 0x0a600UL)
-#define SCHIZO_IOMMU_CONTROL_B		(SCHIZO_PBM_B_REGS_OFF + 0x00200UL)
-#define SCHIZO_IOMMU_TSBBASE_B		(SCHIZO_PBM_B_REGS_OFF + 0x00208UL)
-#define SCHIZO_IOMMU_FLUSH_B		(SCHIZO_PBM_B_REGS_OFF + 0x00210UL)
-#define SCHIZO_IOMMU_CTXFLUSH_B		(SCHIZO_PBM_B_REGS_OFF + 0x00218UL)
-#define SCHIZO_IOMMU_TAG_B		(SCHIZO_PBM_B_REGS_OFF + 0x0a580UL)
-#define SCHIZO_IOMMU_DATA_B		(SCHIZO_PBM_B_REGS_OFF + 0x0a600UL)
-
-static void schizo_pbm_iommu_init(struct pci_controller_info *p,
-				  struct pci_pbm_info *pbm,
-				  int is_pbm_a)
+#define SCHIZO_IOMMU_CONTROL		(0x00200UL)
+#define SCHIZO_IOMMU_TSBBASE		(0x00208UL)
+#define SCHIZO_IOMMU_FLUSH		(0x00210UL)
+#define SCHIZO_IOMMU_CTXFLUSH		(0x00218UL)
+
+static void schizo_pbm_iommu_init(struct pci_pbm_info *pbm)
 {
 	struct pci_iommu *iommu = pbm->iommu;
-	unsigned long tsbbase, i, tagbase, database;
+	unsigned long tsbbase, i, tagbase, database, order;
+	u32 vdma[2], dma_mask;
 	u64 control;
+	int err, tsbsize;
+
+	err = prom_getproperty(pbm->prom_node, "virtual-dma",
+			       (char *)&vdma[0], sizeof(vdma));
+	if (err == 0 || err == -1) {
+		/* No property, use default values. */
+		vdma[0] = 0xc0000000;
+		vdma[1] = 0x40000000;
+	}
+
+	dma_mask = vdma[0];
+	switch (vdma[1]) {
+		case 0x20000000:
+			dma_mask |= 0x1fffffff;
+			tsbsize = 64;
+			break;
+
+		case 0x40000000:
+			dma_mask |= 0x3fffffff;
+			tsbsize = 128;
+			break;
+
+		case 0x80000000:
+			dma_mask |= 0x7fffffff;
+			tsbsize = 128;
+			break;
+
+		default:
+			prom_printf("SCHIZO: strange virtual-dma size.\n");
+			prom_halt();
+	};
 
 	/* Setup initial software IOMMU state. */
 	spin_lock_init(&iommu->lock);
 	iommu->iommu_cur_ctx = 0;
 
 	/* Register addresses, SCHIZO has iommu ctx flushing. */
-	if (is_pbm_a) {
-		iommu->iommu_control  = p->controller_regs + SCHIZO_IOMMU_CONTROL_A;
-		iommu->iommu_tsbbase  = p->controller_regs + SCHIZO_IOMMU_TSBBASE_A;
-		iommu->iommu_flush    = p->controller_regs + SCHIZO_IOMMU_FLUSH_A;
-		iommu->iommu_ctxflush = p->controller_regs + SCHIZO_IOMMU_CTXFLUSH_A;
-	} else {
-		iommu->iommu_control  = p->controller_regs + SCHIZO_IOMMU_CONTROL_B;
-		iommu->iommu_tsbbase  = p->controller_regs + SCHIZO_IOMMU_TSBBASE_B;
-		iommu->iommu_flush    = p->controller_regs + SCHIZO_IOMMU_FLUSH_B;
-		iommu->iommu_ctxflush = p->controller_regs + SCHIZO_IOMMU_CTXFLUSH_B;
-	}
+	iommu->iommu_control  = pbm->pbm_regs + SCHIZO_IOMMU_CONTROL;
+	iommu->iommu_tsbbase  = pbm->pbm_regs + SCHIZO_IOMMU_TSBBASE;
+	iommu->iommu_flush    = pbm->pbm_regs + SCHIZO_IOMMU_FLUSH;
+	iommu->iommu_ctxflush = pbm->pbm_regs + SCHIZO_IOMMU_CTXFLUSH;
 
 	/* We use the main control/status register of SCHIZO as the write
 	 * completion register.
 	 */
-	iommu->write_complete_reg = p->controller_regs + 0x10000UL;
+	iommu->write_complete_reg = pbm->controller_regs + 0x10000UL;
 
 	/*
 	 * Invalidate TLB Entries.
@@ -1644,13 +1832,11 @@
 	control |= SCHIZO_IOMMU_CTRL_DENAB;
 	schizo_write(iommu->iommu_control, control);
 
-	if (is_pbm_a)
-		tagbase = SCHIZO_IOMMU_TAG_A, database = SCHIZO_IOMMU_DATA_A;
-	else
-		tagbase = SCHIZO_IOMMU_TAG_B, database = SCHIZO_IOMMU_DATA_B;
+	tagbase = SCHIZO_IOMMU_TAG, database = SCHIZO_IOMMU_DATA;
+
 	for(i = 0; i < 16; i++) {
-		schizo_write(p->controller_regs + tagbase + (i * 8UL), 0);
-		schizo_write(p->controller_regs + database + (i * 8UL), 0);
+		schizo_write(pbm->pbm_regs + tagbase + (i * 8UL), 0);
+		schizo_write(pbm->pbm_regs + database + (i * 8UL), 0);
 	}
 
 	/* Leave diag mode enabled for full-flushing done
@@ -1661,16 +1847,32 @@
 	 * table (128K ioptes * 8 bytes per iopte).  This is
 	 * page order 7 on UltraSparc.
 	 */
-	tsbbase = __get_free_pages(GFP_KERNEL, get_order(IO_TSB_SIZE));
+	order = get_order(tsbsize * 8 * 1024);
+	tsbbase = __get_free_pages(GFP_KERNEL, order);
 	if (!tsbbase) {
-		prom_printf("SCHIZO_IOMMU: Error, gfp(tsb) failed.\n");
+		prom_printf("%s: Error, gfp(tsb) failed.\n", pbm->name);
 		prom_halt();
 	}
+
 	iommu->page_table = (iopte_t *)tsbbase;
-	iommu->page_table_sz_bits = 17;
-	iommu->page_table_map_base = 0xc0000000;
-	iommu->dma_addr_mask = 0xffffffff;
-	memset((char *)tsbbase, 0, IO_TSB_SIZE);
+	iommu->page_table_map_base = vdma[0];
+	iommu->dma_addr_mask = dma_mask;
+	memset((char *)tsbbase, 0, PAGE_SIZE << order);
+
+	switch (tsbsize) {
+	case 64:
+		iommu->page_table_sz_bits = 16;
+		break;
+
+	case 128:
+		iommu->page_table_sz_bits = 17;
+		break;
+
+	default:
+		prom_printf("iommu_init: Illegal TSB size %d\n", tsbsize);
+		prom_halt();
+		break;
+	};
 
 	/* We start with no consistent mappings. */
 	iommu->lowest_consistent_map =
@@ -1685,28 +1887,194 @@
 
 	control = schizo_read(iommu->iommu_control);
 	control &= ~(SCHIZO_IOMMU_CTRL_TSBSZ | SCHIZO_IOMMU_CTRL_TBWSZ);
-	control |= (SCHIZO_IOMMU_TSBSZ_128K | SCHIZO_IOMMU_CTRL_ENAB);
+	switch (tsbsize) {
+	case 64:
+		control |= SCHIZO_IOMMU_TSBSZ_64K;
+		break;
+	case 128:
+		control |= SCHIZO_IOMMU_TSBSZ_128K;
+		break;
+	};
+
+	control |= SCHIZO_IOMMU_CTRL_ENAB;
 	schizo_write(iommu->iommu_control, control);
 }
 
-static void schizo_pbm_init(struct pci_controller_info *p,
-			    int prom_node, int is_pbm_a)
+#define SCHIZO_PCI_IRQ_RETRY	(0x1a00UL)
+#define  SCHIZO_IRQ_RETRY_INF	 0xffUL
+
+#define SCHIZO_PCI_DIAG			(0x2020UL)
+#define  SCHIZO_PCIDIAG_D_BADECC	(1UL << 10UL) /* Disable BAD ECC errors (Schizo) */
+#define  SCHIZO_PCIDIAG_D_BYPASS	(1UL <<  9UL) /* Disable MMU bypass mode (Schizo/Tomatillo) */
+#define  SCHIZO_PCIDIAG_D_TTO		(1UL <<  8UL) /* Disable TTO errors (Schizo/Tomatillo) */
+#define  SCHIZO_PCIDIAG_D_RTRYARB	(1UL <<  7UL) /* Disable retry arbitration (Schizo) */
+#define  SCHIZO_PCIDIAG_D_RETRY		(1UL <<  6UL) /* Disable retry limit (Schizo/Tomatillo) */
+#define  SCHIZO_PCIDIAG_D_INTSYNC	(1UL <<  5UL) /* Disable interrupt/DMA synch (Schizo/Tomatillo) */
+#define  SCHIZO_PCIDIAG_I_DMA_PARITY	(1UL <<  3UL) /* Invert DMA parity (Schizo/Tomatillo) */
+#define  SCHIZO_PCIDIAG_I_PIOD_PARITY	(1UL <<  2UL) /* Invert PIO data parity (Schizo/Tomatillo) */
+#define  SCHIZO_PCIDIAG_I_PIOA_PARITY	(1UL <<  1UL) /* Invert PIO address parity (Schizo/Tomatillo) */
+
+#define TOMATILLO_PCI_IOC_CSR		(0x2248UL)
+#define TOMATILLO_IOC_PART_WPENAB	0x0000000000080000UL
+#define TOMATILLO_IOC_RDMULT_PENAB	0x0000000000040000UL
+#define TOMATILLO_IOC_RDONE_PENAB	0x0000000000020000UL
+#define TOMATILLO_IOC_RDLINE_PENAB	0x0000000000010000UL
+#define TOMATILLO_IOC_RDMULT_PLEN	0x000000000000c000UL
+#define TOMATILLO_IOC_RDMULT_PLEN_SHIFT	14UL
+#define TOMATILLO_IOC_RDONE_PLEN	0x0000000000003000UL
+#define TOMATILLO_IOC_RDONE_PLEN_SHIFT	12UL
+#define TOMATILLO_IOC_RDLINE_PLEN	0x0000000000000c00UL
+#define TOMATILLO_IOC_RDLINE_PLEN_SHIFT	10UL
+#define TOMATILLO_IOC_PREF_OFF		0x00000000000003f8UL
+#define TOMATILLO_IOC_PREF_OFF_SHIFT	3UL
+#define TOMATILLO_IOC_RDMULT_CPENAB	0x0000000000000004UL
+#define TOMATILLO_IOC_RDONE_CPENAB	0x0000000000000002UL
+#define TOMATILLO_IOC_RDLINE_CPENAB	0x0000000000000001UL
+
+#define TOMATILLO_PCI_IOC_TDIAG		(0x2250UL)
+#define TOMATILLO_PCI_IOC_DDIAG		(0x2290UL)
+
+static void __init schizo_pbm_hw_init(struct pci_pbm_info *pbm)
 {
+	u64 tmp;
+
+	/* Set IRQ retry to infinity. */
+	schizo_write(pbm->pbm_regs + SCHIZO_PCI_IRQ_RETRY,
+		     SCHIZO_IRQ_RETRY_INF);
+
+	/* Enable arbiter for all PCI slots.  Also, disable PCI interval
+	 * timer so that DTO (Discard TimeOuts) are not reported because
+	 * some Schizo revisions report them erroneously.
+	 */
+	tmp = schizo_read(pbm->pbm_regs + SCHIZO_PCI_CTRL);
+	if (pbm->chip_type == PBM_CHIP_TYPE_SCHIZO_PLUS &&
+	    pbm->chip_version == 0x5 &&
+	    pbm->chip_revision == 0x1)
+		tmp |= 0x0f;
+	else
+		tmp |= 0xff;
+
+	tmp &= ~SCHIZO_PCICTRL_PTO;
+	if (pbm->chip_type == PBM_CHIP_TYPE_TOMATILLO &&
+	    pbm->chip_version == 0x2)
+		tmp |= 0x3UL << SCHIZO_PCICTRL_PTO_SHIFT;
+	else
+		tmp |= 0x1UL << SCHIZO_PCICTRL_PTO_SHIFT;
+
+	if (!prom_getbool(pbm->prom_node, "no-bus-parking"))
+		tmp |= SCHIZO_PCICTRL_PARK;
+
+	if (pbm->chip_type == PBM_CHIP_TYPE_TOMATILLO)
+		tmp |= SCHIZO_PCICTRL_MRM_PREF;
+
+	schizo_write(pbm->pbm_regs + SCHIZO_PCI_CTRL, tmp);
+
+	tmp = schizo_read(pbm->pbm_regs + SCHIZO_PCI_DIAG);
+	tmp &= ~(SCHIZO_PCIDIAG_D_RTRYARB |
+		 SCHIZO_PCIDIAG_D_RETRY |
+		 SCHIZO_PCIDIAG_D_INTSYNC);
+	schizo_write(pbm->pbm_regs + SCHIZO_PCI_DIAG, tmp);
+
+	if (pbm->chip_type == PBM_CHIP_TYPE_TOMATILLO) {
+		/* Clear prefetch lengths to workaround a bug in
+		 * Jalapeno...
+		 */
+		tmp = (TOMATILLO_IOC_PART_WPENAB |
+		       (1 << TOMATILLO_IOC_PREF_OFF_SHIFT) |
+		       TOMATILLO_IOC_RDMULT_CPENAB |
+		       TOMATILLO_IOC_RDONE_CPENAB |
+		       TOMATILLO_IOC_RDLINE_CPENAB);
+
+		schizo_write(pbm->pbm_regs + TOMATILLO_PCI_IOC_CSR,
+			     tmp);
+	}
+}
+
+static void __init schizo_pbm_init(struct pci_controller_info *p,
+				   int prom_node, u32 portid,
+				   int chip_type)
+{
+	struct linux_prom64_registers pr_regs[4];
 	unsigned int busrange[2];
 	struct pci_pbm_info *pbm;
+	const char *chipset_name;
+	u32 ino_bitmap[2];
+	int is_pbm_a;
 	int err;
 
+	switch (chip_type) {
+	case PBM_CHIP_TYPE_TOMATILLO:
+		chipset_name = "TOMATILLO";
+		break;
+
+	case PBM_CHIP_TYPE_SCHIZO_PLUS:
+		chipset_name = "SCHIZO+";
+		break;
+
+	case PBM_CHIP_TYPE_SCHIZO:
+	default:
+		chipset_name = "SCHIZO";
+		break;
+	};
+
+	/* For SCHIZO, three OBP regs:
+	 * 1) PBM controller regs
+	 * 2) Schizo front-end controller regs (same for both PBMs)
+	 * 3) PBM PCI config space
+	 *
+	 * For TOMATILLO, four OBP regs:
+	 * 1) PBM controller regs
+	 * 2) Tomatillo front-end controller regs
+	 * 3) PBM PCI config space
+	 * 4) Ichip regs
+	 */
+	err = prom_getproperty(prom_node, "reg",
+			       (char *)&pr_regs[0],
+			       sizeof(pr_regs));
+	if (err == 0 || err == -1) {
+		prom_printf("%s: Fatal error, no reg property.\n",
+			    chipset_name);
+		prom_halt();
+	}
+
+	is_pbm_a = ((pr_regs[0].phys_addr & 0x00700000) == 0x00600000);
+
 	if (is_pbm_a)
 		pbm = &p->pbm_A;
 	else
 		pbm = &p->pbm_B;
 
-	schizo_determine_mem_io_space(pbm, is_pbm_a, p->controller_regs);
-	pbm_register_toplevel_resources(p, pbm);
-
+	pbm->portid = portid;
 	pbm->parent = p;
 	pbm->prom_node = prom_node;
 	pbm->pci_first_slot = 1;
+
+	pbm->chip_type = chip_type;
+	pbm->chip_version =
+		prom_getintdefault(prom_node, "version#", 0);
+	pbm->chip_revision =
+		prom_getintdefault(prom_node, "module-revision#", 0);
+
+	pbm->pbm_regs = pr_regs[0].phys_addr;
+	pbm->controller_regs = pr_regs[1].phys_addr - 0x10000UL;
+
+	sprintf(pbm->name,
+		(chip_type == PBM_CHIP_TYPE_TOMATILLO ?
+		 "TOMATILLO%d PBM%c" :
+		 "SCHIZO%d PBM%c"),
+		p->index,
+		(pbm == &p->pbm_A ? 'A' : 'B'));
+
+	printk("%s: ver[%x:%x], portid %x, "
+	       "cregs[%lx] pregs[%lx]\n",
+	       pbm->name,
+	       pbm->chip_version, pbm->chip_revision,
+	       pbm->portid,
+	       pbm->controller_regs,
+	       pbm->pbm_regs);
+
+	schizo_pbm_hw_init(pbm);
+
 	prom_getstring(prom_node, "name",
 		       pbm->prom_name,
 		       sizeof(pbm->prom_name));
@@ -1714,11 +2082,17 @@
 	err = prom_getproperty(prom_node, "ranges",
 			       (char *) pbm->pbm_ranges,
 			       sizeof(pbm->pbm_ranges));
-	if (err != -1)
-		pbm->num_pbm_ranges =
-			(err / sizeof(struct linux_prom_pci_ranges));
-	else
-		pbm->num_pbm_ranges = 0;
+	if (err == 0 || err == -1) {
+		prom_printf("%s: Fatal error, no ranges property.\n",
+			    pbm->name);
+		prom_halt();
+	}
+
+	pbm->num_pbm_ranges =
+		(err / sizeof(struct linux_prom_pci_ranges));
+
+	schizo_determine_mem_io_space(pbm);
+	pbm_register_toplevel_resources(p, pbm);
 
 	err = prom_getproperty(prom_node, "interrupt-map",
 			       (char *)pbm->pbm_intmap,
@@ -1729,8 +2103,8 @@
 				       (char *)&pbm->pbm_intmask,
 				       sizeof(pbm->pbm_intmask));
 		if (err == -1) {
-			prom_printf("SCHIZO-PBM: Fatal error, no "
-				    "interrupt-map-mask.\n");
+			prom_printf("%s: Fatal error, no "
+				    "interrupt-map-mask.\n", pbm->name);
 			prom_halt();
 		}
 	} else {
@@ -1738,95 +2112,65 @@
 		memset(&pbm->pbm_intmask, 0, sizeof(pbm->pbm_intmask));
 	}
 
+	err = prom_getproperty(prom_node, "ino-bitmap",
+			       (char *) &ino_bitmap[0],
+			       sizeof(ino_bitmap));
+	if (err == 0 || err == -1) {
+		prom_printf("%s: Fatal error, no ino-bitmap.\n", pbm->name);
+		prom_halt();
+	}
+	pbm->ino_bitmap = (((u64)ino_bitmap[1] << 32UL) |
+			   ((u64)ino_bitmap[0] <<  0UL));
+
 	err = prom_getproperty(prom_node, "bus-range",
 			       (char *)&busrange[0],
 			       sizeof(busrange));
 	if (err == 0 || err == -1) {
-		prom_printf("SCHIZO-PBM: Fatal error, no bus-range.\n");
+		prom_printf("%s: Fatal error, no bus-range.\n", pbm->name);
 		prom_halt();
 	}
 	pbm->pci_first_busno = busrange[0];
 	pbm->pci_last_busno = busrange[1];
 
-	schizo_pbm_iommu_init(p, pbm, is_pbm_a);
-	schizo_pbm_strbuf_init(p, pbm, is_pbm_a);
+	schizo_pbm_iommu_init(pbm);
+	schizo_pbm_strbuf_init(pbm);
 }
 
-#define SCHIZO_PCIA_IRQ_RETRY	(SCHIZO_PBM_A_REGS_OFF + 0x1a00UL)
-#define SCHIZO_PCIB_IRQ_RETRY	(SCHIZO_PBM_B_REGS_OFF + 0x1a00UL)
-#define  SCHIZO_IRQ_RETRY_INF	 0xffUL
-
-#define SCHIZO_PCIA_DIAG	(SCHIZO_PBM_A_REGS_OFF + 0x2020UL)
-#define SCHIZO_PCIB_DIAG	(SCHIZO_PBM_B_REGS_OFF + 0x2020UL)
-#define  SCHIZO_PCIDIAG_D_BADECC	(1UL << 10UL) /* Disable BAD ECC errors */
-#define  SCHIZO_PCIDIAG_D_BYPASS	(1UL <<  9UL) /* Disable MMU bypass mode */
-#define  SCHIZO_PCIDIAG_D_TTO		(1UL <<  8UL) /* Disable TTO errors */
-#define  SCHIZO_PCIDIAG_D_RTRYARB	(1UL <<  7UL) /* Disable retry arbitration */
-#define  SCHIZO_PCIDIAG_D_RETRY		(1UL <<  6UL) /* Disable retry limit */
-#define  SCHIZO_PCIDIAG_D_INTSYNC	(1UL <<  5UL) /* Disable interrupt/DMA synch */
-#define  SCHIZO_PCIDIAG_I_DMA_PARITY	(1UL <<  3UL) /* Invert DMA parity */
-#define  SCHIZO_PCIDIAG_I_PIOD_PARITY	(1UL <<  2UL) /* Invert PIO data parity */
-#define  SCHIZO_PCIDIAG_I_PIOA_PARITY	(1UL <<  1U)L /* Invert PIO address parity */
-
-static void schizo_controller_hwinit(struct pci_controller_info *p)
+static inline int portid_compare(u32 x, u32 y, int chip_type)
 {
-	unsigned long pbm_a_base, pbm_b_base;
-	u64 tmp;
-
-	pbm_a_base = p->controller_regs + SCHIZO_PBM_A_REGS_OFF;
-	pbm_b_base = p->controller_regs + SCHIZO_PBM_B_REGS_OFF;
-
-	/* Set IRQ retry to infinity. */
-	schizo_write(p->controller_regs + SCHIZO_PCIA_IRQ_RETRY,
-		     SCHIZO_IRQ_RETRY_INF);
-	schizo_write(p->controller_regs + SCHIZO_PCIB_IRQ_RETRY,
-		     SCHIZO_IRQ_RETRY_INF);
-
-	/* Enable arbiter for all PCI slots.  Also, disable PCI interval
-	 * timer so that DTO (Discard TimeOuts) are not reported because
-	 * some Schizo revisions report them erroneously.
-	 */
-
-	tmp = schizo_read(p->controller_regs + SCHIZO_PCIA_CTRL);
-	tmp |= SCHIZO_PCICTRL_ARB;
-	tmp &= ~SCHIZO_PCICTRL_PTO;
-	schizo_write(p->controller_regs + SCHIZO_PCIA_CTRL, tmp);
-
-	tmp = schizo_read(p->controller_regs + SCHIZO_PCIB_CTRL);
-	tmp |= SCHIZO_PCICTRL_ARB;
-	tmp &= ~SCHIZO_PCICTRL_PTO;
-	schizo_write(p->controller_regs + SCHIZO_PCIB_CTRL, tmp);
-
-	/* Disable TTO error reporting (won't happen anyway since we
-	 * disabled the PCI interval timer above) and retry arbitration
-	 * (can cause hangs in some Schizo revisions).
-	 */
-	tmp = schizo_read(p->controller_regs + SCHIZO_PCIA_DIAG);
-	tmp |= (SCHIZO_PCIDIAG_D_TTO | SCHIZO_PCIDIAG_D_RTRYARB);
-	schizo_write(p->controller_regs + SCHIZO_PCIA_DIAG, tmp);
-
-	tmp = schizo_read(p->controller_regs + SCHIZO_PCIB_DIAG);
-	tmp |= (SCHIZO_PCIDIAG_D_TTO | SCHIZO_PCIDIAG_D_RTRYARB);
-	schizo_write(p->controller_regs + SCHIZO_PCIB_DIAG, tmp);
+	if (chip_type == PBM_CHIP_TYPE_TOMATILLO) {
+		if (x == (y ^ 1))
+			return 1;
+		return 0;
+	}
+	return (x == y);
 }
 
-void __init schizo_init(int node, char *model_name)
+static void __init __schizo_init(int node, char *model_name, int chip_type)
 {
-	struct linux_prom64_registers pr_regs[3];
 	struct pci_controller_info *p;
 	struct pci_iommu *iommu;
 	unsigned long flags;
+	int is_pbm_a;
 	u32 portid;
-	int is_pbm_a, err;
 
 	portid = prom_getintdefault(node, "portid", 0xff);
 
 	spin_lock_irqsave(&pci_controller_lock, flags);
 	for(p = pci_controller_root; p; p = p->next) {
-		if (p->portid == portid) {
+		struct pci_pbm_info *pbm;
+
+		if (p->pbm_A.prom_node && p->pbm_B.prom_node)
+			continue;
+
+		pbm = (p->pbm_A.prom_node ?
+		       &p->pbm_A :
+		       &p->pbm_B);
+
+		if (portid_compare(pbm->portid, portid, chip_type)) {
 			spin_unlock_irqrestore(&pci_controller_lock, flags);
 			is_pbm_a = (p->pbm_A.prom_node == 0);
-			schizo_pbm_init(p, node, is_pbm_a);
+			schizo_pbm_init(p, node, portid, chip_type);
 			return;
 		}
 	}
@@ -1860,38 +2204,33 @@
 	pci_controller_root = p;
 	spin_unlock_irqrestore(&pci_controller_lock, flags);
 
-	p->portid = portid;
 	p->index = pci_num_controllers++;
 	p->pbms_same_domain = 0;
-	p->scan_bus = schizo_scan_bus;
+	p->scan_bus = (chip_type == PBM_CHIP_TYPE_TOMATILLO ?
+		       tomatillo_scan_bus :
+		       schizo_scan_bus);
 	p->irq_build = schizo_irq_build;
 	p->base_address_update = schizo_base_address_update;
 	p->resource_adjust = schizo_resource_adjust;
 	p->pci_ops = &schizo_ops;
 
-	/* Three OBP regs:
-	 * 1) PBM controller regs
-	 * 2) Schizo front-end controller regs (same for both PBMs)
-	 * 3) PBM PCI config space
-	 */
-	err = prom_getproperty(node, "reg",
-			       (char *)&pr_regs[0],
-			       sizeof(pr_regs));
-	if (err == 0 || err == -1) {
-		prom_printf("SCHIZO: Fatal error, no reg property.\n");
-		prom_halt();
-	}
-
-	p->controller_regs = pr_regs[1].phys_addr - 0x10000UL;
-	printk("PCI: Found SCHIZO, control regs at %016lx\n",
-	       p->controller_regs);
-
 	/* Like PSYCHO we have a 2GB aligned area for memory space. */
 	pci_memspace_mask = 0x7fffffffUL;
 
-	/* Init core controller. */
-	schizo_controller_hwinit(p);
+	schizo_pbm_init(p, node, portid, chip_type);
+}
 
-	is_pbm_a = ((pr_regs[0].phys_addr & 0x00700000) == 0x00600000);
-	schizo_pbm_init(p, node, is_pbm_a);
+void __init schizo_init(int node, char *model_name)
+{
+	__schizo_init(node, model_name, PBM_CHIP_TYPE_SCHIZO);
+}
+
+void __init schizo_plus_init(int node, char *model_name)
+{
+	__schizo_init(node, model_name, PBM_CHIP_TYPE_SCHIZO_PLUS);
+}
+
+void __init tomatillo_init(int node, char *model_name)
+{
+	__schizo_init(node, model_name, PBM_CHIP_TYPE_TOMATILLO);
 }
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/setup.c linux-2.4.23-pre1/arch/sparc64/kernel/setup.c
--- linux-2.4.22/arch/sparc64/kernel/setup.c	2002-11-28 23:53:12.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/setup.c	2003-08-27 14:40:06.000000000 +0000
@@ -604,8 +604,8 @@
 
 /* BUFFER is PAGE_SIZE bytes long. */
 
-extern char *sparc_cpu_type[];
-extern char *sparc_fpu_type[];
+extern char *sparc_cpu_type;
+extern char *sparc_fpu_type;
 
 extern void smp_info(struct seq_file *);
 extern void smp_bogo(struct seq_file *);
@@ -617,8 +617,6 @@
 
 static int show_cpuinfo(struct seq_file *m, void *__unused)
 {
-	int cpuid = smp_processor_id();
-
 	seq_printf(m, 
 		   "cpu\t\t: %s\n"
 		   "fpu\t\t: %s\n"
@@ -632,8 +630,8 @@
 		   "Cpu0ClkTck\t: %016lx\n"
 #endif
 		   ,
-		   sparc_cpu_type[cpuid],
-		   sparc_fpu_type[cpuid],
+		   sparc_cpu_type,
+		   sparc_fpu_type,
 		   prom_rev,
 		   prom_prev >> 16,
 		   (prom_prev >> 8) & 0xff,
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/smp.c linux-2.4.23-pre1/arch/sparc64/kernel/smp.c
--- linux-2.4.22/arch/sparc64/kernel/smp.c	2003-06-13 14:51:32.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/smp.c	2003-08-27 14:39:12.000000000 +0000
@@ -133,7 +133,6 @@
 static volatile unsigned long callin_flag = 0;
 
 extern void inherit_locked_prom_mappings(int save_p);
-extern void cpu_probe(void);
 
 void __init smp_callin(void)
 {
@@ -153,8 +152,6 @@
 	__flush_cache_all();
 	__flush_tlb_all();
 
-	cpu_probe();
-
 	smp_setup_percpu_timer();
 
 	__sti();
@@ -537,12 +534,19 @@
 #endif
 static void cheetah_xcall_deliver(u64 data0, u64 data1, u64 data2, unsigned long mask)
 {
-	u64 pstate;
-	int nack_busy_id;
+	u64 pstate, ver;
+	int nack_busy_id, is_jalapeno;
 
 	if (!mask)
 		return;
 
+	/* Unfortunately, someone at Sun had the brilliant idea to make the
+	 * busy/nack fields hard-coded by ITID number for this Ultra-III
+	 * derivative processor.
+	 */
+	__asm__ ("rdpr %%ver, %0" : "=r" (ver));
+	is_jalapeno = ((ver >> 32) == 0x003e0016);
+
 	__asm__ __volatile__("rdpr %%pstate, %0" : "=r" (pstate));
 
 retry:
@@ -567,11 +571,13 @@
 			if (mask & (1UL << i)) {
 				u64 target = (i << 14) | 0x70;
 
-				target |= (nack_busy_id++ << 24);
+				if (!is_jalapeno)
+					target |= (nack_busy_id << 24);
 				__asm__ __volatile__("stxa	%%g0, [%0] %1\n\t"
 						     "membar	#Sync\n\t"
 						     : /* no outputs */
 						     : "r" (target), "i" (ASI_INTR_W));
+				nack_busy_id++;
 				ncpus--;
 			}
 		}
@@ -618,7 +624,14 @@
 			 */
 			for (i = 0; i < NR_CPUS; i++) {
 				if (mask & (1UL << i)) {
-					if ((dispatch_stat & (0x2 << this_busy_nack)) == 0)
+					u64 check_mask;
+
+					if (is_jalapeno)
+						check_mask = (0x2UL << (2*i));
+					else
+						check_mask = (0x2UL <<
+							      this_busy_nack);
+					if ((dispatch_stat & check_mask) == 0)
 						mask &= ~(1UL << i);
 					this_busy_nack += 2;
 				}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/time.c linux-2.4.23-pre1/arch/sparc64/kernel/time.c
--- linux-2.4.22/arch/sparc64/kernel/time.c	2003-06-13 14:51:32.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/time.c	2003-08-27 14:40:31.000000000 +0000
@@ -775,6 +775,7 @@
 		    strcmp(model, "mk48t08") &&
 		    strcmp(model, "mk48t59") &&
 		    strcmp(model, "m5819") &&
+		    strcmp(model, "m5819p") &&
 		    strcmp(model, "ds1287")) {
 			if (cbus != NULL) {
 				prom_printf("clock_probe: Central bus lacks timer chip.\n");
@@ -833,7 +834,8 @@
 			}
 
 			if (!strcmp(model, "ds1287") ||
-			    !strcmp(model, "m5819")) {
+			    !strcmp(model, "m5819") ||
+			    !strcmp(model, "m5819p")) {
 				ds1287_regs = edev->resource[0].start;
 			} else {
 				mstk48t59_regs = edev->resource[0].start;
@@ -853,7 +855,8 @@
 				prom_halt();
 			}
 			if (!strcmp(model, "ds1287") ||
-			    !strcmp(model, "m5819")) {
+			    !strcmp(model, "m5819") ||
+			    !strcmp(model, "m5819p")) {
 				ds1287_regs = isadev->resource.start;
 			} else {
 				mstk48t59_regs = isadev->resource.start;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/traps.c linux-2.4.23-pre1/arch/sparc64/kernel/traps.c
--- linux-2.4.22/arch/sparc64/kernel/traps.c	2003-06-13 14:51:32.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/traps.c	2003-08-27 14:41:52.000000000 +0000
@@ -401,6 +401,179 @@
 };
 #define CHAFSR_INVALID		((u64)-1L)
 
+/* This table is ordered in priority of errors and matches the
+ * AFAR overwrite policy as well.
+ */
+
+struct afsr_error_table {
+	unsigned long mask;
+	const char *name;
+};
+
+static const char CHAFSR_PERR_msg[] =
+	"System interface protocol error";
+static const char CHAFSR_IERR_msg[] =
+	"Internal processor error";
+static const char CHAFSR_ISAP_msg[] =
+	"System request parity error on incoming addresss";
+static const char CHAFSR_UCU_msg[] =
+	"Uncorrectable E-cache ECC error for ifetch/data";
+static const char CHAFSR_UCC_msg[] =
+	"SW Correctable E-cache ECC error for ifetch/data";
+static const char CHAFSR_UE_msg[] =
+	"Uncorrectable system bus data ECC error for read";
+static const char CHAFSR_EDU_msg[] =
+	"Uncorrectable E-cache ECC error for stmerge/blkld";
+static const char CHAFSR_EMU_msg[] =
+	"Uncorrectable system bus MTAG error";
+static const char CHAFSR_WDU_msg[] =
+	"Uncorrectable E-cache ECC error for writeback";
+static const char CHAFSR_CPU_msg[] =
+	"Uncorrectable ECC error for copyout";
+static const char CHAFSR_CE_msg[] =
+	"HW corrected system bus data ECC error for read";
+static const char CHAFSR_EDC_msg[] =
+	"HW corrected E-cache ECC error for stmerge/blkld";
+static const char CHAFSR_EMC_msg[] =
+	"HW corrected system bus MTAG ECC error";
+static const char CHAFSR_WDC_msg[] =
+	"HW corrected E-cache ECC error for writeback";
+static const char CHAFSR_CPC_msg[] =
+	"HW corrected ECC error for copyout";
+static const char CHAFSR_TO_msg[] =
+	"Unmapped error from system bus";
+static const char CHAFSR_BERR_msg[] =
+	"Bus error response from system bus";
+static const char CHAFSR_IVC_msg[] =
+	"HW corrected system bus data ECC error for ivec read";
+static const char CHAFSR_IVU_msg[] =
+	"Uncorrectable system bus data ECC error for ivec read";
+static struct afsr_error_table __cheetah_error_table[] = {
+	{	CHAFSR_PERR,	CHAFSR_PERR_msg		},
+	{	CHAFSR_IERR,	CHAFSR_IERR_msg		},
+	{	CHAFSR_ISAP,	CHAFSR_ISAP_msg		},
+	{	CHAFSR_UCU,	CHAFSR_UCU_msg		},
+	{	CHAFSR_UCC,	CHAFSR_UCC_msg		},
+	{	CHAFSR_UE,	CHAFSR_UE_msg		},
+	{	CHAFSR_EDU,	CHAFSR_EDU_msg		},
+	{	CHAFSR_EMU,	CHAFSR_EMU_msg		},
+	{	CHAFSR_WDU,	CHAFSR_WDU_msg		},
+	{	CHAFSR_CPU,	CHAFSR_CPU_msg		},
+	{	CHAFSR_CE,	CHAFSR_CE_msg		},
+	{	CHAFSR_EDC,	CHAFSR_EDC_msg		},
+	{	CHAFSR_EMC,	CHAFSR_EMC_msg		},
+	{	CHAFSR_WDC,	CHAFSR_WDC_msg		},
+	{	CHAFSR_CPC,	CHAFSR_CPC_msg		},
+	{	CHAFSR_TO,	CHAFSR_TO_msg		},
+	{	CHAFSR_BERR,	CHAFSR_BERR_msg		},
+	/* These two do not update the AFAR. */
+	{	CHAFSR_IVC,	CHAFSR_IVC_msg		},
+	{	CHAFSR_IVU,	CHAFSR_IVU_msg		},
+	{	0,		NULL			},
+};
+static const char CHPAFSR_DTO_msg[] =
+	"System bus unmapped error for prefetch/storequeue-read";
+static const char CHPAFSR_DBERR_msg[] =
+	"System bus error for prefetch/storequeue-read";
+static const char CHPAFSR_THCE_msg[] =
+	"Hardware corrected E-cache Tag ECC error";
+static const char CHPAFSR_TSCE_msg[] =
+	"SW handled correctable E-cache Tag ECC error";
+static const char CHPAFSR_TUE_msg[] =
+	"Uncorrectable E-cache Tag ECC error";
+static const char CHPAFSR_DUE_msg[] =
+	"System bus uncorrectable data ECC error due to prefetch/store-fill";
+static struct afsr_error_table __cheetah_plus_error_table[] = {
+	{	CHAFSR_PERR,	CHAFSR_PERR_msg		},
+	{	CHAFSR_IERR,	CHAFSR_IERR_msg		},
+	{	CHAFSR_ISAP,	CHAFSR_ISAP_msg		},
+	{	CHAFSR_UCU,	CHAFSR_UCU_msg		},
+	{	CHAFSR_UCC,	CHAFSR_UCC_msg		},
+	{	CHAFSR_UE,	CHAFSR_UE_msg		},
+	{	CHAFSR_EDU,	CHAFSR_EDU_msg		},
+	{	CHAFSR_EMU,	CHAFSR_EMU_msg		},
+	{	CHAFSR_WDU,	CHAFSR_WDU_msg		},
+	{	CHAFSR_CPU,	CHAFSR_CPU_msg		},
+	{	CHAFSR_CE,	CHAFSR_CE_msg		},
+	{	CHAFSR_EDC,	CHAFSR_EDC_msg		},
+	{	CHAFSR_EMC,	CHAFSR_EMC_msg		},
+	{	CHAFSR_WDC,	CHAFSR_WDC_msg		},
+	{	CHAFSR_CPC,	CHAFSR_CPC_msg		},
+	{	CHAFSR_TO,	CHAFSR_TO_msg		},
+	{	CHAFSR_BERR,	CHAFSR_BERR_msg		},
+	{	CHPAFSR_DTO,	CHPAFSR_DTO_msg		},
+	{	CHPAFSR_DBERR,	CHPAFSR_DBERR_msg	},
+	{	CHPAFSR_THCE,	CHPAFSR_THCE_msg	},
+	{	CHPAFSR_TSCE,	CHPAFSR_TSCE_msg	},
+	{	CHPAFSR_TUE,	CHPAFSR_TUE_msg		},
+	{	CHPAFSR_DUE,	CHPAFSR_DUE_msg		},
+	/* These two do not update the AFAR. */
+	{	CHAFSR_IVC,	CHAFSR_IVC_msg		},
+	{	CHAFSR_IVU,	CHAFSR_IVU_msg		},
+	{	0,		NULL			},
+};
+static const char JPAFSR_JETO_msg[] =
+	"System interface protocol error, hw timeout caused";
+static const char JPAFSR_SCE_msg[] =
+	"Parity error on system snoop results";
+static const char JPAFSR_JEIC_msg[] =
+	"System interface protocol error, illegal command detected";
+static const char JPAFSR_JEIT_msg[] =
+	"System interface protocol error, illegal ADTYPE detected";
+static const char JPAFSR_OM_msg[] =
+	"Out of range memory error has occurred";
+static const char JPAFSR_ETP_msg[] =
+	"Parity error on L2 cache tag SRAM";
+static const char JPAFSR_UMS_msg[] =
+	"Error due to unsupported store";
+static const char JPAFSR_RUE_msg[] =
+	"Uncorrectable ECC error from remote cache/memory";
+static const char JPAFSR_RCE_msg[] =
+	"Correctable ECC error from remote cache/memory";
+static const char JPAFSR_BP_msg[] =
+	"JBUS parity error on returned read data";
+static const char JPAFSR_WBP_msg[] =
+	"JBUS parity error on data for writeback or block store";
+static const char JPAFSR_FRC_msg[] =
+	"Foreign read to DRAM incurring correctable ECC error";
+static const char JPAFSR_FRU_msg[] =
+	"Foreign read to DRAM incurring uncorrectable ECC error";
+static struct afsr_error_table __jalapeno_error_table[] = {
+	{	JPAFSR_JETO,	JPAFSR_JETO_msg		},
+	{	JPAFSR_SCE,	JPAFSR_SCE_msg		},
+	{	JPAFSR_JEIC,	JPAFSR_JEIC_msg		},
+	{	JPAFSR_JEIT,	JPAFSR_JEIT_msg		},
+	{	CHAFSR_PERR,	CHAFSR_PERR_msg		},
+	{	CHAFSR_IERR,	CHAFSR_IERR_msg		},
+	{	CHAFSR_ISAP,	CHAFSR_ISAP_msg		},
+	{	CHAFSR_UCU,	CHAFSR_UCU_msg		},
+	{	CHAFSR_UCC,	CHAFSR_UCC_msg		},
+	{	CHAFSR_UE,	CHAFSR_UE_msg		},
+	{	CHAFSR_EDU,	CHAFSR_EDU_msg		},
+	{	JPAFSR_OM,	JPAFSR_OM_msg		},
+	{	CHAFSR_WDU,	CHAFSR_WDU_msg		},
+	{	CHAFSR_CPU,	CHAFSR_CPU_msg		},
+	{	CHAFSR_CE,	CHAFSR_CE_msg		},
+	{	CHAFSR_EDC,	CHAFSR_EDC_msg		},
+	{	JPAFSR_ETP,	JPAFSR_ETP_msg		},
+	{	CHAFSR_WDC,	CHAFSR_WDC_msg		},
+	{	CHAFSR_CPC,	CHAFSR_CPC_msg		},
+	{	CHAFSR_TO,	CHAFSR_TO_msg		},
+	{	CHAFSR_BERR,	CHAFSR_BERR_msg		},
+	{	JPAFSR_UMS,	JPAFSR_UMS_msg		},
+	{	JPAFSR_RUE,	JPAFSR_RUE_msg		},
+	{	JPAFSR_RCE,	JPAFSR_RCE_msg		},
+	{	JPAFSR_BP,	JPAFSR_BP_msg		},
+	{	JPAFSR_WBP,	JPAFSR_WBP_msg		},
+	{	JPAFSR_FRC,	JPAFSR_FRC_msg		},
+	{	JPAFSR_FRU,	JPAFSR_FRU_msg		},
+	/* These two do not update the AFAR. */
+	{	CHAFSR_IVU,	CHAFSR_IVU_msg		},
+	{	0,		NULL			},
+};
+static struct afsr_error_table *cheetah_error_table;
+static unsigned long cheetah_afsr_errors;
+
 /* This is allocated at boot time based upon the largest hardware
  * cpu ID in the system.  We allocate two entries per cpu, one for
  * TL==0 logging and one for TL >= 1 logging.
@@ -436,7 +609,7 @@
 
 void cheetah_ecache_flush_init(void)
 {
-	unsigned long largest_size, smallest_linesize, order;
+	unsigned long largest_size, smallest_linesize, order, ver;
 	char type[16];
 	int node, highest_cpu, i;
 
@@ -522,6 +695,18 @@
 	for (i = 0; i < 2 * highest_cpu; i++)
 		cheetah_error_log[i].afsr = CHAFSR_INVALID;
 
+	__asm__ ("rdpr %%ver, %0" : "=r" (ver));
+	if ((ver >> 32) == 0x003e0016) {
+		cheetah_error_table = &__jalapeno_error_table[0];
+		cheetah_afsr_errors = JPAFSR_ERRORS;
+	} else if ((ver >> 32) == 0x003e0015) {
+		cheetah_error_table = &__cheetah_plus_error_table[0];
+		cheetah_afsr_errors = CHPAFSR_ERRORS;
+	} else {
+		cheetah_error_table = &__cheetah_error_table[0];
+		cheetah_afsr_errors = CHAFSR_ERRORS;
+	}
+
 	/* Now patch trap tables. */
 	memcpy(tl0_fecc, cheetah_fecc_trap_vector, (8 * 4));
 	memcpy(tl1_fecc, cheetah_fecc_trap_vector_tl1, (8 * 4));
@@ -720,36 +905,6 @@
        NONE, NONE
 };
 
-/* This table is ordered in priority of errors and matches the
- * AFAR overwrite policy as well.
- */
-static struct {
-	unsigned long mask;
-	char *name;
-} cheetah_error_table[] = {
-	{	CHAFSR_PERR,	"System interface protocol error"			},
-	{	CHAFSR_IERR,	"Internal processor error"				},
-	{	CHAFSR_ISAP,	"System request parity error on incoming addresss"	},
-	{	CHAFSR_UCU,	"Uncorrectable E-cache ECC error for ifetch/data"	},
-	{	CHAFSR_UCC,	"SW Correctable E-cache ECC error for ifetch/data"	},
-	{	CHAFSR_UE,	"Uncorrectable system bus data ECC error for read"	},
-	{	CHAFSR_EDU,	"Uncorrectable E-cache ECC error for stmerge/blkld"	},
-	{	CHAFSR_EMU,	"Uncorrectable system bus MTAG error"			},
-	{	CHAFSR_WDU,	"Uncorrectable E-cache ECC error for writeback"		},
-	{	CHAFSR_CPU,	"Uncorrectable ECC error for copyout"			},
-	{	CHAFSR_CE,	"HW corrected system bus data ECC error for read"	},
-	{	CHAFSR_EDC,	"HW corrected E-cache ECC error for stmerge/blkld"	},
-	{	CHAFSR_EMC,	"HW corrected system bus MTAG ECC error"		},
-	{	CHAFSR_WDC,	"HW corrected E-cache ECC error for writeback"		},
-	{	CHAFSR_CPC,	"HW corrected ECC error for copyout"			},
-	{	CHAFSR_TO,	"Unmapped error from system bus"			},
-	{	CHAFSR_BERR,	"Bus error response from system bus"			},
-	/* These two do not update the AFAR. */
-	{	CHAFSR_IVC,	"HW corrected system bus data ECC error for ivec read"	},
-	{	CHAFSR_IVU,	"Uncorrectable system bus data ECC error for ivec read"	},
-	{	0,		NULL							}
-};
-
 /* Return the highest priority error conditon mentioned. */
 static __inline__ unsigned long cheetah_get_hipri(unsigned long afsr)
 {
@@ -763,7 +918,7 @@
 	return tmp;
 }
 
-static char *cheetah_get_string(unsigned long bit)
+static const char *cheetah_get_string(unsigned long bit)
 {
 	int i;
 
@@ -876,7 +1031,7 @@
 	       info->ecache_data[2],
 	       info->ecache_data[3]);
 
-	afsr = (afsr & ~hipri) & CHAFSR_ERRORS;
+	afsr = (afsr & ~hipri) & cheetah_afsr_errors;
 	while (afsr != 0UL) {
 		unsigned long bit = cheetah_get_hipri(afsr);
 
@@ -899,7 +1054,7 @@
 	__asm__ __volatile__("ldxa [%%g0] %1, %0\n\t"
 			     : "=r" (afsr)
 			     : "i" (ASI_AFSR));
-	if ((afsr & CHAFSR_ERRORS) != 0) {
+	if ((afsr & cheetah_afsr_errors) != 0) {
 		if (logp != NULL) {
 			__asm__ __volatile__("ldxa [%%g0] %1, %0\n\t"
 					     : "=r" (afar)
@@ -1125,12 +1280,12 @@
 
 		flush_all = flush_line = 0;
 		if ((afsr & CHAFSR_EDC) != 0UL) {
-			if ((afsr & CHAFSR_ERRORS) == CHAFSR_EDC)
+			if ((afsr & cheetah_afsr_errors) == CHAFSR_EDC)
 				flush_line = 1;
 			else
 				flush_all = 1;
 		} else if ((afsr & CHAFSR_CPC) != 0UL) {
-			if ((afsr & CHAFSR_ERRORS) == CHAFSR_CPC)
+			if ((afsr & cheetah_afsr_errors) == CHAFSR_CPC)
 				flush_line = 1;
 			else
 				flush_all = 1;
@@ -1253,12 +1408,12 @@
 
 		flush_all = flush_line = 0;
 		if ((afsr & CHAFSR_EDU) != 0UL) {
-			if ((afsr & CHAFSR_ERRORS) == CHAFSR_EDU)
+			if ((afsr & cheetah_afsr_errors) == CHAFSR_EDU)
 				flush_line = 1;
 			else
 				flush_all = 1;
 		} else if ((afsr & CHAFSR_BERR) != 0UL) {
-			if ((afsr & CHAFSR_ERRORS) == CHAFSR_BERR)
+			if ((afsr & cheetah_afsr_errors) == CHAFSR_BERR)
 				flush_line = 1;
 			else
 				flush_all = 1;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/sparc64/kernel/unaligned.c linux-2.4.23-pre1/arch/sparc64/kernel/unaligned.c
--- linux-2.4.22/arch/sparc64/kernel/unaligned.c	2001-04-12 19:10:25.000000000 +0000
+++ linux-2.4.23-pre1/arch/sparc64/kernel/unaligned.c	2003-08-27 14:40:04.000000000 +0000
@@ -479,7 +479,9 @@
 
 extern void do_fpother(struct pt_regs *regs);
 extern void do_privact(struct pt_regs *regs);
-extern void data_access_exception(struct pt_regs *regs);
+extern void data_access_exception(struct pt_regs *regs,
+				  unsigned long sfsr,
+				  unsigned long sfar);
 
 int handle_ldf_stq(u32 insn, struct pt_regs *regs)
 {
@@ -522,14 +524,14 @@
 				break;
 			}
 		default:
-			data_access_exception(regs);
+			data_access_exception(regs, 0, addr);
 			return 1;
 		}
 		if (put_user (first >> 32, (u32 *)addr) ||
 		    __put_user ((u32)first, (u32 *)(addr + 4)) ||
 		    __put_user (second >> 32, (u32 *)(addr + 8)) ||
 		    __put_user ((u32)second, (u32 *)(addr + 12))) {
-		    	data_access_exception(regs);
+		    	data_access_exception(regs, 0, addr);
 		    	return 1;
 		}
 	} else {
@@ -542,7 +544,7 @@
 			do_privact(regs);
 			return 1;
 		} else if (asi > ASI_SNFL) {
-			data_access_exception(regs);
+			data_access_exception(regs, 0, addr);
 			return 1;
 		}
 		switch (insn & 0x180000) {
@@ -559,7 +561,7 @@
 				err |= __get_user (data[i], (u32 *)(addr + 4*i));
 		}
 		if (err && !(asi & 0x2 /* NF */)) {
-			data_access_exception(regs);
+			data_access_exception(regs, 0, addr);
 			return 1;
 		}
 		if (asi & 0x8) /* Little */ {
@@ -662,7 +664,7 @@
 		*(u64 *)(f->regs + freg) = value;
 		current->thread.fpsaved[0] |= flag;
 	} else {
-daex:		data_access_exception(regs);
+daex:		data_access_exception(regs, sfsr, sfar);
 		return;
 	}
 	advance(regs);
@@ -706,7 +708,7 @@
 		    __put_user ((u32)value, (u32 *)(sfar + 4)))
 			goto daex;
 	} else {
-daex:		data_access_exception(regs);
+daex:		data_access_exception(regs, sfsr, sfar);
 		return;
 	}
 	advance(regs);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/x86_64/config.in linux-2.4.23-pre1/arch/x86_64/config.in
--- linux-2.4.22/arch/x86_64/config.in	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/x86_64/config.in	2003-08-27 14:40:58.000000000 +0000
@@ -66,6 +66,7 @@
    define_bool CONFIG_X86_UP_IOAPIC y
 else
    define_bool CONFIG_HAVE_DEC_LOCK y
+   int  'Maximum number of CPUs (2-32)' CONFIG_NR_CPUS 32
 fi
 
 bool 'Machine check support' CONFIG_MCE
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/x86_64/defconfig linux-2.4.23-pre1/arch/x86_64/defconfig
--- linux-2.4.22/arch/x86_64/defconfig	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/x86_64/defconfig	2003-08-27 14:40:28.000000000 +0000
@@ -41,6 +41,7 @@
 CONFIG_X86_LOCAL_APIC=y
 CONFIG_MTRR=y
 # CONFIG_SMP is not set
+CONFIG_NR_CPUS=32
 CONFIG_HPET_TIMER=y
 CONFIG_GART_IOMMU=y
 CONFIG_X86_UP_IOAPIC=y
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/x86_64/kernel/io_apic.c linux-2.4.23-pre1/arch/x86_64/kernel/io_apic.c
--- linux-2.4.22/arch/x86_64/kernel/io_apic.c	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/x86_64/kernel/io_apic.c	2003-08-27 14:40:04.000000000 +0000
@@ -1762,7 +1762,7 @@
 }
 
 
-int io_apic_set_pci_routing (int ioapic, int pin, int irq)
+int io_apic_set_pci_routing (int ioapic, int pin, int irq, int edge_level ,int active_high_low)
 {
 	struct IO_APIC_route_entry entry;
 	unsigned long flags;
@@ -1785,18 +1785,21 @@
 	entry.dest_mode = INT_DELIVERY_MODE;
 	entry.dest.logical.logical_dest = TARGET_CPUS;
 	entry.mask = 1;					 /* Disabled (masked) */
-	entry.trigger = 1;				   /* Level sensitive */
-	entry.polarity = 1;					/* Low active */
+	entry.trigger = edge_level;	
+	entry.polarity = active_high_low;
 
 	add_pin_to_irq(irq, ioapic, pin);
 
 	entry.vector = assign_irq_vector(irq);
 
 	printk(KERN_DEBUG "IOAPIC[%d]: Set PCI routing entry (%d-%d -> 0x%x -> "
-		"IRQ %d)\n", ioapic, 
-		mp_ioapics[ioapic].mpc_apicid, pin, entry.vector, irq);
+		"IRQ %d) Mode:%i Active:%i\n", ioapic, 
+		mp_ioapics[ioapic].mpc_apicid, pin, entry.vector, irq, edge_level, active_high_low);
 
-	irq_desc[irq].handler = &ioapic_level_irq_type;
+	if (edge_level)
+		irq_desc[irq].handler = &ioapic_level_irq_type;
+	else
+		irq_desc[irq].handler = &ioapic_edge_irq_type;
 
 	set_intr_gate(entry.vector, interrupt[irq]);
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/arch/x86_64/kernel/mpparse.c linux-2.4.23-pre1/arch/x86_64/kernel/mpparse.c
--- linux-2.4.22/arch/x86_64/kernel/mpparse.c	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/arch/x86_64/kernel/mpparse.c	2003-08-27 14:39:59.000000000 +0000
@@ -923,7 +923,7 @@
 
 	ioapic_pin = irq - mp_ioapic_routing[ioapic].irq_start;
 
-	io_apic_set_pci_routing(ioapic, ioapic_pin, irq);
+	io_apic_set_pci_routing(ioapic, ioapic_pin, irq, 1, 1);
 }
 
 #endif /*CONFIG_ACPI_HT_ONLY*/
@@ -939,6 +939,8 @@
 	int			ioapic_pin = 0;
 	int			irq = 0;
 	int			idx, bit = 0;
+	int			edge_level = 0;
+	int			active_high_low = 0;
 
 	/*
 	 * Parsing through the PCI Interrupt Routing Table (PRT) and program
@@ -949,11 +951,14 @@
 
 		/* Need to get irq for dynamic entry */
 		if (entry->link.handle) {
-			irq = acpi_pci_link_get_irq(entry->link.handle, entry->link.index);
+			irq = acpi_pci_link_get_irq(entry->link.handle, entry->link.index, &edge_level, &active_high_low);
 			if (!irq)
 				continue;
-		} else
+		} else {
+			edge_level = 1;
+			active_high_low = 1;
 			irq = entry->link.index;
+		}
 
 		irq = entry->link.index;
 		ioapic = mp_find_ioapic(irq);
@@ -983,7 +988,7 @@
 
 		mp_ioapic_routing[ioapic].pin_programmed[idx] |= (1<<bit);
 
-		vector = io_apic_set_pci_routing(ioapic, ioapic_pin, irq);
+		vector = io_apic_set_pci_routing(ioapic, ioapic_pin, irq, edge_level, active_high_low);
 		if (vector)
 			entry->irq = irq;
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/crypto/Config.in linux-2.4.23-pre1/crypto/Config.in
--- linux-2.4.22/crypto/Config.in	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/crypto/Config.in	2003-08-27 14:41:37.000000000 +0000
@@ -70,6 +70,7 @@
   tristate       '  Twofish cipher algorithm' CONFIG_CRYPTO_TWOFISH
   tristate       '  Serpent cipher algorithm' CONFIG_CRYPTO_SERPENT
   tristate       '  AES cipher algorithms' CONFIG_CRYPTO_AES
+  tristate       '  CAST5 (CAST-128) cipher algorithm' CONFIG_CRYPTO_CAST5
   if [ "$CONFIG_INET_IPCOMP" = "y" -o \
        "$CONFIG_INET_IPCOMP" = "m" -o \
        "$CONFIG_INET6_IPCOMP" = "y" -o \
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/crypto/Makefile linux-2.4.23-pre1/crypto/Makefile
--- linux-2.4.22/crypto/Makefile	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/crypto/Makefile	2003-08-27 14:39:50.000000000 +0000
@@ -24,6 +24,7 @@
 obj-$(CONFIG_CRYPTO_TWOFISH) += twofish.o
 obj-$(CONFIG_CRYPTO_SERPENT) += serpent.o
 obj-$(CONFIG_CRYPTO_AES) += aes.o
+obj-$(CONFIG_CRYPTO_CAST5) += cast5.o
 obj-$(CONFIG_CRYPTO_DEFLATE) += deflate.o
 
 obj-$(CONFIG_CRYPTO_TEST) += tcrypt.o
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/crypto/cast5.c linux-2.4.23-pre1/crypto/cast5.c
--- linux-2.4.22/crypto/cast5.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/crypto/cast5.c	2003-08-27 14:39:37.000000000 +0000
@@ -0,0 +1,852 @@
+/* Kernel cryptographic api.
+* cast5.c - Cast5 cipher algorithm (rfc2144).
+*
+* Derived from GnuPG implementation of cast5.
+*
+* Major Changes.
+* 	Complete conformance to rfc2144.
+* 	Supports key size from 40 to 128 bits.
+*
+* Copyright (C) 1998, 1999, 2000, 2001 Free Software Foundation, Inc.
+* Copyright (C) 2003 Kartikey Mahendra Bhatt <kartik_me@hotmail.com>.
+*
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of GNU General Public License as published by the Free
+* Software Foundation; either version 2 of the License, or (at your option)
+* any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA
+*/
+
+
+#include <linux/init.h>
+#include <linux/crypto.h>
+#include <linux/module.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+
+#define CAST5_BLOCK_SIZE 8
+#define CAST5_MIN_KEY_SIZE 5
+#define CAST5_MAX_KEY_SIZE 16
+
+struct cast5_ctx {
+	u32 Km[16];
+	u8 Kr[16];
+	int rr;	/* rr?number of rounds = 16:number of rounds = 12; (rfc 2144) */
+};
+
+
+static const u32 s1[256] = {
+	0x30fb40d4, 0x9fa0ff0b, 0x6beccd2f, 0x3f258c7a, 0x1e213f2f,
+	0x9c004dd3, 0x6003e540, 0xcf9fc949,
+	0xbfd4af27, 0x88bbbdb5, 0xe2034090, 0x98d09675, 0x6e63a0e0,
+	0x15c361d2, 0xc2e7661d, 0x22d4ff8e,
+	0x28683b6f, 0xc07fd059, 0xff2379c8, 0x775f50e2, 0x43c340d3,
+	0xdf2f8656, 0x887ca41a, 0xa2d2bd2d,
+	0xa1c9e0d6, 0x346c4819, 0x61b76d87, 0x22540f2f, 0x2abe32e1,
+	0xaa54166b, 0x22568e3a, 0xa2d341d0,
+	0x66db40c8, 0xa784392f, 0x004dff2f, 0x2db9d2de, 0x97943fac,
+	0x4a97c1d8, 0x527644b7, 0xb5f437a7,
+	0xb82cbaef, 0xd751d159, 0x6ff7f0ed, 0x5a097a1f, 0x827b68d0,
+	0x90ecf52e, 0x22b0c054, 0xbc8e5935,
+	0x4b6d2f7f, 0x50bb64a2, 0xd2664910, 0xbee5812d, 0xb7332290,
+	0xe93b159f, 0xb48ee411, 0x4bff345d,
+	0xfd45c240, 0xad31973f, 0xc4f6d02e, 0x55fc8165, 0xd5b1caad,
+	0xa1ac2dae, 0xa2d4b76d, 0xc19b0c50,
+	0x882240f2, 0x0c6e4f38, 0xa4e4bfd7, 0x4f5ba272, 0x564c1d2f,
+	0xc59c5319, 0xb949e354, 0xb04669fe,
+	0xb1b6ab8a, 0xc71358dd, 0x6385c545, 0x110f935d, 0x57538ad5,
+	0x6a390493, 0xe63d37e0, 0x2a54f6b3,
+	0x3a787d5f, 0x6276a0b5, 0x19a6fcdf, 0x7a42206a, 0x29f9d4d5,
+	0xf61b1891, 0xbb72275e, 0xaa508167,
+	0x38901091, 0xc6b505eb, 0x84c7cb8c, 0x2ad75a0f, 0x874a1427,
+	0xa2d1936b, 0x2ad286af, 0xaa56d291,
+	0xd7894360, 0x425c750d, 0x93b39e26, 0x187184c9, 0x6c00b32d,
+	0x73e2bb14, 0xa0bebc3c, 0x54623779,
+	0x64459eab, 0x3f328b82, 0x7718cf82, 0x59a2cea6, 0x04ee002e,
+	0x89fe78e6, 0x3fab0950, 0x325ff6c2,
+	0x81383f05, 0x6963c5c8, 0x76cb5ad6, 0xd49974c9, 0xca180dcf,
+	0x380782d5, 0xc7fa5cf6, 0x8ac31511,
+	0x35e79e13, 0x47da91d0, 0xf40f9086, 0xa7e2419e, 0x31366241,
+	0x051ef495, 0xaa573b04, 0x4a805d8d,
+	0x548300d0, 0x00322a3c, 0xbf64cddf, 0xba57a68e, 0x75c6372b,
+	0x50afd341, 0xa7c13275, 0x915a0bf5,
+	0x6b54bfab, 0x2b0b1426, 0xab4cc9d7, 0x449ccd82, 0xf7fbf265,
+	0xab85c5f3, 0x1b55db94, 0xaad4e324,
+	0xcfa4bd3f, 0x2deaa3e2, 0x9e204d02, 0xc8bd25ac, 0xeadf55b3,
+	0xd5bd9e98, 0xe31231b2, 0x2ad5ad6c,
+	0x954329de, 0xadbe4528, 0xd8710f69, 0xaa51c90f, 0xaa786bf6,
+	0x22513f1e, 0xaa51a79b, 0x2ad344cc,
+	0x7b5a41f0, 0xd37cfbad, 0x1b069505, 0x41ece491, 0xb4c332e6,
+	0x032268d4, 0xc9600acc, 0xce387e6d,
+	0xbf6bb16c, 0x6a70fb78, 0x0d03d9c9, 0xd4df39de, 0xe01063da,
+	0x4736f464, 0x5ad328d8, 0xb347cc96,
+	0x75bb0fc3, 0x98511bfb, 0x4ffbcc35, 0xb58bcf6a, 0xe11f0abc,
+	0xbfc5fe4a, 0xa70aec10, 0xac39570a,
+	0x3f04442f, 0x6188b153, 0xe0397a2e, 0x5727cb79, 0x9ceb418f,
+	0x1cacd68d, 0x2ad37c96, 0x0175cb9d,
+	0xc69dff09, 0xc75b65f0, 0xd9db40d8, 0xec0e7779, 0x4744ead4,
+	0xb11c3274, 0xdd24cb9e, 0x7e1c54bd,
+	0xf01144f9, 0xd2240eb1, 0x9675b3fd, 0xa3ac3755, 0xd47c27af,
+	0x51c85f4d, 0x56907596, 0xa5bb15e6,
+	0x580304f0, 0xca042cf1, 0x011a37ea, 0x8dbfaadb, 0x35ba3e4a,
+	0x3526ffa0, 0xc37b4d09, 0xbc306ed9,
+	0x98a52666, 0x5648f725, 0xff5e569d, 0x0ced63d0, 0x7c63b2cf,
+	0x700b45e1, 0xd5ea50f1, 0x85a92872,
+	0xaf1fbda7, 0xd4234870, 0xa7870bf3, 0x2d3b4d79, 0x42e04198,
+	0x0cd0ede7, 0x26470db8, 0xf881814c,
+	0x474d6ad7, 0x7c0c5e5c, 0xd1231959, 0x381b7298, 0xf5d2f4db,
+	0xab838653, 0x6e2f1e23, 0x83719c9e,
+	0xbd91e046, 0x9a56456e, 0xdc39200c, 0x20c8c571, 0x962bda1c,
+	0xe1e696ff, 0xb141ab08, 0x7cca89b9,
+	0x1a69e783, 0x02cc4843, 0xa2f7c579, 0x429ef47d, 0x427b169c,
+	0x5ac9f049, 0xdd8f0f00, 0x5c8165bf
+};
+static const u32 s2[256] = {
+	0x1f201094, 0xef0ba75b, 0x69e3cf7e, 0x393f4380, 0xfe61cf7a,
+	0xeec5207a, 0x55889c94, 0x72fc0651,
+	0xada7ef79, 0x4e1d7235, 0xd55a63ce, 0xde0436ba, 0x99c430ef,
+	0x5f0c0794, 0x18dcdb7d, 0xa1d6eff3,
+	0xa0b52f7b, 0x59e83605, 0xee15b094, 0xe9ffd909, 0xdc440086,
+	0xef944459, 0xba83ccb3, 0xe0c3cdfb,
+	0xd1da4181, 0x3b092ab1, 0xf997f1c1, 0xa5e6cf7b, 0x01420ddb,
+	0xe4e7ef5b, 0x25a1ff41, 0xe180f806,
+	0x1fc41080, 0x179bee7a, 0xd37ac6a9, 0xfe5830a4, 0x98de8b7f,
+	0x77e83f4e, 0x79929269, 0x24fa9f7b,
+	0xe113c85b, 0xacc40083, 0xd7503525, 0xf7ea615f, 0x62143154,
+	0x0d554b63, 0x5d681121, 0xc866c359,
+	0x3d63cf73, 0xcee234c0, 0xd4d87e87, 0x5c672b21, 0x071f6181,
+	0x39f7627f, 0x361e3084, 0xe4eb573b,
+	0x602f64a4, 0xd63acd9c, 0x1bbc4635, 0x9e81032d, 0x2701f50c,
+	0x99847ab4, 0xa0e3df79, 0xba6cf38c,
+	0x10843094, 0x2537a95e, 0xf46f6ffe, 0xa1ff3b1f, 0x208cfb6a,
+	0x8f458c74, 0xd9e0a227, 0x4ec73a34,
+	0xfc884f69, 0x3e4de8df, 0xef0e0088, 0x3559648d, 0x8a45388c,
+	0x1d804366, 0x721d9bfd, 0xa58684bb,
+	0xe8256333, 0x844e8212, 0x128d8098, 0xfed33fb4, 0xce280ae1,
+	0x27e19ba5, 0xd5a6c252, 0xe49754bd,
+	0xc5d655dd, 0xeb667064, 0x77840b4d, 0xa1b6a801, 0x84db26a9,
+	0xe0b56714, 0x21f043b7, 0xe5d05860,
+	0x54f03084, 0x066ff472, 0xa31aa153, 0xdadc4755, 0xb5625dbf,
+	0x68561be6, 0x83ca6b94, 0x2d6ed23b,
+	0xeccf01db, 0xa6d3d0ba, 0xb6803d5c, 0xaf77a709, 0x33b4a34c,
+	0x397bc8d6, 0x5ee22b95, 0x5f0e5304,
+	0x81ed6f61, 0x20e74364, 0xb45e1378, 0xde18639b, 0x881ca122,
+	0xb96726d1, 0x8049a7e8, 0x22b7da7b,
+	0x5e552d25, 0x5272d237, 0x79d2951c, 0xc60d894c, 0x488cb402,
+	0x1ba4fe5b, 0xa4b09f6b, 0x1ca815cf,
+	0xa20c3005, 0x8871df63, 0xb9de2fcb, 0x0cc6c9e9, 0x0beeff53,
+	0xe3214517, 0xb4542835, 0x9f63293c,
+	0xee41e729, 0x6e1d2d7c, 0x50045286, 0x1e6685f3, 0xf33401c6,
+	0x30a22c95, 0x31a70850, 0x60930f13,
+	0x73f98417, 0xa1269859, 0xec645c44, 0x52c877a9, 0xcdff33a6,
+	0xa02b1741, 0x7cbad9a2, 0x2180036f,
+	0x50d99c08, 0xcb3f4861, 0xc26bd765, 0x64a3f6ab, 0x80342676,
+	0x25a75e7b, 0xe4e6d1fc, 0x20c710e6,
+	0xcdf0b680, 0x17844d3b, 0x31eef84d, 0x7e0824e4, 0x2ccb49eb,
+	0x846a3bae, 0x8ff77888, 0xee5d60f6,
+	0x7af75673, 0x2fdd5cdb, 0xa11631c1, 0x30f66f43, 0xb3faec54,
+	0x157fd7fa, 0xef8579cc, 0xd152de58,
+	0xdb2ffd5e, 0x8f32ce19, 0x306af97a, 0x02f03ef8, 0x99319ad5,
+	0xc242fa0f, 0xa7e3ebb0, 0xc68e4906,
+	0xb8da230c, 0x80823028, 0xdcdef3c8, 0xd35fb171, 0x088a1bc8,
+	0xbec0c560, 0x61a3c9e8, 0xbca8f54d,
+	0xc72feffa, 0x22822e99, 0x82c570b4, 0xd8d94e89, 0x8b1c34bc,
+	0x301e16e6, 0x273be979, 0xb0ffeaa6,
+	0x61d9b8c6, 0x00b24869, 0xb7ffce3f, 0x08dc283b, 0x43daf65a,
+	0xf7e19798, 0x7619b72f, 0x8f1c9ba4,
+	0xdc8637a0, 0x16a7d3b1, 0x9fc393b7, 0xa7136eeb, 0xc6bcc63e,
+	0x1a513742, 0xef6828bc, 0x520365d6,
+	0x2d6a77ab, 0x3527ed4b, 0x821fd216, 0x095c6e2e, 0xdb92f2fb,
+	0x5eea29cb, 0x145892f5, 0x91584f7f,
+	0x5483697b, 0x2667a8cc, 0x85196048, 0x8c4bacea, 0x833860d4,
+	0x0d23e0f9, 0x6c387e8a, 0x0ae6d249,
+	0xb284600c, 0xd835731d, 0xdcb1c647, 0xac4c56ea, 0x3ebd81b3,
+	0x230eabb0, 0x6438bc87, 0xf0b5b1fa,
+	0x8f5ea2b3, 0xfc184642, 0x0a036b7a, 0x4fb089bd, 0x649da589,
+	0xa345415e, 0x5c038323, 0x3e5d3bb9,
+	0x43d79572, 0x7e6dd07c, 0x06dfdf1e, 0x6c6cc4ef, 0x7160a539,
+	0x73bfbe70, 0x83877605, 0x4523ecf1
+};
+static const u32 s3[256] = {
+	0x8defc240, 0x25fa5d9f, 0xeb903dbf, 0xe810c907, 0x47607fff,
+	0x369fe44b, 0x8c1fc644, 0xaececa90,
+	0xbeb1f9bf, 0xeefbcaea, 0xe8cf1950, 0x51df07ae, 0x920e8806,
+	0xf0ad0548, 0xe13c8d83, 0x927010d5,
+	0x11107d9f, 0x07647db9, 0xb2e3e4d4, 0x3d4f285e, 0xb9afa820,
+	0xfade82e0, 0xa067268b, 0x8272792e,
+	0x553fb2c0, 0x489ae22b, 0xd4ef9794, 0x125e3fbc, 0x21fffcee,
+	0x825b1bfd, 0x9255c5ed, 0x1257a240,
+	0x4e1a8302, 0xbae07fff, 0x528246e7, 0x8e57140e, 0x3373f7bf,
+	0x8c9f8188, 0xa6fc4ee8, 0xc982b5a5,
+	0xa8c01db7, 0x579fc264, 0x67094f31, 0xf2bd3f5f, 0x40fff7c1,
+	0x1fb78dfc, 0x8e6bd2c1, 0x437be59b,
+	0x99b03dbf, 0xb5dbc64b, 0x638dc0e6, 0x55819d99, 0xa197c81c,
+	0x4a012d6e, 0xc5884a28, 0xccc36f71,
+	0xb843c213, 0x6c0743f1, 0x8309893c, 0x0feddd5f, 0x2f7fe850,
+	0xd7c07f7e, 0x02507fbf, 0x5afb9a04,
+	0xa747d2d0, 0x1651192e, 0xaf70bf3e, 0x58c31380, 0x5f98302e,
+	0x727cc3c4, 0x0a0fb402, 0x0f7fef82,
+	0x8c96fdad, 0x5d2c2aae, 0x8ee99a49, 0x50da88b8, 0x8427f4a0,
+	0x1eac5790, 0x796fb449, 0x8252dc15,
+	0xefbd7d9b, 0xa672597d, 0xada840d8, 0x45f54504, 0xfa5d7403,
+	0xe83ec305, 0x4f91751a, 0x925669c2,
+	0x23efe941, 0xa903f12e, 0x60270df2, 0x0276e4b6, 0x94fd6574,
+	0x927985b2, 0x8276dbcb, 0x02778176,
+	0xf8af918d, 0x4e48f79e, 0x8f616ddf, 0xe29d840e, 0x842f7d83,
+	0x340ce5c8, 0x96bbb682, 0x93b4b148,
+	0xef303cab, 0x984faf28, 0x779faf9b, 0x92dc560d, 0x224d1e20,
+	0x8437aa88, 0x7d29dc96, 0x2756d3dc,
+	0x8b907cee, 0xb51fd240, 0xe7c07ce3, 0xe566b4a1, 0xc3e9615e,
+	0x3cf8209d, 0x6094d1e3, 0xcd9ca341,
+	0x5c76460e, 0x00ea983b, 0xd4d67881, 0xfd47572c, 0xf76cedd9,
+	0xbda8229c, 0x127dadaa, 0x438a074e,
+	0x1f97c090, 0x081bdb8a, 0x93a07ebe, 0xb938ca15, 0x97b03cff,
+	0x3dc2c0f8, 0x8d1ab2ec, 0x64380e51,
+	0x68cc7bfb, 0xd90f2788, 0x12490181, 0x5de5ffd4, 0xdd7ef86a,
+	0x76a2e214, 0xb9a40368, 0x925d958f,
+	0x4b39fffa, 0xba39aee9, 0xa4ffd30b, 0xfaf7933b, 0x6d498623,
+	0x193cbcfa, 0x27627545, 0x825cf47a,
+	0x61bd8ba0, 0xd11e42d1, 0xcead04f4, 0x127ea392, 0x10428db7,
+	0x8272a972, 0x9270c4a8, 0x127de50b,
+	0x285ba1c8, 0x3c62f44f, 0x35c0eaa5, 0xe805d231, 0x428929fb,
+	0xb4fcdf82, 0x4fb66a53, 0x0e7dc15b,
+	0x1f081fab, 0x108618ae, 0xfcfd086d, 0xf9ff2889, 0x694bcc11,
+	0x236a5cae, 0x12deca4d, 0x2c3f8cc5,
+	0xd2d02dfe, 0xf8ef5896, 0xe4cf52da, 0x95155b67, 0x494a488c,
+	0xb9b6a80c, 0x5c8f82bc, 0x89d36b45,
+	0x3a609437, 0xec00c9a9, 0x44715253, 0x0a874b49, 0xd773bc40,
+	0x7c34671c, 0x02717ef6, 0x4feb5536,
+	0xa2d02fff, 0xd2bf60c4, 0xd43f03c0, 0x50b4ef6d, 0x07478cd1,
+	0x006e1888, 0xa2e53f55, 0xb9e6d4bc,
+	0xa2048016, 0x97573833, 0xd7207d67, 0xde0f8f3d, 0x72f87b33,
+	0xabcc4f33, 0x7688c55d, 0x7b00a6b0,
+	0x947b0001, 0x570075d2, 0xf9bb88f8, 0x8942019e, 0x4264a5ff,
+	0x856302e0, 0x72dbd92b, 0xee971b69,
+	0x6ea22fde, 0x5f08ae2b, 0xaf7a616d, 0xe5c98767, 0xcf1febd2,
+	0x61efc8c2, 0xf1ac2571, 0xcc8239c2,
+	0x67214cb8, 0xb1e583d1, 0xb7dc3e62, 0x7f10bdce, 0xf90a5c38,
+	0x0ff0443d, 0x606e6dc6, 0x60543a49,
+	0x5727c148, 0x2be98a1d, 0x8ab41738, 0x20e1be24, 0xaf96da0f,
+	0x68458425, 0x99833be5, 0x600d457d,
+	0x282f9350, 0x8334b362, 0xd91d1120, 0x2b6d8da0, 0x642b1e31,
+	0x9c305a00, 0x52bce688, 0x1b03588a,
+	0xf7baefd5, 0x4142ed9c, 0xa4315c11, 0x83323ec5, 0xdfef4636,
+	0xa133c501, 0xe9d3531c, 0xee353783
+};
+static const u32 s4[256] = {
+	0x9db30420, 0x1fb6e9de, 0xa7be7bef, 0xd273a298, 0x4a4f7bdb,
+	0x64ad8c57, 0x85510443, 0xfa020ed1,
+	0x7e287aff, 0xe60fb663, 0x095f35a1, 0x79ebf120, 0xfd059d43,
+	0x6497b7b1, 0xf3641f63, 0x241e4adf,
+	0x28147f5f, 0x4fa2b8cd, 0xc9430040, 0x0cc32220, 0xfdd30b30,
+	0xc0a5374f, 0x1d2d00d9, 0x24147b15,
+	0xee4d111a, 0x0fca5167, 0x71ff904c, 0x2d195ffe, 0x1a05645f,
+	0x0c13fefe, 0x081b08ca, 0x05170121,
+	0x80530100, 0xe83e5efe, 0xac9af4f8, 0x7fe72701, 0xd2b8ee5f,
+	0x06df4261, 0xbb9e9b8a, 0x7293ea25,
+	0xce84ffdf, 0xf5718801, 0x3dd64b04, 0xa26f263b, 0x7ed48400,
+	0x547eebe6, 0x446d4ca0, 0x6cf3d6f5,
+	0x2649abdf, 0xaea0c7f5, 0x36338cc1, 0x503f7e93, 0xd3772061,
+	0x11b638e1, 0x72500e03, 0xf80eb2bb,
+	0xabe0502e, 0xec8d77de, 0x57971e81, 0xe14f6746, 0xc9335400,
+	0x6920318f, 0x081dbb99, 0xffc304a5,
+	0x4d351805, 0x7f3d5ce3, 0xa6c866c6, 0x5d5bcca9, 0xdaec6fea,
+	0x9f926f91, 0x9f46222f, 0x3991467d,
+	0xa5bf6d8e, 0x1143c44f, 0x43958302, 0xd0214eeb, 0x022083b8,
+	0x3fb6180c, 0x18f8931e, 0x281658e6,
+	0x26486e3e, 0x8bd78a70, 0x7477e4c1, 0xb506e07c, 0xf32d0a25,
+	0x79098b02, 0xe4eabb81, 0x28123b23,
+	0x69dead38, 0x1574ca16, 0xdf871b62, 0x211c40b7, 0xa51a9ef9,
+	0x0014377b, 0x041e8ac8, 0x09114003,
+	0xbd59e4d2, 0xe3d156d5, 0x4fe876d5, 0x2f91a340, 0x557be8de,
+	0x00eae4a7, 0x0ce5c2ec, 0x4db4bba6,
+	0xe756bdff, 0xdd3369ac, 0xec17b035, 0x06572327, 0x99afc8b0,
+	0x56c8c391, 0x6b65811c, 0x5e146119,
+	0x6e85cb75, 0xbe07c002, 0xc2325577, 0x893ff4ec, 0x5bbfc92d,
+	0xd0ec3b25, 0xb7801ab7, 0x8d6d3b24,
+	0x20c763ef, 0xc366a5fc, 0x9c382880, 0x0ace3205, 0xaac9548a,
+	0xeca1d7c7, 0x041afa32, 0x1d16625a,
+	0x6701902c, 0x9b757a54, 0x31d477f7, 0x9126b031, 0x36cc6fdb,
+	0xc70b8b46, 0xd9e66a48, 0x56e55a79,
+	0x026a4ceb, 0x52437eff, 0x2f8f76b4, 0x0df980a5, 0x8674cde3,
+	0xedda04eb, 0x17a9be04, 0x2c18f4df,
+	0xb7747f9d, 0xab2af7b4, 0xefc34d20, 0x2e096b7c, 0x1741a254,
+	0xe5b6a035, 0x213d42f6, 0x2c1c7c26,
+	0x61c2f50f, 0x6552daf9, 0xd2c231f8, 0x25130f69, 0xd8167fa2,
+	0x0418f2c8, 0x001a96a6, 0x0d1526ab,
+	0x63315c21, 0x5e0a72ec, 0x49bafefd, 0x187908d9, 0x8d0dbd86,
+	0x311170a7, 0x3e9b640c, 0xcc3e10d7,
+	0xd5cad3b6, 0x0caec388, 0xf73001e1, 0x6c728aff, 0x71eae2a1,
+	0x1f9af36e, 0xcfcbd12f, 0xc1de8417,
+	0xac07be6b, 0xcb44a1d8, 0x8b9b0f56, 0x013988c3, 0xb1c52fca,
+	0xb4be31cd, 0xd8782806, 0x12a3a4e2,
+	0x6f7de532, 0x58fd7eb6, 0xd01ee900, 0x24adffc2, 0xf4990fc5,
+	0x9711aac5, 0x001d7b95, 0x82e5e7d2,
+	0x109873f6, 0x00613096, 0xc32d9521, 0xada121ff, 0x29908415,
+	0x7fbb977f, 0xaf9eb3db, 0x29c9ed2a,
+	0x5ce2a465, 0xa730f32c, 0xd0aa3fe8, 0x8a5cc091, 0xd49e2ce7,
+	0x0ce454a9, 0xd60acd86, 0x015f1919,
+	0x77079103, 0xdea03af6, 0x78a8565e, 0xdee356df, 0x21f05cbe,
+	0x8b75e387, 0xb3c50651, 0xb8a5c3ef,
+	0xd8eeb6d2, 0xe523be77, 0xc2154529, 0x2f69efdf, 0xafe67afb,
+	0xf470c4b2, 0xf3e0eb5b, 0xd6cc9876,
+	0x39e4460c, 0x1fda8538, 0x1987832f, 0xca007367, 0xa99144f8,
+	0x296b299e, 0x492fc295, 0x9266beab,
+	0xb5676e69, 0x9bd3ddda, 0xdf7e052f, 0xdb25701c, 0x1b5e51ee,
+	0xf65324e6, 0x6afce36c, 0x0316cc04,
+	0x8644213e, 0xb7dc59d0, 0x7965291f, 0xccd6fd43, 0x41823979,
+	0x932bcdf6, 0xb657c34d, 0x4edfd282,
+	0x7ae5290c, 0x3cb9536b, 0x851e20fe, 0x9833557e, 0x13ecf0b0,
+	0xd3ffb372, 0x3f85c5c1, 0x0aef7ed2
+};
+static const u32 s5[256] = {
+	0x7ec90c04, 0x2c6e74b9, 0x9b0e66df, 0xa6337911, 0xb86a7fff,
+	0x1dd358f5, 0x44dd9d44, 0x1731167f,
+	0x08fbf1fa, 0xe7f511cc, 0xd2051b00, 0x735aba00, 0x2ab722d8,
+	0x386381cb, 0xacf6243a, 0x69befd7a,
+	0xe6a2e77f, 0xf0c720cd, 0xc4494816, 0xccf5c180, 0x38851640,
+	0x15b0a848, 0xe68b18cb, 0x4caadeff,
+	0x5f480a01, 0x0412b2aa, 0x259814fc, 0x41d0efe2, 0x4e40b48d,
+	0x248eb6fb, 0x8dba1cfe, 0x41a99b02,
+	0x1a550a04, 0xba8f65cb, 0x7251f4e7, 0x95a51725, 0xc106ecd7,
+	0x97a5980a, 0xc539b9aa, 0x4d79fe6a,
+	0xf2f3f763, 0x68af8040, 0xed0c9e56, 0x11b4958b, 0xe1eb5a88,
+	0x8709e6b0, 0xd7e07156, 0x4e29fea7,
+	0x6366e52d, 0x02d1c000, 0xc4ac8e05, 0x9377f571, 0x0c05372a,
+	0x578535f2, 0x2261be02, 0xd642a0c9,
+	0xdf13a280, 0x74b55bd2, 0x682199c0, 0xd421e5ec, 0x53fb3ce8,
+	0xc8adedb3, 0x28a87fc9, 0x3d959981,
+	0x5c1ff900, 0xfe38d399, 0x0c4eff0b, 0x062407ea, 0xaa2f4fb1,
+	0x4fb96976, 0x90c79505, 0xb0a8a774,
+	0xef55a1ff, 0xe59ca2c2, 0xa6b62d27, 0xe66a4263, 0xdf65001f,
+	0x0ec50966, 0xdfdd55bc, 0x29de0655,
+	0x911e739a, 0x17af8975, 0x32c7911c, 0x89f89468, 0x0d01e980,
+	0x524755f4, 0x03b63cc9, 0x0cc844b2,
+	0xbcf3f0aa, 0x87ac36e9, 0xe53a7426, 0x01b3d82b, 0x1a9e7449,
+	0x64ee2d7e, 0xcddbb1da, 0x01c94910,
+	0xb868bf80, 0x0d26f3fd, 0x9342ede7, 0x04a5c284, 0x636737b6,
+	0x50f5b616, 0xf24766e3, 0x8eca36c1,
+	0x136e05db, 0xfef18391, 0xfb887a37, 0xd6e7f7d4, 0xc7fb7dc9,
+	0x3063fcdf, 0xb6f589de, 0xec2941da,
+	0x26e46695, 0xb7566419, 0xf654efc5, 0xd08d58b7, 0x48925401,
+	0xc1bacb7f, 0xe5ff550f, 0xb6083049,
+	0x5bb5d0e8, 0x87d72e5a, 0xab6a6ee1, 0x223a66ce, 0xc62bf3cd,
+	0x9e0885f9, 0x68cb3e47, 0x086c010f,
+	0xa21de820, 0xd18b69de, 0xf3f65777, 0xfa02c3f6, 0x407edac3,
+	0xcbb3d550, 0x1793084d, 0xb0d70eba,
+	0x0ab378d5, 0xd951fb0c, 0xded7da56, 0x4124bbe4, 0x94ca0b56,
+	0x0f5755d1, 0xe0e1e56e, 0x6184b5be,
+	0x580a249f, 0x94f74bc0, 0xe327888e, 0x9f7b5561, 0xc3dc0280,
+	0x05687715, 0x646c6bd7, 0x44904db3,
+	0x66b4f0a3, 0xc0f1648a, 0x697ed5af, 0x49e92ff6, 0x309e374f,
+	0x2cb6356a, 0x85808573, 0x4991f840,
+	0x76f0ae02, 0x083be84d, 0x28421c9a, 0x44489406, 0x736e4cb8,
+	0xc1092910, 0x8bc95fc6, 0x7d869cf4,
+	0x134f616f, 0x2e77118d, 0xb31b2be1, 0xaa90b472, 0x3ca5d717,
+	0x7d161bba, 0x9cad9010, 0xaf462ba2,
+	0x9fe459d2, 0x45d34559, 0xd9f2da13, 0xdbc65487, 0xf3e4f94e,
+	0x176d486f, 0x097c13ea, 0x631da5c7,
+	0x445f7382, 0x175683f4, 0xcdc66a97, 0x70be0288, 0xb3cdcf72,
+	0x6e5dd2f3, 0x20936079, 0x459b80a5,
+	0xbe60e2db, 0xa9c23101, 0xeba5315c, 0x224e42f2, 0x1c5c1572,
+	0xf6721b2c, 0x1ad2fff3, 0x8c25404e,
+	0x324ed72f, 0x4067b7fd, 0x0523138e, 0x5ca3bc78, 0xdc0fd66e,
+	0x75922283, 0x784d6b17, 0x58ebb16e,
+	0x44094f85, 0x3f481d87, 0xfcfeae7b, 0x77b5ff76, 0x8c2302bf,
+	0xaaf47556, 0x5f46b02a, 0x2b092801,
+	0x3d38f5f7, 0x0ca81f36, 0x52af4a8a, 0x66d5e7c0, 0xdf3b0874,
+	0x95055110, 0x1b5ad7a8, 0xf61ed5ad,
+	0x6cf6e479, 0x20758184, 0xd0cefa65, 0x88f7be58, 0x4a046826,
+	0x0ff6f8f3, 0xa09c7f70, 0x5346aba0,
+	0x5ce96c28, 0xe176eda3, 0x6bac307f, 0x376829d2, 0x85360fa9,
+	0x17e3fe2a, 0x24b79767, 0xf5a96b20,
+	0xd6cd2595, 0x68ff1ebf, 0x7555442c, 0xf19f06be, 0xf9e0659a,
+	0xeeb9491d, 0x34010718, 0xbb30cab8,
+	0xe822fe15, 0x88570983, 0x750e6249, 0xda627e55, 0x5e76ffa8,
+	0xb1534546, 0x6d47de08, 0xefe9e7d4
+};
+static const u32 s6[256] = {
+	0xf6fa8f9d, 0x2cac6ce1, 0x4ca34867, 0xe2337f7c, 0x95db08e7,
+	0x016843b4, 0xeced5cbc, 0x325553ac,
+	0xbf9f0960, 0xdfa1e2ed, 0x83f0579d, 0x63ed86b9, 0x1ab6a6b8,
+	0xde5ebe39, 0xf38ff732, 0x8989b138,
+	0x33f14961, 0xc01937bd, 0xf506c6da, 0xe4625e7e, 0xa308ea99,
+	0x4e23e33c, 0x79cbd7cc, 0x48a14367,
+	0xa3149619, 0xfec94bd5, 0xa114174a, 0xeaa01866, 0xa084db2d,
+	0x09a8486f, 0xa888614a, 0x2900af98,
+	0x01665991, 0xe1992863, 0xc8f30c60, 0x2e78ef3c, 0xd0d51932,
+	0xcf0fec14, 0xf7ca07d2, 0xd0a82072,
+	0xfd41197e, 0x9305a6b0, 0xe86be3da, 0x74bed3cd, 0x372da53c,
+	0x4c7f4448, 0xdab5d440, 0x6dba0ec3,
+	0x083919a7, 0x9fbaeed9, 0x49dbcfb0, 0x4e670c53, 0x5c3d9c01,
+	0x64bdb941, 0x2c0e636a, 0xba7dd9cd,
+	0xea6f7388, 0xe70bc762, 0x35f29adb, 0x5c4cdd8d, 0xf0d48d8c,
+	0xb88153e2, 0x08a19866, 0x1ae2eac8,
+	0x284caf89, 0xaa928223, 0x9334be53, 0x3b3a21bf, 0x16434be3,
+	0x9aea3906, 0xefe8c36e, 0xf890cdd9,
+	0x80226dae, 0xc340a4a3, 0xdf7e9c09, 0xa694a807, 0x5b7c5ecc,
+	0x221db3a6, 0x9a69a02f, 0x68818a54,
+	0xceb2296f, 0x53c0843a, 0xfe893655, 0x25bfe68a, 0xb4628abc,
+	0xcf222ebf, 0x25ac6f48, 0xa9a99387,
+	0x53bddb65, 0xe76ffbe7, 0xe967fd78, 0x0ba93563, 0x8e342bc1,
+	0xe8a11be9, 0x4980740d, 0xc8087dfc,
+	0x8de4bf99, 0xa11101a0, 0x7fd37975, 0xda5a26c0, 0xe81f994f,
+	0x9528cd89, 0xfd339fed, 0xb87834bf,
+	0x5f04456d, 0x22258698, 0xc9c4c83b, 0x2dc156be, 0x4f628daa,
+	0x57f55ec5, 0xe2220abe, 0xd2916ebf,
+	0x4ec75b95, 0x24f2c3c0, 0x42d15d99, 0xcd0d7fa0, 0x7b6e27ff,
+	0xa8dc8af0, 0x7345c106, 0xf41e232f,
+	0x35162386, 0xe6ea8926, 0x3333b094, 0x157ec6f2, 0x372b74af,
+	0x692573e4, 0xe9a9d848, 0xf3160289,
+	0x3a62ef1d, 0xa787e238, 0xf3a5f676, 0x74364853, 0x20951063,
+	0x4576698d, 0xb6fad407, 0x592af950,
+	0x36f73523, 0x4cfb6e87, 0x7da4cec0, 0x6c152daa, 0xcb0396a8,
+	0xc50dfe5d, 0xfcd707ab, 0x0921c42f,
+	0x89dff0bb, 0x5fe2be78, 0x448f4f33, 0x754613c9, 0x2b05d08d,
+	0x48b9d585, 0xdc049441, 0xc8098f9b,
+	0x7dede786, 0xc39a3373, 0x42410005, 0x6a091751, 0x0ef3c8a6,
+	0x890072d6, 0x28207682, 0xa9a9f7be,
+	0xbf32679d, 0xd45b5b75, 0xb353fd00, 0xcbb0e358, 0x830f220a,
+	0x1f8fb214, 0xd372cf08, 0xcc3c4a13,
+	0x8cf63166, 0x061c87be, 0x88c98f88, 0x6062e397, 0x47cf8e7a,
+	0xb6c85283, 0x3cc2acfb, 0x3fc06976,
+	0x4e8f0252, 0x64d8314d, 0xda3870e3, 0x1e665459, 0xc10908f0,
+	0x513021a5, 0x6c5b68b7, 0x822f8aa0,
+	0x3007cd3e, 0x74719eef, 0xdc872681, 0x073340d4, 0x7e432fd9,
+	0x0c5ec241, 0x8809286c, 0xf592d891,
+	0x08a930f6, 0x957ef305, 0xb7fbffbd, 0xc266e96f, 0x6fe4ac98,
+	0xb173ecc0, 0xbc60b42a, 0x953498da,
+	0xfba1ae12, 0x2d4bd736, 0x0f25faab, 0xa4f3fceb, 0xe2969123,
+	0x257f0c3d, 0x9348af49, 0x361400bc,
+	0xe8816f4a, 0x3814f200, 0xa3f94043, 0x9c7a54c2, 0xbc704f57,
+	0xda41e7f9, 0xc25ad33a, 0x54f4a084,
+	0xb17f5505, 0x59357cbe, 0xedbd15c8, 0x7f97c5ab, 0xba5ac7b5,
+	0xb6f6deaf, 0x3a479c3a, 0x5302da25,
+	0x653d7e6a, 0x54268d49, 0x51a477ea, 0x5017d55b, 0xd7d25d88,
+	0x44136c76, 0x0404a8c8, 0xb8e5a121,
+	0xb81a928a, 0x60ed5869, 0x97c55b96, 0xeaec991b, 0x29935913,
+	0x01fdb7f1, 0x088e8dfa, 0x9ab6f6f5,
+	0x3b4cbf9f, 0x4a5de3ab, 0xe6051d35, 0xa0e1d855, 0xd36b4cf1,
+	0xf544edeb, 0xb0e93524, 0xbebb8fbd,
+	0xa2d762cf, 0x49c92f54, 0x38b5f331, 0x7128a454, 0x48392905,
+	0xa65b1db8, 0x851c97bd, 0xd675cf2f
+};
+static const u32 s7[256] = {
+	0x85e04019, 0x332bf567, 0x662dbfff, 0xcfc65693, 0x2a8d7f6f,
+	0xab9bc912, 0xde6008a1, 0x2028da1f,
+	0x0227bce7, 0x4d642916, 0x18fac300, 0x50f18b82, 0x2cb2cb11,
+	0xb232e75c, 0x4b3695f2, 0xb28707de,
+	0xa05fbcf6, 0xcd4181e9, 0xe150210c, 0xe24ef1bd, 0xb168c381,
+	0xfde4e789, 0x5c79b0d8, 0x1e8bfd43,
+	0x4d495001, 0x38be4341, 0x913cee1d, 0x92a79c3f, 0x089766be,
+	0xbaeeadf4, 0x1286becf, 0xb6eacb19,
+	0x2660c200, 0x7565bde4, 0x64241f7a, 0x8248dca9, 0xc3b3ad66,
+	0x28136086, 0x0bd8dfa8, 0x356d1cf2,
+	0x107789be, 0xb3b2e9ce, 0x0502aa8f, 0x0bc0351e, 0x166bf52a,
+	0xeb12ff82, 0xe3486911, 0xd34d7516,
+	0x4e7b3aff, 0x5f43671b, 0x9cf6e037, 0x4981ac83, 0x334266ce,
+	0x8c9341b7, 0xd0d854c0, 0xcb3a6c88,
+	0x47bc2829, 0x4725ba37, 0xa66ad22b, 0x7ad61f1e, 0x0c5cbafa,
+	0x4437f107, 0xb6e79962, 0x42d2d816,
+	0x0a961288, 0xe1a5c06e, 0x13749e67, 0x72fc081a, 0xb1d139f7,
+	0xf9583745, 0xcf19df58, 0xbec3f756,
+	0xc06eba30, 0x07211b24, 0x45c28829, 0xc95e317f, 0xbc8ec511,
+	0x38bc46e9, 0xc6e6fa14, 0xbae8584a,
+	0xad4ebc46, 0x468f508b, 0x7829435f, 0xf124183b, 0x821dba9f,
+	0xaff60ff4, 0xea2c4e6d, 0x16e39264,
+	0x92544a8b, 0x009b4fc3, 0xaba68ced, 0x9ac96f78, 0x06a5b79a,
+	0xb2856e6e, 0x1aec3ca9, 0xbe838688,
+	0x0e0804e9, 0x55f1be56, 0xe7e5363b, 0xb3a1f25d, 0xf7debb85,
+	0x61fe033c, 0x16746233, 0x3c034c28,
+	0xda6d0c74, 0x79aac56c, 0x3ce4e1ad, 0x51f0c802, 0x98f8f35a,
+	0x1626a49f, 0xeed82b29, 0x1d382fe3,
+	0x0c4fb99a, 0xbb325778, 0x3ec6d97b, 0x6e77a6a9, 0xcb658b5c,
+	0xd45230c7, 0x2bd1408b, 0x60c03eb7,
+	0xb9068d78, 0xa33754f4, 0xf430c87d, 0xc8a71302, 0xb96d8c32,
+	0xebd4e7be, 0xbe8b9d2d, 0x7979fb06,
+	0xe7225308, 0x8b75cf77, 0x11ef8da4, 0xe083c858, 0x8d6b786f,
+	0x5a6317a6, 0xfa5cf7a0, 0x5dda0033,
+	0xf28ebfb0, 0xf5b9c310, 0xa0eac280, 0x08b9767a, 0xa3d9d2b0,
+	0x79d34217, 0x021a718d, 0x9ac6336a,
+	0x2711fd60, 0x438050e3, 0x069908a8, 0x3d7fedc4, 0x826d2bef,
+	0x4eeb8476, 0x488dcf25, 0x36c9d566,
+	0x28e74e41, 0xc2610aca, 0x3d49a9cf, 0xbae3b9df, 0xb65f8de6,
+	0x92aeaf64, 0x3ac7d5e6, 0x9ea80509,
+	0xf22b017d, 0xa4173f70, 0xdd1e16c3, 0x15e0d7f9, 0x50b1b887,
+	0x2b9f4fd5, 0x625aba82, 0x6a017962,
+	0x2ec01b9c, 0x15488aa9, 0xd716e740, 0x40055a2c, 0x93d29a22,
+	0xe32dbf9a, 0x058745b9, 0x3453dc1e,
+	0xd699296e, 0x496cff6f, 0x1c9f4986, 0xdfe2ed07, 0xb87242d1,
+	0x19de7eae, 0x053e561a, 0x15ad6f8c,
+	0x66626c1c, 0x7154c24c, 0xea082b2a, 0x93eb2939, 0x17dcb0f0,
+	0x58d4f2ae, 0x9ea294fb, 0x52cf564c,
+	0x9883fe66, 0x2ec40581, 0x763953c3, 0x01d6692e, 0xd3a0c108,
+	0xa1e7160e, 0xe4f2dfa6, 0x693ed285,
+	0x74904698, 0x4c2b0edd, 0x4f757656, 0x5d393378, 0xa132234f,
+	0x3d321c5d, 0xc3f5e194, 0x4b269301,
+	0xc79f022f, 0x3c997e7e, 0x5e4f9504, 0x3ffafbbd, 0x76f7ad0e,
+	0x296693f4, 0x3d1fce6f, 0xc61e45be,
+	0xd3b5ab34, 0xf72bf9b7, 0x1b0434c0, 0x4e72b567, 0x5592a33d,
+	0xb5229301, 0xcfd2a87f, 0x60aeb767,
+	0x1814386b, 0x30bcc33d, 0x38a0c07d, 0xfd1606f2, 0xc363519b,
+	0x589dd390, 0x5479f8e6, 0x1cb8d647,
+	0x97fd61a9, 0xea7759f4, 0x2d57539d, 0x569a58cf, 0xe84e63ad,
+	0x462e1b78, 0x6580f87e, 0xf3817914,
+	0x91da55f4, 0x40a230f3, 0xd1988f35, 0xb6e318d2, 0x3ffa50bc,
+	0x3d40f021, 0xc3c0bdae, 0x4958c24c,
+	0x518f36b2, 0x84b1d370, 0x0fedce83, 0x878ddada, 0xf2a279c7,
+	0x94e01be8, 0x90716f4b, 0x954b8aa3
+};
+static const u32 sb8[256] = {
+	0xe216300d, 0xbbddfffc, 0xa7ebdabd, 0x35648095, 0x7789f8b7,
+	0xe6c1121b, 0x0e241600, 0x052ce8b5,
+	0x11a9cfb0, 0xe5952f11, 0xece7990a, 0x9386d174, 0x2a42931c,
+	0x76e38111, 0xb12def3a, 0x37ddddfc,
+	0xde9adeb1, 0x0a0cc32c, 0xbe197029, 0x84a00940, 0xbb243a0f,
+	0xb4d137cf, 0xb44e79f0, 0x049eedfd,
+	0x0b15a15d, 0x480d3168, 0x8bbbde5a, 0x669ded42, 0xc7ece831,
+	0x3f8f95e7, 0x72df191b, 0x7580330d,
+	0x94074251, 0x5c7dcdfa, 0xabbe6d63, 0xaa402164, 0xb301d40a,
+	0x02e7d1ca, 0x53571dae, 0x7a3182a2,
+	0x12a8ddec, 0xfdaa335d, 0x176f43e8, 0x71fb46d4, 0x38129022,
+	0xce949ad4, 0xb84769ad, 0x965bd862,
+	0x82f3d055, 0x66fb9767, 0x15b80b4e, 0x1d5b47a0, 0x4cfde06f,
+	0xc28ec4b8, 0x57e8726e, 0x647a78fc,
+	0x99865d44, 0x608bd593, 0x6c200e03, 0x39dc5ff6, 0x5d0b00a3,
+	0xae63aff2, 0x7e8bd632, 0x70108c0c,
+	0xbbd35049, 0x2998df04, 0x980cf42a, 0x9b6df491, 0x9e7edd53,
+	0x06918548, 0x58cb7e07, 0x3b74ef2e,
+	0x522fffb1, 0xd24708cc, 0x1c7e27cd, 0xa4eb215b, 0x3cf1d2e2,
+	0x19b47a38, 0x424f7618, 0x35856039,
+	0x9d17dee7, 0x27eb35e6, 0xc9aff67b, 0x36baf5b8, 0x09c467cd,
+	0xc18910b1, 0xe11dbf7b, 0x06cd1af8,
+	0x7170c608, 0x2d5e3354, 0xd4de495a, 0x64c6d006, 0xbcc0c62c,
+	0x3dd00db3, 0x708f8f34, 0x77d51b42,
+	0x264f620f, 0x24b8d2bf, 0x15c1b79e, 0x46a52564, 0xf8d7e54e,
+	0x3e378160, 0x7895cda5, 0x859c15a5,
+	0xe6459788, 0xc37bc75f, 0xdb07ba0c, 0x0676a3ab, 0x7f229b1e,
+	0x31842e7b, 0x24259fd7, 0xf8bef472,
+	0x835ffcb8, 0x6df4c1f2, 0x96f5b195, 0xfd0af0fc, 0xb0fe134c,
+	0xe2506d3d, 0x4f9b12ea, 0xf215f225,
+	0xa223736f, 0x9fb4c428, 0x25d04979, 0x34c713f8, 0xc4618187,
+	0xea7a6e98, 0x7cd16efc, 0x1436876c,
+	0xf1544107, 0xbedeee14, 0x56e9af27, 0xa04aa441, 0x3cf7c899,
+	0x92ecbae6, 0xdd67016d, 0x151682eb,
+	0xa842eedf, 0xfdba60b4, 0xf1907b75, 0x20e3030f, 0x24d8c29e,
+	0xe139673b, 0xefa63fb8, 0x71873054,
+	0xb6f2cf3b, 0x9f326442, 0xcb15a4cc, 0xb01a4504, 0xf1e47d8d,
+	0x844a1be5, 0xbae7dfdc, 0x42cbda70,
+	0xcd7dae0a, 0x57e85b7a, 0xd53f5af6, 0x20cf4d8c, 0xcea4d428,
+	0x79d130a4, 0x3486ebfb, 0x33d3cddc,
+	0x77853b53, 0x37effcb5, 0xc5068778, 0xe580b3e6, 0x4e68b8f4,
+	0xc5c8b37e, 0x0d809ea2, 0x398feb7c,
+	0x132a4f94, 0x43b7950e, 0x2fee7d1c, 0x223613bd, 0xdd06caa2,
+	0x37df932b, 0xc4248289, 0xacf3ebc3,
+	0x5715f6b7, 0xef3478dd, 0xf267616f, 0xc148cbe4, 0x9052815e,
+	0x5e410fab, 0xb48a2465, 0x2eda7fa4,
+	0xe87b40e4, 0xe98ea084, 0x5889e9e1, 0xefd390fc, 0xdd07d35b,
+	0xdb485694, 0x38d7e5b2, 0x57720101,
+	0x730edebc, 0x5b643113, 0x94917e4f, 0x503c2fba, 0x646f1282,
+	0x7523d24a, 0xe0779695, 0xf9c17a8f,
+	0x7a5b2121, 0xd187b896, 0x29263a4d, 0xba510cdf, 0x81f47c9f,
+	0xad1163ed, 0xea7b5965, 0x1a00726e,
+	0x11403092, 0x00da6d77, 0x4a0cdd61, 0xad1f4603, 0x605bdfb0,
+	0x9eedc364, 0x22ebe6a8, 0xcee7d28a,
+	0xa0e736a0, 0x5564a6b9, 0x10853209, 0xc7eb8f37, 0x2de705ca,
+	0x8951570f, 0xdf09822b, 0xbd691a6c,
+	0xaa12e4f2, 0x87451c0f, 0xe0f6a27a, 0x3ada4819, 0x4cf1764f,
+	0x0d771c2b, 0x67cdb156, 0x350d8384,
+	0x5938fa0f, 0x42399ef3, 0x36997b07, 0x0e84093d, 0x4aa93e61,
+	0x8360d87b, 0x1fa98b0c, 0x1149382c,
+	0xe97625a5, 0x0614d1b7, 0x0e25244b, 0x0c768347, 0x589e8d82,
+	0x0d2059d1, 0xa466bb1e, 0xf8da0a82,
+	0x04f19130, 0xba6e4ec0, 0x99265164, 0x1ee7230d, 0x50b2ad80,
+	0xeaee6801, 0x8db2a283, 0xea8bf59e
+};
+
+
+#define rol(n,x) ( ((x) << (n)) | ((x) >> (32-(n))) )
+
+#define F1(D,m,r)  (  (I = ((m) + (D))), (I=rol((r),I)),   \
+    (((s1[I >> 24] ^ s2[(I>>16)&0xff]) - s3[(I>>8)&0xff]) + s4[I&0xff]) )
+#define F2(D,m,r)  (  (I = ((m) ^ (D))), (I=rol((r),I)),   \
+    (((s1[I >> 24] - s2[(I>>16)&0xff]) + s3[(I>>8)&0xff]) ^ s4[I&0xff]) )
+#define F3(D,m,r)  (  (I = ((m) - (D))), (I=rol((r),I)),   \
+    (((s1[I >> 24] + s2[(I>>16)&0xff]) ^ s3[(I>>8)&0xff]) - s4[I&0xff]) )
+
+
+static void cast5_encrypt(void *ctx, u8 * outbuf, const u8 * inbuf)
+{
+	struct cast5_ctx *c = (struct cast5_ctx *) ctx;
+	u32 l, r, t;
+	u32 I;			/* used by the Fx macros */
+	u32 *Km;
+	u8 *Kr;
+
+	Km = c->Km;
+	Kr = c->Kr;
+
+	/* (L0,R0) <-- (m1...m64).  (Split the plaintext into left and
+	 * right 32-bit halves L0 = m1...m32 and R0 = m33...m64.)
+	 */
+	l = inbuf[0] << 24 | inbuf[1] << 16 | inbuf[2] << 8 | inbuf[3];
+	r = inbuf[4] << 24 | inbuf[5] << 16 | inbuf[6] << 8 | inbuf[7];
+
+	/* (16 rounds) for i from 1 to 16, compute Li and Ri as follows:
+	 *  Li = Ri-1;
+	 *  Ri = Li-1 ^ f(Ri-1,Kmi,Kri), where f is defined in Section 2.2
+	 * Rounds 1, 4, 7, 10, 13, and 16 use f function Type 1.
+	 * Rounds 2, 5, 8, 11, and 14 use f function Type 2.
+	 * Rounds 3, 6, 9, 12, and 15 use f function Type 3.
+	 */
+
+	if (!(c->rr)) {
+		t = l; l = r; r = t ^ F1(r, Km[0], Kr[0]);
+		t = l; l = r; r = t ^ F2(r, Km[1], Kr[1]);
+		t = l; l = r; r = t ^ F3(r, Km[2], Kr[2]);
+		t = l; l = r; r = t ^ F1(r, Km[3], Kr[3]);
+		t = l; l = r; r = t ^ F2(r, Km[4], Kr[4]);
+		t = l; l = r; r = t ^ F3(r, Km[5], Kr[5]);
+		t = l; l = r; r = t ^ F1(r, Km[6], Kr[6]);
+		t = l; l = r; r = t ^ F2(r, Km[7], Kr[7]);
+		t = l; l = r; r = t ^ F3(r, Km[8], Kr[8]);
+		t = l; l = r; r = t ^ F1(r, Km[9], Kr[9]);
+		t = l; l = r; r = t ^ F2(r, Km[10], Kr[10]);
+		t = l; l = r; r = t ^ F3(r, Km[11], Kr[11]);
+		t = l; l = r; r = t ^ F1(r, Km[12], Kr[12]);
+		t = l; l = r; r = t ^ F2(r, Km[13], Kr[13]);
+		t = l; l = r; r = t ^ F3(r, Km[14], Kr[14]);
+		t = l; l = r; r = t ^ F1(r, Km[15], Kr[15]);
+	} else {
+		t = l; l = r; r = t ^ F1(r, Km[0], Kr[0]);
+		t = l; l = r; r = t ^ F2(r, Km[1], Kr[1]);
+		t = l; l = r; r = t ^ F3(r, Km[2], Kr[2]);
+		t = l; l = r; r = t ^ F1(r, Km[3], Kr[3]);
+		t = l; l = r; r = t ^ F2(r, Km[4], Kr[4]);
+		t = l; l = r; r = t ^ F3(r, Km[5], Kr[5]);
+		t = l; l = r; r = t ^ F1(r, Km[6], Kr[6]);
+		t = l; l = r; r = t ^ F2(r, Km[7], Kr[7]);
+		t = l; l = r; r = t ^ F3(r, Km[8], Kr[8]);
+		t = l; l = r; r = t ^ F1(r, Km[9], Kr[9]);
+		t = l; l = r; r = t ^ F2(r, Km[10], Kr[10]);
+		t = l; l = r; r = t ^ F3(r, Km[11], Kr[11]);
+	}
+
+	/* c1...c64 <-- (R16,L16).  (Exchange final blocks L16, R16 and
+	 *  concatenate to form the ciphertext.) */
+	outbuf[0] = (r >> 24) & 0xff;
+	outbuf[1] = (r >> 16) & 0xff;
+	outbuf[2] = (r >> 8) & 0xff;
+	outbuf[3] = r & 0xff;
+	outbuf[4] = (l >> 24) & 0xff;
+	outbuf[5] = (l >> 16) & 0xff;
+	outbuf[6] = (l >> 8) & 0xff;
+	outbuf[7] = l & 0xff;
+}
+
+static void cast5_decrypt(void *ctx, u8 * outbuf, const u8 * inbuf)
+{
+	struct cast5_ctx *c = (struct cast5_ctx *) ctx;
+	u32 l, r, t;
+	u32 I;
+	u32 *Km;
+	u8 *Kr;
+
+	Km = c->Km;
+	Kr = c->Kr;
+
+	l = inbuf[0] << 24 | inbuf[1] << 16 | inbuf[2] << 8 | inbuf[3];
+	r = inbuf[4] << 24 | inbuf[5] << 16 | inbuf[6] << 8 | inbuf[7];
+
+	if (!(c->rr)) {
+		t = l; l = r; r = t ^ F1(r, Km[15], Kr[15]);
+		t = l; l = r; r = t ^ F3(r, Km[14], Kr[14]);
+		t = l; l = r; r = t ^ F2(r, Km[13], Kr[13]);
+		t = l; l = r; r = t ^ F1(r, Km[12], Kr[12]);
+		t = l; l = r; r = t ^ F3(r, Km[11], Kr[11]);
+		t = l; l = r; r = t ^ F2(r, Km[10], Kr[10]);
+		t = l; l = r; r = t ^ F1(r, Km[9], Kr[9]);
+		t = l; l = r; r = t ^ F3(r, Km[8], Kr[8]);
+		t = l; l = r; r = t ^ F2(r, Km[7], Kr[7]);
+		t = l; l = r; r = t ^ F1(r, Km[6], Kr[6]);
+		t = l; l = r; r = t ^ F3(r, Km[5], Kr[5]);
+		t = l; l = r; r = t ^ F2(r, Km[4], Kr[4]);
+		t = l; l = r; r = t ^ F1(r, Km[3], Kr[3]);
+		t = l; l = r; r = t ^ F3(r, Km[2], Kr[2]);
+		t = l; l = r; r = t ^ F2(r, Km[1], Kr[1]);
+		t = l; l = r; r = t ^ F1(r, Km[0], Kr[0]);
+	} else {
+		t = l; l = r; r = t ^ F3(r, Km[11], Kr[11]);
+		t = l; l = r; r = t ^ F2(r, Km[10], Kr[10]);
+		t = l; l = r; r = t ^ F1(r, Km[9], Kr[9]);
+		t = l; l = r; r = t ^ F3(r, Km[8], Kr[8]);
+		t = l; l = r; r = t ^ F2(r, Km[7], Kr[7]);
+		t = l; l = r; r = t ^ F1(r, Km[6], Kr[6]);
+		t = l; l = r; r = t ^ F3(r, Km[5], Kr[5]);
+		t = l; l = r; r = t ^ F2(r, Km[4], Kr[4]);
+		t = l; l = r; r = t ^ F1(r, Km[3], Kr[3]);
+		t = l; l = r; r = t ^ F3(r, Km[2], Kr[2]);
+		t = l; l = r; r = t ^ F2(r, Km[1], Kr[1]);
+		t = l; l = r; r = t ^ F1(r, Km[0], Kr[0]);
+	}
+
+	outbuf[0] = (r >> 24) & 0xff;
+	outbuf[1] = (r >> 16) & 0xff;
+	outbuf[2] = (r >> 8) & 0xff;
+	outbuf[3] = r & 0xff;
+	outbuf[4] = (l >> 24) & 0xff;
+	outbuf[5] = (l >> 16) & 0xff;
+	outbuf[6] = (l >> 8) & 0xff;
+	outbuf[7] = l & 0xff;
+}
+
+static void key_schedule(u32 * x, u32 * z, u32 * k)
+{
+
+#define xi(i)   ((x[(i)/4] >> (8*(3-((i)%4)))) & 0xff)
+#define zi(i)   ((z[(i)/4] >> (8*(3-((i)%4)))) & 0xff)
+
+	z[0] = x[0] ^ s5[xi(13)] ^ s6[xi(15)] ^ s7[xi(12)] ^ sb8[xi(14)] ^
+	    s7[xi(8)];
+	z[1] = x[2] ^ s5[zi(0)] ^ s6[zi(2)] ^ s7[zi(1)] ^ sb8[zi(3)] ^
+	    sb8[xi(10)];
+	z[2] = x[3] ^ s5[zi(7)] ^ s6[zi(6)] ^ s7[zi(5)] ^ sb8[zi(4)] ^
+	    s5[xi(9)];
+	z[3] = x[1] ^ s5[zi(10)] ^ s6[zi(9)] ^ s7[zi(11)] ^ sb8[zi(8)] ^
+	    s6[xi(11)];
+	k[0] = s5[zi(8)] ^ s6[zi(9)] ^ s7[zi(7)] ^ sb8[zi(6)] ^ s5[zi(2)];
+	k[1] = s5[zi(10)] ^ s6[zi(11)] ^ s7[zi(5)] ^ sb8[zi(4)] ^
+	    s6[zi(6)];
+	k[2] = s5[zi(12)] ^ s6[zi(13)] ^ s7[zi(3)] ^ sb8[zi(2)] ^
+	    s7[zi(9)];
+	k[3] = s5[zi(14)] ^ s6[zi(15)] ^ s7[zi(1)] ^ sb8[zi(0)] ^
+	    sb8[zi(12)];
+
+	x[0] = z[2] ^ s5[zi(5)] ^ s6[zi(7)] ^ s7[zi(4)] ^ sb8[zi(6)] ^
+	    s7[zi(0)];
+	x[1] = z[0] ^ s5[xi(0)] ^ s6[xi(2)] ^ s7[xi(1)] ^ sb8[xi(3)] ^
+	    sb8[zi(2)];
+	x[2] = z[1] ^ s5[xi(7)] ^ s6[xi(6)] ^ s7[xi(5)] ^ sb8[xi(4)] ^
+	    s5[zi(1)];
+	x[3] = z[3] ^ s5[xi(10)] ^ s6[xi(9)] ^ s7[xi(11)] ^ sb8[xi(8)] ^
+	    s6[zi(3)];
+	k[4] = s5[xi(3)] ^ s6[xi(2)] ^ s7[xi(12)] ^ sb8[xi(13)] ^
+	    s5[xi(8)];
+	k[5] = s5[xi(1)] ^ s6[xi(0)] ^ s7[xi(14)] ^ sb8[xi(15)] ^
+	    s6[xi(13)];
+	k[6] = s5[xi(7)] ^ s6[xi(6)] ^ s7[xi(8)] ^ sb8[xi(9)] ^ s7[xi(3)];
+	k[7] = s5[xi(5)] ^ s6[xi(4)] ^ s7[xi(10)] ^ sb8[xi(11)] ^
+	    sb8[xi(7)];
+
+	z[0] = x[0] ^ s5[xi(13)] ^ s6[xi(15)] ^ s7[xi(12)] ^ sb8[xi(14)] ^
+	    s7[xi(8)];
+	z[1] = x[2] ^ s5[zi(0)] ^ s6[zi(2)] ^ s7[zi(1)] ^ sb8[zi(3)] ^
+	    sb8[xi(10)];
+	z[2] = x[3] ^ s5[zi(7)] ^ s6[zi(6)] ^ s7[zi(5)] ^ sb8[zi(4)] ^
+	    s5[xi(9)];
+	z[3] = x[1] ^ s5[zi(10)] ^ s6[zi(9)] ^ s7[zi(11)] ^ sb8[zi(8)] ^
+	    s6[xi(11)];
+	k[8] = s5[zi(3)] ^ s6[zi(2)] ^ s7[zi(12)] ^ sb8[zi(13)] ^
+	    s5[zi(9)];
+	k[9] = s5[zi(1)] ^ s6[zi(0)] ^ s7[zi(14)] ^ sb8[zi(15)] ^
+	    s6[zi(12)];
+	k[10] = s5[zi(7)] ^ s6[zi(6)] ^ s7[zi(8)] ^ sb8[zi(9)] ^ s7[zi(2)];
+	k[11] = s5[zi(5)] ^ s6[zi(4)] ^ s7[zi(10)] ^ sb8[zi(11)] ^
+	    sb8[zi(6)];
+
+	x[0] = z[2] ^ s5[zi(5)] ^ s6[zi(7)] ^ s7[zi(4)] ^ sb8[zi(6)] ^
+	    s7[zi(0)];
+	x[1] = z[0] ^ s5[xi(0)] ^ s6[xi(2)] ^ s7[xi(1)] ^ sb8[xi(3)] ^
+	    sb8[zi(2)];
+	x[2] = z[1] ^ s5[xi(7)] ^ s6[xi(6)] ^ s7[xi(5)] ^ sb8[xi(4)] ^
+	    s5[zi(1)];
+	x[3] = z[3] ^ s5[xi(10)] ^ s6[xi(9)] ^ s7[xi(11)] ^ sb8[xi(8)] ^
+	    s6[zi(3)];
+	k[12] = s5[xi(8)] ^ s6[xi(9)] ^ s7[xi(7)] ^ sb8[xi(6)] ^ s5[xi(3)];
+	k[13] = s5[xi(10)] ^ s6[xi(11)] ^ s7[xi(5)] ^ sb8[xi(4)] ^
+	    s6[xi(7)];
+	k[14] = s5[xi(12)] ^ s6[xi(13)] ^ s7[xi(3)] ^ sb8[xi(2)] ^
+	    s7[xi(8)];
+	k[15] = s5[xi(14)] ^ s6[xi(15)] ^ s7[xi(1)] ^ sb8[xi(0)] ^
+	    sb8[xi(13)];
+
+#undef xi
+#undef zi
+}
+
+
+static int
+cast5_setkey(void *ctx, const u8 * key, unsigned key_len, u32 * flags)
+{
+	int i;
+	u32 x[4];
+	u32 z[4];
+	u32 k[16];
+	u8 p_key[16];
+	struct cast5_ctx *c = (struct cast5_ctx *) ctx;
+	
+	if (key_len < 5 || key_len > 16) {
+		*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;
+		return -EINVAL;
+	}
+
+	c->rr = key_len <= 10 ? 1 : 0;
+
+	memset(p_key, 0, 16);
+	memcpy(p_key, key, key_len);
+
+
+	x[0] = p_key[0] << 24 | p_key[1] << 16 | p_key[2] << 8 | p_key[3];
+	x[1] = p_key[4] << 24 | p_key[5] << 16 | p_key[6] << 8 | p_key[7];
+	x[2] =
+	    p_key[8] << 24 | p_key[9] << 16 | p_key[10] << 8 | p_key[11];
+	x[3] =
+	    p_key[12] << 24 | p_key[13] << 16 | p_key[14] << 8 | p_key[15];
+
+	key_schedule(x, z, k);
+	for (i = 0; i < 16; i++)
+		c->Km[i] = k[i];
+	key_schedule(x, z, k);
+	for (i = 0; i < 16; i++)
+		c->Kr[i] = k[i] & 0x1f;
+	return 0;
+}
+
+static struct crypto_alg alg = {
+	.cra_name 	= "cast5",
+	.cra_flags 	= CRYPTO_ALG_TYPE_CIPHER,
+	.cra_blocksize 	= CAST5_BLOCK_SIZE,
+	.cra_ctxsize 	= sizeof(struct cast5_ctx),
+	.cra_module 	= THIS_MODULE,
+	.cra_list 	= LIST_HEAD_INIT(alg.cra_list),
+	.cra_u 		= {
+		.cipher = {
+			.cia_min_keysize = CAST5_MIN_KEY_SIZE,
+			.cia_max_keysize = CAST5_MAX_KEY_SIZE,
+			.cia_ivsize = CAST5_BLOCK_SIZE,
+			.cia_setkey = cast5_setkey,
+			.cia_encrypt = cast5_encrypt,
+			.cia_decrypt = cast5_decrypt
+		}
+	}
+};
+
+static int __init init(void)
+{
+	return crypto_register_alg(&alg);
+}
+
+static void __exit fini(void)
+{
+	crypto_unregister_alg(&alg);
+}
+
+module_init(init);
+module_exit(fini);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Cast5 Cipher Algorithm");
+
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/crypto/tcrypt.c linux-2.4.23-pre1/crypto/tcrypt.c
--- linux-2.4.22/crypto/tcrypt.c	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/crypto/tcrypt.c	2003-08-27 14:40:45.000000000 +0000
@@ -2192,6 +2192,102 @@
 	crypto_free_tfm(tfm);
 }
 
+void
+test_cast5(void)
+{
+	unsigned int ret, i, tsize;
+	u8 *p, *q, *key;
+	struct crypto_tfm *tfm;
+	struct cast5_tv *c5_tv;
+	struct scatterlist sg[1];
+
+	printk("\ntesting cast5 encryption\n");
+
+	tfm = crypto_alloc_tfm("cast5", 0);
+	if (tfm == NULL) {
+		printk("failed to load transform for cast5 (default ecb)\n");
+		return;
+	}
+
+	tsize = sizeof (cast5_enc_tv_template);
+	if (tsize > TVMEMSIZE) {
+		printk("template (%u) too big for tvmem (%u)\n", tsize,
+		       TVMEMSIZE);
+		return;
+	}
+
+	memcpy(tvmem, cast5_enc_tv_template, tsize);
+	c5_tv = (void *) tvmem;
+	for (i = 0; i < CAST5_ENC_TEST_VECTORS; i++) {
+		printk("test %u (%d bit key):\n", i + 1, c5_tv[i].keylen * 8);
+		key = c5_tv[i].key;
+
+		ret = crypto_cipher_setkey(tfm, key, c5_tv[i].keylen);
+		if (ret) {
+			printk("setkey() failed flags=%x\n", tfm->crt_flags);
+
+			if (!c5_tv[i].fail)
+				goto out;
+		}
+
+		p = c5_tv[i].plaintext;
+		sg[0].page = virt_to_page(p);
+		sg[0].offset = ((long) p & ~PAGE_MASK);
+		sg[0].length = sizeof(c5_tv[i].plaintext);
+		ret = crypto_cipher_encrypt(tfm, sg, sg, sg[0].length);
+		if (ret) {
+			printk("encrypt() failed flags=%x\n", tfm->crt_flags);
+			goto out;
+		}
+
+		q = kmap(sg[0].page) + sg[0].offset;
+		hexdump(q, sizeof(c5_tv[i].ciphertext));
+
+		printk("%s\n", memcmp(q, c5_tv[i].ciphertext,
+			sizeof(c5_tv[i].ciphertext)) ? "fail" : "pass");
+	}
+	
+	tsize = sizeof (cast5_dec_tv_template);
+	if (tsize > TVMEMSIZE) {
+		printk("template (%u) too big for tvmem (%u)\n", tsize,
+		       TVMEMSIZE);
+		return;
+	}
+
+	memcpy(tvmem, cast5_dec_tv_template, tsize);
+	c5_tv = (void *) tvmem;
+	for (i = 0; i < CAST5_DEC_TEST_VECTORS; i++) {
+		printk("test %u (%d bit key):\n", i + 1, c5_tv[i].keylen * 8);
+		key = c5_tv[i].key;
+
+		ret = crypto_cipher_setkey(tfm, key, c5_tv[i].keylen);
+		if (ret) {
+			printk("setkey() failed flags=%x\n", tfm->crt_flags);
+
+			if (!c5_tv[i].fail)
+				goto out;
+		}
+
+		p = c5_tv[i].plaintext;
+		sg[0].page = virt_to_page(p);
+		sg[0].offset = ((long) p & ~PAGE_MASK);
+		sg[0].length = sizeof(c5_tv[i].plaintext);
+		ret = crypto_cipher_decrypt(tfm, sg, sg, sg[0].length);
+		if (ret) {
+			printk("decrypt() failed flags=%x\n", tfm->crt_flags);
+			goto out;
+		}
+
+		q = kmap(sg[0].page) + sg[0].offset;
+		hexdump(q, sizeof(c5_tv[i].ciphertext));
+
+		printk("%s\n", memcmp(q, c5_tv[i].ciphertext,
+			sizeof(c5_tv[i].ciphertext)) ? "fail" : "pass");
+	}
+out:
+	crypto_free_tfm (tfm);
+}
+
 static void
 test_deflate(void)
 {
@@ -2304,6 +2400,7 @@
 		test_sha384();
 		test_sha512();
 		test_deflate();
+		test_cast5();
 #ifdef CONFIG_CRYPTO_HMAC
 		test_hmac_md5();
 		test_hmac_sha1();
@@ -2363,6 +2460,10 @@
 		test_deflate();
 		break;
 
+	case 14:
+		test_cast5();
+		break;
+
 #ifdef CONFIG_CRYPTO_HMAC
 	case 100:
 		test_hmac_md5();
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/crypto/tcrypt.h linux-2.4.23-pre1/crypto/tcrypt.h
--- linux-2.4.22/crypto/tcrypt.h	2003-08-25 11:44:40.000000000 +0000
+++ linux-2.4.23-pre1/crypto/tcrypt.h	2003-08-27 14:41:49.000000000 +0000
@@ -1682,6 +1682,74 @@
 	},
 };
 
+/* Cast5 test vectors from RFC 2144 */
+#define CAST5_ENC_TEST_VECTORS	3
+#define CAST5_DEC_TEST_VECTORS	3
+
+struct cast5_tv {
+	unsigned keylen;
+	unsigned fail;
+	u8 key[16];
+	u8 plaintext[8];
+	u8 ciphertext[8];
+};
+
+struct cast5_tv cast5_enc_tv_template[] =
+{
+	{
+		16,
+		0,
+		{ 0x01, 0x23, 0x45, 0x67, 0x12, 0x34, 0x56, 0x78,
+		  0x23, 0x45, 0x67, 0x89, 0x34, 0x56, 0x78, 0x9A },
+		{ 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef },
+		{ 0x23, 0x8b, 0x4f, 0xe5, 0x84, 0x7e, 0x44, 0xb2 },
+
+	},
+	{
+		10,
+		0,
+		{ 0x01, 0x23, 0x45, 0x67, 0x12, 0x34, 0x56, 0x78,
+		  0x23, 0x45 },
+		{ 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef },
+		{ 0xeb, 0x6a, 0x71, 0x1a, 0x2c, 0x02, 0x27, 0x1b },
+	},
+	{
+		5,
+		0,
+		{ 0x01, 0x23, 0x45, 0x67, 0x12 },
+		{ 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef },
+		{ 0x7a, 0xc8, 0x16, 0xd1, 0x6e, 0x9b, 0x30, 0x2e },
+	}
+};
+
+struct cast5_tv cast5_dec_tv_template[] =
+{
+	{
+		16,
+		0,
+		{ 0x01, 0x23, 0x45, 0x67, 0x12, 0x34, 0x56, 0x78,
+		  0x23, 0x45, 0x67, 0x89, 0x34, 0x56, 0x78, 0x9A },
+		{ 0x23, 0x8b, 0x4f, 0xe5, 0x84, 0x7e, 0x44, 0xb2 },
+		{ 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef },
+
+	},
+	{
+		10,
+		0,
+		{ 0x01, 0x23, 0x45, 0x67, 0x12, 0x34, 0x56, 0x78,
+		  0x23, 0x45 },
+		{ 0xeb, 0x6a, 0x71, 0x1a, 0x2c, 0x02, 0x27, 0x1b },
+		{ 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef },
+	},
+	{
+		5,
+		0,
+		{ 0x01, 0x23, 0x45, 0x67, 0x12 },
+		{ 0x7a, 0xc8, 0x16, 0xd1, 0x6e, 0x9b, 0x30, 0x2e },
+		{ 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef },
+	}
+};
+
 /*
  * Compression stuff.
  */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/atm/Makefile linux-2.4.23-pre1/drivers/atm/Makefile
--- linux-2.4.22/drivers/atm/Makefile	2003-08-25 11:44:41.000000000 +0000
+++ linux-2.4.23-pre1/drivers/atm/Makefile	2003-08-27 14:39:16.000000000 +0000
@@ -59,8 +59,6 @@
   obj-$(CONFIG_ATM_HE)		+= suni.o
 endif
 
-EXTRA_CFLAGS=-g
-
 list-multi	:= fore_200e.o
 fore_200e-objs	:= fore200e.o $(FORE200E_FW_OBJS)
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/atm/he.c linux-2.4.23-pre1/drivers/atm/he.c
--- linux-2.4.22/drivers/atm/he.c	2003-08-25 11:44:41.000000000 +0000
+++ linux-2.4.23-pre1/drivers/atm/he.c	2003-08-27 14:39:40.000000000 +0000
@@ -89,7 +89,7 @@
 
 /* compatibility */
 
-#if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,69)
+#ifndef IRQ_HANDLED
 typedef void irqreturn_t;
 #define IRQ_NONE
 #define IRQ_HANDLED
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/Config.in linux-2.4.23-pre1/drivers/char/Config.in
--- linux-2.4.22/drivers/char/Config.in	2003-08-25 11:44:41.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/Config.in	2003-08-27 14:39:44.000000000 +0000
@@ -267,6 +267,10 @@
 if [ "$CONFIG_X86" = "y" -o "$CONFIG_IA64" = "y" ]; then
    dep_tristate 'Intel i8x0 Random Number Generator support' CONFIG_INTEL_RNG $CONFIG_PCI
 fi
+if [ "$CONFIG_X86" = "y" -o "$CONFIG_IA64" = "y" -o \
+     "$CONFIG_X86_64" = "y" ]; then
+   dep_tristate 'Intel/AMD/VIA HW Random Number Generator support' CONFIG_HW_RANDOM $CONFIG_PCI
+fi
 dep_tristate 'AMD 76x native power management (Experimental)' CONFIG_AMD_PM768 $CONFIG_PCI
 tristate '/dev/nvram support' CONFIG_NVRAM
 tristate 'Enhanced Real Time Clock Support' CONFIG_RTC
@@ -317,18 +321,7 @@
    fi
 fi
 
-bool 'Direct Rendering Manager (XFree86 DRI support)' CONFIG_DRM
-if [ "$CONFIG_DRM" = "y" ]; then
-   bool '  Build drivers for old (XFree 4.0) DRM' CONFIG_DRM_OLD
-   if [ "$CONFIG_DRM_OLD" = "y" ]; then
-      comment 'DRM 4.0 drivers'
-      source drivers/char/drm-4.0/Config.in
-   else
-      comment 'DRM 4.1 drivers'
-      define_bool CONFIG_DRM_NEW y
-      source drivers/char/drm/Config.in
-   fi
-fi
+source drivers/char/DRM-Config.in
 
 if [ "$CONFIG_HOTPLUG" = "y" -a "$CONFIG_PCMCIA" != "n" ]; then
    source drivers/char/pcmcia/Config.in
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/DRM-Config.in linux-2.4.23-pre1/drivers/char/DRM-Config.in
--- linux-2.4.22/drivers/char/DRM-Config.in	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/DRM-Config.in	2003-08-27 14:40:28.000000000 +0000
@@ -0,0 +1,16 @@
+mainmenu_option next_comment
+comment 'Direct Rendering Manager (XFree86 DRI support)'
+bool 'Direct Rendering Manager (XFree86 DRI support)' CONFIG_DRM
+if [ "$CONFIG_DRM" = "y" ]; then
+   bool '  Build drivers for old (XFree 4.0) DRM' CONFIG_DRM_OLD
+   if [ "$CONFIG_DRM_OLD" = "y" ]; then
+      comment 'DRM 4.0 drivers'
+      source drivers/char/drm-4.0/Config.in
+   else
+      comment 'DRM 4.1 drivers'   
+      define_bool CONFIG_DRM_NEW y
+      source drivers/char/drm/Config.in
+   fi
+fi
+endmenu
+
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/Makefile linux-2.4.23-pre1/drivers/char/Makefile
--- linux-2.4.22/drivers/char/Makefile	2003-08-25 11:44:41.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/Makefile	2003-08-27 14:41:46.000000000 +0000
@@ -247,6 +247,7 @@
 obj-$(CONFIG_DS1620) += ds1620.o
 obj-$(CONFIG_INTEL_RNG) += i810_rng.o
 obj-$(CONFIG_AMD_RNG) += amd768_rng.o
+obj-$(CONFIG_HW_RANDOM) += hw_random.o
 obj-$(CONFIG_AMD_PM768) += amd76x_pm.o
 obj-$(CONFIG_BRIQ_PANEL) += briq_panel.o
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/agp/agp.h linux-2.4.23-pre1/drivers/char/agp/agp.h
--- linux-2.4.22/drivers/char/agp/agp.h	2003-08-25 11:44:41.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/agp/agp.h	2003-08-27 14:40:23.000000000 +0000
@@ -223,6 +223,12 @@
 #ifndef PCI_DEVICE_ID_INTEL_860_0
 #define PCI_DEVICE_ID_INTEL_860_0     0x2531
 #endif
+#ifndef PCI_DEVICE_ID_INTEL_7205_0
+#define PCI_DEVICE_ID_INTEL_7205_0     0x255d
+#endif
+#ifndef PCI_DEVICE_ID_INTEL_7505_0
+#define PCI_DEVICE_ID_INTEL_7505_0     0x2550
+#endif
 #ifndef PCI_DEVICE_ID_INTEL_810_DC100_0
 #define PCI_DEVICE_ID_INTEL_810_DC100_0 0x7122
 #endif
@@ -366,6 +372,10 @@
 #define INTEL_I860_MCHCFG	0x50
 #define INTEL_I860_ERRSTS	0xc8
 
+/* intel i7505 registers */
+#define INTEL_I7505_MCHCFG	0x50
+#define INTEL_I7505_ERRSTS	0x42
+
 /* intel i810 registers */
 #define I810_GMADDR 0x10
 #define I810_MMADDR 0x14
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/agp/agpgart_be.c linux-2.4.23-pre1/drivers/char/agp/agpgart_be.c
--- linux-2.4.22/drivers/char/agp/agpgart_be.c	2003-08-25 11:44:41.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/agp/agpgart_be.c	2003-08-27 14:39:36.000000000 +0000
@@ -1817,6 +1817,37 @@
 }
 
 
+static int intel_7505_configure(void)
+{
+	u32 temp;
+	u16 temp2;
+	aper_size_info_8 *current_size;
+
+	current_size = A_SIZE_8(agp_bridge.current_size);
+
+	/* aperture size */
+	pci_write_config_byte(agp_bridge.dev, INTEL_APSIZE,
+			      current_size->size_value);
+
+	/* address to map to */
+	pci_read_config_dword(agp_bridge.dev, INTEL_APBASE, &temp);
+	agp_bridge.gart_bus_addr = (temp & PCI_BASE_ADDRESS_MEM_MASK);
+
+	/* attbase - aperture base */
+	pci_write_config_dword(agp_bridge.dev, INTEL_ATTBASE,
+			       agp_bridge.gatt_bus_addr);
+
+	/* agpctrl */
+	pci_write_config_dword(agp_bridge.dev, INTEL_AGPCTRL, 0x0000);
+
+	/* mcgcfg */
+	pci_read_config_word(agp_bridge.dev, INTEL_I7505_MCHCFG, &temp2);
+	pci_write_config_word(agp_bridge.dev, INTEL_I7505_MCHCFG,
+			      temp2 | (1 << 9));
+	return 0;
+}
+
+
 static unsigned long intel_mask_memory(unsigned long addr, int type)
 {
 	/* Memory type is ignored */
@@ -2126,6 +2157,38 @@
 	(void) pdev; /* unused */
 }
 
+static int __init intel_7505_setup (struct pci_dev *pdev)
+{
+	agp_bridge.masks = intel_generic_masks;
+	agp_bridge.aperture_sizes = (void *) intel_8xx_sizes;
+	agp_bridge.size_type = U8_APER_SIZE;
+	agp_bridge.num_aperture_sizes = 7;
+	agp_bridge.dev_private_data = NULL;
+	agp_bridge.needs_scratch_page = FALSE;
+	agp_bridge.configure = intel_7505_configure;
+	agp_bridge.fetch_size = intel_8xx_fetch_size;
+	agp_bridge.cleanup = intel_8xx_cleanup;
+	agp_bridge.tlb_flush = intel_8xx_tlbflush;
+	agp_bridge.mask_memory = intel_mask_memory;
+	agp_bridge.agp_enable = agp_generic_agp_enable;
+	agp_bridge.cache_flush = global_cache_flush;
+	agp_bridge.create_gatt_table = agp_generic_create_gatt_table;
+	agp_bridge.free_gatt_table = agp_generic_free_gatt_table;
+	agp_bridge.insert_memory = agp_generic_insert_memory;
+	agp_bridge.remove_memory = agp_generic_remove_memory;
+	agp_bridge.alloc_by_type = agp_generic_alloc_by_type;
+	agp_bridge.free_by_type = agp_generic_free_by_type;
+	agp_bridge.agp_alloc_page = agp_generic_alloc_page;
+	agp_bridge.agp_destroy_page = agp_generic_destroy_page;
+	agp_bridge.suspend = agp_generic_suspend;
+	agp_bridge.resume = agp_generic_resume;
+	agp_bridge.cant_use_aperture = 0;
+
+	return 0;
+
+	(void) pdev; /* unused */
+}
+
 #endif /* CONFIG_AGP_INTEL */
 
 #ifdef CONFIG_AGP_VIA
@@ -4942,6 +5005,18 @@
 		"Intel",
 		"i860",
 		intel_860_setup },
+	{ PCI_DEVICE_ID_INTEL_7205_0,
+		PCI_VENDOR_ID_INTEL,
+		INTEL_I7205,
+		"Intel",
+		"i7205",
+		intel_7505_setup },
+	{ PCI_DEVICE_ID_INTEL_7505_0,
+		PCI_VENDOR_ID_INTEL,
+		INTEL_I7505,
+		"Intel",
+		"i7505",
+		intel_7505_setup },
 	{ 0,
 		PCI_VENDOR_ID_INTEL,
 		INTEL_GENERIC,
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/amd76x_pm.c linux-2.4.23-pre1/drivers/char/amd76x_pm.c
--- linux-2.4.22/drivers/char/amd76x_pm.c	2003-08-25 11:44:41.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/amd76x_pm.c	2003-08-27 14:40:08.000000000 +0000
@@ -577,16 +577,18 @@
 	int found;
 
 	/* Find northbridge */
-	found = pci_module_init(&amd_nb_driver);
-	if (found < 0) {
+	found = pci_register_driver(&amd_nb_driver);
+	if (found <= 0) {
 		printk(KERN_ERR "amd76x_pm: Could not find northbridge\n");
+		pci_unregister_driver(&amd_nb_driver);
 		return 1;
 	}
 
 	/* Find southbridge */
-	found = pci_module_init(&amd_sb_driver);
-	if (found < 0) {
+	found = pci_register_driver(&amd_sb_driver);
+	if (found <= 0) {
 		printk(KERN_ERR "amd76x_pm: Could not find southbridge\n");
+		pci_unregister_driver(&amd_sb_driver);
 		pci_unregister_driver(&amd_nb_driver);
 		return 1;
 	}
@@ -620,6 +622,8 @@
 #ifndef AMD76X_NTH
 	if (!amd76x_pm_cfg.curr_idle) {
 		printk(KERN_ERR "amd76x_pm: Idle function not changed\n");
+		pci_unregister_driver(&amd_nb_driver);
+		pci_unregister_driver(&amd_sb_driver);
 		return 1;
 	}
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/console.c linux-2.4.23-pre1/drivers/char/console.c
--- linux-2.4.22/drivers/char/console.c	2002-11-28 23:53:12.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/console.c	2003-08-27 14:41:31.000000000 +0000
@@ -112,6 +112,8 @@
 
 const struct consw *conswitchp;
 
+static void __console_callback(void);
+
 /* A bitmap for codes <32. A bit of 1 indicates that the code
  * corresponding to that bit number invokes some special action
  * (such as cursor movement) and should not be displayed as a
@@ -242,9 +244,16 @@
 	schedule_console_callback();
 }
 
+extern int machine_paniced; 
+
 void schedule_console_callback(void)
 {
-	schedule_task(&console_callback_tq);
+	/* Don't care about locking after panic - but I want to switch the console
+	   NOW */ 
+	if (machine_paniced)
+		__console_callback(); 
+	else
+		schedule_task(&console_callback_tq);
 }
 
 static void scrup(int currcons, unsigned int t, unsigned int b, int nr)
@@ -2039,10 +2048,15 @@
  * with other console code and prevention of re-entrancy is
  * ensured with console_sem.
  */
-static void console_callback(void *ignored)
+static void console_callback(void *unused) 
 {
 	acquire_console_sem();
+	__console_callback(); 
+	release_console_sem();	
+} 
 
+static void __console_callback(void)
+{
 	if (want_console >= 0) {
 		if (want_console != fg_console && vc_cons_allocated(want_console)) {
 			hide_cursor(fg_console);
@@ -2064,8 +2078,6 @@
 			sw->con_scrolldelta(vc_cons[currcons].d, scrollback_delta);
 		scrollback_delta = 0;
 	}
-
-	release_console_sem();
 }
 
 void set_console(int nr)
@@ -2765,6 +2777,12 @@
 	timer_do_blank_screen(0, 1);
 }
 
+void disable_console_blank(void)
+{
+	del_timer_sync(&console_timer);
+	blankinterval = 0;
+}
+
 void poke_blanked_console(void)
 {
 	del_timer(&console_timer);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/hw_random.c linux-2.4.23-pre1/drivers/char/hw_random.c
--- linux-2.4.22/drivers/char/hw_random.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/hw_random.c	2003-08-27 14:39:39.000000000 +0000
@@ -0,0 +1,631 @@
+/*
+ 	Hardware driver for the Intel/AMD/VIA Random Number Generators (RNG)
+	(c) Copyright 2003 Red Hat Inc <jgarzik@redhat.com>
+ 
+ 	derived from
+ 
+        Hardware driver for the AMD 768 Random Number Generator (RNG)
+        (c) Copyright 2001 Red Hat Inc <alan@redhat.com>
+
+ 	derived from
+ 
+	Hardware driver for Intel i810 Random Number Generator (RNG)
+	Copyright 2000,2001 Jeff Garzik <jgarzik@pobox.com>
+	Copyright 2000,2001 Philipp Rumpf <prumpf@mandrakesoft.com>
+
+	Please read Documentation/hw_random.txt for details on use.
+
+	----------------------------------------------------------
+	This software may be used and distributed according to the terms
+        of the GNU General Public License, incorporated herein by reference.
+
+ */
+
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/random.h>
+#include <linux/miscdevice.h>
+#include <linux/smp_lock.h>
+#include <linux/mm.h>
+#include <linux/delay.h>
+
+#ifdef __i386__
+#include <asm/msr.h>
+#include <asm/cpufeature.h>
+#endif
+
+#include <asm/io.h>
+#include <asm/uaccess.h>
+
+
+/*
+ * core module and version information
+ */
+#define RNG_VERSION "1.0.0"
+#define RNG_MODULE_NAME "hw_random"
+#define RNG_DRIVER_NAME   RNG_MODULE_NAME " hardware driver " RNG_VERSION
+#define PFX RNG_MODULE_NAME ": "
+
+
+/*
+ * debugging macros
+ */
+#undef RNG_DEBUG /* define to enable copious debugging info */
+
+#ifdef RNG_DEBUG
+/* note: prints function name for you */
+#define DPRINTK(fmt, args...) printk(KERN_DEBUG "%s: " fmt, __FUNCTION__ , ## args)
+#else
+#define DPRINTK(fmt, args...)
+#endif
+
+#define RNG_NDEBUG        /* define to disable lightweight runtime checks */
+#ifdef RNG_NDEBUG
+#define assert(expr)
+#else
+#define assert(expr) \
+        if(!(expr)) {                                   \
+        printk( "Assertion failed! %s,%s,%s,line=%d\n", \
+        #expr,__FILE__,__FUNCTION__,__LINE__);          \
+        }
+#endif
+
+#define RNG_MISCDEV_MINOR		183 /* official */
+
+static int rng_dev_open (struct inode *inode, struct file *filp);
+static ssize_t rng_dev_read (struct file *filp, char *buf, size_t size,
+			     loff_t * offp);
+
+static int __init intel_init (struct pci_dev *dev);
+static void intel_cleanup(void);
+static unsigned int intel_data_present (void);
+static u32 intel_data_read (void);
+
+static int __init amd_init (struct pci_dev *dev);
+static void amd_cleanup(void);
+static unsigned int amd_data_present (void);
+static u32 amd_data_read (void);
+
+static int __init via_init(struct pci_dev *dev);
+static void via_cleanup(void);
+static unsigned int via_data_present (void);
+static u32 via_data_read (void);
+
+struct rng_operations {
+	int (*init) (struct pci_dev *dev);
+	void (*cleanup) (void);
+	unsigned int (*data_present) (void);
+	u32 (*data_read) (void);
+	unsigned int n_bytes; /* number of bytes per ->data_read */
+};
+static struct rng_operations *rng_ops;
+
+static struct file_operations rng_chrdev_ops = {
+	.owner		= THIS_MODULE,
+	.open		= rng_dev_open,
+	.read		= rng_dev_read,
+};
+
+
+static struct miscdevice rng_miscdev = {
+	RNG_MISCDEV_MINOR,
+	RNG_MODULE_NAME,
+	&rng_chrdev_ops,
+};
+
+enum {
+	rng_hw_none,
+	rng_hw_intel,
+	rng_hw_amd,
+	rng_hw_via,
+};
+
+static struct rng_operations rng_vendor_ops[] = {
+	/* rng_hw_none */
+	{ },
+
+	/* rng_hw_intel */
+	{ intel_init, intel_cleanup, intel_data_present,
+	  intel_data_read, 1 },
+
+	/* rng_hw_amd */
+	{ amd_init, amd_cleanup, amd_data_present, amd_data_read, 4 },
+
+	/* rng_hw_via */
+	{ via_init, via_cleanup, via_data_present, via_data_read, 1 },
+};
+
+/*
+ * Data for PCI driver interface
+ *
+ * This data only exists for exporting the supported
+ * PCI ids via MODULE_DEVICE_TABLE.  We do not actually
+ * register a pci_driver, because someone else might one day
+ * want to register another driver on the same PCI id.
+ */
+static struct pci_device_id rng_pci_tbl[] __initdata = {
+	{ 0x1022, 0x7443, PCI_ANY_ID, PCI_ANY_ID, 0, 0, rng_hw_amd },
+	{ 0x1022, 0x746b, PCI_ANY_ID, PCI_ANY_ID, 0, 0, rng_hw_amd },
+
+	{ 0x8086, 0x2418, PCI_ANY_ID, PCI_ANY_ID, 0, 0, rng_hw_intel },
+	{ 0x8086, 0x2428, PCI_ANY_ID, PCI_ANY_ID, 0, 0, rng_hw_intel },
+	{ 0x8086, 0x2448, PCI_ANY_ID, PCI_ANY_ID, 0, 0, rng_hw_intel },
+	{ 0x8086, 0x244e, PCI_ANY_ID, PCI_ANY_ID, 0, 0, rng_hw_intel },
+	{ 0x8086, 0x245e, PCI_ANY_ID, PCI_ANY_ID, 0, 0, rng_hw_intel },
+
+	{ 0, },	/* terminate list */
+};
+MODULE_DEVICE_TABLE (pci, rng_pci_tbl);
+
+
+/***********************************************************************
+ *
+ * Intel RNG operations
+ *
+ */
+
+/*
+ * RNG registers (offsets from rng_mem)
+ */
+#define INTEL_RNG_HW_STATUS			0
+#define         INTEL_RNG_PRESENT		0x40
+#define         INTEL_RNG_ENABLED		0x01
+#define INTEL_RNG_STATUS			1
+#define         INTEL_RNG_DATA_PRESENT		0x01
+#define INTEL_RNG_DATA				2
+
+/*
+ * Magic address at which Intel PCI bridges locate the RNG
+ */
+#define INTEL_RNG_ADDR				0xFFBC015F
+#define INTEL_RNG_ADDR_LEN			3
+
+/* token to our ioremap'd RNG register area */
+static void *rng_mem;
+
+static inline u8 intel_hwstatus (void)
+{
+	assert (rng_mem != NULL);
+	return readb (rng_mem + INTEL_RNG_HW_STATUS);
+}
+
+static inline u8 intel_hwstatus_set (u8 hw_status)
+{
+	assert (rng_mem != NULL);
+	writeb (hw_status, rng_mem + INTEL_RNG_HW_STATUS);
+	return intel_hwstatus ();
+}
+
+static unsigned int intel_data_present(void)
+{
+	assert (rng_mem != NULL);
+
+	return (readb (rng_mem + INTEL_RNG_STATUS) & INTEL_RNG_DATA_PRESENT) ?
+		1 : 0;
+}
+
+static u32 intel_data_read(void)
+{
+	assert (rng_mem != NULL);
+
+	return readb (rng_mem + INTEL_RNG_DATA);
+}
+
+static int __init intel_init (struct pci_dev *dev)
+{
+	int rc;
+	u8 hw_status;
+
+	DPRINTK ("ENTER\n");
+
+	rng_mem = ioremap (INTEL_RNG_ADDR, INTEL_RNG_ADDR_LEN);
+	if (rng_mem == NULL) {
+		printk (KERN_ERR PFX "cannot ioremap RNG Memory\n");
+		rc = -EBUSY;
+		goto err_out;
+	}
+
+	/* Check for Intel 82802 */
+	hw_status = intel_hwstatus ();
+	if ((hw_status & INTEL_RNG_PRESENT) == 0) {
+		printk (KERN_ERR PFX "RNG not detected\n");
+		rc = -ENODEV;
+		goto err_out_free_map;
+	}
+
+	/* turn RNG h/w on, if it's off */
+	if ((hw_status & INTEL_RNG_ENABLED) == 0)
+		hw_status = intel_hwstatus_set (hw_status | INTEL_RNG_ENABLED);
+	if ((hw_status & INTEL_RNG_ENABLED) == 0) {
+		printk (KERN_ERR PFX "cannot enable RNG, aborting\n");
+		rc = -EIO;
+		goto err_out_free_map;
+	}
+
+	DPRINTK ("EXIT, returning 0\n");
+	return 0;
+
+err_out_free_map:
+	iounmap (rng_mem);
+	rng_mem = NULL;
+err_out:
+	DPRINTK ("EXIT, returning %d\n", rc);
+	return rc;
+}
+
+static void intel_cleanup(void)
+{
+	u8 hw_status;
+
+	hw_status = intel_hwstatus ();
+	if (hw_status & INTEL_RNG_ENABLED)
+		intel_hwstatus_set (hw_status & ~INTEL_RNG_ENABLED);
+	else
+		printk(KERN_WARNING PFX "unusual: RNG already disabled\n");
+	iounmap(rng_mem);
+	rng_mem = NULL;
+}
+
+/***********************************************************************
+ *
+ * AMD RNG operations
+ *
+ */
+
+static u32 pmbase;			/* PMxx I/O base */
+static struct pci_dev *amd_dev;
+
+static unsigned int amd_data_present (void)
+{
+      	return inl(pmbase + 0xF4) & 1;
+}
+
+
+static u32 amd_data_read (void)
+{
+	return inl(pmbase + 0xF0);
+}
+
+static int __init amd_init (struct pci_dev *dev)
+{
+	int rc;
+	u8 rnen;
+
+	DPRINTK ("ENTER\n");
+
+	pci_read_config_dword(dev, 0x58, &pmbase);
+
+	pmbase &= 0x0000FF00;
+
+	if (pmbase == 0)
+	{
+		printk (KERN_ERR PFX "power management base not set\n");
+		rc = -EIO;
+		goto err_out;
+	}
+
+	pci_read_config_byte(dev, 0x40, &rnen);
+	rnen |= (1 << 7);	/* RNG on */
+	pci_write_config_byte(dev, 0x40, rnen);
+
+	pci_read_config_byte(dev, 0x41, &rnen);
+	rnen |= (1 << 7);	/* PMIO enable */
+	pci_write_config_byte(dev, 0x41, rnen);
+
+	printk(KERN_INFO PFX "AMD768 system management I/O registers at 0x%X.\n", pmbase);
+
+	amd_dev = dev;
+
+	DPRINTK ("EXIT, returning 0\n");
+	return 0;
+
+err_out:
+	DPRINTK ("EXIT, returning %d\n", rc);
+	return rc;
+}
+
+static void amd_cleanup(void)
+{
+	u8 rnen;
+
+	pci_read_config_byte(amd_dev, 0x40, &rnen);
+	rnen &= ~(1 << 7);	/* RNG off */
+	pci_write_config_byte(amd_dev, 0x40, rnen);
+
+	/* FIXME: twiddle pmio, also? */
+}
+
+/***********************************************************************
+ *
+ * VIA RNG operations
+ *
+ */
+
+enum {
+	VIA_STRFILT_CNT_SHIFT	= 16,
+	VIA_STRFILT_FAIL	= (1 << 15),
+	VIA_STRFILT_ENABLE	= (1 << 14),
+	VIA_RAWBITS_ENABLE	= (1 << 13),
+	VIA_RNG_ENABLE		= (1 << 6),
+	VIA_XSTORE_CNT_MASK	= 0x0F,
+
+	VIA_RNG_CHUNK_8		= 0x00,	/* 64 rand bits, 64 stored bits */
+	VIA_RNG_CHUNK_4		= 0x01,	/* 32 rand bits, 32 stored bits */
+	VIA_RNG_CHUNK_4_MASK	= 0xFFFFFFFF,
+	VIA_RNG_CHUNK_2		= 0x02,	/* 16 rand bits, 32 stored bits */
+	VIA_RNG_CHUNK_2_MASK	= 0xFFFF,
+	VIA_RNG_CHUNK_1		= 0x03,	/* 8 rand bits, 32 stored bits */
+	VIA_RNG_CHUNK_1_MASK	= 0xFF,
+};
+
+u32 via_rng_datum;
+
+/*
+ * Investigate using the 'rep' prefix to obtain 32 bits of random data
+ * in one insn.  The upside is potentially better performance.  The
+ * downside is that the instruction becomes no longer atomic.  Due to
+ * this, just like familiar issues with /dev/random itself, the worst
+ * case of a 'rep xstore' could potentially pause a cpu for an
+ * unreasonably long time.  In practice, this condition would likely
+ * only occur when the hardware is failing.  (or so we hope :))
+ *
+ * Another possible performance boost may come from simply buffering
+ * until we have 4 bytes, thus returning a u32 at a time,
+ * instead of the current u8-at-a-time.
+ */
+
+static inline u32 xstore(u32 *addr, u32 edx_in)
+{
+	u32 eax_out;
+
+	asm(".byte 0x0F,0xA7,0xC0 /* xstore %%edi (addr=%0) */"
+		:"=m"(*addr), "=a"(eax_out)
+		:"D"(addr), "d"(edx_in));
+
+	return eax_out;
+}
+
+static unsigned int via_data_present(void)
+{
+	u32 bytes_out;
+
+	/* We choose the recommended 1-byte-per-instruction RNG rate,
+	 * for greater randomness at the expense of speed.  Larger
+	 * values 2, 4, or 8 bytes-per-instruction yield greater
+	 * speed at lesser randomness.
+	 *
+	 * If you change this to another VIA_CHUNK_n, you must also
+	 * change the ->n_bytes values in rng_vendor_ops[] tables.
+	 * VIA_CHUNK_8 requires further code changes.
+	 *
+	 * A copy of MSR_VIA_RNG is placed in eax_out when xstore
+	 * completes.
+	 */
+	via_rng_datum = 0; /* paranoia, not really necessary */
+	bytes_out = xstore(&via_rng_datum, VIA_RNG_CHUNK_1) & VIA_XSTORE_CNT_MASK;
+	if (bytes_out == 0)
+		return 0;
+
+	return 1;
+}
+
+static u32 via_data_read(void)
+{
+	return via_rng_datum;
+}
+
+static int __init via_init(struct pci_dev *dev)
+{
+	u32 lo, hi, old_lo;
+
+	/* Control the RNG via MSR.  Tread lightly and pay very close
+	 * close attention to values written, as the reserved fields
+	 * are documented to be "undefined and unpredictable"; but it
+	 * does not say to write them as zero, so I make a guess that
+	 * we restore the values we find in the register.
+	 */
+	rdmsr(MSR_VIA_RNG, lo, hi);
+
+	old_lo = lo;
+	lo &= ~(0x7f << VIA_STRFILT_CNT_SHIFT);
+	lo &= ~VIA_XSTORE_CNT_MASK;
+	lo &= ~(VIA_STRFILT_ENABLE | VIA_STRFILT_FAIL | VIA_RAWBITS_ENABLE);
+	lo |= VIA_RNG_ENABLE;
+
+	if (lo != old_lo)
+		wrmsr(MSR_VIA_RNG, lo, hi);
+
+	/* perhaps-unnecessary sanity check; remove after testing if
+	   unneeded */
+	rdmsr(MSR_VIA_RNG, lo, hi);
+	if ((lo & VIA_RNG_ENABLE) == 0) {
+		printk(KERN_ERR PFX "cannot enable VIA C3 RNG, aborting\n");
+		return -ENODEV;
+	}
+
+	return 0;
+}
+
+static void via_cleanup(void)
+{
+	u32 lo, hi;
+
+	rdmsr(MSR_VIA_RNG, lo, hi);
+	lo &= ~VIA_RNG_ENABLE;
+	wrmsr(MSR_VIA_RNG, lo, hi);
+}
+
+
+/***********************************************************************
+ *
+ * /dev/hwrandom character device handling (major 10, minor 183)
+ *
+ */
+
+static int rng_dev_open (struct inode *inode, struct file *filp)
+{
+	/* enforce read-only access to this chrdev */
+	if ((filp->f_mode & FMODE_READ) == 0)
+		return -EINVAL;
+	if (filp->f_mode & FMODE_WRITE)
+		return -EINVAL;
+
+	return 0;
+}
+
+
+static ssize_t rng_dev_read (struct file *filp, char *buf, size_t size,
+			     loff_t * offp)
+{
+	static spinlock_t rng_lock = SPIN_LOCK_UNLOCKED;
+	unsigned int have_data;
+	u32 data = 0;
+	ssize_t ret = 0;
+
+	while (size) {
+		spin_lock(&rng_lock);
+
+		have_data = 0;
+		if (rng_ops->data_present()) {
+			data = rng_ops->data_read();
+			have_data = rng_ops->n_bytes;
+		}
+
+		spin_unlock (&rng_lock);
+
+		while (have_data && size) {
+			if (put_user((u8)data, buf++)) {
+				ret = ret ? : -EFAULT;
+				break;
+			}
+			size--;
+			ret++;
+			have_data--;
+			data>>=8;
+		}
+
+		if (filp->f_flags & O_NONBLOCK)
+			return ret ? : -EAGAIN;
+
+		if(need_resched())
+		{
+			current->state = TASK_INTERRUPTIBLE;
+			schedule_timeout(1);
+		}
+		else
+			udelay(200);	/* FIXME: We could poll for 250uS ?? */
+
+		if (signal_pending (current))
+			return ret ? : -ERESTARTSYS;
+	}
+	return ret;
+}
+
+
+
+/*
+ * rng_init_one - look for and attempt to init a single RNG
+ */
+static int __init rng_init_one (struct pci_dev *dev)
+{
+	int rc;
+
+	DPRINTK ("ENTER\n");
+
+	assert(rng_ops != NULL);
+
+	rc = rng_ops->init(dev);
+	if (rc)
+		goto err_out;
+
+	rc = misc_register (&rng_miscdev);
+	if (rc) {
+		printk (KERN_ERR PFX "misc device register failed\n");
+		goto err_out_cleanup_hw;
+	}
+
+	DPRINTK ("EXIT, returning 0\n");
+	return 0;
+
+err_out_cleanup_hw:
+	rng_ops->cleanup();
+err_out:
+	DPRINTK ("EXIT, returning %d\n", rc);
+	return rc;
+}
+
+
+
+MODULE_AUTHOR("The Linux Kernel team");
+MODULE_DESCRIPTION("H/W Random Number Generator (RNG) driver");
+MODULE_LICENSE("GPL");
+
+
+/*
+ * rng_init - initialize RNG module
+ */
+static int __init rng_init (void)
+{
+	int rc;
+	struct pci_dev *pdev = NULL;
+	const struct pci_device_id *ent;
+
+	DPRINTK ("ENTER\n");
+
+	/* Probe for Intel, AMD RNGs */
+	while ((pdev = pci_find_device(PCI_ANY_ID, PCI_ANY_ID, pdev)) != NULL) {
+		ent = pci_match_device (rng_pci_tbl, pdev);
+		if (ent) {
+			rng_ops = &rng_vendor_ops[ent->driver_data];
+			goto match;
+		}
+	}
+
+#ifdef __i386__
+	/* Probe for VIA RNG */
+	if (cpu_has_xstore) {
+		rng_ops = &rng_vendor_ops[rng_hw_via];
+		pdev = NULL;
+		goto match;
+	}
+#endif
+
+	DPRINTK ("EXIT, returning -ENODEV\n");
+	return -ENODEV;
+
+match:
+	rc = rng_init_one (pdev);
+	if (rc)
+		return rc;
+
+	printk (KERN_INFO RNG_DRIVER_NAME " loaded\n");
+
+	DPRINTK ("EXIT, returning 0\n");
+	return 0;
+}
+
+
+/*
+ * rng_init - shutdown RNG module
+ */
+static void __exit rng_cleanup (void)
+{
+	DPRINTK ("ENTER\n");
+
+	misc_deregister (&rng_miscdev);
+
+	if (rng_ops->cleanup)
+		rng_ops->cleanup();
+
+	DPRINTK ("EXIT\n");
+}
+
+
+module_init (rng_init);
+module_exit (rng_cleanup);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/pcwd.c linux-2.4.23-pre1/drivers/char/pcwd.c
--- linux-2.4.22/drivers/char/pcwd.c	2002-11-28 23:53:12.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/pcwd.c	2003-08-27 14:39:24.000000000 +0000
@@ -933,8 +933,7 @@
 
 	release_region (pcwd_info.io_addr, pcwd_info.card_info->io_size);
 
-	if (pcwd_info.flags & PCWD_PCI_REG)
-		pci_unregister_driver (&pcwd_driver);
+	pci_unregister_driver (&pcwd_driver);
 
 	return;
 }
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/ser_a2232.c linux-2.4.23-pre1/drivers/char/ser_a2232.c
--- linux-2.4.22/drivers/char/ser_a2232.c	2001-09-13 22:21:32.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/ser_a2232.c	2003-08-27 14:39:53.000000000 +0000
@@ -776,7 +776,7 @@
 	volatile u_char *to;
 	volatile struct a2232memory *mem;
 
-#ifdef __SMP__
+#ifdef CONFIG_SMP
 	return -ENODEV;	/* This driver is not SMP aware. Is there an SMP ZorroII-bus-machine? */
 #endif
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/sonypi.c linux-2.4.23-pre1/drivers/char/sonypi.c
--- linux-2.4.22/drivers/char/sonypi.c	2003-08-25 11:44:41.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/sonypi.c	2003-08-27 14:41:00.000000000 +0000
@@ -308,7 +308,7 @@
 	int i, j;
 
 	v1 = inb_p(sonypi_device.ioport1);
-	v2 = inb_p(sonypi_device.ioport2);
+	v2 = inb_p(sonypi_device.ioport1 + sonypi_device.evtype_offset);
 
 	for (i = 0; sonypi_eventtypes[i].model; i++) {
 		if (sonypi_device.model != sonypi_eventtypes[i].model)
@@ -665,11 +665,13 @@
 	if (sonypi_device.model == SONYPI_DEVICE_MODEL_TYPE2) {
 		ioport_list = sonypi_type2_ioport_list;
 		sonypi_device.region_size = SONYPI_TYPE2_REGION_SIZE;
+		sonypi_device.evtype_offset = SONYPI_TYPE2_EVTYPE_OFFSET;
 		irq_list = sonypi_type2_irq_list;
 	}
 	else {
 		ioport_list = sonypi_type1_ioport_list;
 		sonypi_device.region_size = SONYPI_TYPE1_REGION_SIZE;
+		sonypi_device.evtype_offset = SONYPI_TYPE1_EVTYPE_OFFSET;
 		irq_list = sonypi_type1_irq_list;
 	}
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/char/sonypi.h linux-2.4.23-pre1/drivers/char/sonypi.h
--- linux-2.4.22/drivers/char/sonypi.h	2003-08-25 11:44:41.000000000 +0000
+++ linux-2.4.23-pre1/drivers/char/sonypi.h	2003-08-27 14:39:15.000000000 +0000
@@ -56,12 +56,14 @@
 #define SONYPI_BASE			0x50
 #define SONYPI_G10A			(SONYPI_BASE+0x14)
 #define SONYPI_TYPE1_REGION_SIZE	0x08
+#define SONYPI_TYPE1_EVTYPE_OFFSET	0x04
 
 /* type2 series specifics */
 #define SONYPI_SIRQ			0x9b
 #define SONYPI_SLOB			0x9c
 #define SONYPI_SHIB			0x9d
 #define SONYPI_TYPE2_REGION_SIZE	0x20
+#define SONYPI_TYPE2_EVTYPE_OFFSET	0x12
 
 /* battery / brightness addresses */
 #define SONYPI_BAT_FLAGS	0x81
@@ -167,6 +169,7 @@
 #define SONYPI_THUMBPHRASE_MASK			0x00000200
 #define SONYPI_MEYE_MASK			0x00000400
 #define SONYPI_MEMORYSTICK_MASK			0x00000800
+#define SONYPI_BATTERY_MASK			0x00001000
 
 struct sonypi_event {
 	u8	data;
@@ -293,6 +296,13 @@
 	{ 0, 0 }
 };
 
+/* The set of possible battery events */
+static struct sonypi_event sonypi_batteryev[] = {
+	{ 0x20, SONYPI_EVENT_BATTERY_INSERT },
+	{ 0x30, SONYPI_EVENT_BATTERY_REMOVE },
+	{ 0, 0 }
+};
+
 struct sonypi_eventtypes {
 	int			model;
 	u8			data;
@@ -307,19 +317,22 @@
 	{ SONYPI_DEVICE_MODEL_TYPE1, 0x20, SONYPI_FNKEY_MASK, sonypi_fnkeyev },
 	{ SONYPI_DEVICE_MODEL_TYPE1, 0x30, SONYPI_BLUETOOTH_MASK, sonypi_blueev },
 	{ SONYPI_DEVICE_MODEL_TYPE1, 0x40, SONYPI_PKEY_MASK, sonypi_pkeyev },
+	{ SONYPI_DEVICE_MODEL_TYPE1, 0x30, SONYPI_MEMORYSTICK_MASK, sonypi_memorystickev },
+	{ SONYPI_DEVICE_MODEL_TYPE1, 0x40, SONYPI_BATTERY_MASK, sonypi_batteryev },
 
 	{ SONYPI_DEVICE_MODEL_TYPE2, 0, 0xffffffff, sonypi_releaseev },
 	{ SONYPI_DEVICE_MODEL_TYPE2, 0x38, SONYPI_LID_MASK, sonypi_lidev },
-	{ SONYPI_DEVICE_MODEL_TYPE2, 0x08, SONYPI_JOGGER_MASK, sonypi_joggerev },
+	{ SONYPI_DEVICE_MODEL_TYPE2, 0x11, SONYPI_JOGGER_MASK, sonypi_joggerev },
 	{ SONYPI_DEVICE_MODEL_TYPE2, 0x08, SONYPI_CAPTURE_MASK, sonypi_captureev },
-	{ SONYPI_DEVICE_MODEL_TYPE2, 0x08, SONYPI_FNKEY_MASK, sonypi_fnkeyev },
-	{ SONYPI_DEVICE_MODEL_TYPE2, 0x08, SONYPI_BLUETOOTH_MASK, sonypi_blueev },
+	{ SONYPI_DEVICE_MODEL_TYPE2, 0x21, SONYPI_FNKEY_MASK, sonypi_fnkeyev },
+	{ SONYPI_DEVICE_MODEL_TYPE2, 0x31, SONYPI_BLUETOOTH_MASK, sonypi_blueev },
 	{ SONYPI_DEVICE_MODEL_TYPE2, 0x08, SONYPI_PKEY_MASK, sonypi_pkeyev },
-	{ SONYPI_DEVICE_MODEL_TYPE2, 0x08, SONYPI_BACK_MASK, sonypi_backev },
+	{ SONYPI_DEVICE_MODEL_TYPE2, 0x11, SONYPI_BACK_MASK, sonypi_backev },
 	{ SONYPI_DEVICE_MODEL_TYPE2, 0x08, SONYPI_HELP_MASK, sonypi_helpev },
 	{ SONYPI_DEVICE_MODEL_TYPE2, 0x08, SONYPI_ZOOM_MASK, sonypi_zoomev },
 	{ SONYPI_DEVICE_MODEL_TYPE2, 0x08, SONYPI_THUMBPHRASE_MASK, sonypi_thumbphraseev },
-	{ SONYPI_DEVICE_MODEL_TYPE2, 0x08, SONYPI_MEMORYSTICK_MASK, sonypi_memorystickev },
+	{ SONYPI_DEVICE_MODEL_TYPE2, 0x31, SONYPI_MEMORYSTICK_MASK, sonypi_memorystickev },
+	{ SONYPI_DEVICE_MODEL_TYPE2, 0x41, SONYPI_BATTERY_MASK, sonypi_batteryev },
 
 	{ 0, 0, 0, 0 }
 };
@@ -354,6 +367,7 @@
 	u16 ioport1;
 	u16 ioport2;
 	u16 region_size;
+	u16 evtype_offset;
 	int camera_power;
 	int bluetooth_power;
 	struct semaphore lock;
@@ -380,30 +394,17 @@
 }
 
 #ifdef CONFIG_ACPI
-#include <linux/acpi.h>
-#if (ACPI_CA_VERSION > 0x20021121)
-#ifdef CONFIG_ACPI_EC
-#define SONYPI_USE_ACPI
-#endif
-#endif
-#endif /* CONFIG_ACPI */
-
-#ifdef CONFIG_ACPI
-#ifdef SONYPI_USE_ACPI
 extern int acpi_disabled;
 #define SONYPI_ACPI_ACTIVE (!acpi_disabled)
 #else
-#define SONYPI_ACPI_ACTIVE 1
-#endif
-#else /* CONFIG_ACPI */
 #define SONYPI_ACPI_ACTIVE 0
 #endif /* CONFIG_ACPI */
 
 extern int verbose;
 
 static inline int sonypi_ec_write(u8 addr, u8 value) {
-#ifdef SONYPI_USE_ACPI
-	if (!acpi_disabled)
+#ifdef CONFIG_ACPI_EC
+	if (SONYPI_ACPI_ACTIVE)
 		return ec_write(addr, value);
 #endif
 	wait_on_command(1, inb_p(SONYPI_CST_IOPORT) & 3, ITERATIONS_LONG);
@@ -417,8 +418,8 @@
 }
 
 static inline int sonypi_ec_read(u8 addr, u8 *value) {
-#ifdef SONYPI_USE_ACPI
-	if (!acpi_disabled)
+#ifdef CONFIG_ACPI_EC
+	if (SONYPI_ACPI_ACTIVE)
 		return ec_read(addr, value);
 #endif
 	wait_on_command(1, inb_p(SONYPI_CST_IOPORT) & 3, ITERATIONS_LONG);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/md/lvm-fs.c linux-2.4.23-pre1/drivers/md/lvm-fs.c
--- linux-2.4.22/drivers/md/lvm-fs.c	2002-11-28 23:53:13.000000000 +0000
+++ linux-2.4.23-pre1/drivers/md/lvm-fs.c	2003-08-27 14:39:24.000000000 +0000
@@ -59,9 +59,9 @@
 static int _proc_read_global(char *page, char **start, off_t off,
 			     int count, int *eof, void *data);
 
-static int _vg_info(vg_t *vg_ptr, char *buf);
-static int _lv_info(vg_t *vg_ptr, lv_t *lv_ptr, char *buf);
-static int _pv_info(pv_t *pv_ptr, char *buf);
+static int _vg_info(vg_t * vg_ptr, char *buf);
+static int _lv_info(vg_t * vg_ptr, lv_t * lv_ptr, char *buf);
+static int _pv_info(pv_t * pv_ptr, char *buf);
 
 static void _show_uuid(const char *src, char *b, char *e);
 
@@ -78,65 +78,72 @@
 /* inline functions */
 
 /* public interface */
-void __init lvm_init_fs() {
+void __init lvm_init_fs()
+{
 	struct proc_dir_entry *pde;
 
 /* User-space has already registered this */
 #if 0
-	lvm_devfs_handle = devfs_register(
-		0 , "lvm", 0, LVM_CHAR_MAJOR, 0,
-		S_IFCHR | S_IRUSR | S_IWUSR | S_IRGRP,
-		&lvm_chr_fops, NULL);
+	lvm_devfs_handle = devfs_register(0, "lvm", 0, LVM_CHAR_MAJOR, 0,
+					  S_IFCHR | S_IRUSR | S_IWUSR |
+					  S_IRGRP, &lvm_chr_fops, NULL);
 #endif
 	lvm_proc_dir = create_proc_entry(LVM_DIR, S_IFDIR, &proc_root);
 	if (lvm_proc_dir) {
-		lvm_proc_vg_subdir = create_proc_entry(LVM_VG_SUBDIR, S_IFDIR,
-						       lvm_proc_dir);
+		lvm_proc_vg_subdir =
+		    create_proc_entry(LVM_VG_SUBDIR, S_IFDIR,
+				      lvm_proc_dir);
 		pde = create_proc_entry(LVM_GLOBAL, S_IFREG, lvm_proc_dir);
-		if ( pde != NULL) pde->read_proc = _proc_read_global;
+		if (pde != NULL)
+			pde->read_proc = _proc_read_global;
 	}
 }
 
-void lvm_fin_fs() {
+void lvm_fin_fs()
+{
 #if 0
-	devfs_unregister (lvm_devfs_handle);
+	devfs_unregister(lvm_devfs_handle);
 #endif
 	remove_proc_entry(LVM_GLOBAL, lvm_proc_dir);
 	remove_proc_entry(LVM_VG_SUBDIR, lvm_proc_dir);
 	remove_proc_entry(LVM_DIR, &proc_root);
 }
 
-void lvm_fs_create_vg(vg_t *vg_ptr) {
+void lvm_fs_create_vg(vg_t * vg_ptr)
+{
 	struct proc_dir_entry *pde;
 
 	if (!vg_ptr)
 		return;
 
 	vg_devfs_handle[vg_ptr->vg_number] =
-		devfs_mk_dir(0, vg_ptr->vg_name, NULL);
+	    devfs_mk_dir(0, vg_ptr->vg_name, NULL);
 
-	ch_devfs_handle[vg_ptr->vg_number] = devfs_register(
-		vg_devfs_handle[vg_ptr->vg_number] , "group",
-		DEVFS_FL_DEFAULT, LVM_CHAR_MAJOR, vg_ptr->vg_number,
-		S_IFCHR | S_IRUSR | S_IWUSR | S_IRGRP,
-		&lvm_chr_fops, NULL);
+	ch_devfs_handle[vg_ptr->vg_number] =
+	    devfs_register(vg_devfs_handle[vg_ptr->vg_number], "group",
+			   DEVFS_FL_DEFAULT, LVM_CHAR_MAJOR,
+			   vg_ptr->vg_number,
+			   S_IFCHR | S_IRUSR | S_IWUSR | S_IRGRP,
+			   &lvm_chr_fops, NULL);
 
 	vg_ptr->vg_dir_pde = create_proc_entry(vg_ptr->vg_name, S_IFDIR,
 					       lvm_proc_vg_subdir);
 
-	if((pde = create_proc_entry("group", S_IFREG, vg_ptr->vg_dir_pde))) {
+	if ((pde =
+	     create_proc_entry("group", S_IFREG, vg_ptr->vg_dir_pde))) {
 		pde->read_proc = _proc_read_vg;
 		pde->data = vg_ptr;
 	}
 
 	vg_ptr->lv_subdir_pde =
-		create_proc_entry(LVM_LV_SUBDIR, S_IFDIR, vg_ptr->vg_dir_pde);
+	    create_proc_entry(LVM_LV_SUBDIR, S_IFDIR, vg_ptr->vg_dir_pde);
 
 	vg_ptr->pv_subdir_pde =
-		create_proc_entry(LVM_PV_SUBDIR, S_IFDIR, vg_ptr->vg_dir_pde);
+	    create_proc_entry(LVM_PV_SUBDIR, S_IFDIR, vg_ptr->vg_dir_pde);
 }
 
-void lvm_fs_remove_vg(vg_t *vg_ptr) {
+void lvm_fs_remove_vg(vg_t * vg_ptr)
+{
 	int i;
 
 	if (!vg_ptr)
@@ -146,18 +153,20 @@
 	ch_devfs_handle[vg_ptr->vg_number] = NULL;
 
 	/* remove lv's */
-	for(i = 0; i < vg_ptr->lv_max; i++)
-		if(vg_ptr->lv[i]) lvm_fs_remove_lv(vg_ptr, vg_ptr->lv[i]);
+	for (i = 0; i < vg_ptr->lv_max; i++)
+		if (vg_ptr->lv[i])
+			lvm_fs_remove_lv(vg_ptr, vg_ptr->lv[i]);
 
 	/* must not remove directory before leaf nodes */
 	devfs_unregister(vg_devfs_handle[vg_ptr->vg_number]);
 	vg_devfs_handle[vg_ptr->vg_number] = NULL;
 
 	/* remove pv's */
-	for(i = 0; i < vg_ptr->pv_max; i++)
-		if(vg_ptr->pv[i]) lvm_fs_remove_pv(vg_ptr, vg_ptr->pv[i]);
+	for (i = 0; i < vg_ptr->pv_max; i++)
+		if (vg_ptr->pv[i])
+			lvm_fs_remove_pv(vg_ptr, vg_ptr->pv[i]);
 
-	if(vg_ptr->vg_dir_pde) {
+	if (vg_ptr->vg_dir_pde) {
 		remove_proc_entry(LVM_LV_SUBDIR, vg_ptr->vg_dir_pde);
 		vg_ptr->lv_subdir_pde = NULL;
 
@@ -172,13 +181,15 @@
 }
 
 
-static inline const char *_basename(const char *str) {
+static inline const char *_basename(const char *str)
+{
 	const char *name = strrchr(str, '/');
 	name = name ? name + 1 : str;
 	return name;
 }
 
-devfs_handle_t lvm_fs_create_lv(vg_t *vg_ptr, lv_t *lv) {
+devfs_handle_t lvm_fs_create_lv(vg_t * vg_ptr, lv_t * lv)
+{
 	struct proc_dir_entry *pde;
 	const char *name;
 
@@ -187,21 +198,24 @@
 
 	name = _basename(lv->lv_name);
 
-	lv_devfs_handle[MINOR(lv->lv_dev)] = devfs_register(
-		vg_devfs_handle[vg_ptr->vg_number], name,
-		DEVFS_FL_DEFAULT, LVM_BLK_MAJOR, MINOR(lv->lv_dev),
-		S_IFBLK | S_IRUSR | S_IWUSR | S_IRGRP,
-		&lvm_blk_dops, NULL);
-
-	if(vg_ptr->lv_subdir_pde &&
-	   (pde = create_proc_entry(name, S_IFREG, vg_ptr->lv_subdir_pde))) {
+	lv_devfs_handle[MINOR(lv->lv_dev)] =
+	    devfs_register(vg_devfs_handle[vg_ptr->vg_number], name,
+			   DEVFS_FL_DEFAULT, LVM_BLK_MAJOR,
+			   MINOR(lv->lv_dev),
+			   S_IFBLK | S_IRUSR | S_IWUSR | S_IRGRP,
+			   &lvm_blk_dops, NULL);
+
+	if (vg_ptr->lv_subdir_pde &&
+	    (pde =
+	     create_proc_entry(name, S_IFREG, vg_ptr->lv_subdir_pde))) {
 		pde->read_proc = _proc_read_lv;
 		pde->data = lv;
 	}
 	return lv_devfs_handle[MINOR(lv->lv_dev)];
 }
 
-void lvm_fs_remove_lv(vg_t *vg_ptr, lv_t *lv) {
+void lvm_fs_remove_lv(vg_t * vg_ptr, lv_t * lv)
+{
 
 	if (!vg_ptr || !lv)
 		return;
@@ -209,51 +223,55 @@
 	devfs_unregister(lv_devfs_handle[MINOR(lv->lv_dev)]);
 	lv_devfs_handle[MINOR(lv->lv_dev)] = NULL;
 
-	if(vg_ptr->lv_subdir_pde) {
+	if (vg_ptr->lv_subdir_pde) {
 		const char *name = _basename(lv->lv_name);
 		remove_proc_entry(name, vg_ptr->lv_subdir_pde);
 	}
 }
 
 
-static inline void _make_pv_name(const char *src, char *b, char *e) {
+static inline void _make_pv_name(const char *src, char *b, char *e)
+{
 	int offset = strlen(LVM_DIR_PREFIX);
-	if(strncmp(src, LVM_DIR_PREFIX, offset))
+	if (strncmp(src, LVM_DIR_PREFIX, offset))
 		offset = 0;
 
 	e--;
 	src += offset;
-	while(*src && (b != e)) {
+	while (*src && (b != e)) {
 		*b++ = (*src == '/') ? '_' : *src;
 		src++;
 	}
 	*b = '\0';
 }
 
-void lvm_fs_create_pv(vg_t *vg_ptr, pv_t *pv) {
+void lvm_fs_create_pv(vg_t * vg_ptr, pv_t * pv)
+{
 	struct proc_dir_entry *pde;
 	char name[NAME_LEN];
 
 	if (!vg_ptr || !pv)
 		return;
 
-	if(!vg_ptr->pv_subdir_pde)
+	if (!vg_ptr->pv_subdir_pde)
 		return;
 
 	_make_pv_name(pv->pv_name, name, name + sizeof(name));
-	if((pde = create_proc_entry(name, S_IFREG, vg_ptr->pv_subdir_pde))) {
+	if ((pde =
+	     create_proc_entry(name, S_IFREG, vg_ptr->pv_subdir_pde))) {
 		pde->read_proc = _proc_read_pv;
 		pde->data = pv;
 	}
 }
 
-void lvm_fs_remove_pv(vg_t *vg_ptr, pv_t *pv) {
+void lvm_fs_remove_pv(vg_t * vg_ptr, pv_t * pv)
+{
 	char name[NAME_LEN];
 
 	if (!vg_ptr || !pv)
 		return;
 
-	if(!vg_ptr->pv_subdir_pde)
+	if (!vg_ptr->pv_subdir_pde)
 		return;
 
 	_make_pv_name(pv->pv_name, name, name + sizeof(name));
@@ -262,7 +280,8 @@
 
 
 static int _proc_read_vg(char *page, char **start, off_t off,
-			  int count, int *eof, void *data) {
+			 int count, int *eof, void *data)
+{
 	int sz = 0;
 	vg_t *vg_ptr = data;
 	char uuid[NAME_LEN];
@@ -279,9 +298,11 @@
 	sz += sprintf(page + sz, "PV max:       %u\n", vg_ptr->pv_max);
 	sz += sprintf(page + sz, "PV current:   %u\n", vg_ptr->pv_cur);
 	sz += sprintf(page + sz, "PV active:    %u\n", vg_ptr->pv_act);
-	sz += sprintf(page + sz, "PE size:      %u\n", vg_ptr->pe_size / 2);
+	sz +=
+	    sprintf(page + sz, "PE size:      %u\n", vg_ptr->pe_size / 2);
 	sz += sprintf(page + sz, "PE total:     %u\n", vg_ptr->pe_total);
-	sz += sprintf(page + sz, "PE allocated: %u\n", vg_ptr->pe_allocated);
+	sz +=
+	    sprintf(page + sz, "PE allocated: %u\n", vg_ptr->pe_allocated);
 
 	_show_uuid(vg_ptr->vg_uuid, uuid, uuid + sizeof(uuid));
 	sz += sprintf(page + sz, "uuid:         %s\n", uuid);
@@ -290,7 +311,8 @@
 }
 
 static int _proc_read_lv(char *page, char **start, off_t off,
-			  int count, int *eof, void *data) {
+			 int count, int *eof, void *data)
+{
 	int sz = 0;
 	lv_t *lv = data;
 
@@ -301,7 +323,7 @@
 	sz += sprintf(page + sz, "number:       %u\n", lv->lv_number);
 	sz += sprintf(page + sz, "open:         %u\n", lv->lv_open);
 	sz += sprintf(page + sz, "allocation:   %u\n", lv->lv_allocation);
-	if(lv->lv_stripes > 1) {
+	if (lv->lv_stripes > 1) {
 		sz += sprintf(page + sz, "stripes:      %u\n",
 			      lv->lv_stripes);
 		sz += sprintf(page + sz, "stripesize:   %u\n",
@@ -314,7 +336,8 @@
 }
 
 static int _proc_read_pv(char *page, char **start, off_t off,
-			 int count, int *eof, void *data) {
+			 int count, int *eof, void *data)
+{
 	int sz = 0;
 	pv_t *pv = data;
 	char uuid[NAME_LEN];
@@ -329,7 +352,7 @@
 	sz += sprintf(page + sz, "PE total:     %u\n", pv->pe_total);
 	sz += sprintf(page + sz, "PE allocated: %u\n", pv->pe_allocated);
 	sz += sprintf(page + sz, "device:       %02u:%02u\n",
-                      MAJOR(pv->pv_dev), MINOR(pv->pv_dev));
+		      MAJOR(pv->pv_dev), MINOR(pv->pv_dev));
 
 	_show_uuid(pv->pv_uuid, uuid, uuid + sizeof(uuid));
 	sz += sprintf(page + sz, "uuid:         %s\n", uuid);
@@ -337,13 +360,15 @@
 	return sz;
 }
 
-static int _proc_read_global(char *page, char **start, off_t pos, int count,
-			     int *eof, void *data) {
+static int _proc_read_global(char *page, char **start, off_t pos,
+			     int count, int *eof, void *data)
+{
 
 #define  LVM_PROC_BUF   ( i == 0 ? dummy_buf : &buf[sz])
 
-	int c, i, l, p, v, vg_counter, pv_counter, lv_counter, lv_open_counter,
-		lv_open_total, pe_t_bytes, hash_table_bytes, lv_block_exception_t_bytes, seconds;
+	int c, i, l, p, v, vg_counter, pv_counter, lv_counter,
+	    lv_open_counter, lv_open_total, pe_t_bytes, hash_table_bytes,
+	    lv_block_exception_t_bytes, seconds;
 	static off_t sz;
 	off_t sz_last;
 	static char *buf = NULL;
@@ -359,12 +384,12 @@
 	       lvm_name, pos, count);
 #endif
 
-	if(pos != 0 && buf != NULL)
+	if (pos != 0 && buf != NULL)
 		goto out;
 
-	sz_last = vg_counter = pv_counter = lv_counter = lv_open_counter = \
-		lv_open_total = pe_t_bytes = hash_table_bytes = \
-		lv_block_exception_t_bytes = 0;
+	sz_last = vg_counter = pv_counter = lv_counter = lv_open_counter =
+	    lv_open_total = pe_t_bytes = hash_table_bytes =
+	    lv_block_exception_t_bytes = 0;
 
 	/* get some statistics */
 	for (v = 0; v < ABS_MAX_VG; v++) {
@@ -374,14 +399,26 @@
 			lv_counter += vg_ptr->lv_cur;
 			if (vg_ptr->lv_cur > 0) {
 				for (l = 0; l < vg[v]->lv_max; l++) {
-					if ((lv_ptr = vg_ptr->lv[l]) != NULL) {
-						pe_t_bytes += lv_ptr->lv_allocated_le;
-						hash_table_bytes += lv_ptr->lv_snapshot_hash_table_size;
-						if (lv_ptr->lv_block_exception != NULL)
-							lv_block_exception_t_bytes += lv_ptr->lv_remap_end;
+					if ((lv_ptr =
+					     vg_ptr->lv[l]) != NULL) {
+						pe_t_bytes +=
+						    lv_ptr->
+						    lv_allocated_le;
+						hash_table_bytes +=
+						    lv_ptr->
+						    lv_snapshot_hash_table_size;
+						if (lv_ptr->
+						    lv_block_exception !=
+						    NULL)
+							lv_block_exception_t_bytes
+							    +=
+							    lv_ptr->
+							    lv_remap_end;
 						if (lv_ptr->lv_open > 0) {
 							lv_open_counter++;
-							lv_open_total += lv_ptr->lv_open;
+							lv_open_total +=
+							    lv_ptr->
+							    lv_open;
 						}
 					}
 				}
@@ -403,8 +440,7 @@
 	   2nd to fill the malloced buffer */
 	for (i = 0; i < 2; i++) {
 		sz = 0;
-		sz += sprintf(LVM_PROC_BUF,
-			      "LVM "
+		sz += sprintf(LVM_PROC_BUF, "LVM "
 #ifdef MODULE
 			      "module"
 #else
@@ -422,8 +458,7 @@
 			      lv_open_counter == 1 ? "" : "s");
 		if (lv_open_total > 0)
 			sz += sprintf(LVM_PROC_BUF,
-				      " %d times)\n",
-				      lv_open_total);
+				      " %d times)\n", lv_open_total);
 		else
 			sz += sprintf(LVM_PROC_BUF, ")");
 		sz += sprintf(LVM_PROC_BUF,
@@ -431,7 +466,8 @@
 			      vg_counter * sizeof(vg_t) +
 			      pv_counter * sizeof(pv_t) +
 			      lv_counter * sizeof(lv_t) +
-			      pe_t_bytes + hash_table_bytes + lv_block_exception_t_bytes + sz_last,
+			      pe_t_bytes + hash_table_bytes +
+			      lv_block_exception_t_bytes + sz_last,
 			      lvm_iop_version);
 
 		seconds = CURRENT_TIME - loadtime;
@@ -445,46 +481,70 @@
 		}
 		sz += sprintf(LVM_PROC_BUF, "%d:%02d:%02d active\n",
 			      (seconds % 86400) / 3600,
-			      (seconds % 3600) / 60,
-			      seconds % 60);
+			      (seconds % 3600) / 60, seconds % 60);
 
 		if (vg_counter > 0) {
 			for (v = 0; v < ABS_MAX_VG; v++) {
 				/* volume group */
 				if ((vg_ptr = vg[v]) != NULL) {
-					sz += _vg_info(vg_ptr, LVM_PROC_BUF);
+					sz +=
+					    _vg_info(vg_ptr, LVM_PROC_BUF);
 
 					/* physical volumes */
 					sz += sprintf(LVM_PROC_BUF,
 						      "\n  PV%s ",
-						      vg_ptr->pv_cur == 1 ? ": " : "s:");
+						      vg_ptr->pv_cur ==
+						      1 ? ": " : "s:");
 					c = 0;
-					for (p = 0; p < vg_ptr->pv_max; p++) {
-						if ((pv_ptr = vg_ptr->pv[p]) != NULL) {
-							sz += _pv_info(pv_ptr, LVM_PROC_BUF);
+					for (p = 0; p < vg_ptr->pv_max;
+					     p++) {
+						if ((pv_ptr =
+						     vg_ptr->pv[p]) !=
+						    NULL) {
+							sz +=
+							    _pv_info
+							    (pv_ptr,
+							     LVM_PROC_BUF);
 
 							c++;
-							if (c < vg_ptr->pv_cur)
-								sz += sprintf(LVM_PROC_BUF,
-									      "\n       ");
+							if (c <
+							    vg_ptr->pv_cur)
+								sz +=
+								    sprintf
+								    (LVM_PROC_BUF,
+								     "\n       ");
 						}
 					}
 
 					/* logical volumes */
 					sz += sprintf(LVM_PROC_BUF,
 						      "\n    LV%s ",
-						      vg_ptr->lv_cur == 1 ? ": " : "s:");
+						      vg_ptr->lv_cur ==
+						      1 ? ": " : "s:");
 					c = 0;
-					for (l = 0; l < vg_ptr->lv_max; l++) {
-						if ((lv_ptr = vg_ptr->lv[l]) != NULL) {
-							sz += _lv_info(vg_ptr, lv_ptr, LVM_PROC_BUF);
+					for (l = 0; l < vg_ptr->lv_max;
+					     l++) {
+						if ((lv_ptr =
+						     vg_ptr->lv[l]) !=
+						    NULL) {
+							sz +=
+							    _lv_info
+							    (vg_ptr,
+							     lv_ptr,
+							     LVM_PROC_BUF);
 							c++;
-							if (c < vg_ptr->lv_cur)
-								sz += sprintf(LVM_PROC_BUF,
-									      "\n         ");
+							if (c <
+							    vg_ptr->lv_cur)
+								sz +=
+								    sprintf
+								    (LVM_PROC_BUF,
+								     "\n         ");
 						}
 					}
-					if (vg_ptr->lv_cur == 0) sz += sprintf(LVM_PROC_BUF, "none");
+					if (vg_ptr->lv_cur == 0)
+						sz +=
+						    sprintf(LVM_PROC_BUF,
+							    "none");
 					sz += sprintf(LVM_PROC_BUF, "\n");
 				}
 			}
@@ -495,14 +555,15 @@
 			unlock_kernel();
 			if (buf == NULL) {
 				sz = 0;
-				return sprintf(page, "%s - vmalloc error at line %d\n",
+				return sprintf(page,
+					       "%s - vmalloc error at line %d\n",
 					       lvm_name, __LINE__);
 			}
 		}
 		sz_last = sz;
 	}
 
- out:
+      out:
 	if (pos > sz - 1) {
 		lock_kernel();
 		vfree(buf);
@@ -522,11 +583,13 @@
 /*
  * provide VG info for proc filesystem use (global)
  */
-static int _vg_info(vg_t *vg_ptr, char *buf) {
+static int _vg_info(vg_t * vg_ptr, char *buf)
+{
 	int sz = 0;
 	char inactive_flag = ' ';
 
-	if (!(vg_ptr->vg_status & VG_ACTIVE)) inactive_flag = 'I';
+	if (!(vg_ptr->vg_status & VG_ACTIVE))
+		inactive_flag = 'I';
 	sz = sprintf(buf,
 		     "\nVG: %c%s  [%d PV, %d LV/%d open] "
 		     " PE Size: %d KB\n"
@@ -537,13 +600,13 @@
 		     vg_ptr->pv_cur,
 		     vg_ptr->lv_cur,
 		     vg_ptr->lv_open,
-	     	     vg_ptr->pe_size >> 1,
+		     vg_ptr->pe_size >> 1,
 		     vg_ptr->pe_size * vg_ptr->pe_total >> 1,
 		     vg_ptr->pe_total,
 		     vg_ptr->pe_allocated * vg_ptr->pe_size >> 1,
-	     	     vg_ptr->pe_allocated,
+		     vg_ptr->pe_allocated,
 		     (vg_ptr->pe_total - vg_ptr->pe_allocated) *
-	     	     vg_ptr->pe_size >> 1,
+		     vg_ptr->pe_size >> 1,
 		     vg_ptr->pe_total - vg_ptr->pe_allocated);
 	return sz;
 }
@@ -552,10 +615,11 @@
 /*
  * provide LV info for proc filesystem use (global)
  */
-static int _lv_info(vg_t *vg_ptr, lv_t *lv_ptr, char *buf) {
+static int _lv_info(vg_t * vg_ptr, lv_t * lv_ptr, char *buf)
+{
 	int sz = 0;
 	char inactive_flag = 'A', allocation_flag = ' ',
-		stripes_flag = ' ', rw_flag = ' ', *basename;
+	    stripes_flag = ' ', rw_flag = ' ', *basename;
 
 	if (!(lv_ptr->lv_status & LV_ACTIVE))
 		inactive_flag = 'I';
@@ -568,35 +632,33 @@
 	stripes_flag = 'L';
 	if (lv_ptr->lv_stripes > 1)
 		stripes_flag = 'S';
-	sz += sprintf(buf+sz,
+	sz += sprintf(buf + sz,
 		      "[%c%c%c%c",
 		      inactive_flag,
-	 rw_flag,
-		      allocation_flag,
-		      stripes_flag);
+		      rw_flag, allocation_flag, stripes_flag);
 	if (lv_ptr->lv_stripes > 1)
-		sz += sprintf(buf+sz, "%-2d",
-			      lv_ptr->lv_stripes);
+		sz += sprintf(buf + sz, "%-2d", lv_ptr->lv_stripes);
 	else
-		sz += sprintf(buf+sz, "  ");
+		sz += sprintf(buf + sz, "  ");
 
 	/* FIXME: use _basename */
 	basename = strrchr(lv_ptr->lv_name, '/');
-	if ( basename == 0) basename = lv_ptr->lv_name;
-	else                basename++;
-	sz += sprintf(buf+sz, "] %-25s", basename);
+	if (basename == 0)
+		basename = lv_ptr->lv_name;
+	else
+		basename++;
+	sz += sprintf(buf + sz, "] %-25s", basename);
 	if (strlen(basename) > 25)
-		sz += sprintf(buf+sz,
+		sz += sprintf(buf + sz,
 			      "\n                              ");
-	sz += sprintf(buf+sz, "%9d /%-6d   ",
+	sz += sprintf(buf + sz, "%9d /%-6d   ",
 		      lv_ptr->lv_size >> 1,
 		      lv_ptr->lv_size / vg_ptr->pe_size);
 
 	if (lv_ptr->lv_open == 0)
-		sz += sprintf(buf+sz, "close");
+		sz += sprintf(buf + sz, "close");
 	else
-		sz += sprintf(buf+sz, "%dx open",
-			      lv_ptr->lv_open);
+		sz += sprintf(buf + sz, "%dx open", lv_ptr->lv_open);
 
 	return sz;
 }
@@ -605,7 +667,8 @@
 /*
  * provide PV info for proc filesystem use (global)
  */
-static int _pv_info(pv_t *pv, char *buf) {
+static int _pv_info(pv_t * pv, char *buf)
+{
 	int sz = 0;
 	char inactive_flag = 'A', allocation_flag = ' ';
 	char *pv_name = NULL;
@@ -615,9 +678,11 @@
 	allocation_flag = 'A';
 	if (!(pv->pv_allocatable & PV_ALLOCATABLE))
 		allocation_flag = 'N';
-	pv_name = strchr(pv->pv_name+1,'/');
-	if ( pv_name == 0) pv_name = pv->pv_name;
-	else               pv_name++;
+	pv_name = strchr(pv->pv_name + 1, '/');
+	if (pv_name == 0)
+		pv_name = pv->pv_name;
+	else
+		pv_name++;
 	sz = sprintf(buf,
 		     "[%c%c] %-21s %8d /%-6d  "
 		     "%8d /%-6d  %8d /%-6d",
@@ -629,17 +694,17 @@
 		     pv->pe_allocated * pv->pe_size >> 1,
 		     pv->pe_allocated,
 		     (pv->pe_total - pv->pe_allocated) *
-		     pv->pe_size >> 1,
-		     pv->pe_total - pv->pe_allocated);
+		     pv->pe_size >> 1, pv->pe_total - pv->pe_allocated);
 	return sz;
 }
 
-static void _show_uuid(const char *src, char *b, char *e) {
+static void _show_uuid(const char *src, char *b, char *e)
+{
 	int i;
 
 	e--;
-	for(i = 0; *src && (b != e); i++) {
-		if(i && !(i & 0x3))
+	for (i = 0; *src && (b != e); i++) {
+		if (i && !(i & 0x3))
 			*b++ = '-';
 		*b++ = *src++;
 	}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/md/lvm-internal.h linux-2.4.23-pre1/drivers/md/lvm-internal.h
--- linux-2.4.22/drivers/md/lvm-internal.h	2002-11-28 23:53:13.000000000 +0000
+++ linux-2.4.23-pre1/drivers/md/lvm-internal.h	2003-08-27 14:41:44.000000000 +0000
@@ -50,7 +50,7 @@
 extern struct file_operations lvm_chr_fops;
 
 #ifndef	uchar
-typedef	unsigned char	uchar;
+typedef unsigned char uchar;
 #endif
 
 extern struct block_device_operations lvm_blk_dops;
@@ -89,24 +89,24 @@
 int lvm_get_blksize(kdev_t);
 int lvm_snapshot_alloc(lv_t *);
 int lvm_snapshot_fill_COW_page(vg_t *, lv_t *);
-int lvm_snapshot_COW(kdev_t, ulong, ulong, ulong, vg_t *vg, lv_t *);
+int lvm_snapshot_COW(kdev_t, ulong, ulong, ulong, vg_t * vg, lv_t *);
 int lvm_snapshot_remap_block(kdev_t *, ulong *, ulong, lv_t *);
 void lvm_snapshot_release(lv_t *);
 int lvm_write_COW_table_block(vg_t *, lv_t *);
 void lvm_hash_link(lv_block_exception_t *, kdev_t, ulong, lv_t *);
 int lvm_snapshot_alloc_hash_table(lv_t *);
-void lvm_drop_snapshot(vg_t *vg, lv_t *, const char *);
+void lvm_drop_snapshot(vg_t * vg, lv_t *, const char *);
 
 
 /* lvm_fs.c */
 void lvm_init_fs(void);
 void lvm_fin_fs(void);
 
-void lvm_fs_create_vg(vg_t *vg_ptr);
-void lvm_fs_remove_vg(vg_t *vg_ptr);
-devfs_handle_t lvm_fs_create_lv(vg_t *vg_ptr, lv_t *lv);
-void lvm_fs_remove_lv(vg_t *vg_ptr, lv_t *lv);
-void lvm_fs_create_pv(vg_t *vg_ptr, pv_t *pv);
-void lvm_fs_remove_pv(vg_t *vg_ptr, pv_t *pv);
+void lvm_fs_create_vg(vg_t * vg_ptr);
+void lvm_fs_remove_vg(vg_t * vg_ptr);
+devfs_handle_t lvm_fs_create_lv(vg_t * vg_ptr, lv_t * lv);
+void lvm_fs_remove_lv(vg_t * vg_ptr, lv_t * lv);
+void lvm_fs_create_pv(vg_t * vg_ptr, pv_t * pv);
+void lvm_fs_remove_pv(vg_t * vg_ptr, pv_t * pv);
 
 #endif
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/md/lvm-snap.c linux-2.4.23-pre1/drivers/md/lvm-snap.c
--- linux-2.4.22/drivers/md/lvm-snap.c	2002-11-28 23:53:13.000000000 +0000
+++ linux-2.4.23-pre1/drivers/md/lvm-snap.c	2003-08-27 14:41:12.000000000 +0000
@@ -42,6 +42,8 @@
  *    15/10/2001 - fix snapshot alignment problem [CM]
  *               - fix snapshot full oops (always check lv_block_exception) [CM]
  *    26/06/2002 - support for new list_move macro [patch@luckynet.dynu.com]
+ *    26/07/2002 - removed conditional list_move macro because we will
+ *                 discontinue LVM1 before 2.6 anyway
  *
  */
 
@@ -57,7 +59,8 @@
 
 #include "lvm-internal.h"
 
-static char *lvm_snap_version __attribute__ ((unused)) = "LVM "LVM_RELEASE_NAME" snapshot code ("LVM_RELEASE_DATE")\n";
+static char *lvm_snap_version __attribute__ ((unused)) =
+    "LVM " LVM_RELEASE_NAME " snapshot code (" LVM_RELEASE_DATE ")\n";
 
 
 extern const char *const lvm_name;
@@ -65,19 +68,20 @@
 
 void lvm_snapshot_release(lv_t *);
 
-static int _write_COW_table_block(vg_t *vg, lv_t *lv, int idx,
+static int _write_COW_table_block(vg_t * vg, lv_t * lv, int idx,
 				  const char **reason);
-static void _disable_snapshot(vg_t *vg, lv_t *lv);
+static void _disable_snapshot(vg_t * vg, lv_t * lv);
 
 
 static inline int __brw_kiovec(int rw, int nr, struct kiobuf *iovec[],
 			       kdev_t dev, unsigned long b[], int size,
-			       lv_t *lv) {
+			       lv_t * lv)
+{
 	return brw_kiovec(rw, nr, iovec, dev, b, size);
 }
 
 
-static int _pv_get_number(vg_t * vg, kdev_t rdev, uint *pvn)
+static int _pv_get_number(vg_t * vg, kdev_t rdev, uint * pvn)
 {
 	uint p;
 	for (p = 0; p < vg->pv_max; p++) {
@@ -104,34 +108,32 @@
 #define hashfn(dev,block,mask,chunk_size) \
 	((HASHDEV(dev)^((block)/(chunk_size))) & (mask))
 
-static inline lv_block_exception_t *
-lvm_find_exception_table(kdev_t org_dev, unsigned long org_start, lv_t * lv)
+static inline lv_block_exception_t *lvm_find_exception_table(kdev_t
+							     org_dev,
+							     unsigned long
+							     org_start,
+							     lv_t * lv)
 {
-	struct list_head * hash_table = lv->lv_snapshot_hash_table, * next;
+	struct list_head *hash_table = lv->lv_snapshot_hash_table, *next;
 	unsigned long mask = lv->lv_snapshot_hash_mask;
 	int chunk_size = lv->lv_chunk_size;
-	lv_block_exception_t * ret;
+	lv_block_exception_t *ret;
 	int i = 0;
 
-	hash_table = &hash_table[hashfn(org_dev, org_start, mask, chunk_size)];
+	hash_table =
+	    &hash_table[hashfn(org_dev, org_start, mask, chunk_size)];
 	ret = NULL;
-	for (next = hash_table->next; next != hash_table; next = next->next)
-	{
-		lv_block_exception_t * exception;
+	for (next = hash_table->next; next != hash_table;
+	     next = next->next) {
+		lv_block_exception_t *exception;
 
 		exception = list_entry(next, lv_block_exception_t, hash);
 		if (exception->rsector_org == org_start &&
-		    exception->rdev_org == org_dev)
-		{
-			if (i)
-			{
+		    exception->rdev_org == org_dev) {
+			if (i) {
 				/* fun, isn't it? :) */
-#ifdef	list_move
-				list_move(next, hash_table);
-#else
 				list_del(next);
 				list_add(next, hash_table);
-#endif
 			}
 			ret = exception;
 			break;
@@ -145,13 +147,14 @@
 			  kdev_t org_dev, unsigned long org_start,
 			  lv_t * lv)
 {
-	struct list_head * hash_table = lv->lv_snapshot_hash_table;
+	struct list_head *hash_table = lv->lv_snapshot_hash_table;
 	unsigned long mask = lv->lv_snapshot_hash_mask;
 	int chunk_size = lv->lv_chunk_size;
 
 	if (!hash_table)
 		BUG();
-	hash_table = &hash_table[hashfn(org_dev, org_start, mask, chunk_size)];
+	hash_table =
+	    &hash_table[hashfn(org_dev, org_start, mask, chunk_size)];
 	list_add(&exception->hash, hash_table);
 }
 
@@ -163,26 +166,25 @@
  *
  * We need to be holding at least a read lock on lv->lv_lock.
  */
-int lvm_snapshot_remap_block(kdev_t * org_dev, unsigned long * org_sector,
+int lvm_snapshot_remap_block(kdev_t * org_dev, unsigned long *org_sector,
 			     unsigned long pe_start, lv_t * lv)
 {
 	int ret;
 	unsigned long pe_off, pe_adjustment, __org_start;
 	kdev_t __org_dev;
 	int chunk_size = lv->lv_chunk_size;
-	lv_block_exception_t * exception;
+	lv_block_exception_t *exception;
 
 	if (!lv->lv_block_exception)
 		return -1;
 
 	pe_off = pe_start % chunk_size;
-	pe_adjustment = (*org_sector-pe_off) % chunk_size;
+	pe_adjustment = (*org_sector - pe_off) % chunk_size;
 	__org_start = *org_sector - pe_adjustment;
 	__org_dev = *org_dev;
 	ret = 0;
 	exception = lvm_find_exception_table(__org_dev, __org_start, lv);
-	if (exception)
-	{
+	if (exception) {
 		*org_dev = exception->rdev_new;
 		*org_sector = exception->rsector_new + pe_adjustment;
 		ret = 1;
@@ -190,7 +192,7 @@
 	return ret;
 }
 
-void lvm_drop_snapshot(vg_t *vg, lv_t *lv_snap, const char *reason)
+void lvm_drop_snapshot(vg_t * vg, lv_t * lv_snap, const char *reason)
 {
 	kdev_t last_dev;
 	int i;
@@ -203,7 +205,7 @@
 	_disable_snapshot(vg, lv_snap);
 
 	for (i = last_dev = 0; i < lv_snap->lv_remap_ptr; i++) {
-		if ( lv_snap->lv_block_exception[i].rdev_new != last_dev) {
+		if (lv_snap->lv_block_exception[i].rdev_new != last_dev) {
 			last_dev = lv_snap->lv_block_exception[i].rdev_new;
 			invalidate_buffers(last_dev);
 		}
@@ -214,14 +216,14 @@
 
 	printk(KERN_INFO
 	       "%s -- giving up to snapshot %s on %s: %s\n",
-	       lvm_name, lv_snap->lv_snapshot_org->lv_name, lv_snap->lv_name,
-	       reason);
+	       lvm_name, lv_snap->lv_snapshot_org->lv_name,
+	       lv_snap->lv_name, reason);
 }
 
 static inline int lvm_snapshot_prepare_blocks(unsigned long *blocks,
-					       unsigned long start,
-					       int nr_sectors,
-					       int blocksize)
+					      unsigned long start,
+					      int nr_sectors,
+					      int blocksize)
 {
 	int i, sectors_per_block, nr_blocks;
 
@@ -244,8 +246,7 @@
 	int correct_size = BLOCK_SIZE, i, major;
 
 	major = MAJOR(dev);
-	if (blksize_size[major])
-	{
+	if (blksize_size[major]) {
 		i = blksize_size[major][MINOR(dev)];
 		if (i)
 			correct_size = i;
@@ -254,10 +255,10 @@
 }
 
 #ifdef DEBUG_SNAPSHOT
-static inline void invalidate_snap_cache(unsigned long start, unsigned long nr,
-					 kdev_t dev)
+static inline void invalidate_snap_cache(unsigned long start,
+					 unsigned long nr, kdev_t dev)
 {
-	struct buffer_head * bh;
+	struct buffer_head *bh;
 	int sectors_per_block, i, blksize, minor;
 
 	minor = MINOR(dev);
@@ -266,8 +267,7 @@
 	nr /= sectors_per_block;
 	start /= sectors_per_block;
 
-	for (i = 0; i < nr; i++)
-	{
+	for (i = 0; i < nr; i++) {
 		bh = get_hash_table(dev, start++, blksize);
 		if (bh)
 			bforget(bh);
@@ -280,40 +280,44 @@
 {
 	int id = 0, is = lv_snap->lv_remap_ptr;
 	ulong blksize_snap;
-	lv_COW_table_disk_t * lv_COW_table = (lv_COW_table_disk_t *)
-		page_address(lv_snap->lv_COW_table_iobuf->maplist[0]);
+	lv_COW_table_disk_t *lv_COW_table = (lv_COW_table_disk_t *)
+	    page_address(lv_snap->lv_COW_table_iobuf->maplist[0]);
 
 	if (is == 0)
 		return 0;
 
 	is--;
 	blksize_snap =
-		lvm_get_blksize(lv_snap->lv_block_exception[is].rdev_new);
+	    lvm_get_blksize(lv_snap->lv_block_exception[is].rdev_new);
 	is -= is % (blksize_snap / sizeof(lv_COW_table_disk_t));
 
 	memset(lv_COW_table, 0, blksize_snap);
-	for ( ; is < lv_snap->lv_remap_ptr; is++, id++) {
+	for (; is < lv_snap->lv_remap_ptr; is++, id++) {
 		/* store new COW_table entry */
-		lv_block_exception_t *be = lv_snap->lv_block_exception + is;
+		lv_block_exception_t *be =
+		    lv_snap->lv_block_exception + is;
 		uint pvn;
 
 		if (_pv_get_number(vg, be->rdev_org, &pvn))
 			goto bad;
 
 		lv_COW_table[id].pv_org_number = cpu_to_le64(pvn);
-		lv_COW_table[id].pv_org_rsector = cpu_to_le64(be->rsector_org);
+		lv_COW_table[id].pv_org_rsector =
+		    cpu_to_le64(be->rsector_org);
 
 		if (_pv_get_number(vg, be->rdev_new, &pvn))
 			goto bad;
 
 		lv_COW_table[id].pv_snap_number = cpu_to_le64(pvn);
-		lv_COW_table[id].pv_snap_rsector = cpu_to_le64(be->rsector_new);
+		lv_COW_table[id].pv_snap_rsector =
+		    cpu_to_le64(be->rsector_new);
 	}
 
 	return 0;
 
- bad:
-	printk(KERN_ERR "%s -- lvm_snapshot_fill_COW_page failed", lvm_name);
+      bad:
+	printk(KERN_ERR "%s -- lvm_snapshot_fill_COW_page failed",
+	       lvm_name);
 	return -1;
 }
 
@@ -323,12 +327,12 @@
  *
  * We need to hold a write lock on lv_snap->lv_lock.
  */
-int lvm_write_COW_table_block(vg_t * vg, lv_t *lv_snap)
+int lvm_write_COW_table_block(vg_t * vg, lv_t * lv_snap)
 {
 	int r;
 	const char *err;
-	if((r = _write_COW_table_block(vg, lv_snap,
-				       lv_snap->lv_remap_ptr - 1, &err)))
+	if ((r = _write_COW_table_block(vg, lv_snap,
+					lv_snap->lv_remap_ptr - 1, &err)))
 		lvm_drop_snapshot(vg, lv_snap, err);
 	return r;
 }
@@ -349,13 +353,15 @@
 		     unsigned long org_phys_sector,
 		     unsigned long org_pe_start,
 		     unsigned long org_virt_sector,
-		     vg_t *vg, lv_t* lv_snap)
+		     vg_t * vg, lv_t * lv_snap)
 {
-	const char * reason;
-	unsigned long org_start, snap_start, snap_phys_dev, virt_start, pe_off;
+	const char *reason;
+	unsigned long org_start, snap_start, snap_phys_dev, virt_start,
+	    pe_off;
 	unsigned long phys_start;
-	int idx = lv_snap->lv_remap_ptr, chunk_size = lv_snap->lv_chunk_size;
-	struct kiobuf * iobuf = lv_snap->lv_iobuf;
+	int idx = lv_snap->lv_remap_ptr, chunk_size =
+	    lv_snap->lv_chunk_size;
+	struct kiobuf *iobuf = lv_snap->lv_iobuf;
 	unsigned long *blocks = iobuf->blocks;
 	int blksize_snap, blksize_org, min_blksize, max_blksize;
 	int max_sectors, nr_sectors;
@@ -366,7 +372,8 @@
 
 	/* calculate physical boundaries of source chunk */
 	pe_off = org_pe_start % chunk_size;
-	org_start = org_phys_sector - ((org_phys_sector-pe_off) % chunk_size);
+	org_start =
+	    org_phys_sector - ((org_phys_sector - pe_off) % chunk_size);
 	virt_start = org_virt_sector - (org_phys_sector - org_start);
 
 	/* calculate physical boundaries of destination chunk */
@@ -381,25 +388,22 @@
 	       lvm_name,
 	       kdevname(org_phys_dev), org_phys_sector, org_start,
 	       kdevname(snap_phys_dev), snap_start,
-	       chunk_size,
-	       org_pe_start, pe_off,
-	       org_virt_sector);
+	       chunk_size, org_pe_start, pe_off, org_virt_sector);
 #endif
 
 	blksize_org = lvm_sectsize(org_phys_dev);
 	blksize_snap = lvm_sectsize(snap_phys_dev);
 	max_blksize = max(blksize_org, blksize_snap);
 	min_blksize = min(blksize_org, blksize_snap);
-	max_sectors = KIO_MAX_SECTORS * (min_blksize>>9);
+	max_sectors = KIO_MAX_SECTORS * (min_blksize >> 9);
 
-	if (chunk_size % (max_blksize>>9))
+	if (chunk_size % (max_blksize >> 9))
 		goto fail_blksize;
 
 	/* Don't change org_start, we need it to fill in the exception table */
 	phys_start = org_start;
 
-	while (chunk_size)
-	{
+	while (chunk_size) {
 		nr_sectors = min(chunk_size, max_sectors);
 		chunk_size -= nr_sectors;
 
@@ -410,7 +414,8 @@
 			goto fail_prepare;
 
 		if (__brw_kiovec(READ, 1, &iobuf, org_phys_dev, blocks,
-				 blksize_org, lv_snap) != (nr_sectors<<9))
+				 blksize_org,
+				 lv_snap) != (nr_sectors << 9))
 			goto fail_raw_read;
 
 		if (!lvm_snapshot_prepare_blocks(blocks, snap_start,
@@ -418,7 +423,8 @@
 			goto fail_prepare;
 
 		if (__brw_kiovec(WRITE, 1, &iobuf, snap_phys_dev, blocks,
-				 blksize_snap, lv_snap) != (nr_sectors<<9))
+				 blksize_snap,
+				 lv_snap) != (nr_sectors << 9))
 			goto fail_raw_write;
 
 		phys_start += nr_sectors;
@@ -440,53 +446,55 @@
 		      org_phys_dev, org_start, lv_snap);
 	lv_snap->lv_remap_ptr = idx + 1;
 	if (lv_snap->lv_snapshot_use_rate > 0) {
-		if (lv_snap->lv_remap_ptr * 100 / lv_snap->lv_remap_end >= lv_snap->lv_snapshot_use_rate)
+		if (lv_snap->lv_remap_ptr * 100 / lv_snap->lv_remap_end >=
+		    lv_snap->lv_snapshot_use_rate)
 			wake_up_interruptible(&lv_snap->lv_snapshot_wait);
 	}
 	return 0;
 
 	/* slow path */
-out:
+      out:
 	lvm_drop_snapshot(vg, lv_snap, reason);
 	return 1;
 
-fail_out_of_space:
+      fail_out_of_space:
 	reason = "out of space";
 	goto out;
-fail_raw_read:
+      fail_raw_read:
 	reason = "read error";
 	goto out;
-fail_raw_write:
+      fail_raw_write:
 	reason = "write error";
 	goto out;
-fail_blksize:
+      fail_blksize:
 	reason = "blocksize error";
 	goto out;
 
-fail_prepare:
+      fail_prepare:
 	reason = "couldn't prepare kiovec blocks "
-		"(start probably isn't block aligned)";
+	    "(start probably isn't block aligned)";
 	goto out;
 }
 
-int lvm_snapshot_alloc_iobuf_pages(struct kiobuf * iobuf, int sectors)
+int lvm_snapshot_alloc_iobuf_pages(struct kiobuf *iobuf, int sectors)
 {
 	int bytes, nr_pages, err, i;
 
 	bytes = sectors * SECTOR_SIZE;
 	nr_pages = (bytes + ~PAGE_MASK) >> PAGE_SHIFT;
 	err = expand_kiobuf(iobuf, nr_pages);
-	if (err) goto out;
+	if (err)
+		goto out;
 
 	err = -ENOMEM;
 	iobuf->locked = 1;
 	iobuf->nr_pages = 0;
-	for (i = 0; i < nr_pages; i++)
-	{
-		struct page * page;
+	for (i = 0; i < nr_pages; i++) {
+		struct page *page;
 
 		page = alloc_page(GFP_KERNEL);
-		if (!page) goto out;
+		if (!page)
+			goto out;
 
 		iobuf->maplist[i] = page;
 		LockPage(page);
@@ -496,7 +504,7 @@
 
 	err = 0;
 
-out:
+      out:
 	return err;
 }
 
@@ -516,13 +524,13 @@
 {
 	int err;
 	unsigned long buckets, max_buckets, size;
-	struct list_head * hash;
+	struct list_head *hash;
 
 	buckets = lv->lv_remap_end;
 	max_buckets = calc_max_buckets();
 	buckets = min(buckets, max_buckets);
-	while (buckets & (buckets-1))
-		buckets &= (buckets-1);
+	while (buckets & (buckets - 1))
+		buckets &= (buckets - 1);
 
 	size = buckets * sizeof(struct list_head);
 
@@ -534,11 +542,11 @@
 		goto out;
 	lv->lv_snapshot_hash_table_size = size;
 
-	lv->lv_snapshot_hash_mask = buckets-1;
+	lv->lv_snapshot_hash_mask = buckets - 1;
 	while (buckets--)
-		INIT_LIST_HEAD(hash+buckets);
+		INIT_LIST_HEAD(hash + buckets);
 	err = 0;
-out:
+      out:
 	return err;
 }
 
@@ -548,33 +556,39 @@
 
 	/* allocate kiovec to do chunk io */
 	ret = alloc_kiovec(1, &lv_snap->lv_iobuf);
-	if (ret) goto out;
+	if (ret)
+		goto out;
 
-	max_sectors = KIO_MAX_SECTORS << (PAGE_SHIFT-9);
+	max_sectors = KIO_MAX_SECTORS << (PAGE_SHIFT - 9);
 
-	ret = lvm_snapshot_alloc_iobuf_pages(lv_snap->lv_iobuf, max_sectors);
-	if (ret) goto out_free_kiovec;
+	ret =
+	    lvm_snapshot_alloc_iobuf_pages(lv_snap->lv_iobuf, max_sectors);
+	if (ret)
+		goto out_free_kiovec;
 
 	/* allocate kiovec to do exception table io */
 	ret = alloc_kiovec(1, &lv_snap->lv_COW_table_iobuf);
-	if (ret) goto out_free_kiovec;
+	if (ret)
+		goto out_free_kiovec;
 
 	ret = lvm_snapshot_alloc_iobuf_pages(lv_snap->lv_COW_table_iobuf,
-					     PAGE_SIZE/SECTOR_SIZE);
-	if (ret) goto out_free_both_kiovecs;
+					     PAGE_SIZE / SECTOR_SIZE);
+	if (ret)
+		goto out_free_both_kiovecs;
 
 	ret = lvm_snapshot_alloc_hash_table(lv_snap);
-	if (ret) goto out_free_both_kiovecs;
+	if (ret)
+		goto out_free_both_kiovecs;
 
-out:
+      out:
 	return ret;
 
-out_free_both_kiovecs:
+      out_free_both_kiovecs:
 	unmap_kiobuf(lv_snap->lv_COW_table_iobuf);
 	free_kiovec(1, &lv_snap->lv_COW_table_iobuf);
 	lv_snap->lv_COW_table_iobuf = NULL;
 
-out_free_kiovec:
+      out_free_kiovec:
 	unmap_kiobuf(lv_snap->lv_iobuf);
 	free_kiovec(1, &lv_snap->lv_iobuf);
 	lv_snap->lv_iobuf = NULL;
@@ -585,27 +599,23 @@
 
 void lvm_snapshot_release(lv_t * lv)
 {
-	if (lv->lv_block_exception)
-	{
+	if (lv->lv_block_exception) {
 		vfree(lv->lv_block_exception);
 		lv->lv_block_exception = NULL;
 	}
-	if (lv->lv_snapshot_hash_table)
-	{
+	if (lv->lv_snapshot_hash_table) {
 		vfree(lv->lv_snapshot_hash_table);
 		lv->lv_snapshot_hash_table = NULL;
 		lv->lv_snapshot_hash_table_size = 0;
 	}
-	if (lv->lv_iobuf)
-	{
-	        kiobuf_wait_for_io(lv->lv_iobuf);
+	if (lv->lv_iobuf) {
+		kiobuf_wait_for_io(lv->lv_iobuf);
 		unmap_kiobuf(lv->lv_iobuf);
 		free_kiovec(1, &lv->lv_iobuf);
 		lv->lv_iobuf = NULL;
 	}
-	if (lv->lv_COW_table_iobuf)
-	{
-	        kiobuf_wait_for_io(lv->lv_COW_table_iobuf);
+	if (lv->lv_COW_table_iobuf) {
+		kiobuf_wait_for_io(lv->lv_COW_table_iobuf);
 		unmap_kiobuf(lv->lv_COW_table_iobuf);
 		free_kiovec(1, &lv->lv_COW_table_iobuf);
 		lv->lv_COW_table_iobuf = NULL;
@@ -613,55 +623,67 @@
 }
 
 
-static int _write_COW_table_block(vg_t *vg, lv_t *lv_snap,
-				  int idx, const char **reason) {
+static int _write_COW_table_block(vg_t * vg, lv_t * lv_snap,
+				  int idx, const char **reason)
+{
 	int blksize_snap;
 	int end_of_table;
 	int idx_COW_table;
 	uint pvn;
 	ulong snap_pe_start, COW_table_sector_offset,
-	      COW_entries_per_pe, COW_chunks_per_pe, COW_entries_per_block;
+	    COW_entries_per_pe, COW_chunks_per_pe, COW_entries_per_block;
 	ulong blocks[1];
 	kdev_t snap_phys_dev;
 	lv_block_exception_t *be;
 	struct kiobuf *COW_table_iobuf = lv_snap->lv_COW_table_iobuf;
-	lv_COW_table_disk_t * lv_COW_table =
-	   ( lv_COW_table_disk_t *) page_address(lv_snap->lv_COW_table_iobuf->maplist[0]);
+	lv_COW_table_disk_t *lv_COW_table =
+	    (lv_COW_table_disk_t *) page_address(lv_snap->
+						 lv_COW_table_iobuf->
+						 maplist[0]);
 
 	COW_chunks_per_pe = LVM_GET_COW_TABLE_CHUNKS_PER_PE(vg, lv_snap);
 	COW_entries_per_pe = LVM_GET_COW_TABLE_ENTRIES_PER_PE(vg, lv_snap);
 
 	/* get physical addresse of destination chunk */
 	snap_phys_dev = lv_snap->lv_block_exception[idx].rdev_new;
-	snap_pe_start = lv_snap->lv_block_exception[idx - (idx % COW_entries_per_pe)].rsector_new - lv_snap->lv_chunk_size;
+	snap_pe_start =
+	    lv_snap->lv_block_exception[idx -
+					(idx %
+					 COW_entries_per_pe)].rsector_new -
+	    lv_snap->lv_chunk_size;
 
 	blksize_snap = lvm_sectsize(snap_phys_dev);
 
-        COW_entries_per_block = blksize_snap / sizeof(lv_COW_table_disk_t);
-        idx_COW_table = idx % COW_entries_per_pe % COW_entries_per_block;
+	COW_entries_per_block = blksize_snap / sizeof(lv_COW_table_disk_t);
+	idx_COW_table = idx % COW_entries_per_pe % COW_entries_per_block;
 
-	if ( idx_COW_table == 0) memset(lv_COW_table, 0, blksize_snap);
+	if (idx_COW_table == 0)
+		memset(lv_COW_table, 0, blksize_snap);
 
 	/* sector offset into the on disk COW table */
-	COW_table_sector_offset = (idx % COW_entries_per_pe) / (SECTOR_SIZE / sizeof(lv_COW_table_disk_t));
-
-        /* COW table block to write next */
-	blocks[0] = (snap_pe_start + COW_table_sector_offset) >> (blksize_snap >> 10);
+	COW_table_sector_offset =
+	    (idx % COW_entries_per_pe) / (SECTOR_SIZE /
+					  sizeof(lv_COW_table_disk_t));
+
+	/* COW table block to write next */
+	blocks[0] =
+	    (snap_pe_start +
+	     COW_table_sector_offset) >> (blksize_snap >> 10);
 
 	/* store new COW_table entry */
 	be = lv_snap->lv_block_exception + idx;
-	if(_pv_get_number(vg, be->rdev_org, &pvn))
+	if (_pv_get_number(vg, be->rdev_org, &pvn))
 		goto fail_pv_get_number;
 
 	lv_COW_table[idx_COW_table].pv_org_number = cpu_to_le64(pvn);
 	lv_COW_table[idx_COW_table].pv_org_rsector =
-		cpu_to_le64(be->rsector_org);
-	if(_pv_get_number(vg, snap_phys_dev, &pvn))
+	    cpu_to_le64(be->rsector_org);
+	if (_pv_get_number(vg, snap_phys_dev, &pvn))
 		goto fail_pv_get_number;
 
 	lv_COW_table[idx_COW_table].pv_snap_number = cpu_to_le64(pvn);
 	lv_COW_table[idx_COW_table].pv_snap_rsector =
-		cpu_to_le64(be->rsector_new);
+	    cpu_to_le64(be->rsector_new);
 
 	COW_table_iobuf->length = blksize_snap;
 	/* COW_table_iobuf->nr_pages = 1; */
@@ -672,36 +694,42 @@
 
 	/* initialization of next COW exception table block with zeroes */
 	end_of_table = idx % COW_entries_per_pe == COW_entries_per_pe - 1;
-	if (idx_COW_table % COW_entries_per_block == COW_entries_per_block - 1 || end_of_table)
-	{
+	if (idx_COW_table % COW_entries_per_block ==
+	    COW_entries_per_block - 1 || end_of_table) {
 		/* don't go beyond the end */
-		if (idx + 1 >= lv_snap->lv_remap_end) goto out;
+		if (idx + 1 >= lv_snap->lv_remap_end)
+			goto out;
 
 		memset(lv_COW_table, 0, blksize_snap);
 
-		if (end_of_table)
-		{
+		if (end_of_table) {
 			idx++;
-			snap_phys_dev = lv_snap->lv_block_exception[idx].rdev_new;
-			snap_pe_start = lv_snap->lv_block_exception[idx - (idx % COW_entries_per_pe)].rsector_new - lv_snap->lv_chunk_size;
+			snap_phys_dev =
+			    lv_snap->lv_block_exception[idx].rdev_new;
+			snap_pe_start =
+			    lv_snap->lv_block_exception[idx -
+							(idx %
+							 COW_entries_per_pe)].
+			    rsector_new - lv_snap->lv_chunk_size;
 			blksize_snap = lvm_sectsize(snap_phys_dev);
 			blocks[0] = snap_pe_start >> (blksize_snap >> 10);
-		} else blocks[0]++;
+		} else
+			blocks[0]++;
 
 		if (__brw_kiovec(WRITE, 1, &COW_table_iobuf, snap_phys_dev,
-                                 blocks, blksize_snap, lv_snap) !=
-                    blksize_snap)
+				 blocks, blksize_snap, lv_snap) !=
+		    blksize_snap)
 			goto fail_raw_write;
 	}
 
-out:
+      out:
 	return 0;
 
-fail_raw_write:
+      fail_raw_write:
 	*reason = "write error";
 	return 1;
 
-fail_pv_get_number:
+      fail_pv_get_number:
 	*reason = "_pv_get_number failed";
 	return 1;
 }
@@ -717,10 +745,12 @@
  * to activate the snapshot and prevent this from happening.
  */
 
-static void _disable_snapshot(vg_t *vg, lv_t *lv) {
+static void _disable_snapshot(vg_t * vg, lv_t * lv)
+{
 	const char *err;
-	lv->lv_block_exception[0].rsector_org = LVM_SNAPSHOT_DROPPED_SECTOR;
-	if(_write_COW_table_block(vg, lv, 0, &err) < 0) {
+	lv->lv_block_exception[0].rsector_org =
+	    LVM_SNAPSHOT_DROPPED_SECTOR;
+	if (_write_COW_table_block(vg, lv, 0, &err) < 0) {
 		printk(KERN_ERR "%s -- couldn't disable snapshot: %s\n",
 		       lvm_name, err);
 	}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/md/lvm.c linux-2.4.23-pre1/drivers/md/lvm.c
--- linux-2.4.22/drivers/md/lvm.c	2003-06-13 14:51:34.000000000 +0000
+++ linux-2.4.23-pre1/drivers/md/lvm.c	2003-08-27 14:40:40.000000000 +0000
@@ -8,7 +8,8 @@
  * January-March,May,July,September,October 1999
  * January,February,July,September-November 2000
  * January-May,June,October 2001
- * May-July 2002
+ * May-August 2002
+ * February 2003
  *
  *
  * LVM driver is free software; you can redistribute it and/or modify
@@ -220,6 +221,12 @@
  *               - support HDIO_GETGEO_BIG ioctl
  *    05/07/2002 - fixed OBO error on vg array access [benh@kernel.crashing.org]
  *    22/07/2002 - streamlined blk_ioctl() call
+ *    14/08/2002 - stored fs handle in lvm_do_lv_rename
+ *                 [kaoru@bsd.tnes.nec.co.jp]
+ *    06/02/2003 - fix persistent snapshot extend/reduce bug in
+ *		   lvm_do_lv_extend_reduce() [dalestephenson@mac.com]
+ *    04/03/2003 - snapshot extend/reduce memory leak
+ *               - VG PE counter wrong [dalestephenson@mac.com]
  *
  */
 
@@ -283,13 +290,14 @@
 /*
  * External function prototypes
  */
-static int lvm_make_request_fn(request_queue_t*, int, struct buffer_head*);
+static int lvm_make_request_fn(request_queue_t *, int,
+			       struct buffer_head *);
 
 static int lvm_blk_ioctl(struct inode *, struct file *, uint, ulong);
 static int lvm_blk_open(struct inode *, struct file *);
 
 static int lvm_blk_close(struct inode *, struct file *);
-static int lvm_get_snapshot_use_rate(lv_t *lv_ptr, void *arg);
+static int lvm_get_snapshot_use_rate(lv_t * lv_ptr, void *arg);
 static int lvm_user_bmap(struct inode *, struct lv_bmap *);
 
 static int lvm_chr_open(struct inode *, struct file *);
@@ -319,13 +327,13 @@
 static int lvm_do_lv_extend_reduce(int, char *, lv_t *);
 static int lvm_do_lv_remove(int, char *, int);
 static int lvm_do_lv_rename(vg_t *, lv_req_t *, lv_t *);
-static int lvm_do_lv_status_byname(vg_t *r, void *);
+static int lvm_do_lv_status_byname(vg_t * r, void *);
 static int lvm_do_lv_status_byindex(vg_t *, void *);
 static int lvm_do_lv_status_bydev(vg_t *, void *);
 
-static int lvm_do_pe_lock_unlock(vg_t *r, void *);
+static int lvm_do_pe_lock_unlock(vg_t * r, void *);
 
-static int lvm_do_pv_change(vg_t*, void*);
+static int lvm_do_pv_change(vg_t *, void *);
 static int lvm_do_pv_status(vg_t *, void *);
 static int lvm_do_pv_flush(void *);
 
@@ -335,15 +343,15 @@
 static int lvm_do_vg_rename(vg_t *, void *);
 static int lvm_do_vg_remove(int);
 static void lvm_geninit(struct gendisk *);
-static void __update_hardsectsize(lv_t *lv);
+static void __update_hardsectsize(lv_t * lv);
 
 
 static void _queue_io(struct buffer_head *bh, int rw);
 static struct buffer_head *_dequeue_io(void);
 static void _flush_io(struct buffer_head *bh);
 
-static int _open_pv(pv_t *pv);
-static void _close_pv(pv_t *pv);
+static int _open_pv(pv_t * pv);
+static void _close_pv(pv_t * pv);
 
 static unsigned long _sectors_to_k(unsigned long sect);
 
@@ -354,7 +362,8 @@
 
 
 /* variables */
-char *lvm_version = "LVM version "LVM_RELEASE_NAME"("LVM_RELEASE_DATE")";
+char *lvm_version =
+    "LVM version " LVM_RELEASE_NAME "(" LVM_RELEASE_DATE ")";
 ushort lvm_iop_version = LVM_DRIVER_IOP_VERSION;
 int loadtime = 0;
 const char *const lvm_name = LVM_NAME;
@@ -397,19 +406,18 @@
 
 
 struct file_operations lvm_chr_fops = {
-	owner:		THIS_MODULE,
-	open:		lvm_chr_open,
-	release:	lvm_chr_close,
-	ioctl:		lvm_chr_ioctl,
+	owner:THIS_MODULE,
+	open:lvm_chr_open,
+	release:lvm_chr_close,
+	ioctl:lvm_chr_ioctl,
 };
 
 /* block device operations structure needed for 2.3.38? and above */
-struct block_device_operations lvm_blk_dops =
-{
-	owner:		THIS_MODULE,
-	open:		lvm_blk_open,
-	release:	lvm_blk_close,
-	ioctl:		lvm_blk_ioctl,
+struct block_device_operations lvm_blk_dops = {
+	.owner		= THIS_MODULE,
+	.open		= lvm_blk_open,
+	.release	= lvm_blk_close,
+	.ioctl		= lvm_blk_ioctl,
 };
 
 
@@ -419,15 +427,14 @@
 static int lvm_hardsectsizes[MAX_LV];
 static int lvm_size[MAX_LV];
 
-static struct gendisk lvm_gendisk =
-{
-	major:		MAJOR_NR,
-	major_name:	LVM_NAME,
-	minor_shift:	0,
-	max_p:		1,
-	part:		lvm_hd_struct,
-	sizes:		lvm_size,
-	nr_real:	MAX_LV,
+static struct gendisk lvm_gendisk = {
+	.major		= MAJOR_NR,
+	.major_name	= LVM_NAME,
+	.minor_shift	= 0,
+	.max_p		= 1,
+	.part		= lvm_hd_struct,
+	.sizes		= lvm_size,
+	.nr_real	= MAX_LV,
 };
 
 
@@ -464,7 +471,8 @@
 	lvm_hd_name_ptr = lvm_hd_name;
 #endif
 
-	blk_queue_make_request(BLK_DEFAULT_QUEUE(MAJOR_NR), lvm_make_request_fn);
+	blk_queue_make_request(BLK_DEFAULT_QUEUE(MAJOR_NR),
+			       lvm_make_request_fn);
 
 
 	/* initialise the pe lock */
@@ -482,7 +490,7 @@
 #endif
 
 	return 0;
-} /* lvm_init() */
+}				/* lvm_init() */
 
 /*
  * cleanup...
@@ -515,11 +523,12 @@
 	lvm_fin_fs();
 
 #ifdef MODULE
-	printk(KERN_INFO "%s -- Module successfully deactivated\n", lvm_name);
+	printk(KERN_INFO "%s -- Module successfully deactivated\n",
+	       lvm_name);
 #endif
 
 	return;
-}	/* lvm_cleanup() */
+}				/* lvm_cleanup() */
 
 /*
  * support function to initialize lvm variables
@@ -549,7 +558,7 @@
 	}
 
 	return;
-} /* lvm_init_vars() */
+}				/* lvm_init_vars() */
 
 
 /********************************************************************
@@ -572,13 +581,15 @@
 	      minor, VG_CHR(minor), MODE_TO_STR(file->f_mode), lock);
 
 	/* super user validation */
-	if (!capable(CAP_SYS_ADMIN)) return -EACCES;
+	if (!capable(CAP_SYS_ADMIN))
+		return -EACCES;
 
 	/* Group special file open */
-	if (VG_CHR(minor) > MAX_VG) return -ENXIO;
+	if (VG_CHR(minor) > MAX_VG)
+		return -ENXIO;
 
 	spin_lock(&lvm_lock);
-	if(lock == current->pid)
+	if (lock == current->pid)
 		_lock_open_count++;
 	spin_unlock(&lvm_lock);
 
@@ -587,7 +598,7 @@
 	MOD_INC_USE_COUNT;
 
 	return 0;
-} /* lvm_chr_open() */
+}				/* lvm_chr_open() */
 
 
 /*
@@ -604,16 +615,19 @@
 	uint extendable, l, v;
 	void *arg = (void *) a;
 	lv_t lv;
-	vg_t* vg_ptr = vg[VG_CHR(minor)];
+	vg_t *vg_ptr = vg[VG_CHR(minor)];
 
 	/* otherwise cc will complain about unused variables */
 	(void) lvm_lock;
 
-	P_IOCTL("chr MINOR: %d  command: 0x%X  arg: %p  VG#: %d  mode: %s%s\n",
-		minor, command, arg, VG_CHR(minor), MODE_TO_STR(file->f_mode));
+	P_IOCTL
+	    ("chr MINOR: %d  command: 0x%X  arg: %p  VG#: %d  mode: %s%s\n",
+	     minor, command, arg, VG_CHR(minor),
+	     MODE_TO_STR(file->f_mode));
 
 #ifdef LVM_TOTAL_RESET
-	if (lvm_reset_spindown > 0) return -EACCES;
+	if (lvm_reset_spindown > 0)
+		return -EACCES;
 #endif
 
 	/* Main command switch */
@@ -625,7 +639,8 @@
 	case LVM_GET_IOP_VERSION:
 		/* check lvm version to ensure driver/tools+lib
 		   interoperability */
-		if (copy_to_user(arg, &lvm_iop_version, sizeof(ushort)) != 0)
+		if (copy_to_user(arg, &lvm_iop_version, sizeof(ushort)) !=
+		    0)
 			return -EFAULT;
 		return 0;
 
@@ -634,7 +649,8 @@
 		/* lock reset function */
 		lvm_reset_spindown = 1;
 		for (v = 0; v < ABS_MAX_VG; v++) {
-			if (vg[v] != NULL) lvm_do_vg_remove(v);
+			if (vg[v] != NULL)
+				lvm_do_vg_remove(v);
 		}
 
 #ifdef MODULE
@@ -642,28 +658,28 @@
 			MOD_INC_USE_COUNT;
 		while (GET_USE_COUNT(&__this_module) > 1)
 			MOD_DEC_USE_COUNT;
-#endif /* MODULE */
+#endif				/* MODULE */
 		lock = 0;	/* release lock */
 		wake_up_interruptible(&lvm_wait);
 		return 0;
-#endif /* LVM_TOTAL_RESET */
+#endif				/* LVM_TOTAL_RESET */
 
 
 	case LE_REMAP:
 		/* remap a logical extent (after moving the physical extent) */
-		return lvm_do_le_remap(vg_ptr,arg);
+		return lvm_do_le_remap(vg_ptr, arg);
 
 	case PE_LOCK_UNLOCK:
 		/* lock/unlock i/o to a physical extent to move it to another
 		   physical volume (move's done in user space's pvmove) */
-		return lvm_do_pe_lock_unlock(vg_ptr,arg);
+		return lvm_do_pe_lock_unlock(vg_ptr, arg);
 
 	case VG_CREATE_OLD:
 		/* create a VGDA */
 		return lvm_do_vg_create(arg, minor);
 
 	case VG_CREATE:
-	        /* create a VGDA, assume VG number is filled in */
+		/* create a VGDA, assume VG number is filled in */
 		return lvm_do_vg_create(arg, -1);
 
 	case VG_EXTEND:
@@ -685,8 +701,10 @@
 
 	case VG_SET_EXTENDABLE:
 		/* set/clear extendability flag of volume group */
-		if (vg_ptr == NULL) return -ENXIO;
-		if (copy_from_user(&extendable, arg, sizeof(extendable)) != 0)
+		if (vg_ptr == NULL)
+			return -ENXIO;
+		if (copy_from_user(&extendable, arg, sizeof(extendable)) !=
+		    0)
 			return -EFAULT;
 
 		if (extendable == VG_EXTENDABLE ||
@@ -695,13 +713,15 @@
 				vg_ptr->vg_status |= VG_EXTENDABLE;
 			else
 				vg_ptr->vg_status &= ~VG_EXTENDABLE;
-		} else return -EINVAL;
+		} else
+			return -EINVAL;
 		return 0;
 
 
 	case VG_STATUS:
 		/* get volume group data (only the vg_t struct) */
-		if (vg_ptr == NULL) return -ENXIO;
+		if (vg_ptr == NULL)
+			return -ENXIO;
 		if (copy_to_user(arg, vg_ptr, sizeof(vg_t)) != 0)
 			return -EFAULT;
 		return 0;
@@ -734,21 +754,26 @@
 	case LV_REMOVE:
 	case LV_RENAME:
 		/* create, extend, reduce, remove or rename a logical volume */
-		if (vg_ptr == NULL) return -ENXIO;
+		if (vg_ptr == NULL)
+			return -ENXIO;
 		if (copy_from_user(&lv_req, arg, sizeof(lv_req)) != 0)
 			return -EFAULT;
 
 		if (command != LV_REMOVE) {
-			if (copy_from_user(&lv, lv_req.lv, sizeof(lv_t)) != 0)
+			if (copy_from_user(&lv, lv_req.lv, sizeof(lv_t)) !=
+			    0)
 				return -EFAULT;
 		}
 		switch (command) {
 		case LV_CREATE:
-			return lvm_do_lv_create(minor, lv_req.lv_name, &lv);
+			return lvm_do_lv_create(minor, lv_req.lv_name,
+						&lv);
 
 		case LV_EXTEND:
 		case LV_REDUCE:
-			return lvm_do_lv_extend_reduce(minor, lv_req.lv_name, &lv);
+			return lvm_do_lv_extend_reduce(minor,
+						       lv_req.lv_name,
+						       &lv);
 		case LV_REMOVE:
 			return lvm_do_lv_remove(minor, lv_req.lv_name, -1);
 
@@ -776,12 +801,12 @@
 
 	case PV_CHANGE:
 		/* change a physical volume */
-		return lvm_do_pv_change(vg_ptr,arg);
+		return lvm_do_pv_change(vg_ptr, arg);
 
 
 	case PV_STATUS:
 		/* get physical volume data (pv_t structure only) */
-		return lvm_do_pv_status(vg_ptr,arg);
+		return lvm_do_pv_status(vg_ptr, arg);
 
 
 	case PV_FLUSH:
@@ -797,7 +822,7 @@
 	}
 
 	return 0;
-} /* lvm_chr_ioctl */
+}				/* lvm_chr_ioctl */
 
 
 /*
@@ -815,12 +840,14 @@
 	}
 #endif
 
-	if (lvm_chr_open_count > 0) lvm_chr_open_count--;
+	if (lvm_chr_open_count > 0)
+		lvm_chr_open_count--;
 
 	spin_lock(&lvm_lock);
-	if(lock == current->pid) {
-		if(!_lock_open_count) {
-			P_DEV("chr_close: unlocking LVM for pid %d\n", lock);
+	if (lock == current->pid) {
+		if (!_lock_open_count) {
+			P_DEV("chr_close: unlocking LVM for pid %d\n",
+			      lock);
 			lock = 0;
 			wake_up_interruptible(&lvm_wait);
 		} else
@@ -831,7 +858,7 @@
 	MOD_DEC_USE_COUNT;
 
 	return 0;
-} /* lvm_chr_close() */
+}				/* lvm_chr_close() */
 
 
 
@@ -851,7 +878,8 @@
 	vg_t *vg_ptr = vg[VG_BLK(minor)];
 
 	P_DEV("blk_open MINOR: %d  VG#: %d  LV#: %d  mode: %s%s\n",
-	      minor, VG_BLK(minor), LV_BLK(minor), MODE_TO_STR(file->f_mode));
+	      minor, VG_BLK(minor), LV_BLK(minor),
+	      MODE_TO_STR(file->f_mode));
 
 #ifdef LVM_TOTAL_RESET
 	if (lvm_reset_spindown > 0)
@@ -861,26 +889,27 @@
 	if (vg_ptr != NULL &&
 	    (vg_ptr->vg_status & VG_ACTIVE) &&
 	    (lv_ptr = vg_ptr->lv[LV_BLK(minor)]) != NULL &&
-	    LV_BLK(minor) >= 0 &&
-	    LV_BLK(minor) < vg_ptr->lv_max) {
+	    LV_BLK(minor) >= 0 && LV_BLK(minor) < vg_ptr->lv_max) {
 
 		/* Check parallel LV spindown (LV remove) */
-		if (lv_ptr->lv_status & LV_SPINDOWN) return -EPERM;
+		if (lv_ptr->lv_status & LV_SPINDOWN)
+			return -EPERM;
 
 		/* Check inactive LV and open for read/write */
 		/* We need to be able to "read" an inactive LV
 		   to re-activate it again */
 		if ((file->f_mode & FMODE_WRITE) &&
 		    (!(lv_ptr->lv_status & LV_ACTIVE)))
-		    return -EPERM;
+			return -EPERM;
 
 		if (!(lv_ptr->lv_access & LV_WRITE) &&
 		    (file->f_mode & FMODE_WRITE))
 			return -EACCES;
 
 
-                /* be sure to increment VG counter */
-		if (lv_ptr->lv_open == 0) vg_ptr->lv_open++;
+		/* be sure to increment VG counter */
+		if (lv_ptr->lv_open == 0)
+			vg_ptr->lv_open++;
 		lv_ptr->lv_open++;
 
 		MOD_INC_USE_COUNT;
@@ -890,10 +919,10 @@
 		return 0;
 	}
 	return -ENXIO;
-} /* lvm_blk_open() */
+}				/* lvm_blk_open() */
 
 /* Deliver "hard disk geometry" */
-static int _hdio_getgeo(ulong a, lv_t *lv_ptr, int what)
+static int _hdio_getgeo(ulong a, lv_t * lv_ptr, int what)
 {
 	int ret = 0;
 	uchar heads = 128;
@@ -901,34 +930,34 @@
 	ulong start = 0;
 	uint cylinders;
 
-	while ( heads * sectors > lv_ptr->lv_size) {
+	while (heads * sectors > lv_ptr->lv_size) {
 		heads >>= 1;
 		sectors >>= 1;
 	}
 	cylinders = lv_ptr->lv_size / heads / sectors;
 
 	switch (what) {
-		case 0:
+	case 0:
 		{
 			struct hd_geometry *hd = (struct hd_geometry *) a;
 
 			if (put_user(heads, &hd->heads) ||
-	    		    put_user(sectors, &hd->sectors) ||
-	    		    put_user((ushort) cylinders, &hd->cylinders) ||
+			    put_user(sectors, &hd->sectors) ||
+			    put_user((ushort) cylinders, &hd->cylinders) ||
 			    put_user(start, &hd->start))
 				return -EFAULT;
 			break;
 		}
 
 #ifdef HDIO_GETGEO_BIG
-		case 1:
+	case 1:
 		{
 			struct hd_big_geometry *hd =
-				(struct hd_big_geometry *) a;
+			    (struct hd_big_geometry *) a;
 
 			if (put_user(heads, &hd->heads) ||
-	    		    put_user(sectors, &hd->sectors) ||
-	    		    put_user(cylinders, &hd->cylinders) ||
+			    put_user(sectors, &hd->sectors) ||
+			    put_user(cylinders, &hd->cylinders) ||
 			    put_user(start, &hd->start))
 				return -EFAULT;
 			break;
@@ -960,91 +989,92 @@
 		LV_BLK(minor), MODE_TO_STR(file->f_mode));
 
 	switch (cmd) {
-		case BLKRASET:
-			/* set read ahead for block device */
-			ret = blk_ioctl(dev, cmd, a);
-			if (ret)
-				return ret;
-			lv_ptr->lv_read_ahead = (long) a;
-			LVM_CORRECT_READ_AHEAD(lv_ptr->lv_read_ahead);
-			break;
-	
-		case HDIO_GETGEO:
+	case BLKRASET:
+		/* set read ahead for block device */
+		ret = blk_ioctl(dev, cmd, a);
+		if (ret)
+			return ret;
+		lv_ptr->lv_read_ahead = (long) a;
+		LVM_CORRECT_READ_AHEAD(lv_ptr->lv_read_ahead);
+		break;
+
+	case HDIO_GETGEO:
 #ifdef HDIO_GETGEO_BIG
-		case HDIO_GETGEO_BIG:
+	case HDIO_GETGEO_BIG:
 #endif
-			/* get disk geometry */
-			P_IOCTL("%s -- lvm_blk_ioctl -- HDIO_GETGEO\n",
-				lvm_name);
-			if (!a)
-				return -EINVAL;
-
-			switch (cmd) {
-				case HDIO_GETGEO:
-					return _hdio_getgeo(a, lv_ptr, 0);
+		/* get disk geometry */
+		P_IOCTL("%s -- lvm_blk_ioctl -- HDIO_GETGEO\n", lvm_name);
+		if (!a)
+			return -EINVAL;
+
+		switch (cmd) {
+		case HDIO_GETGEO:
+			return _hdio_getgeo(a, lv_ptr, 0);
 #ifdef HDIO_GETGEO_BIG
-				case HDIO_GETGEO_BIG:
-					return _hdio_getgeo(a, lv_ptr, 1);
+		case HDIO_GETGEO_BIG:
+			return _hdio_getgeo(a, lv_ptr, 1);
 #endif
-			}
-	
-		case LV_BMAP:
-			/* turn logical block into (dev_t, block). non privileged. */
-			/* don't bmap a snapshot, since the mapping can change */
-			if (lv_ptr->lv_access & LV_SNAPSHOT)
-				return -EPERM;
-	
-			return lvm_user_bmap(inode, (struct lv_bmap *) arg);
-	
-		case LV_SET_ACCESS:
-			/* set access flags of a logical volume */
-			if (!capable(CAP_SYS_ADMIN)) return -EACCES;
-	
-			down_write(&lv_ptr->lv_lock);
-			lv_ptr->lv_access = (ulong) arg;
-			up_write(&lv_ptr->lv_lock);
-	
-			if ( lv_ptr->lv_access & LV_WRITE)
-				set_device_ro(lv_ptr->lv_dev, 0);
-			else
-				set_device_ro(lv_ptr->lv_dev, 1);
-			break;
-	
-	
-		case LV_SET_ALLOCATION:
-			/* set allocation flags of a logical volume */
-			if (!capable(CAP_SYS_ADMIN)) return -EACCES;
-			down_write(&lv_ptr->lv_lock);
-			lv_ptr->lv_allocation = (ulong) arg;
-			up_write(&lv_ptr->lv_lock);
-			break;
-	
-		case LV_SET_STATUS:
-			/* set status flags of a logical volume */
-			if (!capable(CAP_SYS_ADMIN)) return -EACCES;
-			if (!((ulong) arg & LV_ACTIVE) && lv_ptr->lv_open > 1)
-				return -EPERM;
-			down_write(&lv_ptr->lv_lock);
-			lv_ptr->lv_status = (ulong) arg;
-			up_write(&lv_ptr->lv_lock);
-			break;
-	
-		case LV_SNAPSHOT_USE_RATE:
-			return lvm_get_snapshot_use_rate(lv_ptr, arg);
-	
-		default:
-			/* Handle rest here */
-			ret = blk_ioctl(dev, cmd, a);
-			if (ret)
-				printk(KERN_WARNING
-				       "%s -- lvm_blk_ioctl: unknown "
-				       "cmd 0x%x\n",
-				       lvm_name, cmd);
-			return ret;
+		}
+
+	case LV_BMAP:
+		/* turn logical block into (dev_t, block). non privileged. */
+		/* don't bmap a snapshot, since the mapping can change */
+		if (lv_ptr->lv_access & LV_SNAPSHOT)
+			return -EPERM;
+
+		return lvm_user_bmap(inode, (struct lv_bmap *) arg);
+
+	case LV_SET_ACCESS:
+		/* set access flags of a logical volume */
+		if (!capable(CAP_SYS_ADMIN))
+			return -EACCES;
+
+		down_write(&lv_ptr->lv_lock);
+		lv_ptr->lv_access = (ulong) arg;
+		up_write(&lv_ptr->lv_lock);
+
+		if (lv_ptr->lv_access & LV_WRITE)
+			set_device_ro(lv_ptr->lv_dev, 0);
+		else
+			set_device_ro(lv_ptr->lv_dev, 1);
+		break;
+
+
+	case LV_SET_ALLOCATION:
+		/* set allocation flags of a logical volume */
+		if (!capable(CAP_SYS_ADMIN))
+			return -EACCES;
+		down_write(&lv_ptr->lv_lock);
+		lv_ptr->lv_allocation = (ulong) arg;
+		up_write(&lv_ptr->lv_lock);
+		break;
+
+	case LV_SET_STATUS:
+		/* set status flags of a logical volume */
+		if (!capable(CAP_SYS_ADMIN))
+			return -EACCES;
+		if (!((ulong) arg & LV_ACTIVE) && lv_ptr->lv_open > 1)
+			return -EPERM;
+		down_write(&lv_ptr->lv_lock);
+		lv_ptr->lv_status = (ulong) arg;
+		up_write(&lv_ptr->lv_lock);
+		break;
+
+	case LV_SNAPSHOT_USE_RATE:
+		return lvm_get_snapshot_use_rate(lv_ptr, arg);
+
+	default:
+		/* Handle rest here */
+		ret = blk_ioctl(dev, cmd, a);
+		if (ret)
+			printk(KERN_WARNING
+			       "%s -- lvm_blk_ioctl: unknown "
+			       "cmd 0x%x\n", lvm_name, cmd);
+		return ret;
 	}
 
 	return 0;
-} /* lvm_blk_ioctl() */
+}				/* lvm_blk_ioctl() */
 
 
 /*
@@ -1059,15 +1089,16 @@
 	P_DEV("blk_close MINOR: %d  VG#: %d  LV#: %d\n",
 	      minor, VG_BLK(minor), LV_BLK(minor));
 
-	if (lv_ptr->lv_open == 1) vg_ptr->lv_open--;
+	if (lv_ptr->lv_open == 1)
+		vg_ptr->lv_open--;
 	lv_ptr->lv_open--;
 
 	MOD_DEC_USE_COUNT;
 
 	return 0;
-} /* lvm_blk_close() */
+}				/* lvm_blk_close() */
 
-static int lvm_get_snapshot_use_rate(lv_t *lv, void *arg)
+static int lvm_get_snapshot_use_rate(lv_t * lv, void *arg)
 {
 	lv_snapshot_use_rate_req_t lv_rate_req;
 
@@ -1122,20 +1153,20 @@
 	if (get_user(block, &user_result->lv_block))
 		return -EFAULT;
 
-	memset(&bh,0,sizeof bh);
+	memset(&bh, 0, sizeof bh);
 	bh.b_blocknr = block;
 	bh.b_dev = bh.b_rdev = inode->i_rdev;
 	bh.b_size = lvm_get_blksize(bh.b_dev);
 	bh.b_rsector = block * (bh.b_size >> 9);
 	bh.b_end_io = NULL;
-	if ((err = lvm_map(&bh, READ)) < 0)  {
+	if ((err = lvm_map(&bh, READ)) < 0) {
 		printk("lvm map failed: %d\n", err);
 		return -EINVAL;
 	}
 
 	return put_user(kdev_t_to_nr(bh.b_rdev), &user_result->lv_dev) ||
-	       put_user(bh.b_rsector/(bh.b_size>>9), &user_result->lv_block) ?
-		-EFAULT : 0;
+	    put_user(bh.b_rsector / (bh.b_size >> 9),
+		     &user_result->lv_block) ? -EFAULT : 0;
 }
 
 
@@ -1144,7 +1175,8 @@
  * (see init_module/lvm_init)
  */
 static void __remap_snapshot(kdev_t rdev, ulong rsector,
-				    ulong pe_start, lv_t *lv, vg_t *vg) {
+			     ulong pe_start, lv_t * lv, vg_t * vg)
+{
 
 	/* copy a chunk from the origin to a snapshot device */
 	down_write(&lv->lv_lock);
@@ -1159,7 +1191,8 @@
 }
 
 static inline void _remap_snapshot(kdev_t rdev, ulong rsector,
-				   ulong pe_start, lv_t *lv, vg_t *vg) {
+				   ulong pe_start, lv_t * lv, vg_t * vg)
+{
 	int r;
 
 	/* check to see if this chunk is already in the snapshot */
@@ -1176,7 +1209,8 @@
 /*
  * extents destined for a pe that is on the move should be deferred
  */
-static inline int _should_defer(kdev_t pv, ulong sector, uint32_t pe_size) {
+static inline int _should_defer(kdev_t pv, ulong sector, uint32_t pe_size)
+{
 	return ((pe_lock_req.lock == LOCK_PE) &&
 		(pv == pe_lock_req.data.pv_dev) &&
 		(sector >= pe_lock_req.data.pv_offset) &&
@@ -1223,34 +1257,32 @@
 		goto bad;
 	}
 
-	if ((rw == WRITE || rw == WRITEA) &&
-	    !(lv->lv_access & LV_WRITE)) {
+	if ((rw == WRITE || rw == WRITEA) && !(lv->lv_access & LV_WRITE)) {
 		printk(KERN_CRIT
 		       "%s - lvm_map: ll_rw_blk write for readonly LV %s\n",
 		       lvm_name, lv->lv_name);
 		goto bad;
 	}
 
-	P_MAP("%s - lvm_map minor: %d  *rdev: %s  *rsector: %lu  size:%lu\n",
-	      lvm_name, minor,
-	      kdevname(bh->b_rdev),
-	      rsector_org, size);
+	P_MAP
+	    ("%s - lvm_map minor: %d  *rdev: %s  *rsector: %lu  size:%lu\n",
+	     lvm_name, minor, kdevname(bh->b_rdev), rsector_org, size);
 
 	if (rsector_org + size > lv->lv_size) {
 		printk(KERN_ALERT
 		       "%s - lvm_map access beyond end of device; *rsector: "
-                       "%lu or size: %lu wrong for minor: %2d\n",
-                       lvm_name, rsector_org, size, minor);
+		       "%lu or size: %lu wrong for minor: %2d\n",
+		       lvm_name, rsector_org, size, minor);
 		goto bad;
 	}
 
 
-	if (lv->lv_stripes < 2) { /* linear mapping */
+	if (lv->lv_stripes < 2) {	/* linear mapping */
 		/* get the index */
 		index = rsector_org / vg_this->pe_size;
 		pe_start = lv->lv_current_pe[index].pe;
 		rsector_map = lv->lv_current_pe[index].pe +
-			(rsector_org % vg_this->pe_size);
+		    (rsector_org % vg_this->pe_size);
 		rdev_map = lv->lv_current_pe[index].dev;
 
 		P_MAP("lv_current_pe[%ld].pe: %d  rdev: %s  rsector:%ld\n",
@@ -1263,22 +1295,23 @@
 
 		stripe_length = vg_this->pe_size * lv->lv_stripes;
 		stripe_index = (rsector_org % stripe_length) /
-			lv->lv_stripesize;
+		    lv->lv_stripesize;
 		index = rsector_org / stripe_length +
-			(stripe_index % lv->lv_stripes) *
-			(lv->lv_allocated_le / lv->lv_stripes);
+		    (stripe_index % lv->lv_stripes) *
+		    (lv->lv_allocated_le / lv->lv_stripes);
 		pe_start = lv->lv_current_pe[index].pe;
 		rsector_map = lv->lv_current_pe[index].pe +
-			(rsector_org % stripe_length) -
-			(stripe_index % lv->lv_stripes) * lv->lv_stripesize -
-			stripe_index / lv->lv_stripes *
-			(lv->lv_stripes - 1) * lv->lv_stripesize;
+		    (rsector_org % stripe_length) -
+		    (stripe_index % lv->lv_stripes) * lv->lv_stripesize -
+		    stripe_index / lv->lv_stripes *
+		    (lv->lv_stripes - 1) * lv->lv_stripesize;
 		rdev_map = lv->lv_current_pe[index].dev;
 
 		P_MAP("lv_current_pe[%ld].pe: %d  rdev: %s  rsector:%ld\n"
 		      "stripe_length: %ld  stripe_index: %ld\n",
-		      index, lv->lv_current_pe[index].pe, kdevname(rdev_map),
-		      rsector_map, stripe_length, stripe_index);
+		      index, lv->lv_current_pe[index].pe,
+		      kdevname(rdev_map), rsector_map, stripe_length,
+		      stripe_index);
 	}
 
 	/*
@@ -1287,8 +1320,8 @@
 	 * we need to queue this request, because this is in the fast path.
 	 */
 	if (rw == WRITE || rw == WRITEA) {
-		if(_defer_extent(bh, rw, rdev_map,
-				 rsector_map, vg_this->pe_size)) {
+		if (_defer_extent(bh, rw, rdev_map,
+				  rsector_map, vg_this->pe_size)) {
 
 			up_read(&lv->lv_lock);
 			return 0;
@@ -1299,15 +1332,15 @@
 		lv->lv_current_pe[index].reads++;	/* statistic */
 
 	/* snapshot volume exception handling on physical device address base */
-	if (!(lv->lv_access & (LV_SNAPSHOT|LV_SNAPSHOT_ORG)))
+	if (!(lv->lv_access & (LV_SNAPSHOT | LV_SNAPSHOT_ORG)))
 		goto out;
 
-	if (lv->lv_access & LV_SNAPSHOT) { /* remap snapshot */
+	if (lv->lv_access & LV_SNAPSHOT) {	/* remap snapshot */
 		if (lvm_snapshot_remap_block(&rdev_map, &rsector_map,
 					     pe_start, lv) < 0)
 			goto bad;
 
-	} else if (rw == WRITE || rw == WRITEA) { /* snapshot origin */
+	} else if (rw == WRITE || rw == WRITEA) {	/* snapshot origin */
 		lv_t *snap;
 
 		/* start with first snapshot and loop through all of
@@ -1321,22 +1354,22 @@
 			/* Serializes the COW with the accesses to the
 			   snapshot device */
 			_remap_snapshot(rdev_map, rsector_map,
-					 pe_start, snap, vg_this);
+					pe_start, snap, vg_this);
 		}
 	}
 
- out:
+      out:
 	bh->b_rdev = rdev_map;
 	bh->b_rsector = rsector_map;
 	up_read(&lv->lv_lock);
 	return 1;
 
- bad:
+      bad:
 	if (bh->b_end_io)
-	buffer_IO_error(bh);
+		buffer_IO_error(bh);
 	up_read(&lv->lv_lock);
 	return -1;
-} /* lvm_map() */
+}				/* lvm_map() */
 
 
 /*
@@ -1368,9 +1401,8 @@
 /*
  * make request function
  */
-static int lvm_make_request_fn(request_queue_t *q,
-			       int rw,
-			       struct buffer_head *bh)
+static int lvm_make_request_fn(request_queue_t * q,
+			       int rw, struct buffer_head *bh)
 {
 	return (lvm_map(bh, rw) <= 0) ? 0 : 1;
 }
@@ -1386,7 +1418,7 @@
  */
 static int lvm_do_lock_lvm(void)
 {
-lock_try_again:
+      lock_try_again:
 	spin_lock(&lvm_lock);
 	if (lock != 0 && lock != current->pid) {
 		P_DEV("lvm_do_lock_lvm: locked by pid %d ...\n", lock);
@@ -1404,19 +1436,20 @@
 	P_DEV("lvm_do_lock_lvm: locking LVM for pid %d\n", lock);
 	spin_unlock(&lvm_lock);
 	return 0;
-} /* lvm_do_lock_lvm */
+}				/* lvm_do_lock_lvm */
 
 
 /*
  * character device support function lock/unlock physical extend
  */
-static int lvm_do_pe_lock_unlock(vg_t *vg_ptr, void *arg)
+static int lvm_do_pe_lock_unlock(vg_t * vg_ptr, void *arg)
 {
 	pe_lock_req_t new_lock;
 	struct buffer_head *bh;
 	uint p;
 
-	if (vg_ptr == NULL) return -ENXIO;
+	if (vg_ptr == NULL)
+		return -ENXIO;
 	if (copy_from_user(&new_lock, arg, sizeof(new_lock)) != 0)
 		return -EFAULT;
 
@@ -1427,7 +1460,8 @@
 			    new_lock.data.pv_dev == vg_ptr->pv[p]->pv_dev)
 				break;
 		}
-		if (p == vg_ptr->pv_max) return -ENXIO;
+		if (p == vg_ptr->pv_max)
+			return -ENXIO;
 
 		/*
 		 * this sync releaves memory pressure to lessen the
@@ -1478,12 +1512,13 @@
 /*
  * character device support function logical extend remap
  */
-static int lvm_do_le_remap(vg_t *vg_ptr, void *arg)
+static int lvm_do_le_remap(vg_t * vg_ptr, void *arg)
 {
 	uint l, le;
 	lv_t *lv_ptr;
 
-	if (vg_ptr == NULL) return -ENXIO;
+	if (vg_ptr == NULL)
+		return -ENXIO;
 	if (copy_from_user(&le_remap_req, arg,
 			   sizeof(le_remap_req_t)) != 0)
 		return -EFAULT;
@@ -1515,7 +1550,7 @@
 		}
 	}
 	return -ENXIO;
-} /* lvm_do_le_remap() */
+}				/* lvm_do_le_remap() */
 
 
 /*
@@ -1529,7 +1564,7 @@
 	vg_t *vg_ptr;
 	lv_t **snap_lv_ptr;
 
-	if ((vg_ptr = kmalloc(sizeof(vg_t),GFP_KERNEL)) == NULL) {
+	if ((vg_ptr = kmalloc(sizeof(vg_t), GFP_KERNEL)) == NULL) {
 		printk(KERN_CRIT
 		       "%s -- VG_CREATE: kmalloc error VG at line %d\n",
 		       lvm_name, __LINE__);
@@ -1537,8 +1572,9 @@
 	}
 	/* get the volume group structure */
 	if (copy_from_user(vg_ptr, arg, sizeof(vg_t)) != 0) {
-		P_IOCTL("lvm_do_vg_create ERROR: copy VG ptr %p (%d bytes)\n",
-			arg, sizeof(vg_t));
+		P_IOCTL
+		    ("lvm_do_vg_create ERROR: copy VG ptr %p (%d bytes)\n",
+		     arg, sizeof(vg_t));
 		kfree(vg_ptr);
 		return -EFAULT;
 	}
@@ -1572,7 +1608,7 @@
 
 	if (vg_ptr->lv_max > ABS_MAX_LV) {
 		printk(KERN_WARNING
-		"%s -- Can't activate VG: ABS_MAX_LV too small for %u\n",
+		       "%s -- Can't activate VG: ABS_MAX_LV too small for %u\n",
 		       lvm_name, vg_ptr->lv_max);
 		kfree(vg_ptr);
 		return -EPERM;
@@ -1590,7 +1626,7 @@
 		/* user space address */
 		if ((pvp = vg_ptr->pv[p]) != NULL) {
 			ret = lvm_do_pv_create(pvp, vg_ptr, p);
-			if ( ret != 0) {
+			if (ret != 0) {
 				lvm_do_vg_remove(minor);
 				return ret;
 			}
@@ -1598,7 +1634,7 @@
 	}
 
 	size = vg_ptr->lv_max * sizeof(lv_t *);
-	if ((snap_lv_ptr = vmalloc ( size)) == NULL) {
+	if ((snap_lv_ptr = vmalloc(size)) == NULL) {
 		printk(KERN_CRIT
 		       "%s -- VG_CREATE: vmalloc error snapshot LVs at line %d\n",
 		       lvm_name, __LINE__);
@@ -1614,12 +1650,13 @@
 		/* user space address */
 		if ((lvp = vg_ptr->lv[l]) != NULL) {
 			if (copy_from_user(&lv, lvp, sizeof(lv_t)) != 0) {
-				P_IOCTL("ERROR: copying LV ptr %p (%d bytes)\n",
-					lvp, sizeof(lv_t));
+				P_IOCTL
+				    ("ERROR: copying LV ptr %p (%d bytes)\n",
+				     lvp, sizeof(lv_t));
 				lvm_do_vg_remove(minor);
 				return -EFAULT;
 			}
-			if ( lv.lv_access & LV_SNAPSHOT) {
+			if (lv.lv_access & LV_SNAPSHOT) {
 				snap_lv_ptr[ls] = lvp;
 				vg_ptr->lv[l] = NULL;
 				ls++;
@@ -1659,24 +1696,26 @@
 	vg_ptr->vg_status |= VG_ACTIVE;
 
 	return 0;
-} /* lvm_do_vg_create() */
+}				/* lvm_do_vg_create() */
 
 
 /*
  * character device support function VGDA extend
  */
-static int lvm_do_vg_extend(vg_t *vg_ptr, void *arg)
+static int lvm_do_vg_extend(vg_t * vg_ptr, void *arg)
 {
 	int ret = 0;
 	uint p;
 	pv_t *pv_ptr;
 
-	if (vg_ptr == NULL) return -ENXIO;
+	if (vg_ptr == NULL)
+		return -ENXIO;
 	if (vg_ptr->pv_cur < vg_ptr->pv_max) {
 		for (p = 0; p < vg_ptr->pv_max; p++) {
-			if ( ( pv_ptr = vg_ptr->pv[p]) == NULL) {
+			if ((pv_ptr = vg_ptr->pv[p]) == NULL) {
 				ret = lvm_do_pv_create(arg, vg_ptr, p);
-				if ( ret != 0) return ret;
+				if (ret != 0)
+					return ret;
 				pv_ptr = vg_ptr->pv[p];
 				vg_ptr->pe_total += pv_ptr->pe_total;
 				return 0;
@@ -1684,26 +1723,28 @@
 		}
 	}
 	return -EPERM;
-} /* lvm_do_vg_extend() */
+}				/* lvm_do_vg_extend() */
 
 
 /*
  * character device support function VGDA reduce
  */
-static int lvm_do_vg_reduce(vg_t *vg_ptr, void *arg) {
+static int lvm_do_vg_reduce(vg_t * vg_ptr, void *arg)
+{
 	uint p;
 	pv_t *pv_ptr;
 
-	if (vg_ptr == NULL) return -ENXIO;
+	if (vg_ptr == NULL)
+		return -ENXIO;
 	if (copy_from_user(pv_name, arg, sizeof(pv_name)) != 0)
 		return -EFAULT;
 
 	for (p = 0; p < vg_ptr->pv_max; p++) {
 		pv_ptr = vg_ptr->pv[p];
 		if (pv_ptr != NULL &&
-		    strcmp(pv_ptr->pv_name,
-			       pv_name) == 0) {
-			if (pv_ptr->lv_cur > 0) return -EPERM;
+		    strcmp(pv_ptr->pv_name, pv_name) == 0) {
+			if (pv_ptr->lv_cur > 0)
+				return -EPERM;
 			lvm_do_pv_remove(vg_ptr, p);
 			/* Make PV pointer array contiguous */
 			for (; p < vg_ptr->pv_max - 1; p++)
@@ -1713,55 +1754,56 @@
 		}
 	}
 	return -ENXIO;
-} /* lvm_do_vg_reduce */
+}				/* lvm_do_vg_reduce */
 
 
 /*
  * character device support function VG rename
  */
-static int lvm_do_vg_rename(vg_t *vg_ptr, void *arg)
+static int lvm_do_vg_rename(vg_t * vg_ptr, void *arg)
 {
 	int l = 0, p = 0, len = 0;
-	char vg_name[NAME_LEN] = { 0,};
-	char lv_name[NAME_LEN] = { 0,};
+	char vg_name[NAME_LEN] = { 0, };
+	char lv_name[NAME_LEN] = { 0, };
 	char *ptr = NULL;
 	lv_t *lv_ptr = NULL;
 	pv_t *pv_ptr = NULL;
 
 	/* If the VG doesn't exist in the kernel then just exit */
-	if (!vg_ptr) return 0;
+	if (!vg_ptr)
+		return 0;
 
 	if (copy_from_user(vg_name, arg, sizeof(vg_name)) != 0)
 		return -EFAULT;
 
 	lvm_fs_remove_vg(vg_ptr);
 
-	strncpy ( vg_ptr->vg_name, vg_name, sizeof ( vg_name)-1);
-	for ( l = 0; l < vg_ptr->lv_max; l++)
-	{
-		if ((lv_ptr = vg_ptr->lv[l]) == NULL) continue;
-		memset (lv_ptr->vg_name, 0, sizeof (*vg_name));
-		strncpy(lv_ptr->vg_name, vg_name, sizeof ( vg_name));
+	strncpy(vg_ptr->vg_name, vg_name, sizeof(vg_name) - 1);
+	for (l = 0; l < vg_ptr->lv_max; l++) {
+		if ((lv_ptr = vg_ptr->lv[l]) == NULL)
+			continue;
+		memset(lv_ptr->vg_name, 0, sizeof(*vg_name));
+		strncpy(lv_ptr->vg_name, vg_name, sizeof(vg_name));
 		ptr = strrchr(lv_ptr->lv_name, '/');
 		ptr = ptr ? ptr + 1 : lv_ptr->lv_name;
-		strncpy(lv_name, ptr, sizeof ( lv_name));
+		strncpy(lv_name, ptr, sizeof(lv_name));
 		len = sizeof(LVM_DIR_PREFIX);
 		strcpy(lv_ptr->lv_name, LVM_DIR_PREFIX);
 		strncat(lv_ptr->lv_name, vg_name, NAME_LEN - len);
-		strcat (lv_ptr->lv_name, "/");
+		strcat(lv_ptr->lv_name, "/");
 		len += strlen(vg_name) + 1;
 		strncat(lv_ptr->lv_name, lv_name, NAME_LEN - len);
 	}
-	for ( p = 0; p < vg_ptr->pv_max; p++)
-	{
-		if ( (pv_ptr = vg_ptr->pv[p]) == NULL) continue;
+	for (p = 0; p < vg_ptr->pv_max; p++) {
+		if ((pv_ptr = vg_ptr->pv[p]) == NULL)
+			continue;
 		strncpy(pv_ptr->vg_name, vg_name, NAME_LEN);
 	}
 
 	lvm_fs_create_vg(vg_ptr);
 
 	/* Need to add PV entries */
-	for ( p = 0; p < vg_ptr->pv_act; p++) {
+	for (p = 0; p < vg_ptr->pv_act; p++) {
 		pv_t *pv_ptr = vg_ptr->pv[p];
 
 		if (pv_ptr)
@@ -1769,18 +1811,18 @@
 	}
 
 	/* Need to add LV entries */
-        for ( l = 0; l < vg_ptr->lv_max; l++) {
+	for (l = 0; l < vg_ptr->lv_max; l++) {
 		lv_t *lv_ptr = vg_ptr->lv[l];
 
 		if (!lv_ptr)
 			continue;
 
 		lvm_gendisk.part[MINOR(lv_ptr->lv_dev)].de =
-	    		lvm_fs_create_lv(vg_ptr, lv_ptr);
+		    lvm_fs_create_lv(vg_ptr, lv_ptr);
 	}
 
 	return 0;
-} /* lvm_do_vg_rename */
+}				/* lvm_do_vg_rename */
 
 
 /*
@@ -1792,7 +1834,8 @@
 	vg_t *vg_ptr = vg[VG_CHR(minor)];
 	pv_t *pv_ptr;
 
-	if (vg_ptr == NULL) return -ENXIO;
+	if (vg_ptr == NULL)
+		return -ENXIO;
 
 #ifdef LVM_TOTAL_RESET
 	if (vg_ptr->lv_open > 0 && lvm_reset_spindown == 0)
@@ -1843,20 +1886,21 @@
 	MOD_DEC_USE_COUNT;
 
 	return 0;
-} /* lvm_do_vg_remove() */
+}				/* lvm_do_vg_remove() */
 
 
 /*
  * character device support function physical volume create
  */
-static int lvm_do_pv_create(pv_t *pvp, vg_t *vg_ptr, ulong p) {
+static int lvm_do_pv_create(pv_t * pvp, vg_t * vg_ptr, ulong p)
+{
 	pv_t *pv;
 	int err;
 
 	if (!vg_ptr)
 		return -ENXIO;
 
-	pv = kmalloc(sizeof(pv_t),GFP_KERNEL);
+	pv = kmalloc(sizeof(pv_t), GFP_KERNEL);
 	if (pv == NULL) {
 		printk(KERN_CRIT
 		       "%s -- PV_CREATE: kmalloc error PV at line %d\n",
@@ -1867,8 +1911,9 @@
 	memset(pv, 0, sizeof(*pv));
 
 	if (copy_from_user(pv, pvp, sizeof(pv_t)) != 0) {
-		P_IOCTL("lvm_do_pv_create ERROR: copy PV ptr %p (%d bytes)\n",
-			pvp, sizeof(pv_t));
+		P_IOCTL
+		    ("lvm_do_pv_create ERROR: copy PV ptr %p (%d bytes)\n",
+		     pvp, sizeof(pv_t));
 		kfree(pv);
 		return -EFAULT;
 	}
@@ -1889,13 +1934,14 @@
 
 	vg_ptr->pv[p] = pv;
 	return 0;
-} /* lvm_do_pv_create() */
+}				/* lvm_do_pv_create() */
 
 
 /*
  * character device support function physical volume remove
  */
-static int lvm_do_pv_remove(vg_t *vg_ptr, ulong p) {
+static int lvm_do_pv_remove(vg_t * vg_ptr, ulong p)
+{
 	pv_t *pv = vg_ptr->pv[p];
 
 	lvm_fs_remove_pv(vg_ptr, pv);
@@ -1913,7 +1959,7 @@
 }
 
 
-static void __update_hardsectsize(lv_t *lv)
+static void __update_hardsectsize(lv_t * lv)
 {
 	int max_hardsectsize = 0, hardsectsize = 0;
 	int p;
@@ -1925,9 +1971,10 @@
 			if (max_hardsectsize == 0)
 				max_hardsectsize = hardsectsize;
 			else if (hardsectsize != max_hardsectsize) {
-				P_DEV("%s PV[%d] (%s) sector size %d, not %d\n",
-				      lv->lv_name, p, kdevname(pv->pv_dev),
-				      hardsectsize, max_hardsectsize);
+				P_DEV
+				    ("%s PV[%d] (%s) sector size %d, not %d\n",
+				     lv->lv_name, p, kdevname(pv->pv_dev),
+				     hardsectsize, max_hardsectsize);
 				break;
 			}
 		}
@@ -1937,12 +1984,14 @@
 	if (hardsectsize != max_hardsectsize) {
 		int le;
 		for (le = 0; le < lv->lv_allocated_le; le++) {
-			hardsectsize = lvm_sectsize(lv->lv_current_pe[le].dev);
+			hardsectsize =
+			    lvm_sectsize(lv->lv_current_pe[le].dev);
 			if (hardsectsize > max_hardsectsize) {
-				P_DEV("%s LE[%d] (%s) blocksize %d not %d\n",
-				      lv->lv_name, le,
-				      kdevname(lv->lv_current_pe[le].dev),
-				      hardsectsize, max_hardsectsize);
+				P_DEV
+				    ("%s LE[%d] (%s) blocksize %d not %d\n",
+				     lv->lv_name, le,
+				     kdevname(lv->lv_current_pe[le].dev),
+				     hardsectsize, max_hardsectsize);
 				max_hardsectsize = hardsectsize;
 			}
 		}
@@ -1952,7 +2001,9 @@
 		    (lv->lv_status & LV_ACTIVE)) {
 			int e;
 			for (e = 0; e < lv->lv_remap_end; e++) {
-				hardsectsize = lvm_sectsize(lv->lv_block_exception[e].rdev_new);
+				hardsectsize =
+				    lvm_sectsize(lv->lv_block_exception[e].
+						 rdev_new);
 				if (hardsectsize > max_hardsectsize)
 					max_hardsectsize = hardsectsize;
 			}
@@ -1969,7 +2020,7 @@
 /*
  * character device support function logical volume create
  */
-static int lvm_do_lv_create(int minor, char *lv_name, lv_t *lv)
+static int lvm_do_lv_create(int minor, char *lv_name, lv_t * lv)
 {
 	int e, ret, l, le, l_new, p, size, activate = 1;
 	ulong lv_status_save;
@@ -1997,14 +2048,18 @@
 	else {
 		for (l = 0; l < vg_ptr->lv_max; l++) {
 			if (vg_ptr->lv[l] == NULL)
-				if (l_new == -1) l_new = l;
+				if (l_new == -1)
+					l_new = l;
 		}
 	}
-	if (l_new == -1) return -EPERM;
-	else             l = l_new;
+	if (l_new == -1)
+		return -EPERM;
+	else
+		l = l_new;
 
-	if ((lv_ptr = kmalloc(sizeof(lv_t),GFP_KERNEL)) == NULL) {;
-		printk(KERN_CRIT "%s -- LV_CREATE: kmalloc error LV at line %d\n",
+	if ((lv_ptr = kmalloc(sizeof(lv_t), GFP_KERNEL)) == NULL) {;
+		printk(KERN_CRIT
+		       "%s -- LV_CREATE: kmalloc error LV at line %d\n",
 		       lvm_name, __LINE__);
 		return -ENOMEM;
 	}
@@ -2036,8 +2091,7 @@
 		if ((lv_ptr->lv_current_pe = vmalloc(size)) == NULL) {
 			printk(KERN_CRIT
 			       "%s -- LV_CREATE: vmalloc error LV_CURRENT_PE of %d Byte "
-			       "at line %d\n",
-			       lvm_name, size, __LINE__);
+			       "at line %d\n", lvm_name, size, __LINE__);
 			P_KFREE("%s -- kfree %d\n", lvm_name, __LINE__);
 			kfree(lv_ptr);
 			vg_ptr->lv[l] = NULL;
@@ -2066,7 +2120,9 @@
 			lv_ptr->lv_snapshot_org =
 			    vg_ptr->lv[LV_BLK(lv_ptr->lv_snapshot_minor)];
 			if (lv_ptr->lv_snapshot_org != NULL) {
-				size = lv_ptr->lv_remap_end * sizeof(lv_block_exception_t);
+				size =
+				    lv_ptr->lv_remap_end *
+				    sizeof(lv_block_exception_t);
 
 				if (!size) {
 					printk(KERN_WARNING
@@ -2076,29 +2132,32 @@
 					return -EINVAL;
 				}
 
-				if ((lv_ptr->lv_block_exception = vmalloc(size)) == NULL) {
+				if ((lv_ptr->lv_block_exception =
+				     vmalloc(size)) == NULL) {
 					printk(KERN_CRIT
 					       "%s -- lvm_do_lv_create: vmalloc error LV_BLOCK_EXCEPTION "
 					       "of %d byte at line %d\n",
 					       lvm_name, size, __LINE__);
-					P_KFREE("%s -- kfree %d\n", lvm_name,
-						__LINE__);
+					P_KFREE("%s -- kfree %d\n",
+						lvm_name, __LINE__);
 					kfree(lv_ptr);
 					vg_ptr->lv[l] = NULL;
 					return -ENOMEM;
 				}
-				if (copy_from_user(lv_ptr->lv_block_exception, lvbe, size)) {
+				if (copy_from_user
+				    (lv_ptr->lv_block_exception, lvbe,
+				     size)) {
 					vfree(lv_ptr->lv_block_exception);
 					kfree(lv_ptr);
 					vg_ptr->lv[l] = NULL;
 					return -EFAULT;
 				}
 
-				if(lv_ptr->lv_block_exception[0].rsector_org ==
-				   LVM_SNAPSHOT_DROPPED_SECTOR)
-				{
+				if (lv_ptr->lv_block_exception[0].
+				    rsector_org ==
+				    LVM_SNAPSHOT_DROPPED_SECTOR) {
 					printk(KERN_WARNING
-   "%s -- lvm_do_lv_create: snapshot has been dropped and will not be activated\n",
+					       "%s -- lvm_do_lv_create: snapshot has been dropped and will not be activated\n",
 					       lvm_name);
 					activate = 0;
 				}
@@ -2112,36 +2171,54 @@
 				   which can be the original logical volume */
 				lv_ptr = vg_ptr->lv[l];
 				/* now lv_ptr points to our new last snapshot logical volume */
-				lv_ptr->lv_current_pe = lv_ptr->lv_snapshot_org->lv_current_pe;
-				lv_ptr->lv_allocated_snapshot_le = lv_ptr->lv_allocated_le;
-				lv_ptr->lv_allocated_le = lv_ptr->lv_snapshot_org->lv_allocated_le;
-				lv_ptr->lv_current_le = lv_ptr->lv_snapshot_org->lv_current_le;
-				lv_ptr->lv_size = lv_ptr->lv_snapshot_org->lv_size;
-				lv_ptr->lv_stripes = lv_ptr->lv_snapshot_org->lv_stripes;
-				lv_ptr->lv_stripesize = lv_ptr->lv_snapshot_org->lv_stripesize;
+				lv_ptr->lv_current_pe =
+				    lv_ptr->lv_snapshot_org->lv_current_pe;
+				lv_ptr->lv_allocated_snapshot_le =
+				    lv_ptr->lv_allocated_le;
+				lv_ptr->lv_allocated_le =
+				    lv_ptr->lv_snapshot_org->
+				    lv_allocated_le;
+				lv_ptr->lv_current_le =
+				    lv_ptr->lv_snapshot_org->lv_current_le;
+				lv_ptr->lv_size =
+				    lv_ptr->lv_snapshot_org->lv_size;
+				lv_ptr->lv_stripes =
+				    lv_ptr->lv_snapshot_org->lv_stripes;
+				lv_ptr->lv_stripesize =
+				    lv_ptr->lv_snapshot_org->lv_stripesize;
 
 				/* Update the VG PE(s) used by snapshot reserve space. */
-				vg_ptr->pe_allocated += lv_ptr->lv_allocated_snapshot_le;
+				vg_ptr->pe_allocated +=
+				    lv_ptr->lv_allocated_snapshot_le;
 
-				if ((ret = lvm_snapshot_alloc(lv_ptr)) != 0)
-				{
+				if ((ret =
+				     lvm_snapshot_alloc(lv_ptr)) != 0) {
 					vfree(lv_ptr->lv_block_exception);
 					kfree(lv_ptr);
 					vg_ptr->lv[l] = NULL;
 					return ret;
 				}
-				for ( e = 0; e < lv_ptr->lv_remap_ptr; e++)
-					lvm_hash_link (lv_ptr->lv_block_exception + e,
-						       lv_ptr->lv_block_exception[e].rdev_org,
-						       lv_ptr->lv_block_exception[e].rsector_org, lv_ptr);
+				for (e = 0; e < lv_ptr->lv_remap_ptr; e++)
+					lvm_hash_link(lv_ptr->
+						      lv_block_exception +
+						      e,
+						      lv_ptr->
+						      lv_block_exception
+						      [e].rdev_org,
+						      lv_ptr->
+						      lv_block_exception
+						      [e].rsector_org,
+						      lv_ptr);
 				/* need to fill the COW exception table data
 				   into the page for disk i/o */
-				if(lvm_snapshot_fill_COW_page(vg_ptr, lv_ptr)) {
+				if (lvm_snapshot_fill_COW_page
+				    (vg_ptr, lv_ptr)) {
 					kfree(lv_ptr);
 					vg_ptr->lv[l] = NULL;
 					return -EINVAL;
 				}
-				init_waitqueue_head(&lv_ptr->lv_snapshot_wait);
+				init_waitqueue_head(&lv_ptr->
+						    lv_snapshot_wait);
 			} else {
 				kfree(lv_ptr);
 				vg_ptr->lv[l] = NULL;
@@ -2152,7 +2229,7 @@
 			vg_ptr->lv[l] = NULL;
 			return -EINVAL;
 		}
-	} /* if ( vg[VG_CHR(minor)]->lv[l]->lv_access & LV_SNAPSHOT) */
+	}			/* if ( vg[VG_CHR(minor)]->lv[l]->lv_access & LV_SNAPSHOT) */
 
 	lv_ptr = vg_ptr->lv[l];
 	lvm_gendisk.part[MINOR(lv_ptr->lv_dev)].start_sect = 0;
@@ -2180,23 +2257,24 @@
 
 		down_write(&org->lv_lock);
 		org->lv_access |= LV_SNAPSHOT_ORG;
-		lv_ptr->lv_access &= ~LV_SNAPSHOT_ORG; /* this can only hide an userspace bug */
+		lv_ptr->lv_access &= ~LV_SNAPSHOT_ORG;	/* this can only hide an userspace bug */
 
 
 		/* Link in the list of snapshot volumes */
-		for (last = org; last->lv_snapshot_next; last = last->lv_snapshot_next);
+		for (last = org; last->lv_snapshot_next;
+		     last = last->lv_snapshot_next);
 		lv_ptr->lv_snapshot_prev = last;
 		last->lv_snapshot_next = lv_ptr;
 		up_write(&org->lv_lock);
 	}
 
 	/* activate the logical volume */
-	if(activate)
+	if (activate)
 		lv_ptr->lv_status |= LV_ACTIVE;
 	else
 		lv_ptr->lv_status &= ~LV_ACTIVE;
 
-	if ( lv_ptr->lv_access & LV_WRITE)
+	if (lv_ptr->lv_access & LV_WRITE)
 		set_device_ro(lv_ptr->lv_dev, 0);
 	else
 		set_device_ro(lv_ptr->lv_dev, 1);
@@ -2210,7 +2288,7 @@
 	lvm_gendisk.part[MINOR(lv_ptr->lv_dev)].de =
 	    lvm_fs_create_lv(vg_ptr, lv_ptr);
 	return 0;
-} /* lvm_do_lv_create() */
+}				/* lvm_do_lv_create() */
 
 
 /*
@@ -2233,7 +2311,8 @@
 			}
 		}
 	}
-	if (l == vg_ptr->lv_max) return -ENXIO;
+	if (l == vg_ptr->lv_max)
+		return -ENXIO;
 
 	lv_ptr = vg_ptr->lv[l];
 #ifdef LVM_TOTAL_RESET
@@ -2253,14 +2332,15 @@
 
 	if (lv_ptr->lv_access & LV_SNAPSHOT) {
 		/*
-		 * Atomically make the snapshot invisible
+		 * Atomically make the the snapshot invisible
 		 * to the original lv before playing with it.
 		 */
-		lv_t * org = lv_ptr->lv_snapshot_org;
+		lv_t *org = lv_ptr->lv_snapshot_org;
 		down_write(&org->lv_lock);
 
 		/* remove this snapshot logical volume from the chain */
-		lv_ptr->lv_snapshot_prev->lv_snapshot_next = lv_ptr->lv_snapshot_next;
+		lv_ptr->lv_snapshot_prev->lv_snapshot_next =
+		    lv_ptr->lv_snapshot_next;
 		if (lv_ptr->lv_snapshot_next != NULL) {
 			lv_ptr->lv_snapshot_next->lv_snapshot_prev =
 			    lv_ptr->lv_snapshot_prev;
@@ -2299,7 +2379,7 @@
 	vg_lv_map[MINOR(lv_ptr->lv_dev)].lv_number = -1;
 
 	/* correct the PE count in PVs if this is not a snapshot
-           logical volume */
+	   logical volume */
 	if (!(lv_ptr->lv_access & LV_SNAPSHOT)) {
 		/* only if this is no snapshot logical volume because
 		   we share the lv_current_pe[] structs with the
@@ -2320,13 +2400,15 @@
 	vg_ptr->lv[l] = NULL;
 	vg_ptr->lv_cur--;
 	return 0;
-} /* lvm_do_lv_remove() */
+}				/* lvm_do_lv_remove() */
 
 
 /*
  * logical volume extend / reduce
  */
-static int __extend_reduce_snapshot(vg_t *vg_ptr, lv_t *old_lv, lv_t *new_lv) {
+static int __extend_reduce_snapshot(vg_t * vg_ptr, lv_t * old_lv,
+				    lv_t * new_lv)
+{
 	ulong size;
 	lv_block_exception_t *lvbe;
 
@@ -2357,7 +2439,8 @@
 	return 0;
 }
 
-static int __extend_reduce(vg_t *vg_ptr, lv_t *old_lv, lv_t *new_lv) {
+static int __extend_reduce(vg_t * vg_ptr, lv_t * old_lv, lv_t * new_lv)
+{
 	ulong size, l, p, end;
 	pe_t *pe;
 
@@ -2373,7 +2456,7 @@
 
 	/* get the PE structures from user space */
 	if (copy_from_user(pe, new_lv->lv_current_pe, size)) {
-		if(old_lv->lv_access & LV_SNAPSHOT)
+		if (old_lv->lv_access & LV_SNAPSHOT)
 			vfree(new_lv->lv_snapshot_hash_table);
 		vfree(pe);
 		return -EFAULT;
@@ -2398,7 +2481,7 @@
 		vg_ptr->pe_allocated++;
 		for (p = 0; p < vg_ptr->pv_cur; p++) {
 			if (vg_ptr->pv[p]->pv_dev ==
-                            new_lv->lv_current_pe[l].dev) {
+			    new_lv->lv_current_pe[l].dev) {
 				vg_ptr->pv[p]->pe_allocated++;
 				break;
 			}
@@ -2410,25 +2493,30 @@
 		end = min(old_lv->lv_current_le, new_lv->lv_current_le);
 		for (l = 0; l < end; l++) {
 			new_lv->lv_current_pe[l].reads +=
-				old_lv->lv_current_pe[l].reads;
+			    old_lv->lv_current_pe[l].reads;
 
 			new_lv->lv_current_pe[l].writes +=
-				old_lv->lv_current_pe[l].writes;
+			    old_lv->lv_current_pe[l].writes;
 		}
 
 	} else {		/* striped logical volume */
-		uint i, j, source, dest, end, old_stripe_size, new_stripe_size;
+		uint i, j, source, dest, end, old_stripe_size,
+		    new_stripe_size;
 
-		old_stripe_size = old_lv->lv_allocated_le / old_lv->lv_stripes;
-		new_stripe_size = new_lv->lv_allocated_le / new_lv->lv_stripes;
+		old_stripe_size =
+		    old_lv->lv_allocated_le / old_lv->lv_stripes;
+		new_stripe_size =
+		    new_lv->lv_allocated_le / new_lv->lv_stripes;
 		end = min(old_stripe_size, new_stripe_size);
 
 		for (i = source = dest = 0; i < new_lv->lv_stripes; i++) {
 			for (j = 0; j < end; j++) {
 				new_lv->lv_current_pe[dest + j].reads +=
-				    old_lv->lv_current_pe[source + j].reads;
+				    old_lv->lv_current_pe[source +
+							  j].reads;
 				new_lv->lv_current_pe[dest + j].writes +=
-				    old_lv->lv_current_pe[source + j].writes;
+				    old_lv->lv_current_pe[source +
+							  j].writes;
 			}
 			source += old_stripe_size;
 			dest += new_stripe_size;
@@ -2438,7 +2526,7 @@
 	return 0;
 }
 
-static int lvm_do_lv_extend_reduce(int minor, char *lv_name, lv_t *new_lv)
+static int lvm_do_lv_extend_reduce(int minor, char *lv_name, lv_t * new_lv)
 {
 	int r;
 	ulong l, e, size;
@@ -2453,7 +2541,8 @@
 		return -EINVAL;
 
 	for (l = 0; l < vg_ptr->lv_max; l++)
-		if (vg_ptr->lv[l] && !strcmp(vg_ptr->lv[l]->lv_name, lv_name))
+		if (vg_ptr->lv[l]
+		    && !strcmp(vg_ptr->lv[l]->lv_name, lv_name))
 			break;
 
 	if (l == vg_ptr->lv_max)
@@ -2464,43 +2553,48 @@
 	if (old_lv->lv_access & LV_SNAPSHOT) {
 		/* only perform this operation on active snapshots */
 		if (old_lv->lv_status & LV_ACTIVE)
-			r = __extend_reduce_snapshot(vg_ptr, old_lv, new_lv);
+			r = __extend_reduce_snapshot(vg_ptr, old_lv,
+						     new_lv);
 		else
 			r = -EPERM;
 
 	} else
 		r = __extend_reduce(vg_ptr, old_lv, new_lv);
 
-	if(r)
+	if (r)
 		return r;
 
-	/* copy relevent fields */
+	/* copy relevant fields */
 	down_write(&old_lv->lv_lock);
 
-	if(new_lv->lv_access & LV_SNAPSHOT) {
+	if (new_lv->lv_access & LV_SNAPSHOT) {
 		size = (new_lv->lv_remap_end > old_lv->lv_remap_end) ?
-			old_lv->lv_remap_ptr : new_lv->lv_remap_end;
+		    old_lv->lv_remap_ptr : new_lv->lv_remap_end;
 		size *= sizeof(lv_block_exception_t);
 		memcpy(new_lv->lv_block_exception,
 		       old_lv->lv_block_exception, size);
+		vfree(old_lv->lv_block_exception);
+		vfree(old_lv->lv_snapshot_hash_table);
 
 		old_lv->lv_remap_end = new_lv->lv_remap_end;
 		old_lv->lv_block_exception = new_lv->lv_block_exception;
 		old_lv->lv_snapshot_hash_table =
-			new_lv->lv_snapshot_hash_table;
+		    new_lv->lv_snapshot_hash_table;
 		old_lv->lv_snapshot_hash_table_size =
-			new_lv->lv_snapshot_hash_table_size;
+		    new_lv->lv_snapshot_hash_table_size;
 		old_lv->lv_snapshot_hash_mask =
-			new_lv->lv_snapshot_hash_mask;
+		    new_lv->lv_snapshot_hash_mask;
 
-		for (e = 0; e < new_lv->lv_remap_ptr; e++)
+		for (e = 0; e < old_lv->lv_remap_ptr; e++)
 			lvm_hash_link(new_lv->lv_block_exception + e,
-				      new_lv->lv_block_exception[e].rdev_org,
-				      new_lv->lv_block_exception[e].rsector_org,
-				      new_lv);
+				      new_lv->lv_block_exception[e].
+				      rdev_org,
+				      new_lv->lv_block_exception[e].
+				      rsector_org, new_lv);
 
+		vg_ptr->pe_allocated -= old_lv->lv_allocated_le;
+		vg_ptr->pe_allocated += new_lv->lv_allocated_le;
 	} else {
-
 		vfree(old_lv->lv_current_pe);
 		vfree(old_lv->lv_snapshot_hash_table);
 
@@ -2509,24 +2603,26 @@
 		old_lv->lv_current_le = new_lv->lv_current_le;
 		old_lv->lv_current_pe = new_lv->lv_current_pe;
 		lvm_gendisk.part[MINOR(old_lv->lv_dev)].nr_sects =
-			old_lv->lv_size;
+		    old_lv->lv_size;
 		lvm_size[MINOR(old_lv->lv_dev)] = old_lv->lv_size >> 1;
 
 		if (old_lv->lv_access & LV_SNAPSHOT_ORG) {
 			lv_t *snap;
-			for(snap = old_lv->lv_snapshot_next; snap;
-			    snap = snap->lv_snapshot_next) {
+			for (snap = old_lv->lv_snapshot_next; snap;
+			     snap = snap->lv_snapshot_next) {
 				down_write(&snap->lv_lock);
-				snap->lv_current_pe = old_lv->lv_current_pe;
+				snap->lv_current_pe =
+				    old_lv->lv_current_pe;
 				snap->lv_allocated_le =
-					old_lv->lv_allocated_le;
-				snap->lv_current_le = old_lv->lv_current_le;
+				    old_lv->lv_allocated_le;
+				snap->lv_current_le =
+				    old_lv->lv_current_le;
 				snap->lv_size = old_lv->lv_size;
 
-				lvm_gendisk.part[MINOR(snap->lv_dev)].nr_sects
-					= old_lv->lv_size;
+				lvm_gendisk.part[MINOR(snap->lv_dev)].
+				    nr_sects = old_lv->lv_size;
 				lvm_size[MINOR(snap->lv_dev)] =
-					old_lv->lv_size >> 1;
+				    old_lv->lv_size >> 1;
 				__update_hardsectsize(snap);
 				up_write(&snap->lv_lock);
 			}
@@ -2537,13 +2633,13 @@
 	up_write(&old_lv->lv_lock);
 
 	return 0;
-} /* lvm_do_lv_extend_reduce() */
+}				/* lvm_do_lv_extend_reduce() */
 
 
 /*
  * character device support function logical volume status by name
  */
-static int lvm_do_lv_status_byname(vg_t *vg_ptr, void *arg)
+static int lvm_do_lv_status_byname(vg_t * vg_ptr, void *arg)
 {
 	uint l;
 	lv_status_byname_req_t lv_status_byname_req;
@@ -2551,137 +2647,166 @@
 	void *saved_ptr2;
 	lv_t *lv_ptr;
 
-	if (vg_ptr == NULL) return -ENXIO;
+	if (vg_ptr == NULL)
+		return -ENXIO;
 	if (copy_from_user(&lv_status_byname_req, arg,
 			   sizeof(lv_status_byname_req_t)) != 0)
 		return -EFAULT;
 
-	if (lv_status_byname_req.lv == NULL) return -EINVAL;
+	if (lv_status_byname_req.lv == NULL)
+		return -EINVAL;
 
 	for (l = 0; l < vg_ptr->lv_max; l++) {
 		if ((lv_ptr = vg_ptr->lv[l]) != NULL &&
 		    strcmp(lv_ptr->lv_name,
 			   lv_status_byname_req.lv_name) == 0) {
-		        /* Save usermode pointers */
-		        if (copy_from_user(&saved_ptr1, &lv_status_byname_req.lv->lv_current_pe, sizeof(void*)) != 0)
+			/* Save usermode pointers */
+			if (copy_from_user
+			    (&saved_ptr1,
+			     &lv_status_byname_req.lv->lv_current_pe,
+			     sizeof(void *)) != 0)
+				return -EFAULT;
+			if (copy_from_user
+			    (&saved_ptr2,
+			     &lv_status_byname_req.lv->lv_block_exception,
+			     sizeof(void *)) != 0)
 				return -EFAULT;
-			if (copy_from_user(&saved_ptr2, &lv_status_byname_req.lv->lv_block_exception, sizeof(void*)) != 0)
-			        return -EFAULT;
-		        if (copy_to_user(lv_status_byname_req.lv,
-					 lv_ptr,
-					 sizeof(lv_t)) != 0)
+			if (copy_to_user(lv_status_byname_req.lv,
+					 lv_ptr, sizeof(lv_t)) != 0)
 				return -EFAULT;
 			if (saved_ptr1 != NULL) {
 				if (copy_to_user(saved_ptr1,
 						 lv_ptr->lv_current_pe,
 						 lv_ptr->lv_allocated_le *
-				       		 sizeof(pe_t)) != 0)
+						 sizeof(pe_t)) != 0)
 					return -EFAULT;
 			}
 			/* Restore usermode pointers */
-			if (copy_to_user(&lv_status_byname_req.lv->lv_current_pe, &saved_ptr1, sizeof(void*)) != 0)
-			        return -EFAULT;
+			if (copy_to_user
+			    (&lv_status_byname_req.lv->lv_current_pe,
+			     &saved_ptr1, sizeof(void *)) != 0)
+				return -EFAULT;
 			return 0;
 		}
 	}
 	return -ENXIO;
-} /* lvm_do_lv_status_byname() */
+}				/* lvm_do_lv_status_byname() */
 
 
 /*
  * character device support function logical volume status by index
  */
-static int lvm_do_lv_status_byindex(vg_t *vg_ptr,void *arg)
+static int lvm_do_lv_status_byindex(vg_t * vg_ptr, void *arg)
 {
 	lv_status_byindex_req_t lv_status_byindex_req;
 	void *saved_ptr1;
 	void *saved_ptr2;
 	lv_t *lv_ptr;
 
-	if (vg_ptr == NULL) return -ENXIO;
+	if (vg_ptr == NULL)
+		return -ENXIO;
 	if (copy_from_user(&lv_status_byindex_req, arg,
 			   sizeof(lv_status_byindex_req)) != 0)
 		return -EFAULT;
 
 	if (lv_status_byindex_req.lv == NULL)
 		return -EINVAL;
-	if ( ( lv_ptr = vg_ptr->lv[lv_status_byindex_req.lv_index]) == NULL)
+	if ((lv_ptr = vg_ptr->lv[lv_status_byindex_req.lv_index]) == NULL)
 		return -ENXIO;
 
 	/* Save usermode pointers */
-	if (copy_from_user(&saved_ptr1, &lv_status_byindex_req.lv->lv_current_pe, sizeof(void*)) != 0)
-	        return -EFAULT;
-	if (copy_from_user(&saved_ptr2, &lv_status_byindex_req.lv->lv_block_exception, sizeof(void*)) != 0)
-	        return -EFAULT;
+	if (copy_from_user
+	    (&saved_ptr1, &lv_status_byindex_req.lv->lv_current_pe,
+	     sizeof(void *)) != 0)
+		return -EFAULT;
+	if (copy_from_user
+	    (&saved_ptr2, &lv_status_byindex_req.lv->lv_block_exception,
+	     sizeof(void *)) != 0)
+		return -EFAULT;
 
-	if (copy_to_user(lv_status_byindex_req.lv, lv_ptr, sizeof(lv_t)) != 0)
+	if (copy_to_user(lv_status_byindex_req.lv, lv_ptr, sizeof(lv_t)) !=
+	    0)
 		return -EFAULT;
 	if (saved_ptr1 != NULL) {
 		if (copy_to_user(saved_ptr1,
 				 lv_ptr->lv_current_pe,
 				 lv_ptr->lv_allocated_le *
-		       		 sizeof(pe_t)) != 0)
+				 sizeof(pe_t)) != 0)
 			return -EFAULT;
 	}
 
 	/* Restore usermode pointers */
-	if (copy_to_user(&lv_status_byindex_req.lv->lv_current_pe, &saved_ptr1, sizeof(void *)) != 0)
-	        return -EFAULT;
+	if (copy_to_user
+	    (&lv_status_byindex_req.lv->lv_current_pe, &saved_ptr1,
+	     sizeof(void *)) != 0)
+		return -EFAULT;
 
 	return 0;
-} /* lvm_do_lv_status_byindex() */
+}				/* lvm_do_lv_status_byindex() */
 
 
 /*
  * character device support function logical volume status by device number
  */
-static int lvm_do_lv_status_bydev(vg_t * vg_ptr, void * arg) {
+static int lvm_do_lv_status_bydev(vg_t * vg_ptr, void *arg)
+{
 	int l;
 	lv_status_bydev_req_t lv_status_bydev_req;
 	void *saved_ptr1;
 	void *saved_ptr2;
 	lv_t *lv_ptr;
 
-	if (vg_ptr == NULL) return -ENXIO;
+	if (vg_ptr == NULL)
+		return -ENXIO;
 	if (copy_from_user(&lv_status_bydev_req, arg,
 			   sizeof(lv_status_bydev_req)) != 0)
 		return -EFAULT;
 
-	for ( l = 0; l < vg_ptr->lv_max; l++) {
-		if ( vg_ptr->lv[l] == NULL) continue;
-		if ( vg_ptr->lv[l]->lv_dev == lv_status_bydev_req.dev) break;
+	for (l = 0; l < vg_ptr->lv_max; l++) {
+		if (vg_ptr->lv[l] == NULL)
+			continue;
+		if (vg_ptr->lv[l]->lv_dev == lv_status_bydev_req.dev)
+			break;
 	}
 
-	if ( l == vg_ptr->lv_max) return -ENXIO;
+	if (l == vg_ptr->lv_max)
+		return -ENXIO;
 	lv_ptr = vg_ptr->lv[l];
 
 	/* Save usermode pointers */
-	if (copy_from_user(&saved_ptr1, &lv_status_bydev_req.lv->lv_current_pe, sizeof(void*)) != 0)
-	        return -EFAULT;
-	if (copy_from_user(&saved_ptr2, &lv_status_bydev_req.lv->lv_block_exception, sizeof(void*)) != 0)
-	        return -EFAULT;
+	if (copy_from_user
+	    (&saved_ptr1, &lv_status_bydev_req.lv->lv_current_pe,
+	     sizeof(void *)) != 0)
+		return -EFAULT;
+	if (copy_from_user
+	    (&saved_ptr2, &lv_status_bydev_req.lv->lv_block_exception,
+	     sizeof(void *)) != 0)
+		return -EFAULT;
 
-	if (copy_to_user(lv_status_bydev_req.lv, lv_ptr, sizeof(lv_t)) != 0)
+	if (copy_to_user(lv_status_bydev_req.lv, lv_ptr, sizeof(lv_t)) !=
+	    0)
 		return -EFAULT;
 	if (saved_ptr1 != NULL) {
 		if (copy_to_user(saved_ptr1,
 				 lv_ptr->lv_current_pe,
 				 lv_ptr->lv_allocated_le *
-		       		 sizeof(pe_t)) != 0)
+				 sizeof(pe_t)) != 0)
 			return -EFAULT;
 	}
 	/* Restore usermode pointers */
-	if (copy_to_user(&lv_status_bydev_req.lv->lv_current_pe, &saved_ptr1, sizeof(void *)) != 0)
-	        return -EFAULT;
+	if (copy_to_user
+	    (&lv_status_bydev_req.lv->lv_current_pe, &saved_ptr1,
+	     sizeof(void *)) != 0)
+		return -EFAULT;
 
 	return 0;
-} /* lvm_do_lv_status_bydev() */
+}				/* lvm_do_lv_status_bydev() */
 
 
 /*
  * character device support function rename a logical volume
  */
-static int lvm_do_lv_rename(vg_t *vg_ptr, lv_req_t *lv_req, lv_t *lv)
+static int lvm_do_lv_rename(vg_t * vg_ptr, lv_req_t * lv_req, lv_t * lv)
 {
 	int l = 0;
 	int ret = 0;
@@ -2690,33 +2815,36 @@
 	if (!vg_ptr)
 		return -ENXIO;
 
-	for (l = 0; l < vg_ptr->lv_max; l++)
-	{
-		if ( (lv_ptr = vg_ptr->lv[l]) == NULL) continue;
-		if (lv_ptr->lv_dev == lv->lv_dev)
-		{
+	for (l = 0; l < vg_ptr->lv_max; l++) {
+		if ((lv_ptr = vg_ptr->lv[l]) == NULL)
+			continue;
+		if (lv_ptr->lv_dev == lv->lv_dev) {
 			lvm_fs_remove_lv(vg_ptr, lv_ptr);
-			strncpy(lv_ptr->lv_name, lv_req->lv_name, NAME_LEN);
-			lvm_fs_create_lv(vg_ptr, lv_ptr);
+			strncpy(lv_ptr->lv_name, lv_req->lv_name,
+				NAME_LEN);
+			lvm_gendisk.part[MINOR(lv_ptr->lv_dev)].de =
+				lvm_fs_create_lv(vg_ptr, lv_ptr);
 			break;
 		}
 	}
-	if (l == vg_ptr->lv_max) ret = -ENODEV;
+	if (l == vg_ptr->lv_max)
+		ret = -ENODEV;
 
 	return ret;
-} /* lvm_do_lv_rename */
+}				/* lvm_do_lv_rename */
 
 
 /*
  * character device support function physical volume change
  */
-static int lvm_do_pv_change(vg_t *vg_ptr, void *arg)
+static int lvm_do_pv_change(vg_t * vg_ptr, void *arg)
 {
 	uint p;
 	pv_t *pv_ptr;
 	struct block_device *bd;
 
-	if (vg_ptr == NULL) return -ENXIO;
+	if (vg_ptr == NULL)
+		return -ENXIO;
 	if (copy_from_user(&pv_change_req, arg,
 			   sizeof(pv_change_req)) != 0)
 		return -EFAULT;
@@ -2724,8 +2852,7 @@
 	for (p = 0; p < vg_ptr->pv_max; p++) {
 		pv_ptr = vg_ptr->pv[p];
 		if (pv_ptr != NULL &&
-		    strcmp(pv_ptr->pv_name,
-			       pv_change_req.pv_name) == 0) {
+		    strcmp(pv_ptr->pv_name, pv_change_req.pv_name) == 0) {
 
 			bd = pv_ptr->bd;
 			if (copy_from_user(pv_ptr,
@@ -2741,17 +2868,18 @@
 		}
 	}
 	return -ENXIO;
-} /* lvm_do_pv_change() */
+}				/* lvm_do_pv_change() */
 
 /*
  * character device support function get physical volume status
  */
-static int lvm_do_pv_status(vg_t *vg_ptr, void *arg)
+static int lvm_do_pv_status(vg_t * vg_ptr, void *arg)
 {
 	uint p;
 	pv_t *pv_ptr;
 
-	if (vg_ptr == NULL) return -ENXIO;
+	if (vg_ptr == NULL)
+		return -ENXIO;
 	if (copy_from_user(&pv_status_req, arg,
 			   sizeof(pv_status_req)) != 0)
 		return -EFAULT;
@@ -2759,17 +2887,15 @@
 	for (p = 0; p < vg_ptr->pv_max; p++) {
 		pv_ptr = vg_ptr->pv[p];
 		if (pv_ptr != NULL &&
-		    strcmp(pv_ptr->pv_name,
-			       pv_status_req.pv_name) == 0) {
+		    strcmp(pv_ptr->pv_name, pv_status_req.pv_name) == 0) {
 			if (copy_to_user(pv_status_req.pv,
-					 pv_ptr,
-				         sizeof(pv_t)) != 0)
+					 pv_ptr, sizeof(pv_t)) != 0)
 				return -EFAULT;
 			return 0;
 		}
 	}
 	return -ENXIO;
-} /* lvm_do_pv_status() */
+}				/* lvm_do_pv_status() */
 
 
 /*
@@ -2811,13 +2937,15 @@
 	hardsect_size[MAJOR_NR] = lvm_hardsectsizes;
 
 	return;
-} /* lvm_gen_init() */
+}				/* lvm_gen_init() */
 
 
 
 /* Must have down_write(_pe_lock) when we enqueue buffers */
-static void _queue_io(struct buffer_head *bh, int rw) {
-	if (bh->b_reqnext) BUG();
+static void _queue_io(struct buffer_head *bh, int rw)
+{
+	if (bh->b_reqnext)
+		BUG();
 	bh->b_reqnext = _pe_requests;
 	_pe_requests = bh;
 }
@@ -2855,14 +2983,15 @@
 /*
  * we must open the pv's before we use them
  */
-static int _open_pv(pv_t *pv) {
+static int _open_pv(pv_t * pv)
+{
 	int err;
 	struct block_device *bd;
 
 	if (!(bd = bdget(kdev_t_to_nr(pv->pv_dev))))
 		return -ENOMEM;
 
-	err = blkdev_get(bd, FMODE_READ|FMODE_WRITE, 0, BDEV_FILE);
+	err = blkdev_get(bd, FMODE_READ | FMODE_WRITE, 0, BDEV_FILE);
 	if (err)
 		return err;
 
@@ -2870,7 +2999,8 @@
 	return 0;
 }
 
-static void _close_pv(pv_t *pv) {
+static void _close_pv(pv_t * pv)
+{
 	if (pv) {
 		struct block_device *bdev = pv->bd;
 		pv->bd = NULL;
@@ -2882,7 +3012,7 @@
 
 static unsigned long _sectors_to_k(unsigned long sect)
 {
-	if(SECTOR_SIZE > 1024) {
+	if (SECTOR_SIZE > 1024) {
 		return sect * (SECTOR_SIZE / 1024);
 	}
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/media/video/meye.c linux-2.4.23-pre1/drivers/media/video/meye.c
--- linux-2.4.22/drivers/media/video/meye.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/media/video/meye.c	2003-08-27 14:40:39.000000000 +0000
@@ -35,7 +35,6 @@
 #include <asm/uaccess.h>
 #include <asm/io.h>
 #include <linux/delay.h>
-#include <linux/wrapper.h>
 #include <linux/interrupt.h>
 #include <linux/vmalloc.h>
 
@@ -139,7 +138,7 @@
 		memset(mem, 0, size); /* Clear the ram out, no junk to the user */
 	        adr = (unsigned long)mem;
 		while (size > 0) {
-			mem_map_reserve(vmalloc_to_page((void *)adr));
+			SetPageReserved(vmalloc_to_page((void *)adr));
 			adr += PAGE_SIZE;
 			size -= PAGE_SIZE;
 		}
@@ -153,7 +152,7 @@
 	if (mem) {
 	        adr = (unsigned long) mem;
 		while ((long) size > 0) {
-			mem_map_unreserve(vmalloc_to_page((void *)adr));
+			ClearPageReserved(vmalloc_to_page((void *)adr));
 			adr += PAGE_SIZE;
 			size -= PAGE_SIZE;
 		}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/message/fusion/linux_compat.h linux-2.4.23-pre1/drivers/message/fusion/linux_compat.h
--- linux-2.4.22/drivers/message/fusion/linux_compat.h	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/message/fusion/linux_compat.h	2003-08-27 14:40:03.000000000 +0000
@@ -93,7 +93,7 @@
  * Used prior to schedule_timeout calls..
  */
 #define __set_current_state(state_value)	do { current->state = state_value; } while (0)
-#ifdef __SMP__
+#ifdef CONFIG_SMP
 #define set_current_state(state_value)		do { __set_current_state(state_value); mb(); } while (0)
 #else
 #define set_current_state(state_value)		__set_current_state(state_value)
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/8139cp.c linux-2.4.23-pre1/drivers/net/8139cp.c
--- linux-2.4.22/drivers/net/8139cp.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/8139cp.c	2003-08-27 14:40:28.000000000 +0000
@@ -468,7 +468,7 @@
 
 #if CP_VLAN_TAG_USED
 	if (cp->vlgrp && (desc->opts2 & RxVlanTagged)) {
-		vlan_hwaccel_rx(skb, cp->vlgrp, desc->opts2 & 0xffff);
+		vlan_hwaccel_rx(skb, cp->vlgrp, be16_to_cpu(desc->opts2 & 0xffff));
 	} else
 #endif
 		netif_rx(skb);
@@ -774,7 +774,7 @@
 
 #if CP_VLAN_TAG_USED
 	if (cp->vlgrp && vlan_tx_tag_present(skb))
-		vlan_tag = TxVlanTag | vlan_tx_tag_get(skb);
+		vlan_tag = TxVlanTag | cpu_to_be16(vlan_tx_tag_get(skb));
 #endif
 
 	entry = cp->tx_head;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/8139too.c linux-2.4.23-pre1/drivers/net/8139too.c
--- linux-2.4.22/drivers/net/8139too.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/8139too.c	2003-08-27 14:39:11.000000000 +0000
@@ -565,6 +565,7 @@
 	void *mmio_addr;
 	int drv_flags;
 	struct pci_dev *pci_dev;
+	u32 pci_state[16];
 	struct net_device_stats stats;
 	unsigned char *rx_ring;
 	unsigned int cur_rx;	/* Index into the Rx buffer of next Rx pkt. */
@@ -2569,6 +2570,9 @@
 	tp->stats.rx_missed_errors += RTL_R32 (RxMissed);
 	RTL_W32 (RxMissed, 0);
 
+	pci_set_power_state (pdev, 3);
+	pci_save_state (pdev, tp->pci_state);
+
 	spin_unlock_irqrestore (&tp->lock, flags);
 	return 0;
 }
@@ -2577,11 +2581,15 @@
 static int rtl8139_resume (struct pci_dev *pdev)
 {
 	struct net_device *dev = pci_get_drvdata (pdev);
+	struct rtl8139_private *tp = dev->priv;
 
 	if (!netif_running (dev))
 		return 0;
-	netif_device_attach (dev);
+	pci_restore_state (pdev, tp->pci_state);
+	pci_set_power_state (pdev, 0);
+	rtl8139_init_ring (dev);
 	rtl8139_hw_start (dev);
+	netif_device_attach (dev);
 	return 0;
 }
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/bonding/bond_main.c linux-2.4.23-pre1/drivers/net/bonding/bond_main.c
--- linux-2.4.22/drivers/net/bonding/bond_main.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/bonding/bond_main.c	2003-08-27 14:40:18.000000000 +0000
@@ -3330,10 +3330,10 @@
 static struct net_device_stats *bond_get_stats(struct net_device *dev)
 {
 	bonding_t *bond = dev->priv;
-	struct net_device_stats *stats = bond->stats, *sstats;
+	struct net_device_stats *stats = &(bond->stats), *sstats;
 	slave_t *slave;
 
-	memset(bond->stats, 0, sizeof(struct net_device_stats));
+	memset(stats, 0, sizeof(struct net_device_stats));
 
 	read_lock_bh(&bond->lock);
 
@@ -3566,13 +3566,6 @@
 	/* initialize rwlocks */
 	rwlock_init(&bond->lock);
 	rwlock_init(&bond->ptrlock);
-	
-	bond->stats = kmalloc(sizeof(struct net_device_stats), GFP_KERNEL);
-	if (bond->stats == NULL) {
-		kfree(bond);
-		return -ENOMEM;
-	}
-	memset(bond->stats, 0, sizeof(struct net_device_stats));
 
 	bond->next = bond->prev = (slave_t *)bond;
 	bond->current_slave = NULL;
@@ -3603,7 +3596,6 @@
 		break;
 	default:
 		printk(KERN_ERR "Unknown bonding mode %d\n", bond_mode);
-		kfree(bond->stats);
 		kfree(bond);
 		return -EINVAL;
 	}
@@ -3654,7 +3646,6 @@
 	if (bond->bond_proc_dir == NULL) {
 		printk(KERN_ERR "%s: Cannot init /proc/net/%s/\n", 
 			dev->name, dev->name);
-		kfree(bond->stats);
 		kfree(bond);
 		return -ENOMEM;
 	}
@@ -3665,7 +3656,6 @@
 		printk(KERN_ERR "%s: Cannot init /proc/net/%s/info\n", 
 			dev->name, dev->name);
 		remove_proc_entry(dev->name, proc_net);
-		kfree(bond->stats);
 		kfree(bond);
 		return -ENOMEM;
 	}
@@ -4007,9 +3997,8 @@
 		remove_proc_entry(dev_bond->name, proc_net);
 #endif
 		unregister_netdev(dev_bond);
-		kfree(bond->stats);
 		kfree(dev_bond->priv);
-		
+
 		dev_bond->priv = NULL;
 		dev_bond++;
 	}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/bonding/bonding.h linux-2.4.23-pre1/drivers/net/bonding/bonding.h
--- linux-2.4.22/drivers/net/bonding/bonding.h	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/bonding/bonding.h	2003-08-27 14:40:20.000000000 +0000
@@ -99,7 +99,7 @@
 	rwlock_t ptrlock;
 	struct timer_list mii_timer;
 	struct timer_list arp_timer;
-	struct net_device_stats *stats;
+	struct net_device_stats stats;
 #ifdef CONFIG_PROC_FS
 	struct proc_dir_entry *bond_proc_dir;
 	struct proc_dir_entry *bond_proc_info_file;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/dummy.c linux-2.4.23-pre1/drivers/net/dummy.c
--- linux-2.4.22/drivers/net/dummy.c	2001-09-30 19:26:06.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/dummy.c	2003-08-27 14:40:25.000000000 +0000
@@ -28,8 +28,6 @@
 			Alan Cox, 30th May 1994
 */
 
-/* To have statistics (just packets sent) define this */
-
 #include <linux/config.h>
 #include <linux/module.h>
 #include <linux/kernel.h>
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/net_init.c linux-2.4.23-pre1/drivers/net/net_init.c
--- linux-2.4.22/drivers/net/net_init.c	2001-09-07 23:18:50.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/net_init.c	2003-08-27 14:39:19.000000000 +0000
@@ -71,7 +71,7 @@
 */
 
 
-static struct net_device *alloc_netdev(int sizeof_priv, const char *mask,
+struct net_device *alloc_netdev(int sizeof_priv, const char *mask,
 				       void (*setup)(struct net_device *))
 {
 	struct net_device *dev;
@@ -97,6 +97,7 @@
 
 	return dev;
 }
+EXPORT_SYMBOL(alloc_netdev);
 
 static struct net_device *init_alloc_dev(int sizeof_priv)
 {
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/sungem.c linux-2.4.23-pre1/drivers/net/sungem.c
--- linux-2.4.22/drivers/net/sungem.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/sungem.c	2003-08-27 14:41:49.000000000 +0000
@@ -2330,17 +2330,14 @@
 		gp->hw_running = 1;
 	}
 
-	spin_lock_irq(&gp->lock);
-
 	/* We can now request the interrupt as we know it's masked
 	 * on the controller
 	 */
 	if (request_irq(gp->pdev->irq, gem_interrupt,
 			SA_SHIRQ, dev->name, (void *)dev)) {
-		spin_unlock_irq(&gp->lock);
-
 		printk(KERN_ERR "%s: failed to request irq !\n", gp->dev->name);
 
+		spin_lock_irq(&gp->lock);
 #ifdef CONFIG_ALL_PPC
 		if (!hw_was_up && gp->pdev->vendor == PCI_VENDOR_ID_APPLE)
 			gem_apple_powerdown(gp);
@@ -2349,10 +2346,13 @@
 		gp->pm_timer.expires = jiffies + 10*HZ;
 		add_timer(&gp->pm_timer);
 		up(&gp->pm_sem);
+		spin_unlock_irq(&gp->lock);
 
 		return -EAGAIN;
 	}
 
+       	spin_lock_irq(&gp->lock);
+
 	/* Allocate & setup ring buffers */
 	gem_init_rings(gp);
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/tg3.c linux-2.4.23-pre1/drivers/net/tg3.c
--- linux-2.4.22/drivers/net/tg3.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/tg3.c	2003-08-27 14:40:22.000000000 +0000
@@ -1,7 +1,7 @@
 /*
  * tg3.c: Broadcom Tigon3 ethernet driver.
  *
- * Copyright (C) 2001, 2002 David S. Miller (davem@redhat.com)
+ * Copyright (C) 2001, 2002, 2003 David S. Miller (davem@redhat.com)
  * Copyright (C) 2001, 2002 Jeff Garzik (jgarzik@pobox.com)
  */
 
@@ -29,6 +29,12 @@
 #include <asm/byteorder.h>
 #include <asm/uaccess.h>
 
+#ifdef CONFIG_SPARC64
+#include <asm/idprom.h>
+#include <asm/oplib.h>
+#include <asm/pbm.h>
+#endif
+
 #if defined(CONFIG_VLAN_8021Q) || defined(CONFIG_VLAN_8021Q_MODULE)
 #define TG3_VLAN_TAG_USED 1
 #else
@@ -46,8 +52,8 @@
 
 #define DRV_MODULE_NAME		"tg3"
 #define PFX DRV_MODULE_NAME	": "
-#define DRV_MODULE_VERSION	"1.6"
-#define DRV_MODULE_RELDATE	"June 11, 2003"
+#define DRV_MODULE_VERSION	"1.9"
+#define DRV_MODULE_RELDATE	"August 3, 2003"
 
 #define TG3_DEF_MAC_MODE	0
 #define TG3_DEF_RX_MODE		0
@@ -143,6 +149,8 @@
 	  PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0UL },
 	{ PCI_VENDOR_ID_ALTIMA, PCI_DEVICE_ID_ALTIMA_AC1000,
 	  PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0UL },
+	{ PCI_VENDOR_ID_ALTIMA, PCI_DEVICE_ID_ALTIMA_AC1001,
+	  PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0UL },
 	{ PCI_VENDOR_ID_ALTIMA, PCI_DEVICE_ID_ALTIMA_AC9100,
 	  PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0UL },
 	{ 0, }
@@ -245,6 +253,7 @@
 {
 	if (!test_bit(__LINK_STATE_RX_SCHED, &dev->state)) BUG();
 	list_del(&dev->poll_list);
+	smp_mb__before_clear_bit();
 	clear_bit(__LINK_STATE_RX_SCHED, &dev->state);
 }
 
@@ -2180,7 +2189,6 @@
 	spin_unlock_irqrestore(&tp->lock, flags);
 }
 
-static void tg3_init_rings(struct tg3 *);
 static int tg3_init_hw(struct tg3 *);
 static int tg3_halt(struct tg3 *);
 
@@ -2198,7 +2206,6 @@
 	tp->tg3_flags2 &= ~TG3_FLG2_RESTART_TIMER;
 
 	tg3_halt(tp);
-	tg3_init_rings(tp);
 	tg3_init_hw(tp);
 
 	spin_unlock(&tp->tx_lock);
@@ -2674,7 +2681,6 @@
 
 	tg3_set_mtu(dev, tp, new_mtu);
 
-	tg3_init_rings(tp);
 	tg3_init_hw(tp);
 
 	spin_unlock(&tp->tx_lock);
@@ -2760,8 +2766,8 @@
  *
  * The chip has been shut down and the driver detached from
  * the networking, so no interrupts or new tx packets will
- * end up in the driver.  tp->{tx,}lock is not held and we are not
- * in an interrupt context and thus may sleep.
+ * end up in the driver.  tp->{tx,}lock are held and thus
+ * we may not sleep.
  */
 static void tg3_init_rings(struct tg3 *tp)
 {
@@ -3058,18 +3064,20 @@
 	u32 val;
 	u32 flags_save;
 
-	/* Force NVRAM to settle.
-	 * This deals with a chip bug which can result in EEPROM
-	 * corruption.
-	 */
-	if (tp->tg3_flags & TG3_FLAG_NVRAM) {
-		int i;
+	if (!(tp->tg3_flags2 & TG3_FLG2_SUN_5704)) {
+		/* Force NVRAM to settle.
+		 * This deals with a chip bug which can result in EEPROM
+		 * corruption.
+		 */
+		if (tp->tg3_flags & TG3_FLAG_NVRAM) {
+			int i;
 
-		tw32(NVRAM_SWARB, SWARB_REQ_SET1);
-		for (i = 0; i < 100000; i++) {
-			if (tr32(NVRAM_SWARB) & SWARB_GNT1)
-				break;
-			udelay(10);
+			tw32(NVRAM_SWARB, SWARB_REQ_SET1);
+			for (i = 0; i < 100000; i++) {
+				if (tr32(NVRAM_SWARB) & SWARB_GNT1)
+					break;
+				udelay(10);
+			}
 		}
 	}
 
@@ -3162,7 +3170,8 @@
 		udelay(10);
 	}
 
-	if (i >= 100000) {
+	if (i >= 100000 &&
+	    !(tp->tg3_flags2 & TG3_FLG2_SUN_5704)) {
 		printk(KERN_ERR PFX "tg3_halt timed out for %s, "
 		       "firmware will not restart magic=%08x\n",
 		       tp->dev->name, val);
@@ -3906,7 +3915,8 @@
 			break;
 		udelay(10);
 	}
-	if (i >= 100000) {
+	if (i >= 100000 &&
+	    !(tp->tg3_flags2 & TG3_FLG2_SUN_5704)) {
 		printk(KERN_ERR PFX "tg3_reset_hw timed out for %s, "
 		       "firmware will not restart magic=%08x\n",
 		       tp->dev->name, val);
@@ -3936,6 +3946,13 @@
 		tw32(TG3PCI_PCISTATE, val);
 	}
 
+	/* Descriptor ring init may make accesses to the
+	 * NIC SRAM area to setup the TX descriptors, so we
+	 * can only do this after the hardware has been
+	 * successfully reset.
+	 */
+	tg3_init_rings(tp);
+
 	/* Clear statistics/status block in chip, and status block in ram. */
 	for (i = NIC_SRAM_STATS_BLK;
 	     i < NIC_SRAM_STATUS_BLK + TG3_HW_STATUS_SIZE;
@@ -4495,8 +4512,6 @@
 	spin_lock_irq(&tp->lock);
 	spin_lock(&tp->tx_lock);
 
-	tg3_init_rings(tp);
-
 	err = tg3_init_hw(tp);
 	if (err) {
 		tg3_halt(tp);
@@ -5308,7 +5323,6 @@
 		tp->tx_pending = ering.tx_pending;
 
 		tg3_halt(tp);
-		tg3_init_rings(tp);
 		tg3_init_hw(tp);
 		netif_wake_queue(tp->dev);
 		spin_unlock(&tp->tx_lock);
@@ -5352,7 +5366,6 @@
 		else
 			tp->tg3_flags &= ~TG3_FLAG_PAUSE_TX;
 		tg3_halt(tp);
-		tg3_init_rings(tp);
 		tg3_init_hw(tp);
 		spin_unlock(&tp->tx_lock);
 		spin_unlock_irq(&tp->lock);
@@ -5522,6 +5535,9 @@
 {
 	int j;
 
+	if (tp->tg3_flags2 & TG3_FLG2_SUN_5704)
+		return;
+
 	tw32(GRC_EEPROM_ADDR,
 	     (EEPROM_ADDR_FSM_RESET |
 	      (EEPROM_DEFAULT_CLOCK_PERIOD <<
@@ -5594,6 +5610,11 @@
 {
 	int i, saw_done_clear;
 
+	if (tp->tg3_flags2 & TG3_FLG2_SUN_5704) {
+		printk(KERN_ERR PFX "Attempt to do nvram_read on Sun 5704\n");
+		return -EINVAL;
+	}
+
 	if (!(tp->tg3_flags & TG3_FLAG_NVRAM))
 		return tg3_nvram_read_using_eeprom(tp, offset, val);
 
@@ -5862,6 +5883,14 @@
 	unsigned char vpd_data[256];
 	int i;
 
+	if (tp->tg3_flags2 & TG3_FLG2_SUN_5704) {
+		/* Sun decided not to put the necessary bits in the
+		 * NVRAM of their onboard tg3 parts :(
+		 */
+		strcpy(tp->board_part_number, "Sun 5704");
+		return;
+	}
+
 	for (i = 0; i < 256; i += 4) {
 		u32 tmp;
 
@@ -5918,6 +5947,34 @@
 	strcpy(tp->board_part_number, "none");
 }
 
+#ifdef CONFIG_SPARC64
+static int __devinit tg3_is_sun_5704(struct tg3 *tp)
+{
+	struct pci_dev *pdev = tp->pdev;
+	struct pcidev_cookie *pcp = pdev->sysdata;
+
+	if (pcp != NULL) {
+		int node = pcp->prom_node;
+		u32 venid, devid;
+		int err;
+
+		err = prom_getproperty(node, "subsystem-vendor-id",
+				       (char *) &venid, sizeof(venid));
+		if (err == 0 || err == -1)
+			return 0;
+		err = prom_getproperty(node, "subsystem-id",
+				       (char *) &devid, sizeof(devid));
+		if (err == 0 || err == -1)
+			return 0;
+
+		if (venid == PCI_VENDOR_ID_SUN &&
+		    devid == PCI_DEVICE_ID_TIGON3_5704)
+			return 1;
+	}
+	return 0;
+}
+#endif
+
 static int __devinit tg3_get_invariants(struct tg3 *tp)
 {
 	u32 misc_ctrl_reg;
@@ -5926,6 +5983,11 @@
 	u16 pci_cmd;
 	int err;
 
+#ifdef CONFIG_SPARC64
+	if (tg3_is_sun_5704(tp))
+		tp->tg3_flags2 |= TG3_FLG2_SUN_5704;
+#endif
+
 	/* If we have an AMD 762 or Intel ICH/ICH0 chipset, write
 	 * reordering to the mailbox registers done by the host
 	 * controller can cause major troubles.  We read back from
@@ -6234,11 +6296,44 @@
 	return err;
 }
 
+#ifdef CONFIG_SPARC64
+static int __devinit tg3_get_macaddr_sparc(struct tg3 *tp)
+{
+	struct net_device *dev = tp->dev;
+	struct pci_dev *pdev = tp->pdev;
+	struct pcidev_cookie *pcp = pdev->sysdata;
+
+	if (pcp != NULL) {
+		int node = pcp->prom_node;
+
+		if (prom_getproplen(node, "local-mac-address") == 6) {
+			prom_getproperty(node, "local-mac-address",
+					 dev->dev_addr, 6);
+			return 0;
+		}
+	}
+	return -ENODEV;
+}
+
+static int __devinit tg3_get_default_macaddr_sparc(struct tg3 *tp)
+{
+	struct net_device *dev = tp->dev;
+
+	memcpy(dev->dev_addr, idprom->id_ethaddr, 6);
+	return 0;
+}
+#endif
+
 static int __devinit tg3_get_device_address(struct tg3 *tp)
 {
 	struct net_device *dev = tp->dev;
 	u32 hi, lo, mac_offset;
 
+#ifdef CONFIG_SPARC64
+	if (!tg3_get_macaddr_sparc(tp))
+		return 0;
+#endif
+
 	if (PCI_FUNC(tp->pdev->devfn) == 0)
 		mac_offset = 0x7c;
 	else
@@ -6257,7 +6352,8 @@
 		dev->dev_addr[5] = (lo >>  0) & 0xff;
 	}
 	/* Next, try NVRAM. */
-	else if (!tg3_nvram_read(tp, mac_offset + 0, &hi) &&
+	else if (!(tp->tg3_flags & TG3_FLG2_SUN_5704) &&
+		 !tg3_nvram_read(tp, mac_offset + 0, &hi) &&
 		 !tg3_nvram_read(tp, mac_offset + 4, &lo)) {
 		dev->dev_addr[0] = ((hi >> 16) & 0xff);
 		dev->dev_addr[1] = ((hi >> 24) & 0xff);
@@ -6279,9 +6375,13 @@
 		dev->dev_addr[0] = (hi >> 8) & 0xff;
 	}
 
-	if (!is_valid_ether_addr(&dev->dev_addr[0]))
+	if (!is_valid_ether_addr(&dev->dev_addr[0])) {
+#ifdef CONFIG_SPARC64
+		if (!tg3_get_default_macaddr_sparc(tp))
+			return 0;
+#endif
 		return -EINVAL;
-
+	}
 	return 0;
 }
 
@@ -6866,7 +6966,6 @@
 		spin_lock_irq(&tp->lock);
 		spin_lock(&tp->tx_lock);
 
-		tg3_init_rings(tp);
 		tg3_init_hw(tp);
 
 		spin_unlock(&tp->tx_lock);
@@ -6897,7 +6996,6 @@
 	spin_lock_irq(&tp->lock);
 	spin_lock(&tp->tx_lock);
 
-	tg3_init_rings(tp);
 	tg3_init_hw(tp);
 	tg3_enable_ints(tp);
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/tg3.h linux-2.4.23-pre1/drivers/net/tg3.h
--- linux-2.4.22/drivers/net/tg3.h	2003-06-13 14:51:35.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/tg3.h	2003-08-27 14:40:41.000000000 +0000
@@ -1823,6 +1823,7 @@
 #define TG3_FLAG_INIT_COMPLETE		0x80000000
 	u32				tg3_flags2;
 #define TG3_FLG2_RESTART_TIMER		0x00000001
+#define TG3_FLG2_SUN_5704		0x00000002
 
 	u32				split_mode_max_reqs;
 #define SPLIT_MODE_5704_MAX_REQ		3
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/tulip/tulip_core.c linux-2.4.23-pre1/drivers/net/tulip/tulip_core.c
--- linux-2.4.22/drivers/net/tulip/tulip_core.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/tulip/tulip_core.c	2003-08-27 14:40:40.000000000 +0000
@@ -232,6 +232,7 @@
 	{ 0x17B3, 0xAB08, PCI_ANY_ID, PCI_ANY_ID, 0, 0, COMET },
 	{ 0x14f1, 0x1803, PCI_ANY_ID, PCI_ANY_ID, 0, 0, CONEXANT },
 	{ 0x10b9, 0x5261, PCI_ANY_ID, PCI_ANY_ID, 0, 0, DM910X },	/* ALi 1563 integrated ethernet */
+	{ 0x10b7, 0x9300, PCI_ANY_ID, PCI_ANY_ID, 0, 0, COMET },	/* 3Com 3CSOHO100B-TX */
 	{ } /* terminate list */
 };
 MODULE_DEVICE_TABLE(pci, tulip_pci_tbl);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/wan/sdla_chdlc.c linux-2.4.23-pre1/drivers/net/wan/sdla_chdlc.c
--- linux-2.4.22/drivers/net/wan/sdla_chdlc.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/wan/sdla_chdlc.c	2003-08-27 14:40:31.000000000 +0000
@@ -3819,7 +3819,7 @@
 
 void s508_lock (sdla_t *card, unsigned long *smp_flags)
 {
-#if defined(__SMP__) || defined(LINUX_2_4)
+#if defined(CONFIG_SMP) || defined(LINUX_2_4)
 	spin_lock_irqsave(&card->wandev.lock, *smp_flags);
         if (card->next){
         	spin_lock(&card->next->wandev.lock);
@@ -3831,7 +3831,7 @@
 
 void s508_unlock (sdla_t *card, unsigned long *smp_flags)
 {
-#if defined(__SMP__) || defined(LINUX_2_4)
+#if defined(CONFIG_SMP) || defined(LINUX_2_4)
         if (card->next){
         	spin_unlock(&card->next->wandev.lock);
         }
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/wan/sdla_fr.c linux-2.4.23-pre1/drivers/net/wan/sdla_fr.c
--- linux-2.4.22/drivers/net/wan/sdla_fr.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/wan/sdla_fr.c	2003-08-27 14:41:53.000000000 +0000
@@ -4707,13 +4707,13 @@
 {
 	if (card->hw.type != SDLA_S514){
 
-#if defined(__SMP__) || defined(LINUX_2_4)
+#if defined(CONFIG_SMP) || defined(LINUX_2_4)
 		spin_lock_irqsave(&card->wandev.lock, *smp_flags);
 #else
           	disable_irq(card->hw.irq);
 #endif
 	}else{
-#if defined(__SMP__) || defined(LINUX_2_4)
+#if defined(CONFIG_SMP) || defined(LINUX_2_4)
 		spin_lock(&card->u.f.if_send_lock);
 #endif
 	}
@@ -4725,13 +4725,13 @@
 {
 	if (card->hw.type != SDLA_S514){
 
-#if defined(__SMP__) || defined(LINUX_2_4)
+#if defined(CONFIG_SMP) || defined(LINUX_2_4)
 		spin_unlock_irqrestore (&card->wandev.lock, *smp_flags);
 #else
           	enable_irq(card->hw.irq);
 #endif
 	}else{
-#if defined(__SMP__) || defined(LINUX_2_4)
+#if defined(CONFIG_SMP) || defined(LINUX_2_4)
 		spin_unlock(&card->u.f.if_send_lock);
 #endif
 	}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/wan/sdla_ppp.c linux-2.4.23-pre1/drivers/net/wan/sdla_ppp.c
--- linux-2.4.22/drivers/net/wan/sdla_ppp.c	2002-08-03 00:39:44.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/wan/sdla_ppp.c	2003-08-27 14:39:42.000000000 +0000
@@ -3331,7 +3331,7 @@
 
 void s508_lock (sdla_t *card, unsigned long *smp_flags)
 {
-#if defined(__SMP__) || defined(LINUX_2_4)
+#if defined(CONFIG_SMP) || defined(LINUX_2_4)
 	spin_lock_irqsave(&card->wandev.lock, *smp_flags);
 #else
 	disable_irq(card->hw.irq);
@@ -3340,7 +3340,7 @@
 
 void s508_unlock (sdla_t *card, unsigned long *smp_flags)
 {
-#if defined(__SMP__) || defined(LINUX_2_4)
+#if defined(CONFIG_SMP) || defined(LINUX_2_4)
         spin_unlock_irqrestore(&card->wandev.lock, *smp_flags);
 #else
 	enable_irq(card->hw.irq);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/wan/sdlamain.c linux-2.4.23-pre1/drivers/net/wan/sdlamain.c
--- linux-2.4.22/drivers/net/wan/sdlamain.c	2002-11-28 23:53:14.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/wan/sdlamain.c	2003-08-27 14:41:12.000000000 +0000
@@ -511,7 +511,7 @@
 	if (!card->configured){
 
 		/* Initialize the Spin lock */
-#if defined(__SMP__) || defined(LINUX_2_4) 
+#if defined(CONFIG_SMP) || defined(LINUX_2_4) 
 		printk(KERN_INFO "%s: Initializing for SMP\n",wandev->name);
 #endif
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/wan/wanpipe_multppp.c linux-2.4.23-pre1/drivers/net/wan/wanpipe_multppp.c
--- linux-2.4.22/drivers/net/wan/wanpipe_multppp.c	2001-09-13 23:04:43.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/wan/wanpipe_multppp.c	2003-08-27 14:42:00.000000000 +0000
@@ -2358,7 +2358,7 @@
 
 void s508_lock (sdla_t *card, unsigned long *smp_flags)
 {
-#if defined(__SMP__) || defined(LINUX_2_4)
+#if defined(CONFIG_SMP) || defined(LINUX_2_4)
 	spin_lock_irqsave(&card->wandev.lock, *smp_flags);
         if (card->next){
 		/* It is ok to use spin_lock here, since we
@@ -2372,7 +2372,7 @@
 
 void s508_unlock (sdla_t *card, unsigned long *smp_flags)
 {
-#if defined(__SMP__) || defined(LINUX_2_4)
+#if defined(CONFIG_SMP) || defined(LINUX_2_4)
 	if (card->next){
 		spin_unlock(&card->next->wandev.lock);
 	}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/net/wireless/airo.c linux-2.4.23-pre1/drivers/net/wireless/airo.c
--- linux-2.4.22/drivers/net/wireless/airo.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/net/wireless/airo.c	2003-08-27 14:39:26.000000000 +0000
@@ -32,7 +32,6 @@
 #include <linux/timer.h>
 #include <linux/interrupt.h>
 #include <linux/in.h>
-#include <linux/tqueue.h>
 #include <asm/io.h>
 #include <asm/system.h>
 #include <asm/bitops.h>
@@ -305,6 +304,7 @@
 #define CMD_DEALLOCATETX 0x000c
 #define NOP		0x0010
 #define CMD_WORKAROUND	0x0011
+#define CMD_ALLOCATEAUX 0x0020
 #define CMD_ACCESS	0x0021
 #define CMD_PCIBAP	0x0022
 #define CMD_PCIAUX	0x0023
@@ -409,6 +409,7 @@
 #define EV_ALLOC 0x08
 #define EV_LINK 0x80
 #define EV_AWAKE 0x100
+#define EV_TXCPY 0x400
 #define EV_UNKNOWN 0x800
 #define EV_MIC 0x1000 /* Message Integrity Check Interrupt */
 #define STATUS_INTS ( EV_AWAKE | EV_LINK | EV_TXEXC | EV_TX | EV_RX | EV_MIC )
@@ -639,7 +640,7 @@
 	u16 SSIDlen;
 	char SSID[32];
 	char apName[16];
-	char bssid[4][ETH_ALEN];
+	u8 bssid[4][ETH_ALEN];
 	u16 beaconPeriod;
 	u16 dimPeriod;
 	u16 atimDuration;
@@ -963,8 +964,6 @@
 static void enable_interrupts(struct airo_info*);
 static void disable_interrupts(struct airo_info*);
 static u16 issuecommand(struct airo_info*, Cmd *pCmd, Resp *pRsp);
-static u16 sendcommand(struct airo_info *ai, Cmd *pCmd);
-static void completecommand(struct airo_info *ai, Resp *pRsp);
 static int bap_setup(struct airo_info*, u16 rid, u16 offset, int whichbap);
 static int aux_bap_read(struct airo_info*, u16 *pu16Dst, int bytelen,
 			int whichbap);
@@ -984,6 +983,8 @@
 
 static void airo_interrupt( int irq, void* dev_id, struct pt_regs
 			    *regs);
+static int airo_thread(void *data);
+static void timer_func( struct net_device *dev );
 static int airo_ioctl(struct net_device *dev, struct ifreq *rq, int cmd);
 #ifdef WIRELESS_EXT
 struct iw_statistics *airo_get_wireless_stats (struct net_device *dev);
@@ -994,8 +995,8 @@
 int flashcard(struct net_device *dev, aironet_ioctl *comp);
 #endif /* CISCO_EXT */
 #ifdef MICSUPPORT
-static void micinit(struct airo_info *ai, MICRid *micr);
-static void micsetup(struct airo_info *ai);
+static void micinit(struct airo_info *ai);
+static int micsetup(struct airo_info *ai);
 static int encapsulate(struct airo_info *ai, etherHead *pPacket, MICBuffer *buffer, int len);
 static int decapsulate(struct airo_info *ai, MICBuffer *mic, etherHead *pPacket, u16 payLen);
 #endif
@@ -1013,50 +1014,63 @@
 	int need_commit;	// Need to set config
 	char keyindex; // Used with auto wep
 	char defindex; // Used with auto wep
-	struct timer_list timer;
 	struct proc_dir_entry *proc_entry;
 	struct airo_info *next;
         spinlock_t aux_lock;
         unsigned long flags;
-#define FLAG_PROMISC   IFF_PROMISC	/* 0x100 - include/linux/if.h */
-#define FLAG_RADIO_OFF 0x02		/* User disabling of MAC */
-#define FLAG_RADIO_DOWN 0x08		/* ifup/ifdown disabling of MAC */
-#define FLAG_FLASHING  0x10
-#define FLAG_ADHOC        0x01 /* Needed by MIC */
-#define FLAG_MIC_CAPABLE  0x20
-#define FLAG_UPDATE_MULTI 0x40
-#define FLAG_UPDATE_UNI   0x80
-#define FLAG_802_11    0x200
-#define FLAG_PENDING_XMIT   0x400
-#define FLAG_PENDING_XMIT11 0x800
+#define FLAG_PROMISC	8	/* IFF_PROMISC 0x100 - include/linux/if.h */
+#define FLAG_RADIO_OFF	0	/* User disabling of MAC */
+#define FLAG_RADIO_DOWN	1	/* ifup/ifdown disabling of MAC */
+#define FLAG_RADIO_MASK 0x03
+#define FLAG_FLASHING	2
+#define FLAG_ADHOC	3	/* Needed by MIC */
+#define FLAG_MIC_CAPABLE 4
+#define FLAG_UPDATE_MULTI 5
+#define FLAG_UPDATE_UNI 6
+#define FLAG_802_11	7
+#define FLAG_PENDING_XMIT 9
+#define FLAG_PENDING_XMIT11 10
+#define FLAG_PCI	11
+#define JOB_MASK	0xff0000
+#define JOB_DIE		16
+#define JOB_XMIT	17
+#define JOB_XMIT11	18
+#define JOB_STATS	19
+#define JOB_PROMISC	20
+#define JOB_MIC		21
+#define JOB_EVENT	22
+#define JOB_AUTOWEP	23
 	int (*bap_read)(struct airo_info*, u16 *pu16Dst, int bytelen,
 			int whichbap);
 	unsigned short *flash;
 	tdsRssiEntry *rssi;
-	struct semaphore sem;
 	struct task_struct *task;
-	struct tq_struct stats_task;
-	struct tq_struct promisc_task;
+	struct semaphore sem;
+	pid_t thr_pid;
+	wait_queue_head_t thr_wait;
+	struct completion thr_exited;
+	unsigned long expires;
 	struct {
 		struct sk_buff *skb;
 		int fid;
-		struct tq_struct task;
 	} xmit, xmit11;
 	struct net_device *wifidev;
 #ifdef WIRELESS_EXT
 	struct iw_statistics	wstats;		// wireless stats
 	unsigned long		scan_timestamp;	/* Time started to scan */
-	struct tq_struct	event_task;
+#if WIRELESS_EXT > 15
+	struct iw_spy_data	spy_data;
+#else /* WIRELESS_EXT > 15 */
 #ifdef WIRELESS_SPY
 	int			spy_number;
 	u_char			spy_address[IW_MAX_SPY][ETH_ALEN];
 	struct iw_quality	spy_stat[IW_MAX_SPY];
 #endif /* WIRELESS_SPY */
+#endif /* WIRELESS_EXT > 15 */
 #endif /* WIRELESS_EXT */
 	/* MIC stuff */
 	mic_module		mod[2];
 	mic_statistics		micstats;
-	struct tq_struct 	mic_task;
 };
 
 static inline int bap_read(struct airo_info *ai, u16 *pu16Dst, int bytelen,
@@ -1203,12 +1217,12 @@
 
 	ai->need_commit = 0;
 	checkThrottle(ai);
+	cfgr = ai->config;
+
 	if ((cfgr.opmode & 0xFF) == MODE_STA_IBSS)
-		ai->flags |= FLAG_ADHOC;
+		set_bit(FLAG_ADHOC, &ai->flags);
 	else
-		ai->flags &= ~FLAG_ADHOC;
-
-	cfgr = ai->config;
+		clear_bit(FLAG_ADHOC, &ai->flags);
 
 	for(s = &cfgr.len; s <= &cfgr.rtsThres; s++) *s = cpu_to_le16(*s);
 
@@ -1272,7 +1286,7 @@
 	struct airo_info *info = dev->priv;
 	Resp rsp;
 
-	if (info->flags & FLAG_FLASHING)
+	if (test_bit(FLAG_FLASHING, &info->flags))
 		return -EIO;
 
 	/* Make sure the card is configured.
@@ -1286,7 +1300,7 @@
 
 	if (info->wifidev != dev) {
 		/* Power on the MAC controller (which may have been disabled) */
-		info->flags &= ~FLAG_RADIO_DOWN;
+		clear_bit(FLAG_RADIO_DOWN, &info->flags);
 		enable_interrupts(info);
 	}
 	enable_MAC(info, &rsp, 1);
@@ -1344,7 +1358,7 @@
 	}
 }
 
-static void airo_do_xmit(struct net_device *dev) {
+static void airo_end_xmit(struct net_device *dev) {
 	u16 status;
 	int i;
 	struct airo_info *priv = dev->priv;
@@ -1352,17 +1366,10 @@
 	int fid = priv->xmit.fid;
 	u32 *fids = priv->fids;
 
-	if (down_trylock(&priv->sem) != 0) {
-		priv->flags |= FLAG_PENDING_XMIT;
-		netif_stop_queue(dev);
-		priv->xmit.task.routine = (void (*)(void *))airo_do_xmit;
-		priv->xmit.task.data = (void *)dev;
-		schedule_task(&priv->xmit.task);
-		return;
-	}
+	clear_bit(JOB_XMIT, &priv->flags);
+	clear_bit(FLAG_PENDING_XMIT, &priv->flags);
 	status = transmit_802_3_packet (priv, fids[fid], skb->data);
 	up(&priv->sem);
-	priv->flags &= ~FLAG_PENDING_XMIT;
 
 	i = 0;
 	if ( status == SUCCESS ) {
@@ -1406,11 +1413,17 @@
 	fids[i] |= (len << 16);
 	priv->xmit.skb = skb;
 	priv->xmit.fid = i;
-	airo_do_xmit(dev);
+	if (down_trylock(&priv->sem) != 0) {
+		set_bit(FLAG_PENDING_XMIT, &priv->flags);
+		netif_stop_queue(dev);
+		set_bit(JOB_XMIT, &priv->flags);
+		wake_up_interruptible(&priv->thr_wait);
+	} else
+		airo_end_xmit(dev);
 	return 0;
 }
 
-static void airo_do_xmit11(struct net_device *dev) {
+static void airo_end_xmit11(struct net_device *dev) {
 	u16 status;
 	int i;
 	struct airo_info *priv = dev->priv;
@@ -1418,17 +1431,10 @@
 	int fid = priv->xmit11.fid;
 	u32 *fids = priv->fids;
 
-	if (down_trylock(&priv->sem) != 0) {
-		priv->flags |= FLAG_PENDING_XMIT11;
-		netif_stop_queue(dev);
-		priv->xmit11.task.routine = (void (*)(void *))airo_do_xmit11;
-		priv->xmit11.task.data = (void *)dev;
-		schedule_task(&priv->xmit11.task);
-		return;
-	}
+	clear_bit(JOB_XMIT11, &priv->flags);
+	clear_bit(FLAG_PENDING_XMIT11, &priv->flags);
 	status = transmit_802_11_packet (priv, fids[fid], skb->data);
 	up(&priv->sem);
-	priv->flags &= ~FLAG_PENDING_XMIT11;
 
 	i = MAX_FIDS / 2;
 	if ( status == SUCCESS ) {
@@ -1472,7 +1478,13 @@
 	fids[i] |= (len << 16);
 	priv->xmit11.skb = skb;
 	priv->xmit11.fid = i;
-	airo_do_xmit11(dev);
+	if (down_trylock(&priv->sem) != 0) {
+		set_bit(FLAG_PENDING_XMIT11, &priv->flags);
+		netif_stop_queue(dev);
+		set_bit(JOB_XMIT11, &priv->flags);
+		wake_up_interruptible(&priv->thr_wait);
+	} else
+		airo_end_xmit11(dev);
 	return 0;
 }
 
@@ -1480,29 +1492,24 @@
 	StatsRid stats_rid;
 	u32 *vals = stats_rid.vals;
 
-	if (down_trylock(&ai->sem) == 0) {
-		readStatsRid(ai, &stats_rid, RID_STATS, 0);
-		up(&ai->sem);
+	clear_bit(JOB_STATS, &ai->flags);
+	readStatsRid(ai, &stats_rid, RID_STATS, 0);
+	up(&ai->sem);
 
-		ai->stats.rx_packets = vals[43] + vals[44] + vals[45];
-		ai->stats.tx_packets = vals[39] + vals[40] + vals[41];
-		ai->stats.rx_bytes = vals[92];
-		ai->stats.tx_bytes = vals[91];
-		ai->stats.rx_errors = vals[0] + vals[2] + vals[3] + vals[4];
-		ai->stats.tx_errors = vals[42] + ai->stats.tx_fifo_errors;
-		ai->stats.multicast = vals[43];
-		ai->stats.collisions = vals[89];
-
-		/* detailed rx_errors: */
-		ai->stats.rx_length_errors = vals[3];
-		ai->stats.rx_crc_errors = vals[4];
-		ai->stats.rx_frame_errors = vals[2];
-		ai->stats.rx_fifo_errors = vals[0];
-	} else {
-		ai->stats_task.routine = (void (*)(void *))airo_read_stats;
-		ai->stats_task.data = (void *)ai;
-		schedule_task(&ai->stats_task);
-	}
+	ai->stats.rx_packets = vals[43] + vals[44] + vals[45];
+	ai->stats.tx_packets = vals[39] + vals[40] + vals[41];
+	ai->stats.rx_bytes = vals[92];
+	ai->stats.tx_bytes = vals[91];
+	ai->stats.rx_errors = vals[0] + vals[2] + vals[3] + vals[4];
+	ai->stats.tx_errors = vals[42] + ai->stats.tx_fifo_errors;
+	ai->stats.multicast = vals[43];
+	ai->stats.collisions = vals[89];
+
+	/* detailed rx_errors: */
+	ai->stats.rx_length_errors = vals[3];
+	ai->stats.rx_crc_errors = vals[4];
+	ai->stats.rx_frame_errors = vals[2];
+	ai->stats.rx_fifo_errors = vals[0];
 }
 
 struct net_device_stats *airo_get_stats(struct net_device *dev)
@@ -1510,46 +1517,37 @@
 	struct airo_info *local =  dev->priv;
 
 	/* Get stats out of the card if available */
-	airo_read_stats(local);
+	if (down_trylock(&local->sem) != 0) {
+		set_bit(JOB_STATS, &local->flags);
+		wake_up_interruptible(&local->thr_wait);
+	} else
+		airo_read_stats(local);
 
 	return &local->stats;
 }
 
-static void airo_end_promisc(struct airo_info *ai) {
-	Resp rsp;
-
-	if ((IN4500(ai, EVSTAT) & EV_CMD) != 0) {
-		completecommand(ai, &rsp);
-		up(&ai->sem);
-	} else {
-		ai->promisc_task.routine = (void (*)(void *))airo_end_promisc;
-		ai->promisc_task.data = (void *)ai;
-		schedule_task(&ai->promisc_task);
-	}
-}
-
 static void airo_set_promisc(struct airo_info *ai) {
 	Cmd cmd;
+	Resp rsp;
 
-	if (down_trylock(&ai->sem) == 0) {
-		memset(&cmd, 0, sizeof(cmd));
-		cmd.cmd=CMD_SETMODE;
-		cmd.parm0=(ai->flags&IFF_PROMISC) ? PROMISC : NOPROMISC;
-		sendcommand(ai, &cmd);
-		airo_end_promisc(ai);
-	} else {
-		ai->promisc_task.routine = (void (*)(void *))airo_set_promisc;
-		ai->promisc_task.data = (void *)ai;
-		schedule_task(&ai->promisc_task);
-	}
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.cmd=CMD_SETMODE;
+	clear_bit(JOB_PROMISC, &ai->flags);
+	cmd.parm0=(ai->flags&IFF_PROMISC) ? PROMISC : NOPROMISC;
+	issuecommand(ai, &cmd, &rsp);
+	up(&ai->sem);
 }
 
 static void airo_set_multicast_list(struct net_device *dev) {
 	struct airo_info *ai = dev->priv;
 
 	if ((dev->flags ^ ai->flags) & IFF_PROMISC) {
-		ai->flags ^= IFF_PROMISC;
-		airo_set_promisc(ai);
+		change_bit(FLAG_PROMISC, &ai->flags);
+		if (down_trylock(&ai->sem) != 0) {
+			set_bit(JOB_PROMISC, &ai->flags);
+			wake_up_interruptible(&ai->thr_wait);
+		} else
+			airo_set_promisc(ai);
 	}
 
 	if ((dev->flags&IFF_ALLMULTI)||dev->mc_count>0) {
@@ -1595,7 +1593,7 @@
 		 * That's the method that is most friendly towards the network
 		 * stack (i.e. the network stack won't try to broadcast
 		 * anything on the interface and routes are gone. Jean II */
-		ai->flags |= FLAG_RADIO_DOWN;
+		set_bit(FLAG_RADIO_DOWN, &ai->flags);
 		disable_MAC(ai, 1);
 #endif
 		disable_interrupts( ai );
@@ -1608,13 +1606,8 @@
 void stop_airo_card( struct net_device *dev, int freeres )
 {
 	struct airo_info *ai = dev->priv;
-	flush_scheduled_tasks();
 	disable_interrupts(ai);
 	free_irq( dev->irq, dev );
-	if (ai->flash)
-		kfree(ai->flash);
-	if (ai->rssi)
-		kfree(ai->rssi);
 	takedown_proc_entry( dev, ai );
 	if (ai->registered) {
 		unregister_netdev( dev );
@@ -1625,7 +1618,13 @@
 		}
 		ai->registered = 0;
 	}
-	if (auto_wep) del_timer_sync(&ai->timer);
+	set_bit(JOB_DIE, &ai->flags);
+	kill_proc(ai->thr_pid, SIGTERM, 1);
+	wait_for_completion(&ai->thr_exited);
+	if (ai->flash)
+		kfree(ai->flash);
+	if (ai->rssi)
+		kfree(ai->rssi);
 	if (freeres) {
 		/* PCMCIA frees this stuff, so only for PCI and ISA */
 	        release_region( dev->base_addr, 64 );
@@ -1726,9 +1725,14 @@
 	sema_init(&ai->sem, 1);
 	ai->need_commit = 0;
 	ai->config.len = 0;
+	init_waitqueue_head (&ai->thr_wait);
+	init_completion (&ai->thr_exited);
+	ai->thr_pid = kernel_thread(airo_thread, dev, CLONE_FS | CLONE_FILES);
+	if (ai->thr_pid < 0)
+		goto err_out_free;
 	rc = add_airo_dev( dev );
 	if (rc)
-		goto err_out_free;
+		goto err_out_thr;
 
 	/* The Airo-specific entries in the device structure. */
 	dev->hard_start_xmit = &airo_start_xmit;
@@ -1768,7 +1772,7 @@
 		}
 	} else {
 		ai->bap_read = fast_bap_read;
-		ai->flags |= FLAG_FLASHING;
+		set_bit(FLAG_FLASHING, &ai->flags);
 	}
 
 	rc = register_netdev(dev);
@@ -1799,6 +1803,10 @@
 	free_irq(dev->irq, dev);
 err_out_unlink:
 	del_airo_dev(dev);
+err_out_thr:
+	set_bit(JOB_DIE, &ai->flags);
+	kill_proc(ai->thr_pid, SIGTERM, 1);
+	wait_for_completion(&ai->thr_exited);
 err_out_free:
 	kfree(dev);
 	return NULL;
@@ -1862,38 +1870,108 @@
 	union iwreq_data wrqu;
 	StatusRid status_rid;
 
-	if (down_trylock(&ai->sem) == 0) {
-		PC4500_readrid(ai, RID_STATUS, &status_rid, sizeof(status_rid), 0);
-		up(&ai->sem);
-		wrqu.data.length = 0;
-		wrqu.data.flags = 0;
-		memcpy(wrqu.ap_addr.sa_data, status_rid.bssid[0], ETH_ALEN);
-		wrqu.ap_addr.sa_family = ARPHRD_ETHER;
+	clear_bit(JOB_EVENT, &ai->flags);
+	PC4500_readrid(ai, RID_STATUS, &status_rid, sizeof(status_rid), 0);
+	up(&ai->sem);
+	wrqu.data.length = 0;
+	wrqu.data.flags = 0;
+	memcpy(wrqu.ap_addr.sa_data, status_rid.bssid[0], ETH_ALEN);
+	wrqu.ap_addr.sa_family = ARPHRD_ETHER;
 
-		/* Send event to user space */
-		wireless_send_event(dev, SIOCGIWAP, &wrqu, NULL);
-	} else {
-		ai->event_task.routine = (void (*)(void *))airo_send_event;
-		ai->event_task.data = (void *)dev;
-		schedule_task(&ai->event_task);
-	}
+	/* Send event to user space */
+	wireless_send_event(dev, SIOCGIWAP, &wrqu, NULL);
 }
 #endif
 
-static void airo_read_mic(struct airo_info *ai) {
-	MICRid mic_rid;
+static int airo_thread(void *data) {
+	struct net_device *dev = data;
+	struct airo_info *ai = dev->priv;
+	int locked;
+	
+	daemonize();
+	reparent_to_init();
+	spin_lock_irq(&current->sigmask_lock);
+	sigemptyset(&current->blocked);
+	recalc_sigpending(current);
+	spin_unlock_irq(&current->sigmask_lock);
+
+	strncpy (current->comm, dev->name, sizeof(current->comm) - 1);
+	current->comm[sizeof(current->comm) - 1] = '\0';
+
+	while(1) {
+		if (signal_pending(current)) {
+			spin_lock_irq(&current->sigmask_lock);
+			flush_signals(current);
+			spin_unlock_irq(&current->sigmask_lock);
+		}
+
+		if (test_bit(JOB_DIE, &ai->flags))
+			break;
 
-	if (down_trylock(&ai->sem) == 0) {
-		PC4500_readrid(ai, RID_MIC, &mic_rid, sizeof(mic_rid), 0);
-		up(&ai->sem);
+		if (ai->flags & JOB_MASK) {
+			locked = down_interruptible(&ai->sem);
+		} else {
+			wait_queue_t wait;
+
+			init_waitqueue_entry(&wait, current);
+			add_wait_queue(&ai->thr_wait, &wait);
+			for (;;) {
+				set_current_state(TASK_INTERRUPTIBLE);
+				if (ai->flags & JOB_MASK)
+					break;
+				if (ai->expires) {
+					if (time_after_eq(jiffies,ai->expires)){
+						set_bit(JOB_AUTOWEP,&ai->flags);
+						break;
+					}
+					if (!signal_pending(current)) {
+						schedule_timeout(ai->expires - jiffies);
+						continue;
+					}
+				} else if (!signal_pending(current)) {
+					schedule();
+					continue;
+				}
+				break;
+			}
+			current->state = TASK_RUNNING;
+			remove_wait_queue(&ai->thr_wait, &wait);
+			locked = 1;
+		}
+
+		if (locked)
+			continue;
+
+		if (test_bit(JOB_DIE, &ai->flags)) {
+			up(&ai->sem);
+			break;
+		}
+
+		if (test_bit(FLAG_FLASHING, &ai->flags)) {
+			up(&ai->sem);
+			continue;
+		}
+
+		if (test_bit(JOB_XMIT, &ai->flags))
+			airo_end_xmit(dev);
+		else if (test_bit(JOB_XMIT11, &ai->flags))
+			airo_end_xmit11(dev);
+		else if (test_bit(JOB_STATS, &ai->flags))
+			airo_read_stats(ai);
+		else if (test_bit(JOB_PROMISC, &ai->flags))
+			airo_set_promisc(ai);
 #ifdef MICSUPPORT
-		micinit (ai, &mic_rid);
+		else if (test_bit(JOB_MIC, &ai->flags))
+			micinit(ai);
 #endif
-	} else {
-		ai->mic_task.routine = (void (*)(void *))airo_read_mic;
-		ai->mic_task.data = (void *)ai;
-		schedule_task(&ai->mic_task);
+#if WIRELESS_EXT > 13
+		else if (test_bit(JOB_EVENT, &ai->flags))
+			airo_send_event(dev);
+#endif
+		else if (test_bit(JOB_AUTOWEP, &ai->flags))
+			timer_func(dev);
 	}
+	complete_and_exit (&ai->thr_exited, 0);
 }
 
 static void airo_interrupt ( int irq, void* dev_id, struct pt_regs *regs) {
@@ -1922,8 +2000,15 @@
 
 		if ( status & EV_MIC ) {
 			OUT4500( apriv, EVACK, EV_MIC );
-			if (apriv->flags & FLAG_MIC_CAPABLE)
-				airo_read_mic( apriv );
+#ifdef MICSUPPORT
+			if (test_bit(FLAG_MIC_CAPABLE, &apriv->flags)) {
+				if (down_trylock(&apriv->sem) != 0) {
+					set_bit(JOB_MIC, &apriv->flags);
+					wake_up_interruptible(&apriv->thr_wait);
+				} else
+					micinit (apriv);
+			}
+#endif
 		}
 		if ( status & EV_LINK ) {
 #if WIRELESS_EXT > 13
@@ -1965,15 +2050,18 @@
 #define RC_NOAUTH 9 /* Station requesting (Re)Association is not
 		       Authenticated with the responding station */
 			if (newStatus != ASSOCIATED) {
-				if (auto_wep && !timer_pending(&apriv->timer)) {
-					apriv->timer.expires = RUN_AT(HZ*3);
-		      			add_timer(&apriv->timer);
+				if (auto_wep && !apriv->expires) {
+					apriv->expires = RUN_AT(3*HZ);
+					wake_up_interruptible(&apriv->thr_wait);
 				}
 			} else {
 				struct task_struct *task = apriv->task;
+				if (auto_wep)
+					apriv->expires = 0;
 				if (task)
 					wake_up_process (task);
-				apriv->flags|=FLAG_UPDATE_UNI|FLAG_UPDATE_MULTI;
+				set_bit(FLAG_UPDATE_UNI, &apriv->flags);
+				set_bit(FLAG_UPDATE_MULTI, &apriv->flags);
 			}
 #if WIRELESS_EXT > 13
 			/* Question : is ASSOCIATED the only status
@@ -1994,7 +2082,11 @@
 					wireless_send_event(dev, SIOCGIWSCAN, &wrqu, NULL);
 					apriv->scan_timestamp = 0;
 				}
-				airo_send_event(dev);
+				if (down_trylock(&apriv->sem) != 0) {
+					set_bit(JOB_EVENT, &apriv->flags);
+					wake_up_interruptible(&apriv->thr_wait);
+				} else
+					airo_send_event(dev);
 			} else {
 				memset(wrqu.ap_addr.sa_data, '\0', ETH_ALEN);
 				wrqu.ap_addr.sa_family = ARPHRD_ETHER;
@@ -2025,7 +2117,7 @@
 			fid = IN4500( apriv, RXFID );
 
 			/* Get the packet length */
-			if (apriv->flags & FLAG_802_11) {
+			if (test_bit(FLAG_802_11, &apriv->flags)) {
 				bap_setup (apriv, fid, 4, BAP0);
 				bap_read (apriv, (u16*)&hdr, sizeof(hdr), BAP0);
 				/* Bad CRC. Ignore packet */
@@ -2044,7 +2136,7 @@
 				len = 0;
 			}
 			if (len) {
-				if (apriv->flags & FLAG_802_11) {
+				if (test_bit(FLAG_802_11, &apriv->flags)) {
 					bap_read (apriv, (u16*)&fc, sizeof(fc), BAP0);
 					fc = le16_to_cpu(fc);
 					switch (fc & 0xc) {
@@ -2073,7 +2165,7 @@
 			}
 			if (len) {
 				buffer = (u16*)skb_put (skb, len + hdrlen);
-				if (apriv->flags & FLAG_802_11) {
+				if (test_bit(FLAG_802_11, &apriv->flags)) {
 					buffer[0] = fc;
 					bap_read (apriv, buffer + 1, hdrlen - 2, BAP0);
 					if (hdrlen == 24)
@@ -2120,11 +2212,12 @@
 					char *sa;
 					struct iw_quality wstats;
 					/* Prepare spy data : addr + qual */
-					sa = (char*)buffer + ((apriv->flags & FLAG_802_11) ? 10 : 6);
-					if (!(apriv->flags & FLAG_802_11)) {
+					if (!test_bit(FLAG_802_11, &apriv->flags)) {
+						sa = (char*)buffer + 6;
 						bap_setup (apriv, fid, 8, BAP0);
 						bap_read (apriv, (u16*)hdr.rssi, 2, BAP0);
-					}
+					} else
+						sa = (char*)buffer + 10;
 					wstats.qual = hdr.rssi[0];
 					if (apriv->rssi)
 						wstats.level = 0x100 - apriv->rssi[hdr.rssi[1]].rssidBm;
@@ -2141,12 +2234,12 @@
 					int i;
 					char *sa;
 
-					sa = (char*)buffer + ((apriv->flags & FLAG_802_11) ? 10 : 6);
+					sa = (char*)buffer + (test_bit(FLAG_802_11, &apriv->flags) ? 10 : 6);
 
 					for (i=0; i<apriv->spy_number; i++)
 						if (!memcmp(sa,apriv->spy_address[i],ETH_ALEN))
 						{
-							if (!(apriv->flags & FLAG_802_11)) {
+							if (!test_bit(FLAG_802_11, &apriv->flags)) {
 								bap_setup (apriv, fid, 8, BAP0);
 								bap_read (apriv, (u16*)hdr.rssi, 2, BAP0);
 							}
@@ -2164,7 +2257,7 @@
 #endif /* WIRELESS_EXT > 15 */
 				OUT4500( apriv, EVACK, EV_RX);
 
-				if (apriv->flags & FLAG_802_11) {
+				if (test_bit(FLAG_802_11, &apriv->flags)) {
 					skb->mac.raw = skb->data;
 					skb->pkt_type = PACKET_OTHERHOST;
 					skb->dev = apriv->wifidev;
@@ -2202,10 +2295,10 @@
 				/* Set up to be used again */
 				apriv->fids[index] &= 0xffff;
 				if (index < MAX_FIDS / 2) {
-					if (!(apriv->flags & FLAG_PENDING_XMIT))
+					if (!test_bit(FLAG_PENDING_XMIT, &apriv->flags))
 						netif_wake_queue(dev);
 				} else {
-					if (!(apriv->flags & FLAG_PENDING_XMIT11))
+					if (!test_bit(FLAG_PENDING_XMIT11, &apriv->flags))
 						netif_wake_queue(apriv->wifidev);
 				}
 			} else {
@@ -2265,7 +2358,7 @@
 	 * instead of this flag, but I don't trust it *within* the
 	 * open/close functions, and testing both flags together is
 	 * "cheaper" - Jean II */
-	if (ai->flags & (FLAG_RADIO_OFF|FLAG_RADIO_DOWN)) return SUCCESS;
+	if (ai->flags & FLAG_RADIO_MASK) return SUCCESS;
 	memset(&cmd, 0, sizeof(cmd));
 	cmd.cmd = MAC_ENABLE;
 	if (!lock)
@@ -2386,10 +2479,10 @@
 		ai->config.opmode = adhoc ? MODE_STA_IBSS : MODE_STA_ESS;
 
 #ifdef MICSUPPORT
-		if ((cap_rid.len==sizeof(cap_rid)) && (cap_rid.extSoftCap&1)) {
+		if ((cap_rid.len>=sizeof(cap_rid)) && (cap_rid.extSoftCap&1) &&
+		    (micsetup(ai) == SUCCESS)) {
 			ai->config.opmode |= MODE_MIC;
-			ai->flags |= FLAG_MIC_CAPABLE;
-			micsetup(ai);
+			set_bit(FLAG_MIC_CAPABLE, &ai->flags);
 		}
 #endif
 
@@ -2455,34 +2548,15 @@
 		rc = readWepKeyRid(ai, &wkr, 0);
 	} while(lastindex != wkr.kindex);
 
-	if (auto_wep && !timer_pending(&ai->timer)) {
-		ai->timer.expires = RUN_AT(HZ*3);
-		add_timer(&ai->timer);
+	if (auto_wep) {
+		ai->expires = RUN_AT(3*HZ);
+		wake_up_interruptible(&ai->thr_wait);
 	}
-	return SUCCESS;
-}
 
-static u16 issuecommand(struct airo_info *ai, Cmd *pCmd, Resp *pRsp) {
-        // Im really paranoid about letting it run forever!
-	int max_tries = 600000;
-
-	if (sendcommand(ai, pCmd) == (u16)ERROR)
-		return ERROR;
-
-	while (max_tries-- && (IN4500(ai, EVSTAT) & EV_CMD) == 0) {
-		if (!in_interrupt() && (max_tries & 255) == 0)
-			schedule();
-	}
-	if ( max_tries == -1 ) {
-		printk( KERN_ERR
-			"airo: Max tries exceeded waiting for command\n" );
-                return ERROR;
-	}
-	completecommand(ai, pRsp);
 	return SUCCESS;
 }
 
-static u16 sendcommand(struct airo_info *ai, Cmd *pCmd) {
+static u16 issuecommand(struct airo_info *ai, Cmd *pCmd, Resp *pRsp) {
         // Im really paranoid about letting it run forever!
 	int max_tries = 600000;
 	u16 cmd;
@@ -2501,10 +2575,16 @@
 			"airo: Max tries exceeded when issueing command\n" );
                 return ERROR;
 	}
-	return SUCCESS;
-}
 
-static void completecommand(struct airo_info *ai, Resp *pRsp) {
+	while (max_tries-- && (IN4500(ai, EVSTAT) & EV_CMD) == 0) {
+		if (!in_interrupt() && (max_tries & 255) == 0)
+			schedule();
+	}
+	if ( max_tries == -1 ) {
+		printk( KERN_ERR
+			"airo: Max tries exceeded waiting for command\n" );
+                return ERROR;
+	}
 	// command completed
 	pRsp->status = IN4500(ai, STATUS);
 	pRsp->rsp0 = IN4500(ai, RESP0);
@@ -2517,6 +2597,8 @@
 	}
 	// acknowledge processing the status/response
 	OUT4500(ai, EVACK, EV_CMD);
+
+	return SUCCESS;
 }
 
 /* Sets up the bap to start exchange data.  whichbap should
@@ -2803,7 +2885,7 @@
 	len -= ETH_ALEN * 2;
 
 #ifdef MICSUPPORT
-	if ((ai->flags & FLAG_MIC_CAPABLE) && ai->micstats.enabled && 
+	if (test_bit(FLAG_MIC_CAPABLE, &ai->flags) && ai->micstats.enabled && 
 	    (ntohs(((u16 *)pPacket)[6]) != 0x888E)) {
 		if (encapsulate(ai,(etherHead *)pPacket,&pMic,len) != SUCCESS)
 			return ERROR;
@@ -3306,7 +3388,7 @@
 			if ((ai->config.rmode & 0xff) >= RXMODE_RFMON)
 					ai->need_commit = 2;
 			ai->config.rmode &= 0xfe00;
-			ai->flags &= ~FLAG_802_11;
+			clear_bit (FLAG_802_11, &ai->flags);
 			ai->config.opmode &= 0xFF00;
 			ai->config.scanMode = SCANMODE_ACTIVE;
 			if ( line[0] == 'a' ) {
@@ -3316,11 +3398,11 @@
 				if ( line[0] == 'r' ) {
 					ai->config.rmode |= RXMODE_RFMON | RXMODE_DISABLE_802_3_HEADER;
 					ai->config.scanMode = SCANMODE_PASSIVE;
-					ai->flags |= FLAG_802_11;
+					set_bit (FLAG_802_11, &ai->flags);
 				} else if ( line[0] == 'y' ) {
 					ai->config.rmode |= RXMODE_RFMON_ANYBSS | RXMODE_DISABLE_802_3_HEADER;
 					ai->config.scanMode = SCANMODE_PASSIVE;
-					ai->flags |= FLAG_802_11;
+					set_bit (FLAG_802_11, &ai->flags);
 				} else if ( line[0] == 'l' )
 					ai->config.rmode |= RXMODE_LANMON;
 			}
@@ -3331,9 +3413,9 @@
 		else if (!strncmp(line,"Radio: ", 7)) {
 			line += 7;
 			if (!strncmp(line,"off",3)) {
-				ai->flags |= FLAG_RADIO_OFF;
+				set_bit (FLAG_RADIO_OFF, &ai->flags);
 			} else {
-				ai->flags &= ~FLAG_RADIO_OFF;
+				clear_bit (FLAG_RADIO_OFF, &ai->flags);
 			}
 		}
 /*** NodeName processing */
@@ -3537,7 +3619,7 @@
 		     (ai->config.opmode & 0xFF) == 1 ? get_rmode(ai->config.rmode):
 		     (ai->config.opmode & 0xFF) == 2 ? "AP" :
 		     (ai->config.opmode & 0xFF) == 3 ? "AP RPTR" : "Error",
-		     ai->flags&FLAG_RADIO_OFF ? "off" : "on",
+		     test_bit(FLAG_RADIO_OFF, &ai->flags) ? "off" : "on",
 		     ai->config.nodeName,
 		     ai->config.powerSaveMode == 0 ? "CAM" :
 		     ai->config.powerSaveMode == 1 ? "PSP" :
@@ -4004,23 +4086,14 @@
    will switch WEP modes to see if that will help.  If the card is
    associated we will check every minute to see if anything has
    changed. */
-static void timer_func( u_long data ) {
-	struct net_device *dev = (struct net_device*)data;
+static void timer_func( struct net_device *dev ) {
 	struct airo_info *apriv = dev->priv;
-	u16 linkstat = IN4500(apriv, LINKSTAT);
 	Resp rsp;
 
-	if (!(apriv->flags & FLAG_FLASHING) && (linkstat != 0x400)) {
 /* We don't have a link so try changing the authtype */
-		if (down_trylock(&apriv->sem) != 0) {
-			apriv->timer.expires = RUN_AT(1);
-			add_timer(&apriv->timer);
-			return;
-		}
-
-		readConfigRid(apriv, 0);
-		disable_MAC(apriv, 0);
-		switch(apriv->config.authType) {
+	readConfigRid(apriv, 0);
+	disable_MAC(apriv, 0);
+	switch(apriv->config.authType) {
 		case AUTH_ENCRYPT:
 /* So drop to OPEN */
 			apriv->config.authType = AUTH_OPEN;
@@ -4039,16 +4112,15 @@
 			break;
 		default:  /* We'll escalate to SHAREDKEY */
 			apriv->config.authType = AUTH_SHAREDKEY;
-		}
-		apriv->need_commit = 1;
-		writeConfigRid(apriv, 0);
-		enable_MAC(apriv, &rsp, 0);
-		up(&apriv->sem);
+	}
+	apriv->need_commit = 1;
+	writeConfigRid(apriv, 0);
+	enable_MAC(apriv, &rsp, 0);
+	up(&apriv->sem);
 
 /* Schedule check to see if the change worked */
-		apriv->timer.expires = RUN_AT(HZ*3);
-		add_timer(&apriv->timer);
-	}
+	clear_bit(JOB_AUTOWEP, &apriv->flags);
+	apriv->expires = RUN_AT(HZ*3);
 }
 
 static int add_airo_dev( struct net_device *dev ) {
@@ -4056,15 +4128,6 @@
 	if ( !node )
 		return -ENOMEM;
 
-	if ( auto_wep ) {
-		struct airo_info *apriv=dev->priv;
-		struct timer_list *timer = &apriv->timer;
-
-		timer->function = timer_func;
-		timer->data = (u_long)dev;
-		init_timer(timer);
-	}
-
 	node->dev = dev;
 	node->next = airo_devices;
 	airo_devices = node;
@@ -4095,6 +4158,7 @@
 		return -ENODEV;
 
 	pci_set_drvdata(pdev, dev);
+	clear_bit (FLAG_PCI, &((struct airo_info *)dev->priv)->flags);
 	return 0;
 }
 
@@ -4136,11 +4200,19 @@
 
 static void __exit airo_cleanup_module( void )
 {
+	int is_pci = 0;
 	while( airo_devices ) {
 		printk( KERN_INFO "airo: Unregistering %s\n", airo_devices->dev->name );
+#ifdef CONFIG_PCI
+		if (test_bit(FLAG_PCI, &((struct airo_info *)airo_devices->dev->priv)->flags))
+			is_pci = 1;
+#endif
 		stop_airo_card( airo_devices->dev, 1 );
 	}
 	remove_proc_entry("aironet", proc_root_driver);
+
+	if (is_pci)
+		pci_unregister_driver(&airo_driver);
 }
 
 #ifdef WIRELESS_EXT
@@ -4606,28 +4678,28 @@
 			local->config.opmode |= MODE_STA_IBSS;
 			local->config.rmode &= 0xfe00;
 			local->config.scanMode = SCANMODE_ACTIVE;
-			local->flags &= ~FLAG_802_11;
+			clear_bit (FLAG_802_11, &local->flags);
 			break;
 		case IW_MODE_INFRA:
 			local->config.opmode &= 0xFF00;
 			local->config.opmode |= MODE_STA_ESS;
 			local->config.rmode &= 0xfe00;
 			local->config.scanMode = SCANMODE_ACTIVE;
-			local->flags &= ~FLAG_802_11;
+			clear_bit (FLAG_802_11, &local->flags);
 			break;
 		case IW_MODE_MASTER:
 			local->config.opmode &= 0xFF00;
 			local->config.opmode |= MODE_AP;
 			local->config.rmode &= 0xfe00;
 			local->config.scanMode = SCANMODE_ACTIVE;
-			local->flags &= ~FLAG_802_11;
+			clear_bit (FLAG_802_11, &local->flags);
 			break;
 		case IW_MODE_REPEAT:
 			local->config.opmode &= 0xFF00;
 			local->config.opmode |= MODE_AP_RPTR;
 			local->config.rmode &= 0xfe00;
 			local->config.scanMode = SCANMODE_ACTIVE;
-			local->flags &= ~FLAG_802_11;
+			clear_bit (FLAG_802_11, &local->flags);
 			break;
 		case IW_MODE_MONITOR:
 			local->config.opmode &= 0xFF00;
@@ -4635,7 +4707,7 @@
 			local->config.rmode &= 0xfe00;
 			local->config.rmode |= RXMODE_RFMON | RXMODE_DISABLE_802_3_HEADER;
 			local->config.scanMode = SCANMODE_PASSIVE;
-			local->flags |= FLAG_802_11;
+			set_bit (FLAG_802_11, &local->flags);
 			break;
 		default:
 			return -EINVAL;
@@ -4824,14 +4896,14 @@
 	readCapabilityRid(local, &cap_rid);
 
 	if (vwrq->disabled) {
-		local->flags |= FLAG_RADIO_OFF;
+		set_bit (FLAG_RADIO_OFF, &local->flags);
 		local->need_commit = 1;
 		return -EINPROGRESS;		/* Call commit handler */
 	}
 	if (vwrq->flags != IW_TXPOW_MWATT) {
 		return -EINVAL;
 	}
-	local->flags &= ~FLAG_RADIO_OFF;
+	clear_bit (FLAG_RADIO_OFF, &local->flags);
 	for (i = 0; cap_rid.txPowerLevels[i] && (i < 8); i++)
 		if ((vwrq->value==cap_rid.txPowerLevels[i])) {
 			local->config.txPower = vwrq->value;
@@ -4855,7 +4927,7 @@
 
 	vwrq->value = local->config.txPower;
 	vwrq->fixed = 1;	/* No power control */
-	vwrq->disabled = (local->flags & FLAG_RADIO_OFF);
+	vwrq->disabled = test_bit(FLAG_RADIO_OFF, &local->flags);
 	vwrq->flags = IW_TXPOW_MWATT;
 
 	return 0;
@@ -5199,7 +5271,7 @@
 			      & status_rid.bssid[i][2]
 			      & status_rid.bssid[i][3]
 			      & status_rid.bssid[i][4]
-			      & status_rid.bssid[i][5])!=-1 &&
+			      & status_rid.bssid[i][5])!=0xff &&
 			     (status_rid.bssid[i][0]
 			      | status_rid.bssid[i][1]
 			      | status_rid.bssid[i][2]
@@ -5293,7 +5365,7 @@
 	capabilities = le16_to_cpu(list->cap);
 	if(capabilities & (CAP_ESS | CAP_IBSS)) {
 		if(capabilities & CAP_ESS)
-			iwe.u.mode = IW_MODE_INFRA;
+			iwe.u.mode = IW_MODE_MASTER;
 		else
 			iwe.u.mode = IW_MODE_ADHOC;
 		current_ev = iwe_stream_add_event(current_ev, end_buf, &iwe, IW_EV_UINT_LEN);
@@ -5505,10 +5577,14 @@
 		writeSsidRid(local, &SSID_rid);
 		writeAPListRid(local, &APList_rid);
 	}
-	writeConfigRid(local, 1);
-	enable_MAC(local, &rsp, 1);
+	if (down_interruptible(&local->sem))
+		return -ERESTARTSYS;
+	writeConfigRid(local, 0);
+	enable_MAC(local, &rsp, 0);
 	if (local->need_commit > 1)
 		airo_set_promisc(local);
+	else
+		up(&local->sem);
 
 	return 0;
 }
@@ -6046,7 +6122,7 @@
 	unsigned char *iobuf;
 	struct airo_info *ai = dev->priv;
 
-	if (ai->flags & FLAG_FLASHING)
+	if (test_bit(FLAG_FLASHING, &ai->flags))
 		return -EIO;
 
 	switch(comp->command)
@@ -6114,7 +6190,7 @@
 	if (!capable(CAP_NET_ADMIN))
 		return -EPERM;
 
-	if (ai->flags & FLAG_FLASHING)
+	if (test_bit(FLAG_FLASHING, &ai->flags))
 		return -EIO;
 
 	ridcode = 0;
@@ -6188,13 +6264,13 @@
 	if (comp->command == AIROPCFG) {
 		ConfigRid *cfg = (ConfigRid *)iobuf;
 
-		if (ai->flags & FLAG_MIC_CAPABLE)
+		if (test_bit(FLAG_MIC_CAPABLE, &ai->flags))
 			cfg->opmode |= MODE_MIC;
 
 		if ((cfg->opmode & 0xFF) == MODE_STA_IBSS)
-			ai->flags |= FLAG_ADHOC;
+			set_bit (FLAG_ADHOC, &ai->flags);
 		else
-			ai->flags &= ~FLAG_ADHOC;
+			clear_bit (FLAG_ADHOC, &ai->flags);
 	}
 
 	if((*writer)(ai, ridcode, iobuf,comp->len,1)) {
@@ -6305,7 +6381,7 @@
  */
 
 int setflashmode (struct airo_info *ai) {
-	ai->flags |= FLAG_FLASHING;
+	set_bit (FLAG_FLASHING, &ai->flags);
 
 	OUT4500(ai, SWS0, FLASH_COMMAND);
 	OUT4500(ai, SWS1, FLASH_COMMAND);
@@ -6321,7 +6397,7 @@
 	schedule_timeout (HZ/2); /* 500ms delay */
 
 	if(!waitbusy(ai)) {
-		ai->flags &= ~FLAG_FLASHING;
+		clear_bit (FLAG_FLASHING, &ai->flags);
 		printk(KERN_INFO "Waitbusy hang after setflash mode\n");
 		return -EIO;
 	}
@@ -6427,7 +6503,7 @@
 
 	set_current_state (TASK_UNINTERRUPTIBLE);
 	schedule_timeout (HZ);          /* Added 12/7/00 */
-	ai->flags &= ~FLAG_FLASHING;
+	clear_bit (FLAG_FLASHING, &ai->flags);
 	status = setup_card(ai, dev->dev_addr);
 
 	for( i = 0; i < MAX_FIDS; i++ ) {
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/pci/pci.ids linux-2.4.23-pre1/drivers/pci/pci.ids
--- linux-2.4.22/drivers/pci/pci.ids	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/pci/pci.ids	2003-08-27 14:40:35.000000000 +0000
@@ -1934,6 +1934,7 @@
 	8001  Schizo PCI Bus Module
 	a000  Ultra IIi
 	a001  Ultra IIe
+	a801  Tomatillo PCI Bus Module
 108f  Systemsoft
 1090  Encore Computer Corporation
 1091  Intergraph Corporation
@@ -6066,6 +6067,7 @@
 1737  Linksys
 173b  Altima (nee Broadcom)
 	03e8  AC1000 Gigabit Ethernet
+	03e9  AC1001 Gigabit Ethernet
 	03ea  AC9100 Gigabit Ethernet
 		173b 0001  AC1002
 1743  Peppercon AG
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/s390/net/ctctty.c linux-2.4.23-pre1/drivers/s390/net/ctctty.c
--- linux-2.4.22/drivers/s390/net/ctctty.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/s390/net/ctctty.c	2003-08-27 14:40:37.000000000 +0000
@@ -42,7 +42,7 @@
 #define init_waitqueue_head(x) *(x)=NULL
 #define __set_current_state(state_value) \
 	do { current->state = state_value; } while (0)
-#ifdef __SMP__
+#ifdef CONFIG_SMP
 #define set_current_state(state_value) \
 	do { __set_current_state(state_value); mb(); } while (0)
 #else
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/scsi/3w-xxxx.c linux-2.4.23-pre1/drivers/scsi/3w-xxxx.c
--- linux-2.4.22/drivers/scsi/3w-xxxx.c	2003-08-25 11:44:42.000000000 +0000
+++ linux-2.4.23-pre1/drivers/scsi/3w-xxxx.c	2003-08-27 14:41:43.000000000 +0000
@@ -178,7 +178,7 @@
 #include <linux/module.h>
 
 MODULE_AUTHOR ("3ware Inc.");
-#ifdef __SMP__
+#ifdef CONFIG_SMP
 MODULE_DESCRIPTION ("3ware Storage Controller Linux Driver (SMP)");
 #else
 MODULE_DESCRIPTION ("3ware Storage Controller Linux Driver");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/scsi/ips.c linux-2.4.23-pre1/drivers/scsi/ips.c
--- linux-2.4.22/drivers/scsi/ips.c	2003-06-13 14:51:36.000000000 +0000
+++ linux-2.4.23-pre1/drivers/scsi/ips.c	2003-08-27 14:39:13.000000000 +0000
@@ -5,8 +5,8 @@
 /*             Jack Hammer, Adaptec, Inc.                                    */
 /*             David Jeffery, Adaptec, Inc.                                  */
 /*                                                                           */
-/* Copyright (C) 2000 IBM Corporation                                        */ 
-/* Copyright (C) 2003 Adaptec, Inc.                                          */ 
+/* Copyright (C) 2000 IBM Corporation                                        */
+/* Copyright (C) 2002,2003 Adaptec, Inc.                                     */
 /*                                                                           */
 /* This program is free software; you can redistribute it and/or modify      */
 /* it under the terms of the GNU General Public License as published by      */
@@ -83,7 +83,7 @@
 /*            2.3.18 and later                                               */
 /*          - Sync with other changes from the 2.3 kernels                   */
 /* 4.00.06  - Fix timeout with initial FFDC command                          */
-/* 4.00.06a - Port to 2.4 (trivial) -- Christoph Hellwig <hch@caldera.de>    */
+/* 4.00.06a - Port to 2.4 (trivial) -- Christoph Hellwig <hch@infradead.org> */
 /* 4.10.00  - Add support for ServeRAID 4M/4L                                */
 /* 4.10.13  - Fix for dynamic unload and proc file system                    */
 /* 4.20.03  - Rename version to coincide with new release schedules          */
@@ -130,6 +130,7 @@
 /* 5.10.15  - remove unused code (sem, macros, etc.)                         */
 /* 5.30.00  - use __devexit_p()                                              */
 /* 6.00.00  - Add 6x Adapters and Battery Flash                              */
+/* 6.10.00  - Remove 1G Addressing Limitations                               */
 /*****************************************************************************/
 
 /*
@@ -150,7 +151,7 @@
  * nommap               - Don't use memory mapped I/O
  * ioctlsize            - Initial size of the IOCTL buffer
  */
- 
+
 #include <asm/io.h>
 #include <asm/byteorder.h>
 #include <asm/page.h>
@@ -182,75 +183,35 @@
 #include <linux/stat.h>
 #include <linux/config.h>
 
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
-  #include <linux/spinlock.h>
-  #include <linux/init.h>
-#else
-  #include <asm/spinlock.h>
-#endif
+#include <linux/spinlock.h>
+#include <linux/init.h>
 
 #include <linux/smp.h>
 
 #ifdef MODULE
-   static char *ips = NULL;
-   MODULE_PARM(ips, "s");
+static char *ips = NULL;
+MODULE_PARM(ips, "s");
 #endif
 
 /*
  * DRIVER_VER
  */
-#define IPS_VERSION_HIGH        "6.00"
-#define IPS_VERSION_LOW         ".26 "
-
-
-#if LINUX_VERSION_CODE < LinuxVersionCode(2,4,0)
-struct proc_dir_entry proc_scsi_ips = {
-   0,
-   3, "ips",
-   S_IFDIR | S_IRUGO | S_IXUGO, 2
-};
-#endif
+#define IPS_VERSION_HIGH        "6.10"
+#define IPS_VERSION_LOW         ".24 "
 
 #if !defined(__i386__) && !defined(__ia64__)
-   #error "This driver has only been tested on the x86/ia64 platforms"
-#endif
-
-#if LINUX_VERSION_CODE < LinuxVersionCode(2,2,0)
-   #error "This driver only works with kernel 2.2.0 and later"
-#elif LINUX_VERSION_CODE <= LinuxVersionCode(2,3,18)
-    #define dma_addr_t uint32_t
-    
-    static inline void *pci_alloc_consistent(struct pci_dev *dev,int size,
-                                             dma_addr_t *dmahandle) {
-       void * ptr = kmalloc(size, GFP_ATOMIC); 
-       if(ptr){     
-          *dmahandle = (uint32_t)virt_to_bus(ptr);
-       }
-       return ptr;
-    }
-    
-    #define pci_free_consistent(a,size,address,dmahandle) kfree(address)
-    
-    #define pci_map_sg(a,b,n,z)       (n)
-    #define pci_unmap_sg(a,b,c,d)     
-    #define pci_map_single(a,b,c,d)   ((uint32_t)virt_to_bus(b))
-    #define pci_unmap_single(a,b,c,d) 
-    #ifndef sg_dma_address
-      #define sg_dma_address(x)         ((uint32_t)virt_to_bus((x)->address))
-      #define sg_dma_len(x)             ((x)->length)
-    #endif
-    #define pci_unregister_driver(x)
+#error "This driver has only been tested on the x86/ia64 platforms"
 #endif
 
 #if LINUX_VERSION_CODE <= LinuxVersionCode(2,5,0)
-    #define IPS_SG_ADDRESS(sg)       ((sg)->address)
-    #define IPS_LOCK_SAVE(lock,flags) spin_lock_irqsave(&io_request_lock,flags)
-    #define IPS_UNLOCK_RESTORE(lock,flags) spin_unlock_irqrestore(&io_request_lock,flags)
+#define IPS_SG_ADDRESS(sg)       ((sg)->address)
+#define IPS_LOCK_SAVE(lock,flags) spin_lock_irqsave(&io_request_lock,flags)
+#define IPS_UNLOCK_RESTORE(lock,flags) spin_unlock_irqrestore(&io_request_lock,flags)
 #else
-    #define IPS_SG_ADDRESS(sg)      (page_address((sg)->page) ? \
+#define IPS_SG_ADDRESS(sg)      (page_address((sg)->page) ? \
                                      page_address((sg)->page)+(sg)->offset : 0)
-    #define IPS_LOCK_SAVE(lock,flags) spin_lock(lock)
-    #define IPS_UNLOCK_RESTORE(lock,flags) spin_unlock(lock)
+#define IPS_LOCK_SAVE(lock,flags) do{spin_lock(lock);(void)flags;}while(0)
+#define IPS_UNLOCK_RESTORE(lock,flags) do{spin_unlock(lock);(void)flags;}while(0)
 #endif
 
 #define IPS_DMA_DIR(scb) ((!scb->scsi_cmd || ips_is_passthru(scb->scsi_cmd) || \
@@ -259,218 +220,144 @@
                          scsi_to_pci_dma_dir(scb->scsi_cmd->sc_data_direction))
 
 #ifdef IPS_DEBUG
-   #define METHOD_TRACE(s, i)    if (ips_debug >= (i+10)) printk(KERN_NOTICE s "\n");
-   #define DEBUG(i, s)           if (ips_debug >= i) printk(KERN_NOTICE s "\n");
-   #define DEBUG_VAR(i, s, v...) if (ips_debug >= i) printk(KERN_NOTICE s "\n", v);
+#define METHOD_TRACE(s, i)    if (ips_debug >= (i+10)) printk(KERN_NOTICE s "\n");
+#define DEBUG(i, s)           if (ips_debug >= i) printk(KERN_NOTICE s "\n");
+#define DEBUG_VAR(i, s, v...) if (ips_debug >= i) printk(KERN_NOTICE s "\n", v);
 #else
-   #define METHOD_TRACE(s, i)
-   #define DEBUG(i, s)
-   #define DEBUG_VAR(i, s, v...)
+#define METHOD_TRACE(s, i)
+#define DEBUG(i, s)
+#define DEBUG_VAR(i, s, v...)
 #endif
 
 /*
  * global variables
  */
-static const char   ips_name[] = "ips";
-static struct Scsi_Host *ips_sh[IPS_MAX_ADAPTERS];   /* Array of host controller structures */
-static ips_ha_t    *ips_ha[IPS_MAX_ADAPTERS];        /* Array of HA structures */
-static unsigned int ips_next_controller = 0;
-static unsigned int ips_num_controllers = 0;
-static unsigned int ips_released_controllers = 0;
-static int          ips_cmd_timeout = 60;
-static int          ips_reset_timeout = 60 * 5;
-static int          ips_force_memio = 1;             /* Always use Memory Mapped I/O    */
-static int          ips_force_i2o = 1;               /* Always use I2O command delivery */
-static int          ips_ioctlsize = IPS_IOCTL_SIZE;  /* Size of the ioctl buffer        */
-static int          ips_cd_boot = 0;                 /* Booting from Manager CD         */
-static char        *ips_FlashData = NULL;            /* CD Boot - Flash Data Buffer      */
-static long         ips_FlashDataInUse = 0;          /* CD Boot - Flash Data In Use Flag */
-static uint32_t     MaxLiteCmds = 32;                /* Max Active Cmds for a Lite Adapter */  
+static const char ips_name[] = "ips";
+static struct Scsi_Host *ips_sh[IPS_MAX_ADAPTERS];	/* Array of host controller structures */
+static ips_ha_t *ips_ha[IPS_MAX_ADAPTERS];	/* Array of HA structures */
+static unsigned int ips_next_controller;
+static unsigned int ips_num_controllers;
+static unsigned int ips_released_controllers;
+static int ips_cmd_timeout = 60;
+static int ips_reset_timeout = 60 * 5;
+static int ips_force_memio = 1;	/* Always use Memory Mapped I/O    */
+static int ips_force_i2o = 1;	/* Always use I2O command delivery */
+static int ips_ioctlsize = IPS_IOCTL_SIZE;	/* Size of the ioctl buffer        */
+static int ips_cd_boot;		/* Booting from Manager CD         */
+static char *ips_FlashData = NULL;	/* CD Boot - Flash Data Buffer      */
+static long ips_FlashDataInUse;	/* CD Boot - Flash Data In Use Flag */
+static uint32_t MaxLiteCmds = 32;	/* Max Active Cmds for a Lite Adapter */
+static Scsi_Host_Template ips_driver_template = IPS;
 
-IPS_DEFINE_COMPAT_TABLE( Compatable );               /* Version Compatability Table      */
+IPS_DEFINE_COMPAT_TABLE(Compatable);	/* Version Compatability Table      */
 
-
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
    /* This table describes all ServeRAID Adapters */
-   static struct  pci_device_id  ips_pci_table[]  __devinitdata = {
-           { 0x1014, 0x002E, PCI_ANY_ID, PCI_ANY_ID, 0, 0 },
-           { 0x1014, 0x01BD, PCI_ANY_ID, PCI_ANY_ID, 0, 0 },
-           { 0x9005, 0x0250, PCI_ANY_ID, PCI_ANY_ID, 0, 0 },
-           { 0, }
-   };
-
-   /* This table describes only Anaconda Family Adapters */
-   static struct  pci_device_id  ips_pci_table_anaconda[]  __devinitdata = {
-           { 0x1014, 0x002E, PCI_ANY_ID, PCI_ANY_ID, 0, 0 },
-           { 0, }
-   };
-
-   /* This table describes only Sarasota ( ServeRAID 5i ) Adapters */
-   static struct  pci_device_id  ips_pci_table_5i[]  __devinitdata = {
-                   { 0x1014, 0x01BD, PCI_ANY_ID, 0x259, 0, 0 },
-                   { 0x1014, 0x01BD, PCI_ANY_ID, 0x258, 0, 0 },
-                   { 0, }
-                   };   
-
-   /* This table describes only Sebring ( ServeRAID 6i ) Adapters */
-   static struct  pci_device_id  ips_pci_table_6i[]  __devinitdata = {
-                   { 0x9005, 0x0250, PCI_ANY_ID, 0x28C, 0, 0 },
-                   { 0, }
-                   };   
-    
-   /* This table describes all i960 ( 4M, 4Mx, 4L, 4Lx ) Adapters */
-   static struct  pci_device_id  ips_pci_table_i960[]  __devinitdata = {
-                   { 0x1014, 0x01BD, PCI_ANY_ID, PCI_ANY_ID, 0, 0 },
-                   { 0, }
-                   };   
-
-   /* This table describes all Adaptec ( 6M ) Adapters */
-   static struct  pci_device_id  ips_pci_table_adaptec[]  __devinitdata = {
-                   { 0x9005, 0x0250, PCI_ANY_ID, PCI_ANY_ID, 0, 0 },
-                   { 0, }
-                   };   
-
-   MODULE_DEVICE_TABLE( pci, ips_pci_table );
-
-   static char ips_hot_plug_name[] = "ips";
-   
-   static int __devinit  ips_insert_device(struct pci_dev *pci_dev, const struct pci_device_id *ent);
-   static void ips_remove_device(struct pci_dev *pci_dev);
-   
-   struct pci_driver ips_pci_driver = {
-       name:		ips_hot_plug_name,
-       id_table:	ips_pci_table,
-       probe:		ips_insert_device,
-       remove:		ips_remove_device,
-   }; 
-           
-   struct pci_driver ips_pci_driver_anaconda = {
-       name:		ips_hot_plug_name,
-       id_table:	ips_pci_table_anaconda,
-       probe:		ips_insert_device,
-       remove:		ips_remove_device,
-   }; 
-
-   struct pci_driver ips_pci_driver_5i = {
-       name:		ips_hot_plug_name,
-       id_table:	ips_pci_table_5i,
-       probe:		ips_insert_device,
-       remove:		ips_remove_device,
-   };
-           
-   struct pci_driver ips_pci_driver_6i = {
-       name:		ips_hot_plug_name,
-       id_table:	ips_pci_table_6i,
-       probe:		ips_insert_device,
-       remove:		ips_remove_device,
-   };
-
-   struct pci_driver ips_pci_driver_i960 = {
-       name:		ips_hot_plug_name,
-       id_table:	ips_pci_table_i960,
-       probe:		ips_insert_device,
-       remove:		ips_remove_device,
-   };
-
-   struct pci_driver ips_pci_driver_adaptec = {
-       name:		ips_hot_plug_name,
-       id_table:	ips_pci_table_adaptec,
-       probe:		ips_insert_device,
-       remove:		ips_remove_device,
-   };
+static struct pci_device_id ips_pci_table[] __devinitdata = {
+	{0x1014, 0x002E, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+	{0x1014, 0x01BD, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+	{0x9005, 0x0250, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+	{0,}
+};
 
-#endif
+MODULE_DEVICE_TABLE(pci, ips_pci_table);
+
+static char ips_hot_plug_name[] = "ips";
+
+static int __devinit ips_insert_device(struct pci_dev *pci_dev,
+				       const struct pci_device_id *ent);
+static void ips_remove_device(struct pci_dev *pci_dev);
+
+struct pci_driver ips_pci_driver = {
+	.name = ips_hot_plug_name,
+	.id_table = ips_pci_table,
+	.probe = ips_insert_device,
+	.remove = ips_remove_device,
+};
 
 /*
  * Necessary forward function protoypes
  */
 static int ips_halt(struct notifier_block *nb, ulong event, void *buf);
 
-#define MAX_ADAPTER_NAME 11
+#define MAX_ADAPTER_NAME 15
 
 static char ips_adapter_name[][30] = {
-   "ServeRAID",
-   "ServeRAID II",
-   "ServeRAID on motherboard",
-   "ServeRAID on motherboard",
-   "ServeRAID 3H",
-   "ServeRAID 3L",
-   "ServeRAID 4H",
-   "ServeRAID 4M",
-   "ServeRAID 4L",
-   "ServeRAID 4Mx",
-   "ServeRAID 4Lx",
-   "ServeRAID 5i",
-   "ServeRAID 5i",
-   "ServeRAID 6M",
-   "ServeRAID 6i"
+	"ServeRAID",
+	"ServeRAID II",
+	"ServeRAID on motherboard",
+	"ServeRAID on motherboard",
+	"ServeRAID 3H",
+	"ServeRAID 3L",
+	"ServeRAID 4H",
+	"ServeRAID 4M",
+	"ServeRAID 4L",
+	"ServeRAID 4Mx",
+	"ServeRAID 4Lx",
+	"ServeRAID 5i",
+	"ServeRAID 5i",
+	"ServeRAID 6M",
+	"ServeRAID 6i"
 };
 
-/* Init State 0 means we're only looking for a device to provide us the BIOS Adapter Ordering Table */
-/* Init State 1 is when we are actually enumerating the devices.                                    */
-static  int      InitState;
-/* IF BIOS wants to tell us the enumeration order, it puts a table in NVRAM Page 5 */
-static  uint8_t  AdapterOrder[16] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
-
 static struct notifier_block ips_notifier = {
-   ips_halt, NULL, 0
+	ips_halt, NULL, 0
 };
 
 /*
  * Direction table
  */
 static char ips_command_direction[] = {
-IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_IN,   IPS_DATA_IN,   IPS_DATA_OUT,
-IPS_DATA_IN,   IPS_DATA_IN,   IPS_DATA_OUT,  IPS_DATA_IN,   IPS_DATA_UNK,
-IPS_DATA_OUT,  IPS_DATA_OUT,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_IN,   IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_IN,   IPS_DATA_OUT,
-IPS_DATA_IN,   IPS_DATA_OUT,  IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_OUT,
-IPS_DATA_NONE, IPS_DATA_IN,   IPS_DATA_NONE, IPS_DATA_IN,   IPS_DATA_OUT,
-IPS_DATA_NONE, IPS_DATA_UNK,  IPS_DATA_IN,   IPS_DATA_UNK,  IPS_DATA_IN,
-IPS_DATA_UNK,  IPS_DATA_OUT,  IPS_DATA_IN,   IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_IN,   IPS_DATA_IN,   IPS_DATA_OUT,  IPS_DATA_NONE, IPS_DATA_UNK,
-IPS_DATA_IN,   IPS_DATA_OUT,  IPS_DATA_OUT,  IPS_DATA_OUT,  IPS_DATA_OUT,
-IPS_DATA_OUT,  IPS_DATA_NONE, IPS_DATA_IN,   IPS_DATA_NONE, IPS_DATA_NONE,
-IPS_DATA_IN,   IPS_DATA_OUT,  IPS_DATA_OUT,  IPS_DATA_OUT,  IPS_DATA_OUT,
-IPS_DATA_IN,   IPS_DATA_OUT,  IPS_DATA_IN,   IPS_DATA_OUT,  IPS_DATA_OUT,
-IPS_DATA_OUT,  IPS_DATA_IN,   IPS_DATA_IN,   IPS_DATA_IN,   IPS_DATA_NONE,
-IPS_DATA_UNK,  IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_UNK,
-IPS_DATA_NONE, IPS_DATA_OUT,  IPS_DATA_IN,   IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_OUT,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_IN,   IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_UNK,  IPS_DATA_IN,   IPS_DATA_NONE,
-IPS_DATA_OUT,  IPS_DATA_UNK,  IPS_DATA_NONE, IPS_DATA_UNK,  IPS_DATA_OUT,
-IPS_DATA_OUT,  IPS_DATA_OUT,  IPS_DATA_OUT,  IPS_DATA_OUT,  IPS_DATA_NONE,
-IPS_DATA_UNK,  IPS_DATA_IN,   IPS_DATA_OUT,  IPS_DATA_IN,   IPS_DATA_IN,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_OUT,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,
-IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK,  IPS_DATA_UNK
+	IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_IN, IPS_DATA_IN, IPS_DATA_OUT,
+	IPS_DATA_IN, IPS_DATA_IN, IPS_DATA_OUT, IPS_DATA_IN, IPS_DATA_UNK,
+	IPS_DATA_OUT, IPS_DATA_OUT, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_IN, IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_IN, IPS_DATA_OUT,
+	IPS_DATA_IN, IPS_DATA_OUT, IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_OUT,
+	IPS_DATA_NONE, IPS_DATA_IN, IPS_DATA_NONE, IPS_DATA_IN, IPS_DATA_OUT,
+	IPS_DATA_NONE, IPS_DATA_UNK, IPS_DATA_IN, IPS_DATA_UNK, IPS_DATA_IN,
+	IPS_DATA_UNK, IPS_DATA_OUT, IPS_DATA_IN, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_IN, IPS_DATA_IN, IPS_DATA_OUT, IPS_DATA_NONE, IPS_DATA_UNK,
+	IPS_DATA_IN, IPS_DATA_OUT, IPS_DATA_OUT, IPS_DATA_OUT, IPS_DATA_OUT,
+	IPS_DATA_OUT, IPS_DATA_NONE, IPS_DATA_IN, IPS_DATA_NONE, IPS_DATA_NONE,
+	IPS_DATA_IN, IPS_DATA_OUT, IPS_DATA_OUT, IPS_DATA_OUT, IPS_DATA_OUT,
+	IPS_DATA_IN, IPS_DATA_OUT, IPS_DATA_IN, IPS_DATA_OUT, IPS_DATA_OUT,
+	IPS_DATA_OUT, IPS_DATA_IN, IPS_DATA_IN, IPS_DATA_IN, IPS_DATA_NONE,
+	IPS_DATA_UNK, IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_UNK,
+	IPS_DATA_NONE, IPS_DATA_OUT, IPS_DATA_IN, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_OUT, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_IN, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_NONE, IPS_DATA_NONE, IPS_DATA_UNK, IPS_DATA_IN, IPS_DATA_NONE,
+	IPS_DATA_OUT, IPS_DATA_UNK, IPS_DATA_NONE, IPS_DATA_UNK, IPS_DATA_OUT,
+	IPS_DATA_OUT, IPS_DATA_OUT, IPS_DATA_OUT, IPS_DATA_OUT, IPS_DATA_NONE,
+	IPS_DATA_UNK, IPS_DATA_IN, IPS_DATA_OUT, IPS_DATA_IN, IPS_DATA_IN,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_OUT,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK,
+	IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK, IPS_DATA_UNK
 };
 
 /*
@@ -480,9 +367,9 @@
 int ips_release(struct Scsi_Host *);
 int ips_eh_abort(Scsi_Cmnd *);
 int ips_eh_reset(Scsi_Cmnd *);
-int ips_queue(Scsi_Cmnd *, void (*) (Scsi_Cmnd *));
+int ips_queue(Scsi_Cmnd *, void (*)(Scsi_Cmnd *));
 int ips_biosparam(Disk *, kdev_t, int *);
-const char * ips_info(struct Scsi_Host *);
+const char *ips_info(struct Scsi_Host *);
 void do_ipsintr(int, void *, struct pt_regs *);
 static int ips_hainit(ips_ha_t *);
 static int ips_map_status(ips_ha_t *, ips_scb_t *, ips_stat_t *);
@@ -527,10 +414,9 @@
 static int ips_flash_copperhead(ips_ha_t *, ips_passthru_t *, ips_scb_t *);
 static int ips_flash_bios(ips_ha_t *, ips_passthru_t *, ips_scb_t *);
 static int ips_flash_firmware(ips_ha_t *, ips_passthru_t *, ips_scb_t *);
-static void ips_free_flash_copperhead(ips_ha_t *ha);
+static void ips_free_flash_copperhead(ips_ha_t * ha);
 static void ips_get_bios_version(ips_ha_t *, int);
 static void ips_identify_controller(ips_ha_t *);
-static void ips_select_queue_depth(struct Scsi_Host *, Scsi_Device *);
 static void ips_chkstatus(ips_ha_t *, IPS_STATUS *);
 static void ips_enable_int_copperhead(ips_ha_t *);
 static void ips_enable_int_copperhead_memio(ips_ha_t *);
@@ -553,40 +439,43 @@
 static uint32_t ips_statupd_copperhead(ips_ha_t *);
 static uint32_t ips_statupd_copperhead_memio(ips_ha_t *);
 static uint32_t ips_statupd_morpheus(ips_ha_t *);
-static ips_scb_t * ips_getscb(ips_ha_t *);
+static ips_scb_t *ips_getscb(ips_ha_t *);
 static inline void ips_putq_scb_head(ips_scb_queue_t *, ips_scb_t *);
 static inline void ips_putq_scb_tail(ips_scb_queue_t *, ips_scb_t *);
 static inline void ips_putq_wait_head(ips_wait_queue_t *, Scsi_Cmnd *);
 static inline void ips_putq_wait_tail(ips_wait_queue_t *, Scsi_Cmnd *);
-static inline void ips_putq_copp_head(ips_copp_queue_t *, ips_copp_wait_item_t *);
-static inline void ips_putq_copp_tail(ips_copp_queue_t *, ips_copp_wait_item_t *);
-static inline ips_scb_t * ips_removeq_scb_head(ips_scb_queue_t *);
-static inline ips_scb_t * ips_removeq_scb(ips_scb_queue_t *, ips_scb_t *);
-static inline Scsi_Cmnd * ips_removeq_wait_head(ips_wait_queue_t *);
-static inline Scsi_Cmnd * ips_removeq_wait(ips_wait_queue_t *, Scsi_Cmnd *);
-static inline ips_copp_wait_item_t * ips_removeq_copp(ips_copp_queue_t *, ips_copp_wait_item_t *);
-static inline ips_copp_wait_item_t * ips_removeq_copp_head(ips_copp_queue_t *);
+static inline void ips_putq_copp_head(ips_copp_queue_t *,
+				      ips_copp_wait_item_t *);
+static inline void ips_putq_copp_tail(ips_copp_queue_t *,
+				      ips_copp_wait_item_t *);
+static inline ips_scb_t *ips_removeq_scb_head(ips_scb_queue_t *);
+static inline ips_scb_t *ips_removeq_scb(ips_scb_queue_t *, ips_scb_t *);
+static inline Scsi_Cmnd *ips_removeq_wait_head(ips_wait_queue_t *);
+static inline Scsi_Cmnd *ips_removeq_wait(ips_wait_queue_t *, Scsi_Cmnd *);
+static inline ips_copp_wait_item_t *ips_removeq_copp(ips_copp_queue_t *,
+						     ips_copp_wait_item_t *);
+static inline ips_copp_wait_item_t *ips_removeq_copp_head(ips_copp_queue_t *);
 
 static int ips_is_passthru(Scsi_Cmnd *);
 static int ips_make_passthru(ips_ha_t *, Scsi_Cmnd *, ips_scb_t *, int);
 static int ips_usrcmd(ips_ha_t *, ips_passthru_t *, ips_scb_t *);
 static void ips_cleanup_passthru(ips_ha_t *, ips_scb_t *);
+static void ips_scmd_buf_write(Scsi_Cmnd * scmd, void *data,
+			       unsigned int count);
+static void ips_scmd_buf_read(Scsi_Cmnd * scmd, void *data, unsigned int count);
 
-int  ips_proc_info(char *, char **, off_t, int, int, int);
+int ips_proc_info(char *, char **, off_t, int, int, int);
 static int ips_host_info(ips_ha_t *, char *, off_t, int);
 static void copy_mem_info(IPS_INFOSTR *, char *, int);
 static int copy_info(IPS_INFOSTR *, char *, ...);
-static int ips_get_version_info(ips_ha_t *ha, IPS_VERSION_DATA *Buffer, int intr );
-static void ips_version_check(ips_ha_t *ha, int intr);
-static int ips_abort_init(ips_ha_t *ha, struct Scsi_Host *sh, int index);
-static int ips_init_phase2( int index );
-
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
-static int ips_init_phase1( struct pci_dev *pci_dev, int *indexPtr );
-#else
-static int ips_init_oldphase1(Scsi_Host_Template *SHT);
-#endif
+static int ips_get_version_info(ips_ha_t * ha, IPS_VERSION_DATA * Buffer,
+				int intr);
+static void ips_version_check(ips_ha_t * ha, int intr);
+static int ips_abort_init(ips_ha_t * ha, int index);
+static int ips_init_phase2(int index);
 
+static int ips_init_phase1(struct pci_dev *pci_dev, int *indexPtr);
+static int ips_register_scsi(int index);
 /*--------------------------------------------------------------------------*/
 /* Exported Functions                                                       */
 /*--------------------------------------------------------------------------*/
@@ -600,92 +489,52 @@
 /*   setup parameters to the driver                                         */
 /*                                                                          */
 /****************************************************************************/
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
 static int
-ips_setup(char *ips_str) {
-#else
-void
-ips_setup(char *ips_str, int *dummy) {
-#endif
-
-   int        i;
-   char      *key;
-   char      *value;
-   IPS_OPTION options[] = {
-      {"noi2o", &ips_force_i2o, 0},
-      {"nommap", &ips_force_memio, 0},
-      {"ioctlsize", &ips_ioctlsize, IPS_IOCTL_SIZE},
-      {"cdboot", &ips_cd_boot, 0},
-      {"maxcmds", &MaxLiteCmds, 32},
-   };
-    
-   /* Don't use strtok() anymore ( if 2.4 Kernel or beyond ) */
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
-   /* Search for value */
-   while ((key = strsep(&ips_str, ",."))) {
-      if (!*key)
-         continue;
-      value = strchr(key, ':');
-      if (value)
-         *value++ = '\0';
-     /*
-      * We now have key/value pairs.
-      * Update the variables
-      */
-      for (i = 0; i < (sizeof(options) / sizeof(options[0])); i++) {
-        if (strnicmp(key, options[i].option_name, strlen(options[i].option_name)) == 0) {
-           if (value)
-              *options[i].option_flag = simple_strtoul(value, NULL, 0);
-           else
-              *options[i].option_flag = options[i].option_value;
-           break;
-        }
-      }
-   }
-
-   return (1);
-
-#else
-
-   char   *p;
-   char    tokens[3] = {',', '.', 0};
-
-   for (key = strtok(ips_str, tokens); key; key = strtok(NULL, tokens)) {
-      p = key;
-
-      /* Search for value */
-      while ((p) && (*p != ':'))
-         p++;
-
-      if (p) {
-         *p = '\0';
-         value = p+1;
-      } else
-         value = NULL;
-                          
-      /*
-       * We now have key/value pairs.
-       * Update the variables
-       */
-      for (i = 0; i < (sizeof(options) / sizeof(options[0])); i++) {
-         if (strnicmp(key, options[i].option_name, strlen(ips_str)) == 0) {
-            if (value)
-               *options[i].option_flag = simple_strtoul(value, NULL, 0);
-            else
-               *options[i].option_flag = options[i].option_value;
-
-            break;
-         }
-      }
-   }
+ips_setup(char *ips_str)
+{
 
-#endif
+	int i;
+	char *key;
+	char *value;
+	IPS_OPTION options[] = {
+		{"noi2o", &ips_force_i2o, 0},
+		{"nommap", &ips_force_memio, 0},
+		{"ioctlsize", &ips_ioctlsize, IPS_IOCTL_SIZE},
+		{"cdboot", &ips_cd_boot, 0},
+		{"maxcmds", &MaxLiteCmds, 32},
+	};
+
+	/* Don't use strtok() anymore ( if 2.4 Kernel or beyond ) */
+	/* Search for value */
+	while ((key = strsep(&ips_str, ",."))) {
+		if (!*key)
+			continue;
+		value = strchr(key, ':');
+		if (value)
+			*value++ = '\0';
+		/*
+		 * We now have key/value pairs.
+		 * Update the variables
+		 */
+		for (i = 0; i < (sizeof (options) / sizeof (options[0])); i++) {
+			if (strnicmp
+			    (key, options[i].option_name,
+			     strlen(options[i].option_name)) == 0) {
+				if (value)
+					*options[i].option_flag =
+					    simple_strtoul(value, NULL, 0);
+				else
+					*options[i].option_flag =
+					    options[i].option_value;
+				break;
+			}
+		}
+	}
 
+	return (1);
 }
 
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
 __setup("ips=", ips_setup);
-#endif
 
 /****************************************************************************/
 /*                                                                          */
@@ -699,682 +548,97 @@
 /*                                                                          */
 /****************************************************************************/
 int
-ips_detect(Scsi_Host_Template *SHT) {
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
-   int  i;
-#endif
+ips_detect(Scsi_Host_Template * SHT)
+{
+	int i;
 
-   METHOD_TRACE("ips_detect", 1);
+	METHOD_TRACE("ips_detect", 1);
 
 #ifdef MODULE
-   if (ips)
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
-      ips_setup(ips);
-#else
-      ips_setup(ips, NULL);
-#endif
-#endif
-
-   /* If Booting from the Manager CD, Allocate a large Flash        */
-   /* Buffer ( so we won't need to allocate one for each adapter ). */
-    if ( ips_cd_boot ) {            
-      ips_FlashData = ( char * ) __get_free_pages( GFP_KERNEL, 7 );   
-      if (ips_FlashData == NULL) {
-         /* The validity of this pointer is checked in ips_make_passthru() before it is used */
-         printk( KERN_WARNING "ERROR: Can't Allocate Large Buffer for Flashing\n" );
-      }
-   }                                                                               
-   /* initalize number of controllers */
-   ips_num_controllers = 0;
-   ips_next_controller = 0;
-   ips_released_controllers = 0;
-
-   if (!pci_present())
-      return (0);
-
-/**********************************************************************************/
-/* For Kernel Versions 2.4 or greater, use new PCI ( Hot Pluggable ) architecture */
-/**********************************************************************************/
-
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
- #if LINUX_VERSION_CODE < LinuxVersionCode(2,5,0)
-   spin_unlock_irq(&io_request_lock);
- #endif
-   SHT->proc_info = ips_proc_info;
-   SHT->proc_name = "ips";
-
-   /* There are several special cases ( which are too complicated to enumerate here ) where, due */
-   /* to System BIOS rules, the adapters must be enumerated in a certain order.  If ServeRAID    */
-   /* BIOS tells us the order, then we will follow it.  The first pass at init is simply to be   */
-   /* able to communicate with the first adapter to see if BIOS is telling us the order.         */ 
-   /* This does not apply to ia64 EFI BIOS.                                                      */
-
-#if !defined(__ia64__)
-   InitState = 0;
-   pci_module_init(&ips_pci_driver); /* Look for Any Adapter, to fill in the Adapter Order Table */
+	if (ips)
+		ips_setup(ips);
 #endif
 
-   InitState = 1;       
-   
-   if ( AdapterOrder[0] ) {  
-      /* BIOS has dictated the order that we should enumerate Adapters */
-      for ( i = 1; i <= AdapterOrder[0]; i++ ) {
-          switch (AdapterOrder[i]) {
-          case 'M':
-              pci_module_init(&ips_pci_driver_adaptec);     /* Ask for Adaptec Adapters */
-              break;
-          case 'S':
-              pci_module_init(&ips_pci_driver_5i);          /* Ask for 5i Adapters      */
-              pci_module_init(&ips_pci_driver_6i);          /* Ask for 6i Adapters      */
-              break;
-          case 'N':
-              pci_module_init(&ips_pci_driver_i960);        /* Ask for i960 Adapters    */
-              break;
-          case 'A':
-              pci_module_init(&ips_pci_driver_anaconda);    /* Ask for Anaconda Family Adapters */
-              break;
-          default:
-              i = AdapterOrder[0] + 1;                      /* Premature End of List - Ensure Loop Ends */
-              break;
-          }
-      }
-   }
-   else { 
-      /* No Adapter Order Table from BIOS, so sort things the old-fashioned way */
-
-      /* By definition, an Internal ( 5i or 6i ) Adapter MUST be enumerated first */
-      /* or the server may not boot properly. The adapters must be enumerated in  */
-      /* exactly the same order as BIOS for the machine to come up properly.      */
-      /*    NOTE: There will never be both a 5i and a 6i in the same machine.     */
-
-      pci_module_init(&ips_pci_driver_5i);          /* Ask for 5i Adapters First  */
-      if (ips_num_controllers) {                    /* If there is a 5i Adapter   */
-         pci_module_init(&ips_pci_driver_i960);     /*    Get all i960's next     */
-      }
-      else {
-         pci_module_init(&ips_pci_driver_6i);         /* Ask if any 6i Adapters   */
-         if (ips_num_controllers)                     /* If there is a 6i Adapter */
-            pci_module_init(&ips_pci_driver_adaptec); /*    Get all Adaptecs next */
-      }
-
-      pci_module_init(&ips_pci_driver);             /* Get all remaining Adapters */
-                                                    /*  ( in normal BUS order )   */
-   }
-
- #if LINUX_VERSION_CODE < LinuxVersionCode(2,5,0)
-   spin_lock_irq(&io_request_lock);
- #endif
-   if (ips_num_controllers > 0) 
-      register_reboot_notifier(&ips_notifier);
-
-   return (ips_num_controllers);
-#else
-   InitState = 1;
-   SHT->proc_info = ips_proc_info;
-   SHT->proc_dir = &proc_scsi_ips;
-   return ips_init_oldphase1(SHT);
-#endif /* LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0) */
-
-}
-
-#if LINUX_VERSION_CODE < LinuxVersionCode(2,4,0)
-
-/***********************************************************************************/
-/*   Sort the Device Structures                                                    */
-/*   Devices are sorted by groups ( type ) and then PCI address within each group  */  
-/*   This also results in the same ordering that results when using the 2.4 kernel */
-/*   architecture for initialization.                                              */
-/***********************************************************************************/
-
-static void 
-ips_sort_controllers(struct pci_dev *dev[]) {
-   struct pci_dev *tempdev[IPS_MAX_ADAPTERS];
-   struct pci_dev *lowestdev;
-   int             i, j;
-   int             temp_index = 0;    /* Index into tempdev[] array */    
-   int             lowIndex = 0;
-   int             newlowflag = 0;    /* Flag to indicate when a new low address has been found */
-   uint16_t        subdevice_id;
-   unsigned char   BusNumber;
-
-   /* Clear the Temporary Dev Structure */
-   for (i = 0; i < IPS_MAX_ADAPTERS; i++) 
-       tempdev[i] = NULL;
-
-   /* The Outer Loop goes thru each Adapter Type Supported */
-   for (j = 0; j < IPS_MAX_ADAPTER_TYPES; j++) {
-      lowestdev = NULL;
-      /* The Inner Loop Checks each Device still in the List and */
-      /* Finds the lowset adapter left ( by PCI boot order )     */
-      for (i = 0; i < IPS_MAX_ADAPTERS; i++) {
-         if (dev[i]) {
-            if (lowestdev == NULL) {  /* If this is the first one found, it must be the lowest ! */
-               lowestdev = dev[i];
-               lowIndex = i;
-            }
-
-            /* If you find a Sarasota ( 5i ), it must always be treated as the first adapter */
-            if (dev[i]->device == IPS_DEVICEID_MORPHEUS) {
-                pci_read_config_word(dev[i], PCI_SUBSYSTEM_ID, &subdevice_id);
-                if ((subdevice_id == IPS_SUBDEVICEID_5I1) || 
-                    (subdevice_id == IPS_SUBDEVICEID_5I2)) {
-                     lowestdev = dev[i];
-                     lowIndex = i;
-                     break;
-                }
-            } 
-
-            /* If you find a Sebring ( 6i ), it must always be treated as the first adapter */
-            if (dev[i]->device == IPS_DEVICEID_MARCO) {
-                pci_read_config_word(dev[i], PCI_SUBSYSTEM_ID, &subdevice_id);
-                if (subdevice_id == IPS_SUBDEVICEID_6I) {
-                    lowestdev = dev[i];
-                    lowIndex = i;
-                    break;
-                }
-            }    
-
-            /* Determine if this device is at a lower PCI address than the current lowest device */
-            newlowflag = 0;
-
-            if (dev[i]->device == IPS_DEVICEID_MARCO)     /* System BIOS adds 1 to Marco Bus Number */
-                BusNumber = ( dev[i]->bus->number ) - 1;  /*        because of Bridge Chip          */
-            else
-                BusNumber = dev[i]->bus->number;
-
-            if (BusNumber < lowestdev->bus->number)        /* IF a lower BUS # */
-                newlowflag = i;
-
-            if ((BusNumber == lowestdev->bus->number) &&   /* If Same Bus #, but a lower device # */
-                (dev[i]->devfn < lowestdev->devfn)) 
-                newlowflag = i;
-
-            if ( newlowflag ) {
-                lowestdev = dev[i];
-                lowIndex = i;
-            }
-         }
-      }
-                                                                                     
-      if (lowestdev) {                       /* If we found another adapter */
-         tempdev[temp_index] = lowestdev;    /*    Add it in the list       */
-         dev[lowIndex] = NULL;               /*    Null it out so we don't find it again */
-         temp_index++;
-         /* Now get all the adapters that are the same type as the low one      . */
-         /* They will already be in order, so they don't need any further sorting.*/
-         for (i = 0; i < IPS_MAX_ADAPTERS; i++) {
-            if (dev[i]) {
-               if (dev[i]->device == lowestdev->device) {
-                  tempdev[temp_index] = dev[i];  /* Add the same type adapter to the list */
-                  temp_index++;                    
-                  dev[i] = NULL;                 /* Null it out so we don't find it again */
-               }                           
-            }
-         }
-      }
-   }
-
-   /* Copy the Sorted Adapter Pointers ( tempdev[] ) to the Original Structure */
-   for (i = 0; i < IPS_MAX_ADAPTERS; i++) 
-       dev[i] = tempdev[i];
+	/* If Booting from the Manager CD, Allocate a large Flash        */
+	/* Buffer ( so we won't need to allocate one for each adapter ). */
+	if (ips_cd_boot) {
+		ips_FlashData = (char *) __get_free_pages(IPS_INIT_GFP, 7);
+		if (ips_FlashData == NULL) {
+			/* The validity of this pointer is checked in ips_make_passthru() before it is used */
+			printk(KERN_WARNING
+			       "ERROR: Can't Allocate Large Buffer for Flashing\n");
+		}
+	}
+
+	SHT->proc_info = ips_proc_info;
+	SHT->proc_name = "ips";
+
+	for (i = 0; i < ips_num_controllers; i++) {
+		if (ips_register_scsi(i))
+			ips_free(ips_ha[i]);
+		ips_released_controllers++;
+	}
 
+	return (ips_num_controllers);
 }
 
 /****************************************************************************/
-/*   Detect and initialize the driver for 2.2 kernels                       */
-/*                                                                          */
-/* NOTE: this routine is called under the io_request_lock spinlock          */
-/****************************************************************************/
-static int ips_init_oldphase1(Scsi_Host_Template *SHT){
-   struct Scsi_Host *sh;
-   ips_ha_t         *ha;
-   uint32_t          io_addr;
-   uint32_t          mem_addr;
-   uint32_t          io_len;
-   uint32_t          mem_len;
-   uint16_t          planer;
-   uint8_t           revision_id;
-   uint8_t           bus;
-   uint8_t           func;
-   uint8_t           irq;
-   uint16_t          subdevice_id;
-   int               i;
-   int               j;
-   uint32_t          count;
-   char             *ioremap_ptr;
-   char             *mem_ptr;
-   struct pci_dev   *dev[IPS_MAX_ADAPTERS];
-   dma_addr_t        dma_address;
-   uint32_t          currbar;
-   uint32_t          maskbar;
-   uint8_t           barnum;
-   uint32_t          IsDead;
-
-   METHOD_TRACE("ips_init_oldphase1", 1);
-   
-   for ( i = 0; i < IPS_MAX_ADAPTERS; i++ ) 
-       dev[i] = NULL;
-   
-   /* Find all the adapters that we support and save them in the dev[] structure */
-   i = 0;
-   dev[i] = pci_find_device(IPS_VENDORID_IBM, IPS_DEVICEID_MORPHEUS, NULL);
-   while ( dev[i] ) {
-      i++;
-      dev[i] = pci_find_device(IPS_VENDORID_IBM, IPS_DEVICEID_MORPHEUS, dev[i-1]);
-   }
-
-   dev[i] = pci_find_device(IPS_VENDORID_IBM, IPS_DEVICEID_COPPERHEAD, NULL);
-   while ( dev[i] ) {
-       i++;
-       dev[i] = pci_find_device(IPS_VENDORID_IBM, IPS_DEVICEID_COPPERHEAD, dev[i-1]);
-   }
-
-   dev[i] = pci_find_device(IPS_VENDORID_ADAPTEC, IPS_DEVICEID_MARCO, NULL);
-   while ( dev[i] ) {
-       i++;
-       dev[i] = pci_find_device(IPS_VENDORID_IBM, IPS_DEVICEID_MARCO, dev[i-1]);
-   }
-     
-   /* Sort the Adapters */
-   if ( dev[0] ) 
-      ips_sort_controllers( dev );
-   else
-      return (0);    
-
-   /* Now scan and Initialize the controllers */
-   for ( i = 0; i < IPS_MAX_ADAPTERS; i++ ) {
-      if (!dev[i])
-         break;
-
-      if (ips_next_controller >= IPS_MAX_ADAPTERS)
-         break;
-
-      /* stuff that we get in dev */
-      irq = dev[i]->irq;
-      bus = dev[i]->bus->number;
-      func = dev[i]->devfn;
-
-      /* Init MEM/IO addresses to 0 */
-      mem_addr = 0;
-      io_addr = 0;
-      mem_len = 0;
-      io_len = 0;
-
-      for (j = 0; j < 2; j++) {
-         if (!dev[i]->base_address[j])
-            break;
-
-         if ((dev[i]->base_address[j] & PCI_BASE_ADDRESS_SPACE) == PCI_BASE_ADDRESS_SPACE_IO) {
-            barnum = PCI_BASE_ADDRESS_0 + (j * 4);
-            io_addr = dev[i]->base_address[j] & PCI_BASE_ADDRESS_IO_MASK;
-
-            /* Get Size */
-            pci_read_config_dword(dev[i], barnum, &currbar);
-            pci_write_config_dword(dev[i], barnum, ~0);
-            pci_read_config_dword(dev[i], barnum, &maskbar);
-            pci_write_config_dword(dev[i], barnum, currbar);
-
-            io_len = ~(maskbar & PCI_BASE_ADDRESS_IO_MASK) + 1;
-        } else {
-            barnum = PCI_BASE_ADDRESS_0 + (j * 4);
-            mem_addr = dev[i]->base_address[j] & PCI_BASE_ADDRESS_MEM_MASK;
-
-            /* Get Size */
-            pci_read_config_dword(dev[i], barnum, &currbar);
-            pci_write_config_dword(dev[i], barnum, ~0);
-            pci_read_config_dword(dev[i], barnum, &maskbar);
-            pci_write_config_dword(dev[i], barnum, currbar);
-
-            mem_len = ~(maskbar & PCI_BASE_ADDRESS_MEM_MASK) + 1;
-         }
-      }
-
-      /* setup memory mapped area (if applicable) */
-      if (mem_addr) {
-         uint32_t base;
-         uint32_t offs;
-
-         DEBUG_VAR(1, "(%s%d) detect, Memory region %x, size: %d",
-                   ips_name, ips_next_controller, mem_addr, mem_len);
-
-         base = mem_addr & PAGE_MASK;
-         offs = mem_addr - base;
-
-         ioremap_ptr = ioremap(base, PAGE_SIZE);
-         mem_ptr = ioremap_ptr + offs;
-      } else {
-         ioremap_ptr = NULL;
-         mem_ptr = NULL;
-      }
-
-      /* setup I/O mapped area (if applicable) */
-      if (io_addr) {
-         DEBUG_VAR(1, "(%s%d) detect, IO region %x, size: %d",
-                   ips_name, ips_next_controller, io_addr, io_len);
-
-         if (check_region(io_addr, io_len)) {
-             /* Couldn't allocate io space */
-            printk(KERN_WARNING "(%s%d) couldn't allocate IO space %x len %d.\n",
-                   ips_name, ips_next_controller, io_addr, io_len);
-
-            ips_next_controller++;
-
-            continue;
-         }
-
-         request_region(io_addr, io_len, "ips");
-      }
-
-      /* get planer status */
-      if (pci_read_config_word(dev[i], 0x04, &planer)) {
-         printk(KERN_WARNING "(%s%d) can't get planer status.\n",
-                ips_name, ips_next_controller);
-
-         ips_next_controller++;
-
-         continue;
-      }
-
-      /* check to see if an onboard planer controller is disabled */
-      if (!(planer & 0x000C)) {
-
-         DEBUG_VAR(1, "(%s%d) detect, Onboard controller disabled by BIOS",
-                   ips_name, ips_next_controller);
-
-         ips_next_controller++;
-
-         continue;
-      }
-
-      DEBUG_VAR(1, "(%s%d) detect bus %d, func %x, irq %d, io %x, mem: %x, ptr: %p",
-                ips_name, ips_next_controller, bus, func, irq, io_addr, mem_addr, mem_ptr);
-
-      /* get the revision ID */
-      if (pci_read_config_byte(dev[i], PCI_REVISION_ID, &revision_id)) {
-          printk(KERN_WARNING "(%s%d) can't get revision id.\n",
-                 ips_name, ips_next_controller);
-
-        ips_next_controller++;
-        continue;
-      }
-
-      /* get the subdevice id */
-      if (pci_read_config_word(dev[i], PCI_SUBSYSTEM_ID, &subdevice_id)) {
-         printk(KERN_WARNING "(%s%d) can't get subdevice id.\n",
-                ips_name, ips_next_controller);
-
-         ips_next_controller++;
-
-         continue;
-      }
-
-      /* found a controller */
-      sh = scsi_register(SHT, sizeof(ips_ha_t));
-
-      if (sh == NULL) {
-         printk(KERN_WARNING "(%s%d) Unable to register controller with SCSI subsystem - skipping controller\n",
-                ips_name, ips_next_controller);
-
-         ips_next_controller++;
-
-         continue;
-      }
-
-      ha = IPS_HA(sh);
-      memset(ha, 0, sizeof(ips_ha_t));
-
-      ips_sh[ips_next_controller] = sh;
-      ips_ha[ips_next_controller] = ha;
-      ips_num_controllers++;
-      ha->active = 1;
-
-      ha->enq = kmalloc(sizeof(IPS_ENQ), GFP_KERNEL);
-
-      if (!ha->enq) {
-         printk(KERN_WARNING "(%s%d) Unable to allocate host inquiry structure - skipping contoller\n",
-                ips_name, ips_next_controller);
-         ips_abort_init(ha, sh, ips_next_controller);
-         ips_next_controller++;
-         ips_num_controllers--;
-
-         continue;
-      }
-
-      ha->adapt = pci_alloc_consistent(dev[i], sizeof(IPS_ADAPTER) + sizeof(IPS_IO_CMD), &dma_address);
-
-      if (!ha->adapt) {
-         printk(KERN_WARNING "(%s%d) Unable to allocate host adapt and dummy structure - skipping controller\n",
-                ips_name, ips_next_controller);
-         ips_abort_init(ha, sh, ips_next_controller);
-         ips_next_controller++;
-         ips_num_controllers--;
-
-         continue;
-      }
-      ha->adapt->hw_status_start = dma_address;
-      ha->dummy = (void *)ha->adapt + 1;
-
-      ha->conf = kmalloc(sizeof(IPS_CONF), GFP_KERNEL);
-
-      if (!ha->conf) {
-         printk(KERN_WARNING "(%s%d) Unable to allocate host conf structure - skipping controller\n",
-                ips_name, ips_next_controller);
-         ips_abort_init(ha, sh, ips_next_controller);
-         ips_next_controller++;
-         ips_num_controllers--;
-
-         continue;
-      }
-
-      ha->nvram = kmalloc(sizeof(IPS_NVRAM_P5), GFP_KERNEL);
-
-      if (!ha->nvram) {
-         printk(KERN_WARNING "(%s%d) Unable to allocate host nvram structure - skipping controller\n",
-                ips_name, ips_next_controller);
-         ips_abort_init(ha, sh, ips_next_controller);
-         ips_next_controller++;
-         ips_num_controllers--;
-
-         continue;
-      }
-
-      ha->subsys = kmalloc(sizeof(IPS_SUBSYS), GFP_KERNEL);
-
-      if (!ha->subsys) {
-         printk(KERN_WARNING "(%s%d) Unable to allocate host subsystem structure - skipping controller\n",
-                ips_name, ips_next_controller);
-         ips_abort_init(ha, sh, ips_next_controller);
-         ips_next_controller++;
-         ips_num_controllers--;
-
-         continue;
-      }
-
-      for (count = PAGE_SIZE, ha->ioctl_order = 0;
-           count < ips_ioctlsize;
-           ha->ioctl_order++, count <<= 1);
-
-      ha->ioctl_data = (char *) __get_free_pages(GFP_KERNEL, ha->ioctl_order);
-      ha->ioctl_datasize = count;
-
-      if (!ha->ioctl_data) {
-         printk(KERN_WARNING "(%s%d) Unable to allocate ioctl data\n",
-                ips_name, ips_next_controller);
-
-         ha->ioctl_data = NULL;
-         ha->ioctl_order = 0;
-         ha->ioctl_datasize = 0;
-      }
-
-      /* Store away needed values for later use */
-      sh->io_port = io_addr;
-      sh->n_io_port = io_addr ? 255 : 0;
-      sh->unique_id = (io_addr) ? io_addr : mem_addr;
-      sh->irq = irq;
-      sh->select_queue_depths = ips_select_queue_depth;
-      sh->sg_tablesize = sh->hostt->sg_tablesize;
-      sh->can_queue = sh->hostt->can_queue;
-      sh->cmd_per_lun = sh->hostt->cmd_per_lun;
-      sh->unchecked_isa_dma = sh->hostt->unchecked_isa_dma;
-      sh->use_clustering = sh->hostt->use_clustering;
-
-      sh->wish_block = FALSE;
-
-      /* Store info in HA structure */
-      ha->irq = irq;
-      ha->io_addr = io_addr;
-      ha->io_len = io_len;
-      ha->mem_addr = mem_addr;
-      ha->mem_len = mem_len;
-      ha->mem_ptr = mem_ptr;
-      ha->ioremap_ptr = ioremap_ptr;
-      ha->host_num = ips_next_controller;
-      ha->revision_id = revision_id;
-      ha->slot_num = PCI_SLOT(dev[i]->devfn);
-      ha->device_id = dev[i]->device;
-      ha->subdevice_id = subdevice_id;
-      ha->pcidev = dev[i];
-
-      /*
-       * Setup Functions
-       */
-      ips_setup_funclist(ha);
-            
-      /* If Morpheus appears dead, reset it */
-      if ( ( IPS_IS_MORPHEUS( ha ) ) || ( IPS_IS_MARCO( ha ) ) ) {
-          IsDead = readl( ha->mem_ptr + IPS_REG_I960_MSG1 );
-          if ( IsDead == 0xDEADBEEF ) {
-              ips_reset_morpheus( ha );
-          }
-      }
-
-      /*
-       * Initialize the card if it isn't already
-       */
-
-      if (!(*ha->func.isinit)(ha)) {
-         if (!(*ha->func.init)(ha)) {
-            /*
-             * Initialization failed
-             */
-            printk(KERN_WARNING "(%s%d) unable to initialize controller - skipping controller\n",
-                   ips_name, ips_next_controller);
-            ips_abort_init(ha, sh, ips_next_controller);
-            ips_next_controller++;
-            ips_num_controllers--;
-
-            continue;
-         }
-      }
-
-      /* install the interrupt handler */
-      if (request_irq(irq, do_ipsintr, SA_SHIRQ, ips_name, ha)) {
-         printk(KERN_WARNING "(%s%d) unable to install interrupt handler - skipping controller\n",
-                ips_name, ips_next_controller);
-         ips_abort_init(ha, sh, ips_next_controller);
-         ips_next_controller++;
-         ips_num_controllers--;
-
-         continue;
-      }
-
-      /*
-       * Allocate a temporary SCB for initialization
-       */
-      ha->max_cmds = 1;
-      if (!ips_allocatescbs(ha)) {
-         /* couldn't allocate a temp SCB */
-         printk(KERN_WARNING "(%s%d) unable to allocate CCBs - skipping contoller\n",
-                ips_name, ips_next_controller);
-         free_irq(ha->irq, ha);
-         ips_abort_init(ha, sh, ips_next_controller);
-         ips_next_controller++;
-         ips_num_controllers--;
-
-         continue;
-      }
-
-      ips_next_controller++;
-   }
-
-   /*
-    * Do Phase 2 Initialization
-    * Controller init
-    */
-   for (i = 0; i < ips_next_controller; i++) {
-
-      if (ips_ha[i] == 0) {
-         printk(KERN_WARNING "(%s%d) ignoring bad controller\n", ips_name, i);
-         continue;
-      }
-
-      if (ips_init_phase2(i) != SUCCESS)
-         ips_num_controllers--;
-
-   }
-
-   if (ips_num_controllers > 0)
-      register_reboot_notifier(&ips_notifier);
-
-   return (ips_num_controllers);
-}
-#endif
-
-/****************************************************************************/
 /*   configure the function pointers to use the functions that will work    */
 /*   with the found version of the adapter                                  */
 /****************************************************************************/
-static void ips_setup_funclist(ips_ha_t *ha){
+static void
+ips_setup_funclist(ips_ha_t * ha)
+{
 
-   /*                                
-    * Setup Functions
-    */
-   if (IPS_IS_MORPHEUS(ha) || IPS_IS_MARCO(ha)) {
-      /* morpheus / marco / sebring */
-      ha->func.isintr = ips_isintr_morpheus;
-      ha->func.isinit = ips_isinit_morpheus;
-      ha->func.issue = ips_issue_i2o_memio;
-      ha->func.init = ips_init_morpheus;
-      ha->func.statupd = ips_statupd_morpheus;
-      ha->func.reset = ips_reset_morpheus;
-      ha->func.intr = ips_intr_morpheus;
-      ha->func.enableint = ips_enable_int_morpheus;
-   } else if (IPS_USE_MEMIO(ha)) {
-      /* copperhead w/MEMIO */
-      ha->func.isintr = ips_isintr_copperhead_memio;
-      ha->func.isinit = ips_isinit_copperhead_memio;
-      ha->func.init = ips_init_copperhead_memio;
-      ha->func.statupd = ips_statupd_copperhead_memio;
-      ha->func.statinit = ips_statinit_memio;
-      ha->func.reset = ips_reset_copperhead_memio;
-      ha->func.intr = ips_intr_copperhead;
-      ha->func.erasebios = ips_erase_bios_memio;
-      ha->func.programbios = ips_program_bios_memio;
-      ha->func.verifybios = ips_verify_bios_memio;
-      ha->func.enableint = ips_enable_int_copperhead_memio;
-      if (IPS_USE_I2O_DELIVER(ha))
-         ha->func.issue = ips_issue_i2o_memio;
-      else
-         ha->func.issue = ips_issue_copperhead_memio;
-   } else {
-      /* copperhead */
-      ha->func.isintr = ips_isintr_copperhead;
-      ha->func.isinit = ips_isinit_copperhead;
-      ha->func.init = ips_init_copperhead;
-      ha->func.statupd = ips_statupd_copperhead;
-      ha->func.statinit = ips_statinit;
-      ha->func.reset = ips_reset_copperhead;
-      ha->func.intr = ips_intr_copperhead;
-      ha->func.erasebios = ips_erase_bios;
-      ha->func.programbios = ips_program_bios;
-      ha->func.verifybios = ips_verify_bios;
-      ha->func.enableint = ips_enable_int_copperhead;
-
-      if (IPS_USE_I2O_DELIVER(ha))
-         ha->func.issue = ips_issue_i2o;
-      else
-         ha->func.issue = ips_issue_copperhead;
-   }
+	/*                                
+	 * Setup Functions
+	 */
+	if (IPS_IS_MORPHEUS(ha) || IPS_IS_MARCO(ha)) {
+		/* morpheus / marco / sebring */
+		ha->func.isintr = ips_isintr_morpheus;
+		ha->func.isinit = ips_isinit_morpheus;
+		ha->func.issue = ips_issue_i2o_memio;
+		ha->func.init = ips_init_morpheus;
+		ha->func.statupd = ips_statupd_morpheus;
+		ha->func.reset = ips_reset_morpheus;
+		ha->func.intr = ips_intr_morpheus;
+		ha->func.enableint = ips_enable_int_morpheus;
+	} else if (IPS_USE_MEMIO(ha)) {
+		/* copperhead w/MEMIO */
+		ha->func.isintr = ips_isintr_copperhead_memio;
+		ha->func.isinit = ips_isinit_copperhead_memio;
+		ha->func.init = ips_init_copperhead_memio;
+		ha->func.statupd = ips_statupd_copperhead_memio;
+		ha->func.statinit = ips_statinit_memio;
+		ha->func.reset = ips_reset_copperhead_memio;
+		ha->func.intr = ips_intr_copperhead;
+		ha->func.erasebios = ips_erase_bios_memio;
+		ha->func.programbios = ips_program_bios_memio;
+		ha->func.verifybios = ips_verify_bios_memio;
+		ha->func.enableint = ips_enable_int_copperhead_memio;
+		if (IPS_USE_I2O_DELIVER(ha))
+			ha->func.issue = ips_issue_i2o_memio;
+		else
+			ha->func.issue = ips_issue_copperhead_memio;
+	} else {
+		/* copperhead */
+		ha->func.isintr = ips_isintr_copperhead;
+		ha->func.isinit = ips_isinit_copperhead;
+		ha->func.init = ips_init_copperhead;
+		ha->func.statupd = ips_statupd_copperhead;
+		ha->func.statinit = ips_statinit;
+		ha->func.reset = ips_reset_copperhead;
+		ha->func.intr = ips_intr_copperhead;
+		ha->func.erasebios = ips_erase_bios;
+		ha->func.programbios = ips_program_bios;
+		ha->func.verifybios = ips_verify_bios;
+		ha->func.enableint = ips_enable_int_copperhead;
+
+		if (IPS_USE_I2O_DELIVER(ha))
+			ha->func.issue = ips_issue_i2o;
+		else
+			ha->func.issue = ips_issue_copperhead;
+	}
 }
 
 /****************************************************************************/
@@ -1387,79 +651,72 @@
 /*                                                                          */
 /****************************************************************************/
 int
-ips_release(struct Scsi_Host *sh) {
-   ips_scb_t *scb;
-   ips_ha_t  *ha;
-   int        i;
-
-   METHOD_TRACE("ips_release", 1);
-
-   for (i = 0; i < IPS_MAX_ADAPTERS && ips_sh[i] != sh; i++);
-
-   if (i == IPS_MAX_ADAPTERS) {
-      printk(KERN_WARNING "(%s) release, invalid Scsi_Host pointer.\n",
-            ips_name);
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
-      BUG();
-#endif
-      return (FALSE);
-   }
+ips_release(struct Scsi_Host *sh)
+{
+	ips_scb_t *scb;
+	ips_ha_t *ha;
+	int i;
 
-   ha = IPS_HA(sh);
+	METHOD_TRACE("ips_release", 1);
 
-   if (!ha)
-      return (FALSE);
+	for (i = 0; i < IPS_MAX_ADAPTERS && ips_sh[i] != sh; i++) ;
 
-   /* flush the cache on the controller */
-   scb = &ha->scbs[ha->max_cmds-1];
+	if (i == IPS_MAX_ADAPTERS) {
+		printk(KERN_WARNING
+		       "(%s) release, invalid Scsi_Host pointer.\n", ips_name);
+		BUG();
+		return (FALSE);
+	}
 
-   ips_init_scb(ha, scb);
+	ha = IPS_HA(sh);
 
-   scb->timeout = ips_cmd_timeout;
-   scb->cdb[0] = IPS_CMD_FLUSH;
+	if (!ha)
+		return (FALSE);
 
-   scb->cmd.flush_cache.op_code = IPS_CMD_FLUSH;
-   scb->cmd.flush_cache.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->cmd.flush_cache.state = IPS_NORM_STATE;
-   scb->cmd.flush_cache.reserved = 0;
-   scb->cmd.flush_cache.reserved2 = 0;
-   scb->cmd.flush_cache.reserved3 = 0;
-   scb->cmd.flush_cache.reserved4 = 0;
+	/* flush the cache on the controller */
+	scb = &ha->scbs[ha->max_cmds - 1];
 
-   if (InitState != 0)    /* If Not just Searching for the Adapter Order Table */
-      printk(KERN_NOTICE "(%s%d) Flushing Cache.\n", ips_name, ha->host_num);
+	ips_init_scb(ha, scb);
 
-   /* send command */
-   if (ips_send_wait(ha, scb, ips_cmd_timeout, IPS_INTR_ON) == IPS_FAILURE)
-      printk(KERN_NOTICE "(%s%d) Incomplete Flush.\n", ips_name, ha->host_num);
+	scb->timeout = ips_cmd_timeout;
+	scb->cdb[0] = IPS_CMD_FLUSH;
 
-   if (InitState != 0)    /* If Not just Searching for the Adapter Order Table */
-      printk(KERN_NOTICE "(%s%d) Flushing Complete.\n", ips_name, ha->host_num);
+	scb->cmd.flush_cache.op_code = IPS_CMD_FLUSH;
+	scb->cmd.flush_cache.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->cmd.flush_cache.state = IPS_NORM_STATE;
+	scb->cmd.flush_cache.reserved = 0;
+	scb->cmd.flush_cache.reserved2 = 0;
+	scb->cmd.flush_cache.reserved3 = 0;
+	scb->cmd.flush_cache.reserved4 = 0;
 
-   ips_sh[i] = NULL;
-   ips_ha[i] = NULL;
+	printk(KERN_NOTICE "(%s%d) Flushing Cache.\n", ips_name, ha->host_num);
 
-   /* free extra memory */
-   ips_free(ha);
+	/* send command */
+	if (ips_send_wait(ha, scb, ips_cmd_timeout, IPS_INTR_ON) == IPS_FAILURE)
+		printk(KERN_NOTICE "(%s%d) Incomplete Flush.\n", ips_name,
+		       ha->host_num);
 
-   /* Free I/O Region */
-   if (ha->io_addr)
-      release_region(ha->io_addr, ha->io_len);
+	printk(KERN_NOTICE "(%s%d) Flushing Complete.\n", ips_name,
+	       ha->host_num);
 
-   /* free IRQ */
-   free_irq(ha->irq, ha);
+	ips_sh[i] = NULL;
+	ips_ha[i] = NULL;
 
-   scsi_unregister(sh);
+	/* free extra memory */
+	ips_free(ha);
 
-   if (InitState != 0) {
-      ips_released_controllers++;
-      if (ips_num_controllers == ips_released_controllers){
-         unregister_reboot_notifier(&ips_notifier);
-         pci_unregister_driver(ha->pcidev->driver);
-      }
-   }
+	/* Free I/O Region */
+	if (ha->io_addr)
+		release_region(ha->io_addr, ha->io_len);
 
-   return (FALSE);
+	/* free IRQ */
+	free_irq(ha->irq, ha);
+
+	scsi_unregister(sh);
+
+	ips_released_controllers++;
+
+	return (FALSE);
 }
 
 /****************************************************************************/
@@ -1472,50 +729,54 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_halt(struct notifier_block *nb, ulong event, void *buf) {
-   ips_scb_t *scb;
-   ips_ha_t  *ha;
-   int        i;
-
-   if ((event != SYS_RESTART) && (event != SYS_HALT) &&
-       (event != SYS_POWER_OFF))
-      return (NOTIFY_DONE);
-
-   for (i = 0; i < ips_next_controller; i++) {
-      ha = (ips_ha_t *) ips_ha[i];
-
-      if (!ha)
-         continue;
-
-      if (!ha->active)
-         continue;
-
-      /* flush the cache on the controller */
-      scb = &ha->scbs[ha->max_cmds-1];
-
-      ips_init_scb(ha, scb);
-
-      scb->timeout = ips_cmd_timeout;
-      scb->cdb[0] = IPS_CMD_FLUSH;
-
-      scb->cmd.flush_cache.op_code = IPS_CMD_FLUSH;
-      scb->cmd.flush_cache.command_id = IPS_COMMAND_ID(ha, scb);
-      scb->cmd.flush_cache.state = IPS_NORM_STATE;
-      scb->cmd.flush_cache.reserved = 0;
-      scb->cmd.flush_cache.reserved2 = 0;
-      scb->cmd.flush_cache.reserved3 = 0;
-      scb->cmd.flush_cache.reserved4 = 0;
-
-      printk(KERN_NOTICE "(%s%d) Flushing Cache.\n", ips_name, ha->host_num);
-
-      /* send command */
-      if (ips_send_wait(ha, scb, ips_cmd_timeout, IPS_INTR_ON) == IPS_FAILURE)
-         printk(KERN_NOTICE "(%s%d) Incomplete Flush.\n", ips_name, ha->host_num);
-      else
-         printk(KERN_NOTICE "(%s%d) Flushing Complete.\n", ips_name, ha->host_num);
-   }
+ips_halt(struct notifier_block *nb, ulong event, void *buf)
+{
+	ips_scb_t *scb;
+	ips_ha_t *ha;
+	int i;
+
+	if ((event != SYS_RESTART) && (event != SYS_HALT) &&
+	    (event != SYS_POWER_OFF)) return (NOTIFY_DONE);
+
+	for (i = 0; i < ips_next_controller; i++) {
+		ha = (ips_ha_t *) ips_ha[i];
+
+		if (!ha)
+			continue;
+
+		if (!ha->active)
+			continue;
+
+		/* flush the cache on the controller */
+		scb = &ha->scbs[ha->max_cmds - 1];
+
+		ips_init_scb(ha, scb);
+
+		scb->timeout = ips_cmd_timeout;
+		scb->cdb[0] = IPS_CMD_FLUSH;
+
+		scb->cmd.flush_cache.op_code = IPS_CMD_FLUSH;
+		scb->cmd.flush_cache.command_id = IPS_COMMAND_ID(ha, scb);
+		scb->cmd.flush_cache.state = IPS_NORM_STATE;
+		scb->cmd.flush_cache.reserved = 0;
+		scb->cmd.flush_cache.reserved2 = 0;
+		scb->cmd.flush_cache.reserved3 = 0;
+		scb->cmd.flush_cache.reserved4 = 0;
+
+		printk(KERN_NOTICE "(%s%d) Flushing Cache.\n", ips_name,
+		       ha->host_num);
+
+		/* send command */
+		if (ips_send_wait(ha, scb, ips_cmd_timeout, IPS_INTR_ON) ==
+		    IPS_FAILURE) printk(KERN_NOTICE
+					"(%s%d) Incomplete Flush.\n", ips_name,
+					ha->host_num);
+		else
+			printk(KERN_NOTICE "(%s%d) Flushing Complete.\n",
+			       ips_name, ha->host_num);
+	}
 
-   return (NOTIFY_OK);
+	return (NOTIFY_OK);
 }
 
 /****************************************************************************/
@@ -1528,50 +789,51 @@
 /* Note: this routine is called under the io_request_lock                   */
 /****************************************************************************/
 int
-ips_eh_abort(Scsi_Cmnd *SC) {
-   ips_ha_t         *ha;
-   ips_copp_wait_item_t *item;
-   int ret;
-
-   METHOD_TRACE("ips_eh_abort", 1);
-
-   if (!SC)
-      return (FAILED);
-
-   ha = (ips_ha_t *) SC->host->hostdata;
-
-   if (!ha)
-      return (FAILED);
-
-   if (!ha->active)
-      return (FAILED);
-
-   if (SC->serial_number != SC->serial_number_at_timeout) {
-      /* HMM, looks like a bogus command */
-      DEBUG(1, "Abort called with bogus scsi command");
-
-      return (FAILED);
-   }
-
-   /* See if the command is on the copp queue */
-   item = ha->copp_waitlist.head;
-   while ((item) && (item->scsi_cmd != SC))
-      item = item->next;
-
-   if (item) {
-      /* Found it */
-      ips_removeq_copp(&ha->copp_waitlist, item);
-      ret = (SUCCESS);
-
-   /* See if the command is on the wait queue */
-   } else if (ips_removeq_wait(&ha->scb_waitlist, SC)) {
-      /* command not sent yet */
-      ret = (SUCCESS);
-   } else {
-      /* command must have already been sent */
-      ret = (FAILED);
-   }
-   return ret;
+ips_eh_abort(Scsi_Cmnd * SC)
+{
+	ips_ha_t *ha;
+	ips_copp_wait_item_t *item;
+	int ret;
+
+	METHOD_TRACE("ips_eh_abort", 1);
+
+	if (!SC)
+		return (FAILED);
+
+	ha = (ips_ha_t *) SC->host->hostdata;
+
+	if (!ha)
+		return (FAILED);
+
+	if (!ha->active)
+		return (FAILED);
+
+	if (SC->serial_number != SC->serial_number_at_timeout) {
+		/* HMM, looks like a bogus command */
+		DEBUG(1, "Abort called with bogus scsi command");
+
+		return (FAILED);
+	}
+
+	/* See if the command is on the copp queue */
+	item = ha->copp_waitlist.head;
+	while ((item) && (item->scsi_cmd != SC))
+		item = item->next;
+
+	if (item) {
+		/* Found it */
+		ips_removeq_copp(&ha->copp_waitlist, item);
+		ret = (SUCCESS);
+
+		/* See if the command is on the wait queue */
+	} else if (ips_removeq_wait(&ha->scb_waitlist, SC)) {
+		/* command not sent yet */
+		ret = (SUCCESS);
+	} else {
+		/* command must have already been sent */
+		ret = (FAILED);
+	}
+	return ret;
 }
 
 /****************************************************************************/
@@ -1586,191 +848,194 @@
 /*                                                                          */
 /****************************************************************************/
 int
-ips_eh_reset(Scsi_Cmnd *SC) {
-   int                   ret;
-   int                   i;
-   ips_ha_t             *ha;
-   ips_scb_t            *scb;
-   ips_copp_wait_item_t *item;
+ips_eh_reset(Scsi_Cmnd * SC)
+{
+	int ret;
+	int i;
+	ips_ha_t *ha;
+	ips_scb_t *scb;
+	ips_copp_wait_item_t *item;
 
-   METHOD_TRACE("ips_eh_reset", 1);
+	METHOD_TRACE("ips_eh_reset", 1);
 
 #ifdef NO_IPS_RESET
-   return (FAILED);
+	return (FAILED);
 #else
 
-   if (!SC) {
-      DEBUG(1, "Reset called with NULL scsi command");
+	if (!SC) {
+		DEBUG(1, "Reset called with NULL scsi command");
 
-      return (FAILED);
-   }
+		return (FAILED);
+	}
 
-   ha = (ips_ha_t *) SC->host->hostdata;
+	ha = (ips_ha_t *) SC->host->hostdata;
 
-   if (!ha) {
-      DEBUG(1, "Reset called with NULL ha struct");
-
-      return (FAILED);
-   }
-
-   if (!ha->active)
-      return (FAILED);
-
-   /* See if the command is on the copp queue */
-   item = ha->copp_waitlist.head;
-   while ((item) && (item->scsi_cmd != SC))
-      item = item->next;
-
-   if (item) {
-      /* Found it */
-      ips_removeq_copp(&ha->copp_waitlist, item);
-      return (SUCCESS);
-   }
-
-   /* See if the command is on the wait queue */
-   if (ips_removeq_wait(&ha->scb_waitlist, SC)) {
-      /* command not sent yet */
-      return (SUCCESS);
-   }
-
-   /* An explanation for the casual observer:                              */
-   /* Part of the function of a RAID controller is automatic error         */
-   /* detection and recovery.  As such, the only problem that physically   */
-   /* resetting an adapter will ever fix is when, for some reason,         */
-   /* the driver is not successfully communicating with the adapter.       */
-   /* Therefore, we will attempt to flush this adapter.  If that succeeds, */
-   /* then there's no real purpose in a physical reset. This will complete */
-   /* much faster and avoids any problems that might be caused by a        */
-   /* physical reset ( such as having to fail all the outstanding I/O's ). */
-                                                           
-   if (ha->ioctl_reset == 0) {          /* IF Not an IOCTL Requested Reset */
-      scb = &ha->scbs[ha->max_cmds-1];
-
-      ips_init_scb(ha, scb);
-
-      scb->timeout = ips_cmd_timeout;
-      scb->cdb[0] = IPS_CMD_FLUSH;
-
-      scb->cmd.flush_cache.op_code = IPS_CMD_FLUSH;
-      scb->cmd.flush_cache.command_id = IPS_COMMAND_ID(ha, scb);
-      scb->cmd.flush_cache.state = IPS_NORM_STATE;
-      scb->cmd.flush_cache.reserved = 0;
-      scb->cmd.flush_cache.reserved2 = 0;
-      scb->cmd.flush_cache.reserved3 = 0;
-      scb->cmd.flush_cache.reserved4 = 0;
-
-      /* Attempt the flush command */
-      ret = ips_send_wait(ha, scb, ips_cmd_timeout, IPS_INTR_IORL);
-      if (ret == IPS_SUCCESS) {
-         printk(KERN_NOTICE "(%s%d) Reset Request - Flushed Cache\n", ips_name, ha->host_num);
-         return (SUCCESS);
-         }
-   }
-
-   /* Either we can't communicate with the adapter or it's an IOCTL request */
-   /* from a utility.  A physical reset is needed at this point.            */
-
-   ha->ioctl_reset = 0;             /* Reset the IOCTL Requested Reset Flag */
-
-   /*
-    * command must have already been sent
-    * reset the controller
-    */
-   printk(KERN_NOTICE "(%s%d) Resetting controller.\n",
-          ips_name, ha->host_num);
-   ret = (*ha->func.reset)(ha);
-
-   if (!ret) {
-      Scsi_Cmnd *scsi_cmd;
-
-      printk(KERN_NOTICE
-             "(%s%d) Controller reset failed - controller now offline.\n",
-             ips_name, ha->host_num);
-
-      /* Now fail all of the active commands */
-      DEBUG_VAR(1, "(%s%d) Failing active commands",
-                ips_name, ha->host_num);
-
-      while ((scb = ips_removeq_scb_head(&ha->scb_activelist))) {
-         scb->scsi_cmd->result = DID_ERROR << 16;
-         scb->scsi_cmd->scsi_done(scb->scsi_cmd);
-         ips_freescb(ha, scb);
-      }
-
-      /* Now fail all of the pending commands */
-      DEBUG_VAR(1, "(%s%d) Failing pending commands",
-                ips_name, ha->host_num);
-
-      while ((scsi_cmd = ips_removeq_wait_head(&ha->scb_waitlist))) {
-         scsi_cmd->result = DID_ERROR;
-         scsi_cmd->scsi_done(scsi_cmd);
-      }
-
-      ha->active = FALSE;
-      return (FAILED);
-   }
-
-   if (!ips_clear_adapter(ha, IPS_INTR_IORL)) {
-      Scsi_Cmnd *scsi_cmd;
-
-      printk(KERN_NOTICE
-             "(%s%d) Controller reset failed - controller now offline.\n",
-             ips_name, ha->host_num);
-
-      /* Now fail all of the active commands */
-      DEBUG_VAR(1, "(%s%d) Failing active commands",
-                ips_name, ha->host_num);
-
-      while ((scb = ips_removeq_scb_head(&ha->scb_activelist))) {
-         scb->scsi_cmd->result = DID_ERROR << 16;
-         scb->scsi_cmd->scsi_done(scb->scsi_cmd);
-         ips_freescb(ha, scb);
-      }
-
-      /* Now fail all of the pending commands */
-      DEBUG_VAR(1, "(%s%d) Failing pending commands",
-                ips_name, ha->host_num);
-
-      while ((scsi_cmd = ips_removeq_wait_head(&ha->scb_waitlist))) {
-         scsi_cmd->result = DID_ERROR << 16;
-         scsi_cmd->scsi_done(scsi_cmd);
-      }
-
-      ha->active = FALSE;
-      return (FAILED);
-   }
-
-   /* FFDC */
-   if (le32_to_cpu(ha->subsys->param[3]) & 0x300000) {
-      struct timeval tv;
-
-      do_gettimeofday(&tv);
-      ha->last_ffdc = tv.tv_sec;
-      ha->reset_count++;
-      ips_ffdc_reset(ha, IPS_INTR_IORL);
-   }
-
-   /* Now fail all of the active commands */
-   DEBUG_VAR(1, "(%s%d) Failing active commands",
-             ips_name, ha->host_num);
-
-   while ((scb = ips_removeq_scb_head(&ha->scb_activelist))) {
-      scb->scsi_cmd->result = (DID_RESET << 16) | (SUGGEST_RETRY << 24);
-      scb->scsi_cmd->scsi_done(scb->scsi_cmd);
-      ips_freescb(ha, scb);
-   }
-
-   /* Reset DCDB active command bits */
-   for (i = 1; i < ha->nbus; i++)
-      ha->dcdb_active[i-1] = 0;
+	if (!ha) {
+		DEBUG(1, "Reset called with NULL ha struct");
+
+		return (FAILED);
+	}
+
+	if (!ha->active)
+		return (FAILED);
+
+	/* See if the command is on the copp queue */
+	item = ha->copp_waitlist.head;
+	while ((item) && (item->scsi_cmd != SC))
+		item = item->next;
+
+	if (item) {
+		/* Found it */
+		ips_removeq_copp(&ha->copp_waitlist, item);
+		return (SUCCESS);
+	}
+
+	/* See if the command is on the wait queue */
+	if (ips_removeq_wait(&ha->scb_waitlist, SC)) {
+		/* command not sent yet */
+		return (SUCCESS);
+	}
+
+	/* An explanation for the casual observer:                              */
+	/* Part of the function of a RAID controller is automatic error         */
+	/* detection and recovery.  As such, the only problem that physically   */
+	/* resetting an adapter will ever fix is when, for some reason,         */
+	/* the driver is not successfully communicating with the adapter.       */
+	/* Therefore, we will attempt to flush this adapter.  If that succeeds, */
+	/* then there's no real purpose in a physical reset. This will complete */
+	/* much faster and avoids any problems that might be caused by a        */
+	/* physical reset ( such as having to fail all the outstanding I/O's ). */
+
+	if (ha->ioctl_reset == 0) {	/* IF Not an IOCTL Requested Reset */
+		scb = &ha->scbs[ha->max_cmds - 1];
+
+		ips_init_scb(ha, scb);
+
+		scb->timeout = ips_cmd_timeout;
+		scb->cdb[0] = IPS_CMD_FLUSH;
+
+		scb->cmd.flush_cache.op_code = IPS_CMD_FLUSH;
+		scb->cmd.flush_cache.command_id = IPS_COMMAND_ID(ha, scb);
+		scb->cmd.flush_cache.state = IPS_NORM_STATE;
+		scb->cmd.flush_cache.reserved = 0;
+		scb->cmd.flush_cache.reserved2 = 0;
+		scb->cmd.flush_cache.reserved3 = 0;
+		scb->cmd.flush_cache.reserved4 = 0;
+
+		/* Attempt the flush command */
+		ret = ips_send_wait(ha, scb, ips_cmd_timeout, IPS_INTR_IORL);
+		if (ret == IPS_SUCCESS) {
+			printk(KERN_NOTICE
+			       "(%s%d) Reset Request - Flushed Cache\n",
+			       ips_name, ha->host_num);
+			return (SUCCESS);
+		}
+	}
+
+	/* Either we can't communicate with the adapter or it's an IOCTL request */
+	/* from a utility.  A physical reset is needed at this point.            */
+
+	ha->ioctl_reset = 0;	/* Reset the IOCTL Requested Reset Flag */
+
+	/*
+	 * command must have already been sent
+	 * reset the controller
+	 */
+	printk(KERN_NOTICE "(%s%d) Resetting controller.\n",
+	       ips_name, ha->host_num);
+	ret = (*ha->func.reset) (ha);
+
+	if (!ret) {
+		Scsi_Cmnd *scsi_cmd;
+
+		printk(KERN_NOTICE
+		       "(%s%d) Controller reset failed - controller now offline.\n",
+		       ips_name, ha->host_num);
+
+		/* Now fail all of the active commands */
+		DEBUG_VAR(1, "(%s%d) Failing active commands",
+			  ips_name, ha->host_num);
+
+		while ((scb = ips_removeq_scb_head(&ha->scb_activelist))) {
+			scb->scsi_cmd->result = DID_ERROR << 16;
+			scb->scsi_cmd->scsi_done(scb->scsi_cmd);
+			ips_freescb(ha, scb);
+		}
+
+		/* Now fail all of the pending commands */
+		DEBUG_VAR(1, "(%s%d) Failing pending commands",
+			  ips_name, ha->host_num);
+
+		while ((scsi_cmd = ips_removeq_wait_head(&ha->scb_waitlist))) {
+			scsi_cmd->result = DID_ERROR;
+			scsi_cmd->scsi_done(scsi_cmd);
+		}
+
+		ha->active = FALSE;
+		return (FAILED);
+	}
+
+	if (!ips_clear_adapter(ha, IPS_INTR_IORL)) {
+		Scsi_Cmnd *scsi_cmd;
+
+		printk(KERN_NOTICE
+		       "(%s%d) Controller reset failed - controller now offline.\n",
+		       ips_name, ha->host_num);
+
+		/* Now fail all of the active commands */
+		DEBUG_VAR(1, "(%s%d) Failing active commands",
+			  ips_name, ha->host_num);
+
+		while ((scb = ips_removeq_scb_head(&ha->scb_activelist))) {
+			scb->scsi_cmd->result = DID_ERROR << 16;
+			scb->scsi_cmd->scsi_done(scb->scsi_cmd);
+			ips_freescb(ha, scb);
+		}
+
+		/* Now fail all of the pending commands */
+		DEBUG_VAR(1, "(%s%d) Failing pending commands",
+			  ips_name, ha->host_num);
+
+		while ((scsi_cmd = ips_removeq_wait_head(&ha->scb_waitlist))) {
+			scsi_cmd->result = DID_ERROR << 16;
+			scsi_cmd->scsi_done(scsi_cmd);
+		}
+
+		ha->active = FALSE;
+		return (FAILED);
+	}
+
+	/* FFDC */
+	if (le32_to_cpu(ha->subsys->param[3]) & 0x300000) {
+		struct timeval tv;
+
+		do_gettimeofday(&tv);
+		ha->last_ffdc = tv.tv_sec;
+		ha->reset_count++;
+		ips_ffdc_reset(ha, IPS_INTR_IORL);
+	}
+
+	/* Now fail all of the active commands */
+	DEBUG_VAR(1, "(%s%d) Failing active commands", ips_name, ha->host_num);
+
+	while ((scb = ips_removeq_scb_head(&ha->scb_activelist))) {
+		scb->scsi_cmd->result =
+		    (DID_RESET << 16) | (SUGGEST_RETRY << 24);
+		scb->scsi_cmd->scsi_done(scb->scsi_cmd);
+		ips_freescb(ha, scb);
+	}
+
+	/* Reset DCDB active command bits */
+	for (i = 1; i < ha->nbus; i++)
+		ha->dcdb_active[i - 1] = 0;
 
-   /* Reset the number of active IOCTLs */
-   ha->num_ioctl = 0;
+	/* Reset the number of active IOCTLs */
+	ha->num_ioctl = 0;
 
-   ips_next(ha, IPS_INTR_IORL);
+	ips_next(ha, IPS_INTR_IORL);
 
-   return (SUCCESS);
-#endif /* NO_IPS_RESET */
+	return (SUCCESS);
+#endif				/* NO_IPS_RESET */
 
 }
 
@@ -1787,103 +1052,92 @@
 /*                                                                          */
 /****************************************************************************/
 int
-ips_queue(Scsi_Cmnd *SC, void (*done) (Scsi_Cmnd *)) {
-   ips_ha_t         *ha;
-   ips_passthru_t   *pt;                                             
-
-   METHOD_TRACE("ips_queue", 1);
-
-   ha = (ips_ha_t *) SC->host->hostdata;
-
-   if (!ha)
-      return (1);
-
-   if (!ha->active)
-      return (DID_ERROR);
-
-   if (ips_is_passthru(SC)) {
-      if (ha->copp_waitlist.count == IPS_MAX_IOCTL_QUEUE) {
-         SC->result = DID_BUS_BUSY << 16;
-         done(SC);
-
-         return (0);
-      }
-   } else if (ha->scb_waitlist.count == IPS_MAX_QUEUE) {
-      SC->result = DID_BUS_BUSY << 16;
-      done(SC);
-
-      return (0);
-   }
-
-   SC->scsi_done = done;
-
-   DEBUG_VAR(2, "(%s%d): ips_queue: cmd 0x%X (%d %d %d)",
-             ips_name,
-             ha->host_num,
-             SC->cmnd[0],
-             SC->channel,
-             SC->target,
-             SC->lun);
-
-   /* Check for command to initiator IDs */
-   if ((SC->channel > 0) && (SC->target == ha->ha_id[SC->channel])) {
-      SC->result = DID_NO_CONNECT << 16;
-      done(SC);
-
-      return (0);
-   }
-
-   if (ips_is_passthru(SC)) {
-
-      ips_copp_wait_item_t *scratch;
-      
-      /* A Reset IOCTL is only sent by the boot CD in extreme cases.           */
-      /* There can never be any system activity ( network or disk ), but check */
-      /* anyway just as a good practice.                                       */
-      pt = (ips_passthru_t *) SC->request_buffer;                                
-      if ((pt->CoppCP.cmd.reset.op_code == IPS_CMD_RESET_CHANNEL) &&            
-           (pt->CoppCP.cmd.reset.adapter_flag == 1))  {                         
-         if (ha->scb_activelist.count != 0) {
-             SC->result = DID_BUS_BUSY << 16;
-             done(SC);
-             return (0);
-         }
-         ha->ioctl_reset = 1;           /* This reset request is from an IOCTL */
-         ips_eh_reset(SC);                                                         
-         SC->result = DID_OK << 16;                                                
-         SC->scsi_done(SC);                                                        
-         return (0);                                                               
-      }
-
-      /* allocate space for the scribble */
-      scratch = kmalloc(sizeof(ips_copp_wait_item_t), GFP_ATOMIC);
-
-      if (!scratch) {
-         SC->result = DID_ERROR << 16;
-         done(SC);
-
-         return (0);
-      }
-
-      scratch->scsi_cmd = SC;
-      scratch->next = NULL;
-
-      ips_putq_copp_tail(&ha->copp_waitlist, scratch);
-   }
-   else {
-      ips_putq_wait_tail(&ha->scb_waitlist, SC);
-   }
-
-   ips_next(ha, IPS_INTR_IORL);
-   
-   /* If We were using the CD Boot Flash Buffer, Restore the Old Values */
-   if ( ips_FlashData == ha->ioctl_data ) {                               
-      ha->ioctl_data = ha->flash_data;                           
-      ha->ioctl_order = ha->flash_order;                          
-      ha->ioctl_datasize = ha->flash_datasize;                       
-      ips_FlashDataInUse = 0;                                             
-   }
-   return (0);
+ips_queue(Scsi_Cmnd * SC, void (*done) (Scsi_Cmnd *))
+{
+	ips_ha_t *ha;
+	ips_passthru_t *pt;
+
+	METHOD_TRACE("ips_queue", 1);
+
+	ha = (ips_ha_t *) SC->host->hostdata;
+
+	if (!ha)
+		return (1);
+
+	if (!ha->active)
+		return (DID_ERROR);
+
+	if (ips_is_passthru(SC)) {
+		if (ha->copp_waitlist.count == IPS_MAX_IOCTL_QUEUE) {
+			SC->result = DID_BUS_BUSY << 16;
+			done(SC);
+
+			return (0);
+		}
+	} else if (ha->scb_waitlist.count == IPS_MAX_QUEUE) {
+		SC->result = DID_BUS_BUSY << 16;
+		done(SC);
+
+		return (0);
+	}
+
+	SC->scsi_done = done;
+
+	DEBUG_VAR(2, "(%s%d): ips_queue: cmd 0x%X (%d %d %d)",
+		  ips_name,
+		  ha->host_num, SC->cmnd[0], SC->channel, SC->target, SC->lun);
+
+	/* Check for command to initiator IDs */
+	if ((SC->channel > 0) && (SC->target == ha->ha_id[SC->channel])) {
+		SC->result = DID_NO_CONNECT << 16;
+		done(SC);
+
+		return (0);
+	}
+
+	if (ips_is_passthru(SC)) {
+
+		ips_copp_wait_item_t *scratch;
+
+		/* A Reset IOCTL is only sent by the boot CD in extreme cases.           */
+		/* There can never be any system activity ( network or disk ), but check */
+		/* anyway just as a good practice.                                       */
+		pt = (ips_passthru_t *) SC->request_buffer;
+		if ((pt->CoppCP.cmd.reset.op_code == IPS_CMD_RESET_CHANNEL) &&
+		    (pt->CoppCP.cmd.reset.adapter_flag == 1)) {
+			if (ha->scb_activelist.count != 0) {
+				SC->result = DID_BUS_BUSY << 16;
+				done(SC);
+				return (0);
+			}
+			ha->ioctl_reset = 1;	/* This reset request is from an IOCTL */
+			ips_eh_reset(SC);
+			SC->result = DID_OK << 16;
+			SC->scsi_done(SC);
+			return (0);
+		}
+
+		/* allocate space for the scribble */
+		scratch = kmalloc(sizeof (ips_copp_wait_item_t), GFP_ATOMIC);
+
+		if (!scratch) {
+			SC->result = DID_ERROR << 16;
+			done(SC);
+
+			return (0);
+		}
+
+		scratch->scsi_cmd = SC;
+		scratch->next = NULL;
+
+		ips_putq_copp_tail(&ha->copp_waitlist, scratch);
+	} else {
+		ips_putq_wait_tail(&ha->scb_waitlist, SC);
+	}
+
+	ips_next(ha, IPS_INTR_IORL);
+
+	return (0);
 }
 
 /****************************************************************************/
@@ -1896,48 +1150,49 @@
 /*                                                                          */
 /****************************************************************************/
 int
-ips_biosparam(Disk *disk, kdev_t dev, int geom[]) {
-   ips_ha_t         *ha;
-   int               heads;
-   int               sectors;
-   int               cylinders;
-
-   METHOD_TRACE("ips_biosparam", 1);
-
-   ha = (ips_ha_t *) disk->device->host->hostdata;
-
-   if (!ha)
-      /* ?!?! host adater info invalid */
-      return (0);
-
-   if (!ha->active)
-      return (0);
-
-   if (!ips_read_adapter_status(ha, IPS_INTR_ON))
-      /* ?!?! Enquiry command failed */
-      return (0);
-
-   if ((disk->capacity > 0x400000) &&
-       ((ha->enq->ucMiscFlag & 0x8) == 0)) {
-      heads = IPS_NORM_HEADS;
-      sectors = IPS_NORM_SECTORS;
-   } else {
-      heads = IPS_COMP_HEADS;
-      sectors = IPS_COMP_SECTORS;
-   }
-
-   cylinders = disk->capacity / (heads * sectors);
-
-   DEBUG_VAR(2, "Geometry: heads: %d, sectors: %d, cylinders: %d",
-             heads, sectors, cylinders);
-
-   geom[0] = heads;
-   geom[1] = sectors;
-   geom[2] = cylinders;
+ips_biosparam(Disk * disk, kdev_t dev, int geom[])
+{
+	ips_ha_t *ha;
+	int heads;
+	int sectors;
+	int cylinders;
+
+	METHOD_TRACE("ips_biosparam", 1);
 
-   return (0);
+	ha = (ips_ha_t *) disk->device->host->hostdata;
+
+	if (!ha)
+		/* ?!?! host adater info invalid */
+		return (0);
+
+	if (!ha->active)
+		return (0);
+
+	if (!ips_read_adapter_status(ha, IPS_INTR_ON))
+		/* ?!?! Enquiry command failed */
+		return (0);
+
+	if ((disk->capacity > 0x400000) && ((ha->enq->ucMiscFlag & 0x8) == 0)) {
+		heads = IPS_NORM_HEADS;
+		sectors = IPS_NORM_SECTORS;
+	} else {
+		heads = IPS_COMP_HEADS;
+		sectors = IPS_COMP_SECTORS;
+	}
+
+	cylinders = disk->capacity / (heads * sectors);
+
+	DEBUG_VAR(2, "Geometry: heads: %d, sectors: %d, cylinders: %d",
+		  heads, sectors, cylinders);
+
+	geom[0] = heads;
+	geom[1] = sectors;
+	geom[2] = cylinders;
+
+	return (0);
 }
 
+#if LINUX_VERSION_CODE < LinuxVersionCode(2,5,0)
 /****************************************************************************/
 /*                                                                          */
 /* Routine Name: ips_select_queue_depth                                     */
@@ -1948,39 +1203,67 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_select_queue_depth(struct Scsi_Host *host, Scsi_Device *scsi_devs) {
-   Scsi_Device *device;
-   ips_ha_t    *ha;
-   int          count = 0;
-   int          min;
-
-   ha = IPS_HA(host);
-   min = ha->max_cmds / 4;
-
-   for (device = scsi_devs; device; device = device->next) {
-     if (device->host == host) {
-        if ((device->channel == 0) && (device->type == 0))
-           count++;
-     }
-   }
-
-   for (device = scsi_devs; device; device = device->next) {
-      if (device->host == host) {
-         if ((device->channel == 0) && (device->type == 0)) {
-            device->queue_depth = ( ha->max_cmds - 1 ) / count;
-            if (device->queue_depth < min) 
-               device->queue_depth = min;
-         }
-         else {
-            device->queue_depth = 2;
-         }
-
-         if (device->queue_depth < 2)
-            device->queue_depth = 2;
-      }
-   }
+ips_select_queue_depth(struct Scsi_Host *host, Scsi_Device * scsi_devs)
+{
+	Scsi_Device *device;
+	ips_ha_t *ha;
+	int count = 0;
+	int min;
+
+	ha = IPS_HA(host);
+	min = ha->max_cmds / 4;
+
+	for (device = scsi_devs; device; device = device->next) {
+		if (device->host == host) {
+			if ((device->channel == 0) && (device->type == 0))
+				count++;
+		}
+	}
+
+	for (device = scsi_devs; device; device = device->next) {
+		if (device->host == host) {
+			if ((device->channel == 0) && (device->type == 0)) {
+				device->queue_depth =
+				    (ha->max_cmds - 1) / count;
+				if (device->queue_depth < min)
+					device->queue_depth = min;
+			} else {
+				device->queue_depth = 2;
+			}
+
+			if (device->queue_depth < 2)
+				device->queue_depth = 2;
+		}
+	}
 }
 
+#else
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_slave_configure                                        */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*                                                                          */
+/*   Set queue depths on devices once scan is complete                      */
+/*                                                                          */
+/****************************************************************************/
+int
+ips_slave_configure(Scsi_Device * SDptr)
+{
+	ips_ha_t *ha;
+	int min;
+
+	ha = IPS_HA(SDptr->host);
+	if (SDptr->tagged_supported && SDptr->type == TYPE_DISK) {
+		min = ha->max_cmds / 2;
+		if (ha->enq->ucLogDriveCount <= 2)
+			min = ha->max_cmds - 1;
+		scsi_adjust_queue_depth(SDptr, MSG_ORDERED_TAG, min);
+	}
+	return 0;
+}
+#endif
+
 /****************************************************************************/
 /*                                                                          */
 /* Routine Name: do_ipsintr                                                 */
@@ -1991,30 +1274,37 @@
 /*                                                                          */
 /****************************************************************************/
 void
-do_ipsintr(int irq, void *dev_id, struct pt_regs *regs) {
-   ips_ha_t         *ha;
-   unsigned long     cpu_flags;
-   struct Scsi_Host *host;
-
-   METHOD_TRACE("do_ipsintr", 2);
-
-   ha = (ips_ha_t *) dev_id;
-   if (!ha) 
-      return;
-   host = ips_sh[ha->host_num];
-   IPS_LOCK_SAVE(host->host_lock, cpu_flags);
-
-   if (!ha->active) {
-      IPS_UNLOCK_RESTORE(host->host_lock, cpu_flags);
-      return;
-   }
+do_ipsintr(int irq, void *dev_id, struct pt_regs *regs)
+{
+	ips_ha_t *ha;
+	unsigned long cpu_flags;
+	struct Scsi_Host *host;
+
+	METHOD_TRACE("do_ipsintr", 2);
+
+	ha = (ips_ha_t *) dev_id;
+	if (!ha)
+		return;
+	host = ips_sh[ha->host_num];
+	/* interrupt during initialization */
+	if (!host) {
+		(*ha->func.intr) (ha);
+		return;
+	}
+
+	IPS_LOCK_SAVE(host->host_lock, cpu_flags);
+
+	if (!ha->active) {
+		IPS_UNLOCK_RESTORE(host->host_lock, cpu_flags);
+		return;
+	}
 
-   (*ha->func.intr)(ha);
+	(*ha->func.intr) (ha);
 
-   IPS_UNLOCK_RESTORE(host->host_lock, cpu_flags);
+	IPS_UNLOCK_RESTORE(host->host_lock, cpu_flags);
 
-   /* start the next command */
-   ips_next(ha, IPS_INTR_ON);
+	/* start the next command */
+	ips_next(ha, IPS_INTR_ON);
 }
 
 /****************************************************************************/
@@ -2029,54 +1319,55 @@
 /*                                                                          */
 /****************************************************************************/
 void
-ips_intr_copperhead(ips_ha_t *ha) {
-   ips_stat_t       *sp;
-   ips_scb_t        *scb;
-   IPS_STATUS        cstatus;
-   int               intrstatus;
-
-   METHOD_TRACE("ips_intr", 2);
-
-   if (!ha)
-      return;
-
-   if (!ha->active)
-      return;
-
-   intrstatus = (*ha->func.isintr)(ha);
-
-   if (!intrstatus) {
-      /*
-       * Unexpected/Shared interrupt
-       */
-
-      return;
-   }
-
-   while (TRUE) {
-      sp = &ha->sp;
-
-      intrstatus = (*ha->func.isintr)(ha);
-
-      if (!intrstatus)
-         break;
-      else
-         cstatus.value = (*ha->func.statupd)(ha);
-
-      if (cstatus.fields.command_id > (IPS_MAX_CMDS - 1)) {
-         /* Spurious Interupt ? */
-         continue;
-      }
-
-      ips_chkstatus(ha, &cstatus);
-      scb = (ips_scb_t *) sp->scb_addr;
-
-      /*
-       * use the callback function to finish things up
-       * NOTE: interrupts are OFF for this
-       */
-      (*scb->callback) (ha, scb);
-   } /* end while */
+ips_intr_copperhead(ips_ha_t * ha)
+{
+	ips_stat_t *sp;
+	ips_scb_t *scb;
+	IPS_STATUS cstatus;
+	int intrstatus;
+
+	METHOD_TRACE("ips_intr", 2);
+
+	if (!ha)
+		return;
+
+	if (!ha->active)
+		return;
+
+	intrstatus = (*ha->func.isintr) (ha);
+
+	if (!intrstatus) {
+		/*
+		 * Unexpected/Shared interrupt
+		 */
+
+		return;
+	}
+
+	while (TRUE) {
+		sp = &ha->sp;
+
+		intrstatus = (*ha->func.isintr) (ha);
+
+		if (!intrstatus)
+			break;
+		else
+			cstatus.value = (*ha->func.statupd) (ha);
+
+		if (cstatus.fields.command_id > (IPS_MAX_CMDS - 1)) {
+			/* Spurious Interupt ? */
+			continue;
+		}
+
+		ips_chkstatus(ha, &cstatus);
+		scb = (ips_scb_t *) sp->scb_addr;
+
+		/*
+		 * use the callback function to finish things up
+		 * NOTE: interrupts are OFF for this
+		 */
+		(*scb->callback) (ha, scb);
+	}			/* end while */
 }
 
 /****************************************************************************/
@@ -2091,60 +1382,62 @@
 /*                                                                          */
 /****************************************************************************/
 void
-ips_intr_morpheus(ips_ha_t *ha) {
-   ips_stat_t       *sp;
-   ips_scb_t        *scb;
-   IPS_STATUS        cstatus;
-   int               intrstatus;
+ips_intr_morpheus(ips_ha_t * ha)
+{
+	ips_stat_t *sp;
+	ips_scb_t *scb;
+	IPS_STATUS cstatus;
+	int intrstatus;
 
-   METHOD_TRACE("ips_intr_morpheus", 2);
+	METHOD_TRACE("ips_intr_morpheus", 2);
 
-   if (!ha)
-      return;
+	if (!ha)
+		return;
 
-   if (!ha->active)
-      return;
+	if (!ha->active)
+		return;
 
-   intrstatus = (*ha->func.isintr)(ha);
+	intrstatus = (*ha->func.isintr) (ha);
 
-   if (!intrstatus) {
-      /*
-       * Unexpected/Shared interrupt
-       */
+	if (!intrstatus) {
+		/*
+		 * Unexpected/Shared interrupt
+		 */
 
-      return;
-   }
+		return;
+	}
 
-   while (TRUE) {
-      sp = &ha->sp;
+	while (TRUE) {
+		sp = &ha->sp;
 
-      intrstatus = (*ha->func.isintr)(ha);
+		intrstatus = (*ha->func.isintr) (ha);
 
-      if (!intrstatus)
-         break;
-      else
-         cstatus.value = (*ha->func.statupd)(ha);
+		if (!intrstatus)
+			break;
+		else
+			cstatus.value = (*ha->func.statupd) (ha);
 
-      if (cstatus.value == 0xffffffff)
-         /* No more to process */
-         break;
+		if (cstatus.value == 0xffffffff)
+			/* No more to process */
+			break;
 
-      if (cstatus.fields.command_id > (IPS_MAX_CMDS - 1)) {
-         printk(KERN_WARNING "(%s%d) Spurious interrupt; no ccb.\n",
-                ips_name, ha->host_num);
+		if (cstatus.fields.command_id > (IPS_MAX_CMDS - 1)) {
+			printk(KERN_WARNING
+			       "(%s%d) Spurious interrupt; no ccb.\n", ips_name,
+			       ha->host_num);
 
-         continue;
-      }
+			continue;
+		}
 
-      ips_chkstatus(ha, &cstatus);
-      scb = (ips_scb_t *) sp->scb_addr;
+		ips_chkstatus(ha, &cstatus);
+		scb = (ips_scb_t *) sp->scb_addr;
 
-      /*
-       * use the callback function to finish things up
-       * NOTE: interrupts are OFF for this
-       */
-      (*scb->callback) (ha, scb);
-   } /* end while */
+		/*
+		 * use the callback function to finish things up
+		 * NOTE: interrupts are OFF for this
+		 */
+		(*scb->callback) (ha, scb);
+	}			/* end while */
 }
 
 /****************************************************************************/
@@ -2157,31 +1450,32 @@
 /*                                                                          */
 /****************************************************************************/
 const char *
-ips_info(struct Scsi_Host *SH) {
-   static char  buffer[256];
-   char        *bp;
-   ips_ha_t    *ha;
+ips_info(struct Scsi_Host *SH)
+{
+	static char buffer[256];
+	char *bp;
+	ips_ha_t *ha;
 
-   METHOD_TRACE("ips_info", 1);
+	METHOD_TRACE("ips_info", 1);
 
-   ha = IPS_HA(SH);
+	ha = IPS_HA(SH);
 
-   if (!ha)
-      return (NULL);
+	if (!ha)
+		return (NULL);
 
-   bp = &buffer[0];
-   memset(bp, 0, sizeof(buffer));
+	bp = &buffer[0];
+	memset(bp, 0, sizeof (buffer));
 
-   sprintf(bp, "%s%s%s", "IBM PCI ServeRAID ", IPS_VERSION_HIGH, IPS_VERSION_LOW );
+	sprintf(bp, "%s%s%s Build %d", "IBM PCI ServeRAID ",
+		IPS_VERSION_HIGH, IPS_VERSION_LOW, IPS_BUILD_IDENT);
 
-   if (ha->ad_type > 0 &&
-       ha->ad_type <= MAX_ADAPTER_NAME) {
-      strcat(bp, " <");
-      strcat(bp, ips_adapter_name[ha->ad_type-1]);
-      strcat(bp, ">");
-   }
+	if (ha->ad_type > 0 && ha->ad_type <= MAX_ADAPTER_NAME) {
+		strcat(bp, " <");
+		strcat(bp, ips_adapter_name[ha->ad_type - 1]);
+		strcat(bp, ">");
+	}
 
-   return (bp);
+	return (bp);
 }
 
 /****************************************************************************/
@@ -2195,38 +1489,39 @@
 /****************************************************************************/
 int
 ips_proc_info(char *buffer, char **start, off_t offset,
-              int length, int hostno, int func) {
-   int           i;
-   int           ret;
-   ips_ha_t     *ha = NULL;
-
-   METHOD_TRACE("ips_proc_info", 1);
-
-   /* Find our host structure */
-   for (i = 0; i < ips_next_controller; i++) {
-      if (ips_sh[i]) {
-         if (ips_sh[i]->host_no == hostno) {
-            ha = (ips_ha_t *) ips_sh[i]->hostdata;
-            break;
-         }
-      }
-   }
-
-   if (!ha)
-      return (-EINVAL);
-
-   if (func) {
-      /* write */
-      return (0);
-   } else {
-      /* read */
-      if (start)
-         *start = buffer;
+	      int length, int hostno, int func)
+{
+	int i;
+	int ret;
+	ips_ha_t *ha = NULL;
+
+	METHOD_TRACE("ips_proc_info", 1);
+
+	/* Find our host structure */
+	for (i = 0; i < ips_next_controller; i++) {
+		if (ips_sh[i]) {
+			if (ips_sh[i]->host_no == hostno) {
+				ha = (ips_ha_t *) ips_sh[i]->hostdata;
+				break;
+			}
+		}
+	}
+
+	if (!ha)
+		return (-EINVAL);
+
+	if (func) {
+		/* write */
+		return (0);
+	} else {
+		/* read */
+		if (start)
+			*start = buffer;
 
-      ret = ips_host_info(ha, buffer, offset, length);
+		ret = ips_host_info(ha, buffer, offset, length);
 
-      return (ret);
-   }
+		return (ret);
+	}
 }
 
 /*--------------------------------------------------------------------------*/
@@ -2243,32 +1538,65 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_is_passthru(Scsi_Cmnd *SC) {
-   METHOD_TRACE("ips_is_passthru", 1);
+ips_is_passthru(Scsi_Cmnd * SC)
+{
+	METHOD_TRACE("ips_is_passthru", 1);
 
-   if (!SC)
-      return (0);
+	if (!SC)
+		return (0);
+
+	if ((SC->cmnd[0] == IPS_IOCTL_COMMAND) &&
+	    (SC->channel == 0) &&
+	    (SC->target == IPS_ADAPTER_ID) &&
+	    (SC->lun == 0) && SC->request_buffer) {
+		if ((!SC->use_sg) && SC->request_bufflen &&
+		    (((char *) SC->request_buffer)[0] == 'C') &&
+		    (((char *) SC->request_buffer)[1] == 'O') &&
+		    (((char *) SC->request_buffer)[2] == 'P') &&
+		    (((char *) SC->request_buffer)[3] == 'P'))
+			return 1;
+		else if (SC->use_sg) {
+			struct scatterlist *sg = SC->request_buffer;
+			char *buffer = IPS_SG_ADDRESS(sg);
+			if (buffer && buffer[0] == 'C' && buffer[1] == 'O' &&
+			    buffer[2] == 'P' && buffer[3] == 'P')
+				return 1;
+		}
+	}
+	return 0;
+}
 
-   if ((SC->cmnd[0] == IPS_IOCTL_COMMAND) &&
-       (SC->channel == 0) &&
-       (SC->target == IPS_ADAPTER_ID) &&
-       (SC->lun == 0) &&
-        SC->request_buffer){
-      if((!SC->use_sg) && SC->request_bufflen &&
-         (((char *) SC->request_buffer)[0] == 'C') &&
-         (((char *) SC->request_buffer)[1] == 'O') &&
-         (((char *) SC->request_buffer)[2] == 'P') &&
-         (((char *) SC->request_buffer)[3] == 'P'))
-         return 1;
-      else if(SC->use_sg){
-         struct scatterlist *sg = SC->request_buffer;
-         char *buffer = IPS_SG_ADDRESS(sg);
-         if(buffer && buffer[0] == 'C' && buffer[1] == 'O' && 
-            buffer[2] == 'P' && buffer[3] == 'P')
-            return 1;
-      }
-   }
-   return 0;
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_alloc_passthru_buffer                                  */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*   allocate a buffer large enough for the ioctl data if the ioctl buffer  */
+/*   is too small or doesn't exist                                          */
+/****************************************************************************/
+static int
+ips_alloc_passthru_buffer(ips_ha_t * ha, int length)
+{
+	void *bigger_buf;
+	int count;
+	int order;
+
+	if (ha->ioctl_data && length <= (PAGE_SIZE << ha->ioctl_order))
+		return 0;
+	/* there is no buffer or it's not big enough, allocate a new one */
+	for (count = PAGE_SIZE, order = 0;
+	     count < length; order++, count <<= 1) ;
+	bigger_buf = (void *) __get_free_pages(IPS_ATOMIC_GFP, order);
+	if (bigger_buf) {
+		/* free the old memory */
+		free_pages((unsigned long) ha->ioctl_data, ha->ioctl_order);
+		/* use the new memory */
+		ha->ioctl_data = (char *) bigger_buf;
+		ha->ioctl_order = order;
+	} else {
+		return -1;
+	}
+	return 0;
 }
 
 /****************************************************************************/
@@ -2281,127 +1609,96 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_make_passthru(ips_ha_t *ha, Scsi_Cmnd *SC, ips_scb_t *scb, int intr) {
-   ips_passthru_t *pt;
-   char *buffer;
-   int length = 0;
-
-   METHOD_TRACE("ips_make_passthru", 1);
-
-   if(!SC->use_sg){
-      buffer = SC->request_buffer;
-      length = SC->request_bufflen;
-   }else{
-      struct scatterlist *sg = SC->request_buffer;
-      int i;
-      for(i = 0; i < SC->use_sg; i++)
-         length += sg[i].length;
-
-      if (length < sizeof(ips_passthru_t)) {
-         /* wrong size */
-         DEBUG_VAR(1, "(%s%d) Passthru structure wrong size",
-             ips_name, ha->host_num);
-         return (IPS_FAILURE);
-      }else if(!ha->ioctl_data || length > (PAGE_SIZE << ha->ioctl_order)){
-         void *bigger_buf;
-         int count;
-         int order;
-         /* try to allocate a bigger buffer */
-         for (count = PAGE_SIZE, order = 0;
-              count < length;
-              order++, count <<= 1);
-         bigger_buf = (void *) __get_free_pages(GFP_ATOMIC, order);
-         if (bigger_buf) {
-            /* free the old memory */
-            free_pages((unsigned long) ha->ioctl_data, ha->ioctl_order);
-            /* use the new memory */
-            ha->ioctl_data = (char *) bigger_buf;
-            ha->ioctl_order = order;
-            ha->ioctl_datasize = count;
-         } else {
-             pt = (ips_passthru_t*)IPS_SG_ADDRESS(sg);
-             pt->BasicStatus = 0x0B;
-             pt->ExtendedStatus = 0x00;
-             SC->result = DID_ERROR << 16;
-             return (IPS_FAILURE);
-         }
-      }
-      ha->ioctl_datasize = length;
-      length = 0;
-      for(i = 0; i < SC->use_sg; i++){
-         memcpy(&ha->ioctl_data[length], IPS_SG_ADDRESS(&sg[i]), sg[i].length);
-         length += sg[i].length;
-      }
-      pt = (ips_passthru_t *)ha->ioctl_data;
-      buffer = ha->ioctl_data;
-   }
-   if (!length || !buffer) {
-      /* no data */
-      DEBUG_VAR(1, "(%s%d) No passthru structure",
-                ips_name, ha->host_num);
-
-      return (IPS_FAILURE);
-   }
-   if (length < sizeof(ips_passthru_t)) {
-      /* wrong size */
-      DEBUG_VAR(1, "(%s%d) Passthru structure wrong size",
-             ips_name, ha->host_num);
-
-      return (IPS_FAILURE);
-   }
-   pt = (ips_passthru_t*) buffer;
-   /*
-    * Some notes about the passthru interface used
-    *
-    * IF the scsi op_code == 0x0d then we assume
-    * that the data came along with/goes with the
-    * packet we received from the sg driver. In this
-    * case the CmdBSize field of the pt structure is
-    * used for the size of the buffer.
-    */
-
-   switch (pt->CoppCmd) {
-   case IPS_NUMCTRLS:
-      memcpy(buffer + sizeof(ips_passthru_t),
-             &ips_num_controllers, sizeof(int));
-      SC->result = DID_OK << 16;
-
-      return (IPS_SUCCESS_IMM);
-
-   case IPS_CTRLINFO:
-      memcpy(buffer + sizeof(ips_passthru_t),
-             ha, sizeof(ips_ha_t));
-      SC->result = DID_OK << 16;
-
-      return (IPS_SUCCESS_IMM);
-
-   case IPS_COPPUSRCMD:
-   case IPS_COPPIOCCMD:
-      if (SC->cmnd[0] == IPS_IOCTL_COMMAND) {
-         if (length < (sizeof(ips_passthru_t) + pt->CmdBSize)) {
-            /* wrong size */
-            DEBUG_VAR(1, "(%s%d) Passthru structure wrong size",
-                      ips_name, ha->host_num);
-
-            return (IPS_FAILURE);
-         }
-
-         if(ha->device_id == IPS_DEVICEID_COPPERHEAD &&
-            pt->CoppCP.cmd.flashfw.op_code == IPS_CMD_RW_BIOSFW)
-            return ips_flash_copperhead(ha, pt, scb);
-
-         if (ips_usrcmd(ha, pt, scb))
-            return (IPS_SUCCESS);
-         else
-            return (IPS_FAILURE);
-      } 
-     
-      break;
+ips_make_passthru(ips_ha_t * ha, Scsi_Cmnd * SC, ips_scb_t * scb, int intr)
+{
+	ips_passthru_t *pt;
+	int length = 0;
+	int ret;
+
+	METHOD_TRACE("ips_make_passthru", 1);
+
+	if (!SC->use_sg) {
+		length = SC->request_bufflen;
+	} else {
+		struct scatterlist *sg = SC->request_buffer;
+		int i;
+		for (i = 0; i < SC->use_sg; i++)
+			length += sg[i].length;
+	}
+	if (length < sizeof (ips_passthru_t)) {
+		/* wrong size */
+		DEBUG_VAR(1, "(%s%d) Passthru structure wrong size",
+			  ips_name, ha->host_num);
+		return (IPS_FAILURE);
+	}
+	if (ips_alloc_passthru_buffer(ha, length)) {
+		/* allocation failure!  If ha->ioctl_data exists, use it to return
+		   some error codes.  Return a failed command to the scsi layer. */
+		if (ha->ioctl_data) {
+			pt = (ips_passthru_t *) ha->ioctl_data;
+			ips_scmd_buf_read(SC, pt, sizeof (ips_passthru_t));
+			pt->BasicStatus = 0x0B;
+			pt->ExtendedStatus = 0x00;
+			ips_scmd_buf_write(SC, pt, sizeof (ips_passthru_t));
+		}
+		return IPS_FAILURE;
+	}
+	ha->ioctl_datasize = length;
+
+	ips_scmd_buf_read(SC, ha->ioctl_data, ha->ioctl_datasize);
+	pt = (ips_passthru_t *) ha->ioctl_data;
+
+	/*
+	 * Some notes about the passthru interface used
+	 *
+	 * IF the scsi op_code == 0x0d then we assume
+	 * that the data came along with/goes with the
+	 * packet we received from the sg driver. In this
+	 * case the CmdBSize field of the pt structure is
+	 * used for the size of the buffer.
+	 */
+
+	switch (pt->CoppCmd) {
+	case IPS_NUMCTRLS:
+		memcpy(ha->ioctl_data + sizeof (ips_passthru_t),
+		       &ips_num_controllers, sizeof (int));
+		ips_scmd_buf_write(SC, ha->ioctl_data,
+				   sizeof (ips_passthru_t) + sizeof (int));
+		SC->result = DID_OK << 16;
+
+		return (IPS_SUCCESS_IMM);
+
+	case IPS_COPPUSRCMD:
+	case IPS_COPPIOCCMD:
+		if (SC->cmnd[0] == IPS_IOCTL_COMMAND) {
+			if (length < (sizeof (ips_passthru_t) + pt->CmdBSize)) {
+				/* wrong size */
+				DEBUG_VAR(1,
+					  "(%s%d) Passthru structure wrong size",
+					  ips_name, ha->host_num);
+
+				return (IPS_FAILURE);
+			}
+
+			if (ha->device_id == IPS_DEVICEID_COPPERHEAD &&
+			    pt->CoppCP.cmd.flashfw.op_code == IPS_CMD_RW_BIOSFW) {
+				ret = ips_flash_copperhead(ha, pt, scb);
+				ips_scmd_buf_write(SC, ha->ioctl_data,
+						   sizeof (ips_passthru_t));
+				return ret;
+			}
+			if (ips_usrcmd(ha, pt, scb))
+				return (IPS_SUCCESS);
+			else
+				return (IPS_FAILURE);
+		}
 
-   } /* end switch */
+		break;
 
-         return (IPS_FAILURE);
-      }
+	}			/* end switch */
+
+	return (IPS_FAILURE);
+}
 
 /****************************************************************************/
 /* Routine Name: ips_flash_copperhead                                       */
@@ -2409,62 +1706,65 @@
 /*   Flash the BIOS/FW on a Copperhead style controller                     */
 /****************************************************************************/
 static int
-ips_flash_copperhead(ips_ha_t *ha, ips_passthru_t *pt, ips_scb_t *scb){
-   int datasize, count;
+ips_flash_copperhead(ips_ha_t * ha, ips_passthru_t * pt, ips_scb_t * scb)
+{
+	int datasize, count;
 
-   /* Trombone is the only copperhead that can do packet flash, but only
-    * for firmware. No one said it had to make sence. */
-   if(IPS_IS_TROMBONE(ha) && pt->CoppCP.cmd.flashfw.type == IPS_FW_IMAGE){
-      if(ips_usrcmd(ha, pt, scb))
-         return IPS_SUCCESS;
-      else
-         return IPS_FAILURE;
-   }
-   pt->BasicStatus = 0x0B;
-   pt->ExtendedStatus = 0;
-   scb->scsi_cmd->result = DID_OK <<16;
-   /* IF it's OK to Use the "CD BOOT" Flash Buffer, then you can     */
-   /* avoid allocating a huge buffer per adapter ( which can fail ). */
-   if(pt->CoppCP.cmd.flashfw.type == IPS_BIOS_IMAGE &&
-      pt->CoppCP.cmd.flashfw.direction == IPS_ERASE_BIOS){
-      pt->BasicStatus = 0;
-      return ips_flash_bios(ha, pt, scb);
-   }else if(pt->CoppCP.cmd.flashfw.packet_num == 0){
-      if(ips_FlashData && !test_and_set_bit(0, &ips_FlashDataInUse)){
-         ha->flash_data  = ips_FlashData;
-         ha->flash_order = 7;
-         ha->flash_datasize = 0;
-      }else if(!ha->flash_data){
-         datasize = pt->CoppCP.cmd.flashfw.total_packets *
-                    pt->CoppCP.cmd.flashfw.count;
-         for (count = PAGE_SIZE, ha->flash_order = 0; count < datasize;
-              ha->flash_order++, count <<= 1);
-         ha->flash_data = (char *)__get_free_pages(GFP_ATOMIC, ha->flash_order);
-         ha->flash_datasize = 0;
-      }else
-         return IPS_FAILURE;
-   }else{
-      if(pt->CoppCP.cmd.flashfw.count + ha->flash_datasize >
-        (PAGE_SIZE << ha->flash_order)){
-         ips_free_flash_copperhead(ha);
-         printk(KERN_WARNING "failed size sanity check\n");
-         return IPS_FAILURE;
-      }
-   }
-   if(!ha->flash_data)
-      return IPS_FAILURE;
-   pt->BasicStatus = 0;
-   memcpy(&ha->flash_data[ha->flash_datasize], pt + 1,
-          pt->CoppCP.cmd.flashfw.count);
-   ha->flash_datasize += pt->CoppCP.cmd.flashfw.count;
-   if(pt->CoppCP.cmd.flashfw.packet_num ==
-      pt->CoppCP.cmd.flashfw.total_packets - 1){
-      if(pt->CoppCP.cmd.flashfw.type == IPS_BIOS_IMAGE)
-         return ips_flash_bios(ha, pt, scb);
-      else if(pt->CoppCP.cmd.flashfw.type == IPS_FW_IMAGE)
-         return ips_flash_firmware(ha, pt, scb);
-   }
-   return IPS_SUCCESS_IMM;
+	/* Trombone is the only copperhead that can do packet flash, but only
+	 * for firmware. No one said it had to make sence. */
+	if (IPS_IS_TROMBONE(ha) && pt->CoppCP.cmd.flashfw.type == IPS_FW_IMAGE) {
+		if (ips_usrcmd(ha, pt, scb))
+			return IPS_SUCCESS;
+		else
+			return IPS_FAILURE;
+	}
+	pt->BasicStatus = 0x0B;
+	pt->ExtendedStatus = 0;
+	scb->scsi_cmd->result = DID_OK << 16;
+	/* IF it's OK to Use the "CD BOOT" Flash Buffer, then you can     */
+	/* avoid allocating a huge buffer per adapter ( which can fail ). */
+	if (pt->CoppCP.cmd.flashfw.type == IPS_BIOS_IMAGE &&
+	    pt->CoppCP.cmd.flashfw.direction == IPS_ERASE_BIOS) {
+		pt->BasicStatus = 0;
+		return ips_flash_bios(ha, pt, scb);
+	} else if (pt->CoppCP.cmd.flashfw.packet_num == 0) {
+		if (ips_FlashData && !test_and_set_bit(0, &ips_FlashDataInUse)) {
+			ha->flash_data = ips_FlashData;
+			ha->flash_order = 7;
+			ha->flash_datasize = 0;
+		} else if (!ha->flash_data) {
+			datasize = pt->CoppCP.cmd.flashfw.total_packets *
+			    pt->CoppCP.cmd.flashfw.count;
+			for (count = PAGE_SIZE, ha->flash_order = 0;
+			     count < datasize; ha->flash_order++, count <<= 1) ;
+			ha->flash_data =
+			    (char *) __get_free_pages(IPS_ATOMIC_GFP,
+						      ha->flash_order);
+			ha->flash_datasize = 0;
+		} else
+			return IPS_FAILURE;
+	} else {
+		if (pt->CoppCP.cmd.flashfw.count + ha->flash_datasize >
+		    (PAGE_SIZE << ha->flash_order)) {
+			ips_free_flash_copperhead(ha);
+			printk(KERN_WARNING "failed size sanity check\n");
+			return IPS_FAILURE;
+		}
+	}
+	if (!ha->flash_data)
+		return IPS_FAILURE;
+	pt->BasicStatus = 0;
+	memcpy(&ha->flash_data[ha->flash_datasize], pt + 1,
+	       pt->CoppCP.cmd.flashfw.count);
+	ha->flash_datasize += pt->CoppCP.cmd.flashfw.count;
+	if (pt->CoppCP.cmd.flashfw.packet_num ==
+	    pt->CoppCP.cmd.flashfw.total_packets - 1) {
+		if (pt->CoppCP.cmd.flashfw.type == IPS_BIOS_IMAGE)
+			return ips_flash_bios(ha, pt, scb);
+		else if (pt->CoppCP.cmd.flashfw.type == IPS_FW_IMAGE)
+			return ips_flash_firmware(ha, pt, scb);
+	}
+	return IPS_SUCCESS_IMM;
 }
 
 /****************************************************************************/
@@ -2473,46 +1773,95 @@
 /*   flashes the bios of a copperhead adapter                               */
 /****************************************************************************/
 static int
-ips_flash_bios(ips_ha_t * ha, ips_passthru_t *pt, ips_scb_t *scb){
+ips_flash_bios(ips_ha_t * ha, ips_passthru_t * pt, ips_scb_t * scb)
+{
 
-   if(pt->CoppCP.cmd.flashfw.type == IPS_BIOS_IMAGE &&
-      pt->CoppCP.cmd.flashfw.direction == IPS_WRITE_BIOS){
-      if ((!ha->func.programbios) || (!ha->func.erasebios) ||
-          (!ha->func.verifybios))
-         goto error;
-      if((*ha->func.erasebios)(ha)){
-         DEBUG_VAR(1, "(%s%d) flash bios failed - unable to erase flash",
-                   ips_name, ha->host_num);
-         goto error;
-      }else if ((*ha->func.programbios)(ha, ha->flash_data + IPS_BIOS_HEADER,
-          ha->flash_datasize - IPS_BIOS_HEADER, 0 )) {
-         DEBUG_VAR(1, "(%s%d) flash bios failed - unable to flash",
-                   ips_name, ha->host_num);
-         goto error;
-      }else if ((*ha->func.verifybios)(ha, ha->flash_data + IPS_BIOS_HEADER,
-          ha->flash_datasize - IPS_BIOS_HEADER, 0 )) {
-         DEBUG_VAR(1, "(%s%d) flash bios failed - unable to verify flash",
-                   ips_name, ha->host_num);
-         goto error;
-      }
-      ips_free_flash_copperhead(ha);
-      return IPS_SUCCESS_IMM;
-   }else if(pt->CoppCP.cmd.flashfw.type == IPS_BIOS_IMAGE &&
-      pt->CoppCP.cmd.flashfw.direction == IPS_ERASE_BIOS){
-      if(!ha->func.erasebios)
-         goto error;
-      if((*ha->func.erasebios)(ha)){
-         DEBUG_VAR(1, "(%s%d) flash bios failed - unable to erase flash",
-                   ips_name, ha->host_num);
-         goto error;
-      }
-      return IPS_SUCCESS_IMM;
-   }
-error:
-   pt->BasicStatus = 0x0B;
-   pt->ExtendedStatus = 0x00;
-   ips_free_flash_copperhead(ha);
-   return IPS_FAILURE;
+	if (pt->CoppCP.cmd.flashfw.type == IPS_BIOS_IMAGE &&
+	    pt->CoppCP.cmd.flashfw.direction == IPS_WRITE_BIOS) {
+		if ((!ha->func.programbios) || (!ha->func.erasebios) ||
+		    (!ha->func.verifybios)) goto error;
+		if ((*ha->func.erasebios) (ha)) {
+			DEBUG_VAR(1,
+				  "(%s%d) flash bios failed - unable to erase flash",
+				  ips_name, ha->host_num);
+			goto error;
+		} else
+		    if ((*ha->func.programbios)
+			(ha, ha->flash_data + IPS_BIOS_HEADER,
+			 ha->flash_datasize - IPS_BIOS_HEADER, 0)) {
+			DEBUG_VAR(1,
+				  "(%s%d) flash bios failed - unable to flash",
+				  ips_name, ha->host_num);
+			goto error;
+		} else
+		    if ((*ha->func.verifybios)
+			(ha, ha->flash_data + IPS_BIOS_HEADER,
+			 ha->flash_datasize - IPS_BIOS_HEADER, 0)) {
+			DEBUG_VAR(1,
+				  "(%s%d) flash bios failed - unable to verify flash",
+				  ips_name, ha->host_num);
+			goto error;
+		}
+		ips_free_flash_copperhead(ha);
+		return IPS_SUCCESS_IMM;
+	} else if (pt->CoppCP.cmd.flashfw.type == IPS_BIOS_IMAGE &&
+		   pt->CoppCP.cmd.flashfw.direction == IPS_ERASE_BIOS) {
+		if (!ha->func.erasebios)
+			goto error;
+		if ((*ha->func.erasebios) (ha)) {
+			DEBUG_VAR(1,
+				  "(%s%d) flash bios failed - unable to erase flash",
+				  ips_name, ha->host_num);
+			goto error;
+		}
+		return IPS_SUCCESS_IMM;
+	}
+      error:
+	pt->BasicStatus = 0x0B;
+	pt->ExtendedStatus = 0x00;
+	ips_free_flash_copperhead(ha);
+	return IPS_FAILURE;
+}
+
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_fill_scb_sg_single                                     */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*   Fill in a single scb sg_list element from an address                   */
+/*   return a -1 if a breakup occured                                       */
+/****************************************************************************/
+static inline int
+ips_fill_scb_sg_single(ips_ha_t * ha, dma_addr_t busaddr,
+		       ips_scb_t * scb, int indx, unsigned int e_len)
+{
+
+	int ret_val = 0;
+
+	if ((scb->data_len + e_len) > ha->max_xfer) {
+		e_len = ha->max_xfer - scb->data_len;
+		scb->breakup = indx;
+		++scb->sg_break;
+		ret_val = -1;
+	} else {
+		scb->breakup = 0;
+		scb->sg_break = 0;
+	}
+	if (IPS_USE_ENH_SGLIST(ha)) {
+		scb->sg_list.enh_list[indx].address_lo =
+		    cpu_to_le32(pci_dma_lo32(busaddr));
+		scb->sg_list.enh_list[indx].address_hi =
+		    cpu_to_le32(pci_dma_hi32(busaddr));
+		scb->sg_list.enh_list[indx].length = cpu_to_le32(e_len);
+	} else {
+		scb->sg_list.std_list[indx].address =
+		    cpu_to_le32(pci_dma_lo32(busaddr));
+		scb->sg_list.std_list[indx].length = cpu_to_le32(e_len);
+	}
+
+	++scb->sg_len;
+	scb->data_len += e_len;
+	return ret_val;
 }
 
 /****************************************************************************/
@@ -2521,49 +1870,51 @@
 /*   flashes the firmware of a copperhead adapter                           */
 /****************************************************************************/
 static int
-ips_flash_firmware(ips_ha_t * ha, ips_passthru_t *pt, ips_scb_t *scb){
-   IPS_SG_LIST *sg_list;
-   uint32_t cmd_busaddr;
-
-   if(pt->CoppCP.cmd.flashfw.type == IPS_FW_IMAGE &&
-      pt->CoppCP.cmd.flashfw.direction == IPS_WRITE_FW ){
-      memset(&pt->CoppCP.cmd, 0, sizeof(IPS_HOST_COMMAND));
-      pt->CoppCP.cmd.flashfw.op_code = IPS_CMD_DOWNLOAD;
-      pt->CoppCP.cmd.flashfw.count = cpu_to_le32(ha->flash_datasize);
-   }else{
-      pt->BasicStatus = 0x0B;
-      pt->ExtendedStatus = 0x00;
-      ips_free_flash_copperhead(ha);
-      return IPS_FAILURE;
-   }
-   /* Save the S/G list pointer so it doesn't get clobbered */
-   sg_list = scb->sg_list;
-   cmd_busaddr = scb->scb_busaddr;
-   /* copy in the CP */
-   memcpy(&scb->cmd, &pt->CoppCP.cmd, sizeof(IPS_IOCTL_CMD));
-   /* FIX stuff that might be wrong */
-   scb->sg_list = sg_list;
-   scb->scb_busaddr = cmd_busaddr;
-   scb->bus = scb->scsi_cmd->channel;
-   scb->target_id = scb->scsi_cmd->target;
-   scb->lun = scb->scsi_cmd->lun;
-   scb->sg_len = 0;
-   scb->data_len = 0;
-   scb->flags = 0;
-   scb->op_code = 0;
-   scb->callback = ipsintr_done;
-   scb->timeout = ips_cmd_timeout;
-
-   scb->data_len = ha->flash_datasize;
-   scb->data_busaddr = pci_map_single(ha->pcidev, ha->flash_data, scb->data_len,
-                                      IPS_DMA_DIR(scb));
-   scb->flags |= IPS_SCB_MAP_SINGLE;
-   scb->cmd.flashfw.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->cmd.flashfw.buffer_addr = scb->data_busaddr;
-   if (pt->TimeOut)
-      scb->timeout = pt->TimeOut;
-   scb->scsi_cmd->result = DID_OK <<16;
-   return IPS_SUCCESS;
+ips_flash_firmware(ips_ha_t * ha, ips_passthru_t * pt, ips_scb_t * scb)
+{
+	IPS_SG_LIST sg_list;
+	uint32_t cmd_busaddr;
+
+	if (pt->CoppCP.cmd.flashfw.type == IPS_FW_IMAGE &&
+	    pt->CoppCP.cmd.flashfw.direction == IPS_WRITE_FW) {
+		memset(&pt->CoppCP.cmd, 0, sizeof (IPS_HOST_COMMAND));
+		pt->CoppCP.cmd.flashfw.op_code = IPS_CMD_DOWNLOAD;
+		pt->CoppCP.cmd.flashfw.count = cpu_to_le32(ha->flash_datasize);
+	} else {
+		pt->BasicStatus = 0x0B;
+		pt->ExtendedStatus = 0x00;
+		ips_free_flash_copperhead(ha);
+		return IPS_FAILURE;
+	}
+	/* Save the S/G list pointer so it doesn't get clobbered */
+	sg_list.list = scb->sg_list.list;
+	cmd_busaddr = scb->scb_busaddr;
+	/* copy in the CP */
+	memcpy(&scb->cmd, &pt->CoppCP.cmd, sizeof (IPS_IOCTL_CMD));
+	/* FIX stuff that might be wrong */
+	scb->sg_list.list = sg_list.list;
+	scb->scb_busaddr = cmd_busaddr;
+	scb->bus = scb->scsi_cmd->channel;
+	scb->target_id = scb->scsi_cmd->target;
+	scb->lun = scb->scsi_cmd->lun;
+	scb->sg_len = 0;
+	scb->data_len = 0;
+	scb->flags = 0;
+	scb->op_code = 0;
+	scb->callback = ipsintr_done;
+	scb->timeout = ips_cmd_timeout;
+
+	scb->data_len = ha->flash_datasize;
+	scb->data_busaddr =
+	    pci_map_single(ha->pcidev, ha->flash_data, scb->data_len,
+			   IPS_DMA_DIR(scb));
+	scb->flags |= IPS_SCB_MAP_SINGLE;
+	scb->cmd.flashfw.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->cmd.flashfw.buffer_addr = cpu_to_le32(scb->data_busaddr);
+	if (pt->TimeOut)
+		scb->timeout = pt->TimeOut;
+	scb->scsi_cmd->result = DID_OK << 16;
+	return IPS_SUCCESS;
 }
 
 /****************************************************************************/
@@ -2572,12 +1923,13 @@
 /*   release the memory resources used to hold the flash image              */
 /****************************************************************************/
 static void
-ips_free_flash_copperhead(ips_ha_t *ha){
-   if(ha->flash_data == ips_FlashData)
-      test_and_clear_bit(0, &ips_FlashDataInUse);
-   else if(ha->flash_data)
-      free_pages((unsigned long)ha->flash_data, ha->flash_order);
-   ha->flash_data = NULL;
+ips_free_flash_copperhead(ips_ha_t * ha)
+{
+	if (ha->flash_data == ips_FlashData)
+		test_and_clear_bit(0, &ips_FlashDataInUse);
+	else if (ha->flash_data)
+		free_pages((unsigned long) ha->flash_data, ha->flash_order);
+	ha->flash_data = NULL;
 }
 
 /****************************************************************************/
@@ -2590,93 +1942,87 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_usrcmd(ips_ha_t *ha, ips_passthru_t *pt, ips_scb_t *scb) {
-   IPS_SG_LIST *sg_list;
-   uint32_t cmd_busaddr;
-
-   METHOD_TRACE("ips_usrcmd", 1);
-
-   if ((!scb) || (!pt) || (!ha))
-      return (0);
-
-   /* Save the S/G list pointer so it doesn't get clobbered */
-   sg_list = scb->sg_list;
-   cmd_busaddr = scb->scb_busaddr;
-   /* copy in the CP */
-   memcpy(&scb->cmd, &pt->CoppCP.cmd, sizeof(IPS_IOCTL_CMD));
-   memcpy(&scb->dcdb, &pt->CoppCP.dcdb, sizeof(IPS_DCDB_TABLE));
-
-   /* FIX stuff that might be wrong */
-   scb->sg_list = sg_list;
-   scb->scb_busaddr = cmd_busaddr;
-   scb->bus = scb->scsi_cmd->channel;
-   scb->target_id = scb->scsi_cmd->target;
-   scb->lun = scb->scsi_cmd->lun;
-   scb->sg_len = 0;
-   scb->data_len = 0;
-   scb->flags = 0;
-   scb->op_code = 0;
-   scb->callback = ipsintr_done;
-   scb->timeout = ips_cmd_timeout;
-   scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
-
-   /* we don't support DCDB/READ/WRITE Scatter Gather */
-   if ((scb->cmd.basic_io.op_code == IPS_CMD_READ_SG) ||
-       (scb->cmd.basic_io.op_code == IPS_CMD_WRITE_SG) ||
-       (scb->cmd.basic_io.op_code == IPS_CMD_DCDB_SG))
-      return (0);
-
-   if (pt->CmdBSize) {
-      if(!scb->scsi_cmd->use_sg){
-         scb->data_len = pt->CmdBSize;
-         scb->data_busaddr = pci_map_single(ha->pcidev,
-                                            scb->scsi_cmd->request_buffer +
-                                            sizeof(ips_passthru_t),
-                                            pt->CmdBSize,
-                                            IPS_DMA_DIR(scb));
-         scb->flags |= IPS_SCB_MAP_SINGLE;
-      } else {
-         scb->data_len = pt->CmdBSize;
-         scb->data_busaddr = pci_map_single(ha->pcidev,
-                                            ha->ioctl_data +
-                                            sizeof(ips_passthru_t),
-                                            pt->CmdBSize,
-                                            IPS_DMA_DIR(scb));
-         scb->flags |= IPS_SCB_MAP_SINGLE;
-      }
-   } else {
-      scb->data_busaddr = 0L;
-   }
-
-   if (scb->cmd.dcdb.op_code == IPS_CMD_DCDB)
-      scb->cmd.dcdb.dcdb_address = cpu_to_le32(scb->scb_busaddr +
-                                          (unsigned long)&scb->dcdb -
-                                          (unsigned long)scb);
-
-   if (pt->CmdBSize) {
-      if (scb->cmd.dcdb.op_code == IPS_CMD_DCDB)
-         scb->dcdb.buffer_pointer = cpu_to_le32(scb->data_busaddr);
-      else
-         scb->cmd.basic_io.sg_addr = cpu_to_le32(scb->data_busaddr);
-   }
-
-   /* set timeouts */
-   if (pt->TimeOut) {
-      scb->timeout = pt->TimeOut;
-
-      if (pt->TimeOut <= 10)
-         scb->dcdb.cmd_attribute |= IPS_TIMEOUT10;
-      else if (pt->TimeOut <= 60)
-         scb->dcdb.cmd_attribute |= IPS_TIMEOUT60;
-      else
-         scb->dcdb.cmd_attribute |= IPS_TIMEOUT20M;
-   }
+ips_usrcmd(ips_ha_t * ha, ips_passthru_t * pt, ips_scb_t * scb)
+{
+	IPS_SG_LIST sg_list;
+	uint32_t cmd_busaddr;
+
+	METHOD_TRACE("ips_usrcmd", 1);
+
+	if ((!scb) || (!pt) || (!ha))
+		return (0);
+
+	/* Save the S/G list pointer so it doesn't get clobbered */
+	sg_list.list = scb->sg_list.list;
+	cmd_busaddr = scb->scb_busaddr;
+	/* copy in the CP */
+	memcpy(&scb->cmd, &pt->CoppCP.cmd, sizeof (IPS_IOCTL_CMD));
+	memcpy(&scb->dcdb, &pt->CoppCP.dcdb, sizeof (IPS_DCDB_TABLE));
+
+	/* FIX stuff that might be wrong */
+	scb->sg_list.list = sg_list.list;
+	scb->scb_busaddr = cmd_busaddr;
+	scb->bus = scb->scsi_cmd->channel;
+	scb->target_id = scb->scsi_cmd->target;
+	scb->lun = scb->scsi_cmd->lun;
+	scb->sg_len = 0;
+	scb->data_len = 0;
+	scb->flags = 0;
+	scb->op_code = 0;
+	scb->callback = ipsintr_done;
+	scb->timeout = ips_cmd_timeout;
+	scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
+
+	/* we don't support DCDB/READ/WRITE Scatter Gather */
+	if ((scb->cmd.basic_io.op_code == IPS_CMD_READ_SG) ||
+	    (scb->cmd.basic_io.op_code == IPS_CMD_WRITE_SG) ||
+	    (scb->cmd.basic_io.op_code == IPS_CMD_DCDB_SG))
+		return (0);
+
+	if (pt->CmdBSize) {
+		scb->data_len = pt->CmdBSize;
+		scb->data_busaddr = pci_map_single(ha->pcidev,
+						   ha->ioctl_data +
+						   sizeof (ips_passthru_t),
+						   pt->CmdBSize,
+						   IPS_DMA_DIR(scb));
+		scb->flags |= IPS_SCB_MAP_SINGLE;
+	} else {
+		scb->data_busaddr = 0L;
+	}
+
+	if (scb->cmd.dcdb.op_code == IPS_CMD_DCDB)
+		scb->cmd.dcdb.dcdb_address = cpu_to_le32(scb->scb_busaddr +
+							 (unsigned long) &scb->
+							 dcdb -
+							 (unsigned long) scb);
+
+	if (pt->CmdBSize) {
+		if (scb->cmd.dcdb.op_code == IPS_CMD_DCDB)
+			scb->dcdb.buffer_pointer =
+			    cpu_to_le32(scb->data_busaddr);
+		else
+			scb->cmd.basic_io.sg_addr =
+			    cpu_to_le32(scb->data_busaddr);
+	}
+
+	/* set timeouts */
+	if (pt->TimeOut) {
+		scb->timeout = pt->TimeOut;
+
+		if (pt->TimeOut <= 10)
+			scb->dcdb.cmd_attribute |= IPS_TIMEOUT10;
+		else if (pt->TimeOut <= 60)
+			scb->dcdb.cmd_attribute |= IPS_TIMEOUT60;
+		else
+			scb->dcdb.cmd_attribute |= IPS_TIMEOUT20M;
+	}
 
-   /* assume success */
-   scb->scsi_cmd->result = DID_OK << 16;
+	/* assume success */
+	scb->scsi_cmd->result = DID_OK << 16;
 
-   /* success */
-   return (1);
+	/* success */
+	return (1);
 }
 
 /****************************************************************************/
@@ -2689,43 +2035,34 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_cleanup_passthru(ips_ha_t *ha, ips_scb_t *scb) {
-   ips_passthru_t *pt;
+ips_cleanup_passthru(ips_ha_t * ha, ips_scb_t * scb)
+{
+	ips_passthru_t *pt;
+
+	METHOD_TRACE("ips_cleanup_passthru", 1);
+
+	if ((!scb) || (!scb->scsi_cmd) || (!scb->scsi_cmd->request_buffer)) {
+		DEBUG_VAR(1, "(%s%d) couldn't cleanup after passthru",
+			  ips_name, ha->host_num);
 
-   METHOD_TRACE("ips_cleanup_passthru", 1);
+		return;
+	}
+	pt = (ips_passthru_t *) ha->ioctl_data;
 
-   if ((!scb) || (!scb->scsi_cmd) || (!scb->scsi_cmd->request_buffer)) {
-      DEBUG_VAR(1, "(%s%d) couldn't cleanup after passthru",
-                ips_name, ha->host_num);
-
-      return ;
-   }
-   if(!scb->scsi_cmd->use_sg)
-      pt = (ips_passthru_t *) scb->scsi_cmd->request_buffer;
-   else
-      pt = (ips_passthru_t *) ha->ioctl_data;
-
-   /* Copy data back to the user */
-   if (scb->cmd.dcdb.op_code == IPS_CMD_DCDB)        /* Copy DCDB Back to Caller's Area */
-      memcpy(&pt->CoppCP.dcdb, &scb->dcdb, sizeof(IPS_DCDB_TABLE));
-   
-   pt->BasicStatus = scb->basic_status;
-   pt->ExtendedStatus = scb->extended_status;
-   pt->AdapterType = ha->ad_type;
-
-   if(ha->device_id == IPS_DEVICEID_COPPERHEAD && 
-     (scb->cmd.flashfw.op_code == IPS_CMD_DOWNLOAD || 
-     scb->cmd.flashfw.op_code == IPS_CMD_RW_BIOSFW))
-      ips_free_flash_copperhead(ha);
-
-   if(scb->scsi_cmd->use_sg){
-      int i, length = 0;
-      struct scatterlist *sg = scb->scsi_cmd->request_buffer;
-      for(i = 0; i < scb->scsi_cmd->use_sg; i++){
-         memcpy(IPS_SG_ADDRESS(&sg[i]), &ha->ioctl_data[length], sg[i].length);
-         length += sg[i].length;
-      }
-   }
+	/* Copy data back to the user */
+	if (scb->cmd.dcdb.op_code == IPS_CMD_DCDB)	/* Copy DCDB Back to Caller's Area */
+		memcpy(&pt->CoppCP.dcdb, &scb->dcdb, sizeof (IPS_DCDB_TABLE));
+
+	pt->BasicStatus = scb->basic_status;
+	pt->ExtendedStatus = scb->extended_status;
+	pt->AdapterType = ha->ad_type;
+
+	if (ha->device_id == IPS_DEVICEID_COPPERHEAD &&
+	    (scb->cmd.flashfw.op_code == IPS_CMD_DOWNLOAD ||
+	     scb->cmd.flashfw.op_code == IPS_CMD_RW_BIOSFW))
+		ips_free_flash_copperhead(ha);
+
+	ips_scmd_buf_write(scb->scsi_cmd, ha->ioctl_data, ha->ioctl_datasize);
 }
 
 /****************************************************************************/
@@ -2738,75 +2075,88 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_host_info(ips_ha_t *ha, char *ptr, off_t offset, int len) {
-   IPS_INFOSTR info;
+ips_host_info(ips_ha_t * ha, char *ptr, off_t offset, int len)
+{
+	IPS_INFOSTR info;
 
-   METHOD_TRACE("ips_host_info", 1);
+	METHOD_TRACE("ips_host_info", 1);
 
-   info.buffer = ptr;
-   info.length = len;
-   info.offset = offset;
-   info.pos = 0;
-   info.localpos = 0;
-
-   copy_info(&info, "\nIBM ServeRAID General Information:\n\n");
-
-   if ((le32_to_cpu(ha->nvram->signature) == IPS_NVRAM_P5_SIG) &&
-       (le16_to_cpu(ha->nvram->adapter_type) != 0))
-      copy_info(&info, "\tController Type                   : %s\n", ips_adapter_name[ha->ad_type-1]);
-   else
-      copy_info(&info, "\tController Type                   : Unknown\n");
-
-   if (ha->io_addr)
-      copy_info(&info, "\tIO region                         : 0x%lx (%d bytes)\n",
-                ha->io_addr, ha->io_len);
-
-   if (ha->mem_addr) {
-      copy_info(&info, "\tMemory region                     : 0x%lx (%d bytes)\n",
-                ha->mem_addr, ha->mem_len);
-      copy_info(&info, "\tShared memory address             : 0x%lx\n", ha->mem_ptr);
-   }
-
-   copy_info(&info, "\tIRQ number                        : %d\n", ha->irq);
-
-   if (le32_to_cpu(ha->nvram->signature) == IPS_NVRAM_P5_SIG)
-      copy_info(&info, "\tBIOS Version                      : %c%c%c%c%c%c%c%c\n",
-                ha->nvram->bios_high[0], ha->nvram->bios_high[1],
-                ha->nvram->bios_high[2], ha->nvram->bios_high[3],
-                ha->nvram->bios_low[0], ha->nvram->bios_low[1],
-                ha->nvram->bios_low[2], ha->nvram->bios_low[3]);
-
-   copy_info(&info, "\tFirmware Version                  : %c%c%c%c%c%c%c%c\n",
-             ha->enq->CodeBlkVersion[0], ha->enq->CodeBlkVersion[1],
-             ha->enq->CodeBlkVersion[2], ha->enq->CodeBlkVersion[3],
-             ha->enq->CodeBlkVersion[4], ha->enq->CodeBlkVersion[5],
-             ha->enq->CodeBlkVersion[6], ha->enq->CodeBlkVersion[7]);
-
-   copy_info(&info, "\tBoot Block Version                : %c%c%c%c%c%c%c%c\n",
-             ha->enq->BootBlkVersion[0], ha->enq->BootBlkVersion[1],
-             ha->enq->BootBlkVersion[2], ha->enq->BootBlkVersion[3],
-             ha->enq->BootBlkVersion[4], ha->enq->BootBlkVersion[5],
-             ha->enq->BootBlkVersion[6], ha->enq->BootBlkVersion[7]);
-
-   copy_info(&info, "\tDriver Version                    : %s%s\n",
-             IPS_VERSION_HIGH, IPS_VERSION_LOW);
-
-   copy_info(&info, "\tMax Physical Devices              : %d\n",
-             ha->enq->ucMaxPhysicalDevices);
-   copy_info(&info, "\tMax Active Commands               : %d\n",
-             ha->max_cmds);
-   copy_info(&info, "\tCurrent Queued Commands           : %d\n",
-             ha->scb_waitlist.count);
-   copy_info(&info, "\tCurrent Active Commands           : %d\n",
-             ha->scb_activelist.count - ha->num_ioctl);
-   copy_info(&info, "\tCurrent Queued PT Commands        : %d\n",
-             ha->copp_waitlist.count);
-   copy_info(&info, "\tCurrent Active PT Commands        : %d\n",
-             ha->num_ioctl);
+	info.buffer = ptr;
+	info.length = len;
+	info.offset = offset;
+	info.pos = 0;
+	info.localpos = 0;
+
+	copy_info(&info, "\nIBM ServeRAID General Information:\n\n");
+
+	if ((le32_to_cpu(ha->nvram->signature) == IPS_NVRAM_P5_SIG) &&
+	    (le16_to_cpu(ha->nvram->adapter_type) != 0))
+		copy_info(&info, "\tController Type                   : %s\n",
+			  ips_adapter_name[ha->ad_type - 1]);
+	else
+		copy_info(&info,
+			  "\tController Type                   : Unknown\n");
+
+	if (ha->io_addr)
+		copy_info(&info,
+			  "\tIO region                         : 0x%lx (%d bytes)\n",
+			  ha->io_addr, ha->io_len);
+
+	if (ha->mem_addr) {
+		copy_info(&info,
+			  "\tMemory region                     : 0x%lx (%d bytes)\n",
+			  ha->mem_addr, ha->mem_len);
+		copy_info(&info,
+			  "\tShared memory address             : 0x%lx\n",
+			  ha->mem_ptr);
+	}
+
+	copy_info(&info, "\tIRQ number                        : %d\n", ha->irq);
+
+	if (le32_to_cpu(ha->nvram->signature) == IPS_NVRAM_P5_SIG)
+		copy_info(&info,
+			  "\tBIOS Version                      : %c%c%c%c%c%c%c%c\n",
+			  ha->nvram->bios_high[0], ha->nvram->bios_high[1],
+			  ha->nvram->bios_high[2], ha->nvram->bios_high[3],
+			  ha->nvram->bios_low[0], ha->nvram->bios_low[1],
+			  ha->nvram->bios_low[2], ha->nvram->bios_low[3]);
+
+	copy_info(&info,
+		  "\tFirmware Version                  : %c%c%c%c%c%c%c%c\n",
+		  ha->enq->CodeBlkVersion[0], ha->enq->CodeBlkVersion[1],
+		  ha->enq->CodeBlkVersion[2], ha->enq->CodeBlkVersion[3],
+		  ha->enq->CodeBlkVersion[4], ha->enq->CodeBlkVersion[5],
+		  ha->enq->CodeBlkVersion[6], ha->enq->CodeBlkVersion[7]);
+
+	copy_info(&info,
+		  "\tBoot Block Version                : %c%c%c%c%c%c%c%c\n",
+		  ha->enq->BootBlkVersion[0], ha->enq->BootBlkVersion[1],
+		  ha->enq->BootBlkVersion[2], ha->enq->BootBlkVersion[3],
+		  ha->enq->BootBlkVersion[4], ha->enq->BootBlkVersion[5],
+		  ha->enq->BootBlkVersion[6], ha->enq->BootBlkVersion[7]);
+
+	copy_info(&info, "\tDriver Version                    : %s%s\n",
+		  IPS_VERSION_HIGH, IPS_VERSION_LOW);
+
+	copy_info(&info, "\tDriver Build                      : %d\n",
+		  IPS_BUILD_IDENT);
+
+	copy_info(&info, "\tMax Physical Devices              : %d\n",
+		  ha->enq->ucMaxPhysicalDevices);
+	copy_info(&info, "\tMax Active Commands               : %d\n",
+		  ha->max_cmds);
+	copy_info(&info, "\tCurrent Queued Commands           : %d\n",
+		  ha->scb_waitlist.count);
+	copy_info(&info, "\tCurrent Active Commands           : %d\n",
+		  ha->scb_activelist.count - ha->num_ioctl);
+	copy_info(&info, "\tCurrent Queued PT Commands        : %d\n",
+		  ha->copp_waitlist.count);
+	copy_info(&info, "\tCurrent Active PT Commands        : %d\n",
+		  ha->num_ioctl);
 
-   copy_info(&info, "\n");
+	copy_info(&info, "\n");
 
-   return (info.localpos);
+	return (info.localpos);
 }
 
 /****************************************************************************/
@@ -2819,28 +2169,29 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-copy_mem_info(IPS_INFOSTR *info, char *data, int len) {
-   METHOD_TRACE("copy_mem_info", 1);
+copy_mem_info(IPS_INFOSTR * info, char *data, int len)
+{
+	METHOD_TRACE("copy_mem_info", 1);
 
-   if (info->pos + len < info->offset) {
-      info->pos += len;
-      return;
-   }
-
-   if (info->pos < info->offset) {
-      data += (info->offset - info->pos);
-      len -= (info->offset - info->pos);
-      info->pos += (info->offset - info->pos);
-   }
-
-   if (info->localpos + len > info->length)
-      len = info->length - info->localpos;
-
-   if (len > 0) {
-      memcpy(info->buffer + info->localpos, data, len);
-      info->pos += len;
-      info->localpos += len;
-   }
+	if (info->pos + len < info->offset) {
+		info->pos += len;
+		return;
+	}
+
+	if (info->pos < info->offset) {
+		data += (info->offset - info->pos);
+		len -= (info->offset - info->pos);
+		info->pos += (info->offset - info->pos);
+	}
+
+	if (info->localpos + len > info->length)
+		len = info->length - info->localpos;
+
+	if (len > 0) {
+		memcpy(info->buffer + info->localpos, data, len);
+		info->pos += len;
+		info->localpos += len;
+	}
 }
 
 /****************************************************************************/
@@ -2853,20 +2204,21 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-copy_info(IPS_INFOSTR *info, char *fmt, ...) {
-   va_list args;
-   char buf[128];
-   int len;
+copy_info(IPS_INFOSTR * info, char *fmt, ...)
+{
+	va_list args;
+	char buf[128];
+	int len;
 
-   METHOD_TRACE("copy_info", 1);
+	METHOD_TRACE("copy_info", 1);
 
-   va_start(args, fmt);
-   len = vsprintf(buf, fmt, args);
-   va_end(args);
+	va_start(args, fmt);
+	len = vsprintf(buf, fmt, args);
+	va_end(args);
 
-   copy_mem_info(info, buf, len);
+	copy_mem_info(info, buf, len);
 
-   return (len);
+	return (len);
 }
 
 /****************************************************************************/
@@ -2879,71 +2231,73 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_identify_controller(ips_ha_t *ha) {
-   METHOD_TRACE("ips_identify_controller", 1);
+ips_identify_controller(ips_ha_t * ha)
+{
+	METHOD_TRACE("ips_identify_controller", 1);
 
-   switch (ha->device_id) {
-   case IPS_DEVICEID_COPPERHEAD:
-      if (ha->revision_id <= IPS_REVID_SERVERAID) {
-         ha->ad_type = IPS_ADTYPE_SERVERAID;
-      } else if (ha->revision_id == IPS_REVID_SERVERAID2) {
-         ha->ad_type = IPS_ADTYPE_SERVERAID2;
-      } else if (ha->revision_id == IPS_REVID_NAVAJO) {
-         ha->ad_type = IPS_ADTYPE_NAVAJO;
-      } else if ((ha->revision_id == IPS_REVID_SERVERAID2) && (ha->slot_num == 0)) {
-         ha->ad_type = IPS_ADTYPE_KIOWA;
-      } else if ((ha->revision_id >= IPS_REVID_CLARINETP1) &&
-                 (ha->revision_id <= IPS_REVID_CLARINETP3)) {
-         if (ha->enq->ucMaxPhysicalDevices == 15)
-            ha->ad_type = IPS_ADTYPE_SERVERAID3L;
-         else
-            ha->ad_type = IPS_ADTYPE_SERVERAID3;
-      } else if ((ha->revision_id >= IPS_REVID_TROMBONE32) &&
-                 (ha->revision_id <= IPS_REVID_TROMBONE64)) {
-         ha->ad_type = IPS_ADTYPE_SERVERAID4H;
-      }
-      break;
-
-   case IPS_DEVICEID_MORPHEUS:
-      switch (ha->subdevice_id) {
-      case IPS_SUBDEVICEID_4L:
-         ha->ad_type = IPS_ADTYPE_SERVERAID4L;
-         break;
-
-      case IPS_SUBDEVICEID_4M:
-         ha->ad_type = IPS_ADTYPE_SERVERAID4M;
-         break;
-
-      case IPS_SUBDEVICEID_4MX:
-         ha->ad_type = IPS_ADTYPE_SERVERAID4MX;
-         break;
-
-      case IPS_SUBDEVICEID_4LX:
-         ha->ad_type = IPS_ADTYPE_SERVERAID4LX;
-         break;
-
-      case IPS_SUBDEVICEID_5I2:
-         ha->ad_type = IPS_ADTYPE_SERVERAID5I2;
-         break;
-
-      case IPS_SUBDEVICEID_5I1:
-         ha->ad_type = IPS_ADTYPE_SERVERAID5I1;
-         break;
-      }
-
-      break;
-
-   case IPS_DEVICEID_MARCO:
-      switch (ha->subdevice_id) {
-      case IPS_SUBDEVICEID_6M:
-          ha->ad_type = IPS_ADTYPE_SERVERAID6M;
-          break;
-      case IPS_SUBDEVICEID_6I:
-          ha->ad_type = IPS_ADTYPE_SERVERAID6I;
-          break;
-      }
-      break;
-   }
+	switch (ha->device_id) {
+	case IPS_DEVICEID_COPPERHEAD:
+		if (ha->revision_id <= IPS_REVID_SERVERAID) {
+			ha->ad_type = IPS_ADTYPE_SERVERAID;
+		} else if (ha->revision_id == IPS_REVID_SERVERAID2) {
+			ha->ad_type = IPS_ADTYPE_SERVERAID2;
+		} else if (ha->revision_id == IPS_REVID_NAVAJO) {
+			ha->ad_type = IPS_ADTYPE_NAVAJO;
+		} else if ((ha->revision_id == IPS_REVID_SERVERAID2)
+			   && (ha->slot_num == 0)) {
+			ha->ad_type = IPS_ADTYPE_KIOWA;
+		} else if ((ha->revision_id >= IPS_REVID_CLARINETP1) &&
+			   (ha->revision_id <= IPS_REVID_CLARINETP3)) {
+			if (ha->enq->ucMaxPhysicalDevices == 15)
+				ha->ad_type = IPS_ADTYPE_SERVERAID3L;
+			else
+				ha->ad_type = IPS_ADTYPE_SERVERAID3;
+		} else if ((ha->revision_id >= IPS_REVID_TROMBONE32) &&
+			   (ha->revision_id <= IPS_REVID_TROMBONE64)) {
+			ha->ad_type = IPS_ADTYPE_SERVERAID4H;
+		}
+		break;
+
+	case IPS_DEVICEID_MORPHEUS:
+		switch (ha->subdevice_id) {
+		case IPS_SUBDEVICEID_4L:
+			ha->ad_type = IPS_ADTYPE_SERVERAID4L;
+			break;
+
+		case IPS_SUBDEVICEID_4M:
+			ha->ad_type = IPS_ADTYPE_SERVERAID4M;
+			break;
+
+		case IPS_SUBDEVICEID_4MX:
+			ha->ad_type = IPS_ADTYPE_SERVERAID4MX;
+			break;
+
+		case IPS_SUBDEVICEID_4LX:
+			ha->ad_type = IPS_ADTYPE_SERVERAID4LX;
+			break;
+
+		case IPS_SUBDEVICEID_5I2:
+			ha->ad_type = IPS_ADTYPE_SERVERAID5I2;
+			break;
+
+		case IPS_SUBDEVICEID_5I1:
+			ha->ad_type = IPS_ADTYPE_SERVERAID5I1;
+			break;
+		}
+
+		break;
+
+	case IPS_DEVICEID_MARCO:
+		switch (ha->subdevice_id) {
+		case IPS_SUBDEVICEID_6M:
+			ha->ad_type = IPS_ADTYPE_SERVERAID6M;
+			break;
+		case IPS_SUBDEVICEID_6I:
+			ha->ad_type = IPS_ADTYPE_SERVERAID6I;
+			break;
+		}
+		break;
+	}
 }
 
 /****************************************************************************/
@@ -2956,158 +2310,164 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_get_bios_version(ips_ha_t *ha, int intr) {
-   ips_scb_t *scb;
-   int        ret;
-   uint8_t   major;
-   uint8_t   minor;
-   uint8_t   subminor;
-   uint8_t  *buffer;
-   char       hexDigits[] = {'0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F'};
-
-   METHOD_TRACE("ips_get_bios_version", 1);
-
-   major = 0;
-   minor = 0;
-
-   strncpy(ha->bios_version, "       ?", 8);
-
-   if (ha->device_id == IPS_DEVICEID_COPPERHEAD) {
-      if (IPS_USE_MEMIO(ha)) {
-         /* Memory Mapped I/O */
-
-         /* test 1st byte */
-         writel(0, ha->mem_ptr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         if (readb(ha->mem_ptr + IPS_REG_FLDP) != 0x55)
-            return;
-
-         writel(1, ha->mem_ptr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         if (readb(ha->mem_ptr + IPS_REG_FLDP) != 0xAA)
-            return;
-
-         /* Get Major version */
-         writel(0x1FF, ha->mem_ptr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         major = readb(ha->mem_ptr + IPS_REG_FLDP);
-
-         /* Get Minor version */
-         writel(0x1FE, ha->mem_ptr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-         minor = readb(ha->mem_ptr + IPS_REG_FLDP);
-
-         /* Get SubMinor version */
-         writel(0x1FD, ha->mem_ptr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-         subminor = readb(ha->mem_ptr + IPS_REG_FLDP);
-
-      } else {
-         /* Programmed I/O */
-
-         /* test 1st byte */
-         outl(0, ha->io_addr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         if (inb(ha->io_addr + IPS_REG_FLDP) != 0x55)
-            return ;
-
-         outl(cpu_to_le32(1), ha->io_addr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         if (inb(ha->io_addr + IPS_REG_FLDP) != 0xAA)
-            return ;
-
-         /* Get Major version */
-         outl(cpu_to_le32(0x1FF), ha->io_addr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         major = inb(ha->io_addr + IPS_REG_FLDP);
-
-         /* Get Minor version */
-         outl(cpu_to_le32(0x1FE), ha->io_addr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         minor = inb(ha->io_addr + IPS_REG_FLDP);
-
-         /* Get SubMinor version */
-         outl(cpu_to_le32(0x1FD), ha->io_addr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         subminor = inb(ha->io_addr + IPS_REG_FLDP);
-
-      }
-   } else {
-      /* Morpheus Family - Send Command to the card */
-
-      buffer = kmalloc(0x1000, GFP_ATOMIC);
-      if (!buffer)
-         return;
-
-      memset(buffer, 0, 0x1000);
-
-      scb = &ha->scbs[ha->max_cmds-1];
-
-      ips_init_scb(ha, scb);
-
-      scb->timeout = ips_cmd_timeout;
-      scb->cdb[0] = IPS_CMD_RW_BIOSFW;
-
-      scb->cmd.flashfw.op_code = IPS_CMD_RW_BIOSFW;
-      scb->cmd.flashfw.command_id = IPS_COMMAND_ID(ha, scb);
-      scb->cmd.flashfw.type = 1;
-      scb->cmd.flashfw.direction = 0;
-      scb->cmd.flashfw.count = cpu_to_le32(0x800);
-      scb->cmd.flashfw.total_packets = 1;
-      scb->cmd.flashfw.packet_num = 0;
-      scb->data_len = 0x1000;
-      scb->data_busaddr = pci_map_single(ha->pcidev, buffer, scb->data_len,
-                                         IPS_DMA_DIR(scb));
-      scb->cmd.flashfw.buffer_addr = scb->data_busaddr;
-      scb->flags |= IPS_SCB_MAP_SINGLE;
-
-      /* issue the command */
-      if (((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) == IPS_FAILURE) ||
-          (ret == IPS_SUCCESS_IMM) ||
-          ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1)) {
-         /* Error occurred */
-         kfree(buffer);
-
-         return;
-      }
-
-      if ((buffer[0xC0] == 0x55) && (buffer[0xC1] == 0xAA)) {
-         major    = buffer[0x1ff + 0xC0];  /* Offset 0x1ff after the header (0xc0) */
-         minor    = buffer[0x1fe + 0xC0];  /* Offset 0x1fe after the header (0xc0) */
-         subminor = buffer[0x1fd + 0xC0];  /* Offset 0x1fd after the header (0xc0) */
-      } else {
-         return;
-      }
-
-      kfree(buffer);
-   }
-
-   ha->bios_version[0] = hexDigits[(major & 0xF0) >> 4];
-   ha->bios_version[1] = '.';
-   ha->bios_version[2] = hexDigits[major & 0x0F];
-   ha->bios_version[3] = hexDigits[subminor];
-   ha->bios_version[4] = '.';
-   ha->bios_version[5] = hexDigits[(minor & 0xF0) >> 4];
-   ha->bios_version[6] = hexDigits[minor & 0x0F];
-   ha->bios_version[7] = 0;
+ips_get_bios_version(ips_ha_t * ha, int intr)
+{
+	ips_scb_t *scb;
+	int ret;
+	uint8_t major;
+	uint8_t minor;
+	uint8_t subminor;
+	uint8_t *buffer;
+	char hexDigits[] =
+	    { '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C',
+		    'D', 'E', 'F' };
+
+	METHOD_TRACE("ips_get_bios_version", 1);
+
+	major = 0;
+	minor = 0;
+
+	strncpy(ha->bios_version, "       ?", 8);
+
+	if (ha->device_id == IPS_DEVICEID_COPPERHEAD) {
+		if (IPS_USE_MEMIO(ha)) {
+			/* Memory Mapped I/O */
+
+			/* test 1st byte */
+			writel(0, ha->mem_ptr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			if (readb(ha->mem_ptr + IPS_REG_FLDP) != 0x55)
+				return;
+
+			writel(1, ha->mem_ptr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			if (readb(ha->mem_ptr + IPS_REG_FLDP) != 0xAA)
+				return;
+
+			/* Get Major version */
+			writel(0x1FF, ha->mem_ptr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			major = readb(ha->mem_ptr + IPS_REG_FLDP);
+
+			/* Get Minor version */
+			writel(0x1FE, ha->mem_ptr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+			minor = readb(ha->mem_ptr + IPS_REG_FLDP);
+
+			/* Get SubMinor version */
+			writel(0x1FD, ha->mem_ptr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+			subminor = readb(ha->mem_ptr + IPS_REG_FLDP);
+
+		} else {
+			/* Programmed I/O */
+
+			/* test 1st byte */
+			outl(0, ha->io_addr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			if (inb(ha->io_addr + IPS_REG_FLDP) != 0x55)
+				return;
+
+			outl(cpu_to_le32(1), ha->io_addr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			if (inb(ha->io_addr + IPS_REG_FLDP) != 0xAA)
+				return;
+
+			/* Get Major version */
+			outl(cpu_to_le32(0x1FF), ha->io_addr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			major = inb(ha->io_addr + IPS_REG_FLDP);
+
+			/* Get Minor version */
+			outl(cpu_to_le32(0x1FE), ha->io_addr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			minor = inb(ha->io_addr + IPS_REG_FLDP);
+
+			/* Get SubMinor version */
+			outl(cpu_to_le32(0x1FD), ha->io_addr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			subminor = inb(ha->io_addr + IPS_REG_FLDP);
+
+		}
+	} else {
+		/* Morpheus Family - Send Command to the card */
+
+		buffer = kmalloc(0x1000, IPS_ATOMIC_GFP);
+		if (!buffer)
+			return;
+
+		memset(buffer, 0, 0x1000);
+
+		scb = &ha->scbs[ha->max_cmds - 1];
+
+		ips_init_scb(ha, scb);
+
+		scb->timeout = ips_cmd_timeout;
+		scb->cdb[0] = IPS_CMD_RW_BIOSFW;
+
+		scb->cmd.flashfw.op_code = IPS_CMD_RW_BIOSFW;
+		scb->cmd.flashfw.command_id = IPS_COMMAND_ID(ha, scb);
+		scb->cmd.flashfw.type = 1;
+		scb->cmd.flashfw.direction = 0;
+		scb->cmd.flashfw.count = cpu_to_le32(0x800);
+		scb->cmd.flashfw.total_packets = 1;
+		scb->cmd.flashfw.packet_num = 0;
+		scb->data_len = 0x1000;
+		scb->data_busaddr =
+		    pci_map_single(ha->pcidev, buffer, scb->data_len,
+				   IPS_DMA_DIR(scb));
+		scb->cmd.flashfw.buffer_addr = scb->data_busaddr;
+		scb->flags |= IPS_SCB_MAP_SINGLE;
+
+		/* issue the command */
+		if (
+		    ((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) ==
+		     IPS_FAILURE) || (ret == IPS_SUCCESS_IMM)
+		    || ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1)) {
+			/* Error occurred */
+			kfree(buffer);
+
+			return;
+		}
+
+		if ((buffer[0xC0] == 0x55) && (buffer[0xC1] == 0xAA)) {
+			major = buffer[0x1ff + 0xC0];	/* Offset 0x1ff after the header (0xc0) */
+			minor = buffer[0x1fe + 0xC0];	/* Offset 0x1fe after the header (0xc0) */
+			subminor = buffer[0x1fd + 0xC0];	/* Offset 0x1fd after the header (0xc0) */
+		} else {
+			kfree(buffer);
+			return;
+		}
+
+		kfree(buffer);
+	}
+
+	ha->bios_version[0] = hexDigits[(major & 0xF0) >> 4];
+	ha->bios_version[1] = '.';
+	ha->bios_version[2] = hexDigits[major & 0x0F];
+	ha->bios_version[3] = hexDigits[subminor];
+	ha->bios_version[4] = '.';
+	ha->bios_version[5] = hexDigits[(minor & 0xF0) >> 4];
+	ha->bios_version[6] = hexDigits[minor & 0x0F];
+	ha->bios_version[7] = 0;
 }
 
 /****************************************************************************/
@@ -3122,129 +2482,134 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_hainit(ips_ha_t *ha) {
-   int            i;
-   struct timeval tv;
-
-   METHOD_TRACE("ips_hainit", 1);
-
-   if (!ha)
-      return (0);
-
-   if (ha->func.statinit)
-      (*ha->func.statinit)(ha);
-
-   if (ha->func.enableint)
-      (*ha->func.enableint)(ha);
-
-   /* Send FFDC */
-   ha->reset_count = 1;
-   do_gettimeofday(&tv);
-   ha->last_ffdc = tv.tv_sec;
-   ips_ffdc_reset(ha, IPS_INTR_IORL);
-
-   if (!ips_read_config(ha, IPS_INTR_IORL)) {
-      printk(KERN_WARNING "(%s%d) unable to read config from controller.\n",
-             ips_name, ha->host_num);
-
-      return (0);
-   } /* end if */
-
-   if (!ips_read_adapter_status(ha, IPS_INTR_IORL)) {
-      printk(KERN_WARNING "(%s%d) unable to read controller status.\n",
-             ips_name, ha->host_num);
-
-      return (0);
-   }
-
-   /* Identify this controller */
-   ips_identify_controller(ha);
-
-   if (!ips_read_subsystem_parameters(ha, IPS_INTR_IORL)) {
-      printk(KERN_WARNING "(%s%d) unable to read subsystem parameters.\n",
-             ips_name, ha->host_num);
-
-      return (0);
-   }
-
-   /* write nvram user page 5 */
-   if (!ips_write_driver_status(ha, IPS_INTR_IORL)) {
-      printk(KERN_WARNING "(%s%d) unable to write driver info to controller.\n",
-             ips_name, ha->host_num);
-
-      return (0);
-   }
-
-   /* If there are Logical Drives and a Reset Occurred, then an EraseStripeLock is Needed */
-   if ( (ha->conf->ucLogDriveCount > 0) && (ha->requires_esl == 1) ) 
-      ips_clear_adapter(ha, IPS_INTR_IORL);
-   
-   /* set limits on SID, LUN, BUS */
-   ha->ntargets = IPS_MAX_TARGETS + 1;
-   ha->nlun = 1;
-   ha->nbus = (ha->enq->ucMaxPhysicalDevices / IPS_MAX_TARGETS) + 1;
-
-   switch (ha->conf->logical_drive[0].ucStripeSize) {
-   case 4:
-      ha->max_xfer = 0x10000;
-      break;
-
-   case 5:
-      ha->max_xfer = 0x20000;
-      break;
-
-   case 6:
-      ha->max_xfer = 0x40000;
-      break;
-
-   case 7:
-   default:
-      ha->max_xfer = 0x80000;
-      break;
-   }
-
-   /* setup max concurrent commands */
-   if (le32_to_cpu(ha->subsys->param[4]) & 0x1) {
-      /* Use the new method */
-      ha->max_cmds = ha->enq->ucConcurrentCmdCount;
-   } else {
-      /* use the old method */
-      switch (ha->conf->logical_drive[0].ucStripeSize) {
-      case 4:
-         ha->max_cmds = 32;
-         break;
-
-      case 5:
-         ha->max_cmds = 16;
-         break;
-
-      case 6:
-         ha->max_cmds = 8;
-         break;
-
-      case 7:
-      default:
-         ha->max_cmds = 4;
-         break;
-      }
-   }
-
-   /* Limit the Active Commands on a Lite Adapter */
-   if ((ha->ad_type == IPS_ADTYPE_SERVERAID3L) ||
-       (ha->ad_type == IPS_ADTYPE_SERVERAID4L) ||
-       (ha->ad_type == IPS_ADTYPE_SERVERAID4LX)) {
-      if ((ha->max_cmds > MaxLiteCmds) && (MaxLiteCmds)) 
-         ha->max_cmds = MaxLiteCmds;
-   }
-
-   /* set controller IDs */
-   ha->ha_id[0] = IPS_ADAPTER_ID;
-   for (i = 1; i < ha->nbus; i++) {
-      ha->ha_id[i] = ha->conf->init_id[i-1] & 0x1f;
-      ha->dcdb_active[i-1] = 0;
-   }
+ips_hainit(ips_ha_t * ha)
+{
+	int i;
+	struct timeval tv;
+
+	METHOD_TRACE("ips_hainit", 1);
 
-   return (1);
+	if (!ha)
+		return (0);
+
+	if (ha->func.statinit)
+		(*ha->func.statinit) (ha);
+
+	if (ha->func.enableint)
+		(*ha->func.enableint) (ha);
+
+	/* Send FFDC */
+	ha->reset_count = 1;
+	do_gettimeofday(&tv);
+	ha->last_ffdc = tv.tv_sec;
+	ips_ffdc_reset(ha, IPS_INTR_IORL);
+
+	if (!ips_read_config(ha, IPS_INTR_IORL)) {
+		printk(KERN_WARNING
+		       "(%s%d) unable to read config from controller.\n",
+		       ips_name, ha->host_num);
+
+		return (0);
+	}
+	/* end if */
+	if (!ips_read_adapter_status(ha, IPS_INTR_IORL)) {
+		printk(KERN_WARNING
+		       "(%s%d) unable to read controller status.\n", ips_name,
+		       ha->host_num);
+
+		return (0);
+	}
+
+	/* Identify this controller */
+	ips_identify_controller(ha);
+
+	if (!ips_read_subsystem_parameters(ha, IPS_INTR_IORL)) {
+		printk(KERN_WARNING
+		       "(%s%d) unable to read subsystem parameters.\n",
+		       ips_name, ha->host_num);
+
+		return (0);
+	}
+
+	/* write nvram user page 5 */
+	if (!ips_write_driver_status(ha, IPS_INTR_IORL)) {
+		printk(KERN_WARNING
+		       "(%s%d) unable to write driver info to controller.\n",
+		       ips_name, ha->host_num);
+
+		return (0);
+	}
+
+	/* If there are Logical Drives and a Reset Occurred, then an EraseStripeLock is Needed */
+	if ((ha->conf->ucLogDriveCount > 0) && (ha->requires_esl == 1))
+		ips_clear_adapter(ha, IPS_INTR_IORL);
+
+	/* set limits on SID, LUN, BUS */
+	ha->ntargets = IPS_MAX_TARGETS + 1;
+	ha->nlun = 1;
+	ha->nbus = (ha->enq->ucMaxPhysicalDevices / IPS_MAX_TARGETS) + 1;
+
+	switch (ha->conf->logical_drive[0].ucStripeSize) {
+	case 4:
+		ha->max_xfer = 0x10000;
+		break;
+
+	case 5:
+		ha->max_xfer = 0x20000;
+		break;
+
+	case 6:
+		ha->max_xfer = 0x40000;
+		break;
+
+	case 7:
+	default:
+		ha->max_xfer = 0x80000;
+		break;
+	}
+
+	/* setup max concurrent commands */
+	if (le32_to_cpu(ha->subsys->param[4]) & 0x1) {
+		/* Use the new method */
+		ha->max_cmds = ha->enq->ucConcurrentCmdCount;
+	} else {
+		/* use the old method */
+		switch (ha->conf->logical_drive[0].ucStripeSize) {
+		case 4:
+			ha->max_cmds = 32;
+			break;
+
+		case 5:
+			ha->max_cmds = 16;
+			break;
+
+		case 6:
+			ha->max_cmds = 8;
+			break;
+
+		case 7:
+		default:
+			ha->max_cmds = 4;
+			break;
+		}
+	}
+
+	/* Limit the Active Commands on a Lite Adapter */
+	if ((ha->ad_type == IPS_ADTYPE_SERVERAID3L) ||
+	    (ha->ad_type == IPS_ADTYPE_SERVERAID4L) ||
+	    (ha->ad_type == IPS_ADTYPE_SERVERAID4LX)) {
+		if ((ha->max_cmds > MaxLiteCmds) && (MaxLiteCmds))
+			ha->max_cmds = MaxLiteCmds;
+	}
+
+	/* set controller IDs */
+	ha->ha_id[0] = IPS_ADAPTER_ID;
+	for (i = 1; i < ha->nbus; i++) {
+		ha->ha_id[i] = ha->conf->init_id[i - 1] & 0x1f;
+		ha->dcdb_active[i - 1] = 0;
+	}
+
+	return (1);
 }
 
 /****************************************************************************/
@@ -3257,275 +2622,238 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_next(ips_ha_t *ha, int intr) {
-   ips_scb_t            *scb;
-   Scsi_Cmnd            *SC;
-   Scsi_Cmnd            *p;
-   Scsi_Cmnd            *q;
-   ips_copp_wait_item_t *item;
-   int                   ret;
-   unsigned long         cpu_flags = 0;
-   struct Scsi_Host *host;
-   METHOD_TRACE("ips_next", 1);
-
-   if (!ha)
-      return ;
-   host = ips_sh[ha->host_num];
-   /*
-    * Block access to the queue function so
-    * this command won't time out
-    */
-   if(intr == IPS_INTR_ON)
-      IPS_LOCK_SAVE(host->host_lock, cpu_flags);
-   
-   if ((ha->subsys->param[3] & 0x300000)  && ( ha->scb_activelist.count == 0 )) {
-      struct timeval tv;
-
-      do_gettimeofday(&tv);
-
-      if (tv.tv_sec - ha->last_ffdc > IPS_SECS_8HOURS) {
-         ha->last_ffdc = tv.tv_sec;
-         ips_ffdc_time(ha);
-      }
-   }
-
-   /*
-    * Send passthru commands
-    * These have priority over normal I/O
-    * but shouldn't affect performance too much
-    * since we limit the number that can be active
-    * on the card at any one time
-    */
-   while ((ha->num_ioctl < IPS_MAX_IOCTL) &&
-          (ha->copp_waitlist.head) &&
-          (scb = ips_getscb(ha))) {
-
-      item = ips_removeq_copp_head(&ha->copp_waitlist);
-      ha->num_ioctl++;
-      if(intr == IPS_INTR_ON)
-         IPS_UNLOCK_RESTORE(host->host_lock, cpu_flags);
-      scb->scsi_cmd = item->scsi_cmd;
-      kfree(item);
-
-      ret = ips_make_passthru(ha, scb->scsi_cmd, scb, intr);
-
-      if(intr == IPS_INTR_ON)
-         IPS_LOCK_SAVE(host->host_lock, cpu_flags);
-      switch (ret) {
-      case IPS_FAILURE:
-         if (scb->scsi_cmd) {
-            scb->scsi_cmd->result = DID_ERROR << 16;
-            scb->scsi_cmd->scsi_done(scb->scsi_cmd);
-         }
-
-         ips_freescb(ha, scb);
-         break;
-      case IPS_SUCCESS_IMM:
-         if (scb->scsi_cmd) {
-            scb->scsi_cmd->result = DID_OK << 16;
-            scb->scsi_cmd->scsi_done(scb->scsi_cmd);
-         }
-
-         ips_freescb(ha, scb);
-         break;
-      default:
-         break;
-      } /* end case */
-
-      if (ret != IPS_SUCCESS) {
-         ha->num_ioctl--;
-         continue;
-     }
-
-      ret = ips_send_cmd(ha, scb);
-
-      if (ret == IPS_SUCCESS) 
-         ips_putq_scb_head(&ha->scb_activelist, scb);
-      else
-         ha->num_ioctl--;
-
-      switch(ret) {
-      case IPS_FAILURE:
-         if (scb->scsi_cmd) {
-            scb->scsi_cmd->result = DID_ERROR << 16;
-         }
-
-         ips_freescb(ha, scb);
-         break;
-      case IPS_SUCCESS_IMM:
-         ips_freescb(ha, scb);
-         break;
-      default:
-         break;
-      } /* end case */
-
-   }
-
-
-   /*
-    * Send "Normal" I/O commands
-    */
-    
-   p = ha->scb_waitlist.head;
-   while ((p) && (scb = ips_getscb(ha))) {
-      if ((p->channel > 0) && (ha->dcdb_active[p->channel-1] & (1 << p->target))) {
-         ips_freescb(ha, scb);
-         p = (Scsi_Cmnd *) p->host_scribble;
-         continue;
-      }
-
-      q = p;
-      SC = ips_removeq_wait(&ha->scb_waitlist, q);
-
-      if(intr == IPS_INTR_ON)
-         IPS_UNLOCK_RESTORE(host->host_lock, cpu_flags); /* Unlock HA after command is taken off queue */
-
-      SC->result = DID_OK;
-      SC->host_scribble = NULL;
-
-      memset(SC->sense_buffer, 0, sizeof(SC->sense_buffer));
-
-      scb->target_id = SC->target;
-      scb->lun = SC->lun;
-      scb->bus = SC->channel;
-      scb->scsi_cmd = SC;
-      scb->breakup = 0;
-      scb->data_len = 0;
-      scb->callback = ipsintr_done;
-      scb->timeout = ips_cmd_timeout;
-      memset(&scb->cmd, 0, 16);
-
-      /* copy in the CDB */
-      memcpy(scb->cdb, SC->cmnd, SC->cmd_len);
-
-      /* Now handle the data buffer */
-      if (SC->use_sg) {
-         struct scatterlist *sg;
-         int                 i;
-
-         sg = SC->request_buffer;
-         scb->sg_count = pci_map_sg(ha->pcidev, sg, SC->use_sg,
-                                    scsi_to_pci_dma_dir(SC->sc_data_direction));
-         scb->flags |= IPS_SCB_MAP_SG;
-         if (scb->sg_count == 1) {
-            if (sg_dma_len(sg) > ha->max_xfer) {
-     	       scb->breakup = 1;
-               scb->data_len = ha->max_xfer;
-            } else
-               scb->data_len = sg_dma_len(sg);
-
-            scb->dcdb.transfer_length = scb->data_len;
-            scb->data_busaddr = sg_dma_address(sg);
-            scb->sg_len = 0;
-         } else {
-            /* Check for the first Element being bigger than MAX_XFER */
-            if (sg_dma_len(&sg[0]) > ha->max_xfer) {
-               scb->sg_list[0].address = cpu_to_le32(sg_dma_address(&sg[0]));
-               scb->sg_list[0].length = ha->max_xfer;
-               scb->data_len = ha->max_xfer;
-               scb->breakup = 0; 
-               scb->sg_break=1;  
-               scb->sg_len = 1;
-            } else {
-               for (i = 0; i < scb->sg_count; i++) {
-                  scb->sg_list[i].address = cpu_to_le32(sg_dma_address(&sg[i]));
-                  scb->sg_list[i].length = cpu_to_le32(sg_dma_len(&sg[i]));
-            
-                  if (scb->data_len + sg_dma_len(&sg[i]) > ha->max_xfer) {
-                     /*
-                      * Data Breakup required
-                      */
-                     scb->breakup = i;
-                     break;
-                  }
-               
-                  scb->data_len += sg_dma_len(&sg[i]);
-               }
-
-               if (!scb->breakup)
-                  scb->sg_len = scb->sg_count;
-               else
-                  scb->sg_len = scb->breakup;
-            }
-
-            scb->dcdb.transfer_length = scb->data_len;
-            scb->data_busaddr = scb->sg_busaddr;
-         }
-      } else {
-         if (SC->request_bufflen) {
-            if (SC->request_bufflen > ha->max_xfer) {
-               /*
-                * Data breakup required
-                */
-               scb->breakup = 1;
-               scb->data_len = ha->max_xfer;
-            } else {
-               scb->data_len = SC->request_bufflen;
-            }
-
-            scb->dcdb.transfer_length = scb->data_len;
-            scb->data_busaddr = pci_map_single(ha->pcidev, SC->request_buffer,
-                                               scb->data_len,
-                                               scsi_to_pci_dma_dir(SC->sc_data_direction));
-            scb->flags |= IPS_SCB_MAP_SINGLE;
-            scb->sg_len = 0;
-         } else {
-            scb->data_busaddr = 0L;
-            scb->sg_len = 0;
-            scb->data_len = 0;
-            scb->dcdb.transfer_length = 0;
-         }
-
-      }
-
-      scb->dcdb.cmd_attribute = ips_command_direction[scb->scsi_cmd->cmnd[0]];
-
-      if (!scb->dcdb.cmd_attribute & 0x3)
-         scb->dcdb.transfer_length = 0;
-
-      if (scb->data_len >= IPS_MAX_XFER) {
-         scb->dcdb.cmd_attribute |= IPS_TRANSFER64K;
-         scb->dcdb.transfer_length = 0;
-      }
-      if(intr == IPS_INTR_ON)
-         IPS_LOCK_SAVE(host->host_lock, cpu_flags);
-      
-      ret = ips_send_cmd(ha, scb);
-
-      switch(ret) {
-      case IPS_SUCCESS:
-         ips_putq_scb_head(&ha->scb_activelist, scb);
-         break;
-      case IPS_FAILURE:
-         if (scb->scsi_cmd) {
-            scb->scsi_cmd->result = DID_ERROR << 16;
-            scb->scsi_cmd->scsi_done(scb->scsi_cmd);
-         }
-
-         if (scb->bus)
-            ha->dcdb_active[scb->bus-1] &= ~(1 << scb->target_id);
-
-         ips_freescb(ha, scb);
-         break;
-      case IPS_SUCCESS_IMM:
-         if (scb->scsi_cmd)
-            scb->scsi_cmd->scsi_done(scb->scsi_cmd);
-
-         if (scb->bus)
-            ha->dcdb_active[scb->bus-1] &= ~(1 << scb->target_id);
-
-         ips_freescb(ha, scb);
-         break;
-      default:
-         break;
-      } /* end case */
+ips_next(ips_ha_t * ha, int intr)
+{
+	ips_scb_t *scb;
+	Scsi_Cmnd *SC;
+	Scsi_Cmnd *p;
+	Scsi_Cmnd *q;
+	ips_copp_wait_item_t *item;
+	int ret;
+	unsigned long cpu_flags = 0;
+	struct Scsi_Host *host;
+	METHOD_TRACE("ips_next", 1);
+
+	if (!ha)
+		return;
+	host = ips_sh[ha->host_num];
+	/*
+	 * Block access to the queue function so
+	 * this command won't time out
+	 */
+	if (intr == IPS_INTR_ON)
+		IPS_LOCK_SAVE(host->host_lock, cpu_flags);
+
+	if ((ha->subsys->param[3] & 0x300000)
+	    && (ha->scb_activelist.count == 0)) {
+		struct timeval tv;
+
+		do_gettimeofday(&tv);
+
+		if (tv.tv_sec - ha->last_ffdc > IPS_SECS_8HOURS) {
+			ha->last_ffdc = tv.tv_sec;
+			ips_ffdc_time(ha);
+		}
+	}
+
+	/*
+	 * Send passthru commands
+	 * These have priority over normal I/O
+	 * but shouldn't affect performance too much
+	 * since we limit the number that can be active
+	 * on the card at any one time
+	 */
+	while ((ha->num_ioctl < IPS_MAX_IOCTL) &&
+	       (ha->copp_waitlist.head) && (scb = ips_getscb(ha))) {
+
+		item = ips_removeq_copp_head(&ha->copp_waitlist);
+		ha->num_ioctl++;
+		if (intr == IPS_INTR_ON)
+			IPS_UNLOCK_RESTORE(host->host_lock, cpu_flags);
+		scb->scsi_cmd = item->scsi_cmd;
+		kfree(item);
+
+		ret = ips_make_passthru(ha, scb->scsi_cmd, scb, intr);
+
+		if (intr == IPS_INTR_ON)
+			IPS_LOCK_SAVE(host->host_lock, cpu_flags);
+		switch (ret) {
+		case IPS_FAILURE:
+			if (scb->scsi_cmd) {
+				scb->scsi_cmd->result = DID_ERROR << 16;
+				scb->scsi_cmd->scsi_done(scb->scsi_cmd);
+			}
+
+			ips_freescb(ha, scb);
+			break;
+		case IPS_SUCCESS_IMM:
+			if (scb->scsi_cmd) {
+				scb->scsi_cmd->result = DID_OK << 16;
+				scb->scsi_cmd->scsi_done(scb->scsi_cmd);
+			}
+
+			ips_freescb(ha, scb);
+			break;
+		default:
+			break;
+		}		/* end case */
+
+		if (ret != IPS_SUCCESS) {
+			ha->num_ioctl--;
+			continue;
+		}
+
+		ret = ips_send_cmd(ha, scb);
+
+		if (ret == IPS_SUCCESS)
+			ips_putq_scb_head(&ha->scb_activelist, scb);
+		else
+			ha->num_ioctl--;
+
+		switch (ret) {
+		case IPS_FAILURE:
+			if (scb->scsi_cmd) {
+				scb->scsi_cmd->result = DID_ERROR << 16;
+			}
+
+			ips_freescb(ha, scb);
+			break;
+		case IPS_SUCCESS_IMM:
+			ips_freescb(ha, scb);
+			break;
+		default:
+			break;
+		}		/* end case */
+
+	}
+
+	/*
+	 * Send "Normal" I/O commands
+	 */
+
+	p = ha->scb_waitlist.head;
+	while ((p) && (scb = ips_getscb(ha))) {
+		if ((p->channel > 0)
+		    && (ha->dcdb_active[p->channel - 1] & (1 << p->target))) {
+			ips_freescb(ha, scb);
+			p = (Scsi_Cmnd *) p->host_scribble;
+			continue;
+		}
+
+		q = p;
+		SC = ips_removeq_wait(&ha->scb_waitlist, q);
+
+		if (intr == IPS_INTR_ON)
+			IPS_UNLOCK_RESTORE(host->host_lock, cpu_flags);	/* Unlock HA after command is taken off queue */
+
+		SC->result = DID_OK;
+		SC->host_scribble = NULL;
+
+		memset(SC->sense_buffer, 0, sizeof (SC->sense_buffer));
+
+		scb->target_id = SC->target;
+		scb->lun = SC->lun;
+		scb->bus = SC->channel;
+		scb->scsi_cmd = SC;
+		scb->breakup = 0;
+		scb->data_len = 0;
+		scb->callback = ipsintr_done;
+		scb->timeout = ips_cmd_timeout;
+		memset(&scb->cmd, 0, 16);
+
+		/* copy in the CDB */
+		memcpy(scb->cdb, SC->cmnd, SC->cmd_len);
+
+		/* Now handle the data buffer */
+		if (SC->use_sg) {
+			struct scatterlist *sg;
+			int i;
+
+			sg = SC->request_buffer;
+			scb->sg_count = pci_map_sg(ha->pcidev, sg, SC->use_sg,
+						   scsi_to_pci_dma_dir(SC->
+								       sc_data_direction));
+			scb->flags |= IPS_SCB_MAP_SG;
+			for (i = 0; i < scb->sg_count; i++) {
+				if (ips_fill_scb_sg_single
+				    (ha, sg_dma_address(&sg[i]), scb, i,
+				     sg_dma_len(&sg[i])) < 0)
+					break;
+			}
+			scb->dcdb.transfer_length = scb->data_len;
+		} else {
+			if (SC->request_bufflen) {
+				scb->data_busaddr =
+				    pci_map_single(ha->pcidev,
+						   SC->request_buffer,
+						   SC->request_bufflen,
+						   scsi_to_pci_dma_dir(SC->
+								       sc_data_direction));
+				scb->flags |= IPS_SCB_MAP_SINGLE;
+				ips_fill_scb_sg_single(ha, scb->data_busaddr,
+						       scb, 0,
+						       SC->request_bufflen);
+				scb->dcdb.transfer_length = scb->data_len;
+			} else {
+				scb->data_busaddr = 0L;
+				scb->sg_len = 0;
+				scb->data_len = 0;
+				scb->dcdb.transfer_length = 0;
+			}
+
+		}
+
+		scb->dcdb.cmd_attribute =
+		    ips_command_direction[scb->scsi_cmd->cmnd[0]];
+
+		if (!(scb->dcdb.cmd_attribute & 0x3))
+			scb->dcdb.transfer_length = 0;
+
+		if (scb->data_len >= IPS_MAX_XFER) {
+			scb->dcdb.cmd_attribute |= IPS_TRANSFER64K;
+			scb->dcdb.transfer_length = 0;
+		}
+		if (intr == IPS_INTR_ON)
+			IPS_LOCK_SAVE(host->host_lock, cpu_flags);
+
+		ret = ips_send_cmd(ha, scb);
+
+		switch (ret) {
+		case IPS_SUCCESS:
+			ips_putq_scb_head(&ha->scb_activelist, scb);
+			break;
+		case IPS_FAILURE:
+			if (scb->scsi_cmd) {
+				scb->scsi_cmd->result = DID_ERROR << 16;
+				scb->scsi_cmd->scsi_done(scb->scsi_cmd);
+			}
+
+			if (scb->bus)
+				ha->dcdb_active[scb->bus - 1] &=
+				    ~(1 << scb->target_id);
+
+			ips_freescb(ha, scb);
+			break;
+		case IPS_SUCCESS_IMM:
+			if (scb->scsi_cmd)
+				scb->scsi_cmd->scsi_done(scb->scsi_cmd);
+
+			if (scb->bus)
+				ha->dcdb_active[scb->bus - 1] &=
+				    ~(1 << scb->target_id);
+
+			ips_freescb(ha, scb);
+			break;
+		default:
+			break;
+		}		/* end case */
 
-      p = (Scsi_Cmnd *) p->host_scribble;
+		p = (Scsi_Cmnd *) p->host_scribble;
 
-   } /* end while */
+	}			/* end while */
 
-   if(intr == IPS_INTR_ON)
-      IPS_UNLOCK_RESTORE(host->host_lock, cpu_flags);
+	if (intr == IPS_INTR_ON)
+		IPS_UNLOCK_RESTORE(host->host_lock, cpu_flags);
 }
 
 /****************************************************************************/
@@ -3540,19 +2868,20 @@
 /*                                                                          */
 /****************************************************************************/
 static inline void
-ips_putq_scb_head(ips_scb_queue_t *queue, ips_scb_t *item) {
-   METHOD_TRACE("ips_putq_scb_head", 1);
+ips_putq_scb_head(ips_scb_queue_t * queue, ips_scb_t * item)
+{
+	METHOD_TRACE("ips_putq_scb_head", 1);
 
-   if (!item)
-      return ;
+	if (!item)
+		return;
 
-   item->q_next = queue->head;
-   queue->head = item;
+	item->q_next = queue->head;
+	queue->head = item;
 
-   if (!queue->tail)
-      queue->tail = item;
+	if (!queue->tail)
+		queue->tail = item;
 
-   queue->count++;
+	queue->count++;
 }
 
 /****************************************************************************/
@@ -3567,23 +2896,24 @@
 /*                                                                          */
 /****************************************************************************/
 static inline void
-ips_putq_scb_tail(ips_scb_queue_t *queue, ips_scb_t *item) {
-   METHOD_TRACE("ips_putq_scb_tail", 1);
+ips_putq_scb_tail(ips_scb_queue_t * queue, ips_scb_t * item)
+{
+	METHOD_TRACE("ips_putq_scb_tail", 1);
 
-   if (!item)
-      return ;
+	if (!item)
+		return;
 
-   item->q_next = NULL;
+	item->q_next = NULL;
 
-   if (queue->tail)
-      queue->tail->q_next = item;
+	if (queue->tail)
+		queue->tail->q_next = item;
 
-   queue->tail = item;
+	queue->tail = item;
 
-   if (!queue->head)
-      queue->head = item;
+	if (!queue->head)
+		queue->head = item;
 
-   queue->count++;
+	queue->count++;
 }
 
 /****************************************************************************/
@@ -3598,26 +2928,27 @@
 /*                                                                          */
 /****************************************************************************/
 static inline ips_scb_t *
-ips_removeq_scb_head(ips_scb_queue_t *queue) {
-   ips_scb_t  *item;
+ips_removeq_scb_head(ips_scb_queue_t * queue)
+{
+	ips_scb_t *item;
 
-   METHOD_TRACE("ips_removeq_scb_head", 1);
+	METHOD_TRACE("ips_removeq_scb_head", 1);
 
-   item = queue->head;
+	item = queue->head;
 
-   if (!item) {
-      return (NULL);
-   }
+	if (!item) {
+		return (NULL);
+	}
 
-   queue->head = item->q_next;
-   item->q_next = NULL;
+	queue->head = item->q_next;
+	item->q_next = NULL;
 
-   if (queue->tail == item)
-      queue->tail = NULL;
+	if (queue->tail == item)
+		queue->tail = NULL;
 
-   queue->count--;
+	queue->count--;
 
-   return (item);
+	return (item);
 }
 
 /****************************************************************************/
@@ -3632,37 +2963,38 @@
 /*                                                                          */
 /****************************************************************************/
 static inline ips_scb_t *
-ips_removeq_scb(ips_scb_queue_t *queue, ips_scb_t *item) {
-   ips_scb_t  *p;
+ips_removeq_scb(ips_scb_queue_t * queue, ips_scb_t * item)
+{
+	ips_scb_t *p;
 
-   METHOD_TRACE("ips_removeq_scb", 1);
+	METHOD_TRACE("ips_removeq_scb", 1);
 
-   if (!item)
-      return (NULL);
+	if (!item)
+		return (NULL);
 
-   if (item == queue->head) {
-      return (ips_removeq_scb_head(queue));
-   }
+	if (item == queue->head) {
+		return (ips_removeq_scb_head(queue));
+	}
 
-   p = queue->head;
+	p = queue->head;
 
-   while ((p) && (item != p->q_next))
-      p = p->q_next;
+	while ((p) && (item != p->q_next))
+		p = p->q_next;
 
-   if (p) {
-      /* found a match */
-      p->q_next = item->q_next;
+	if (p) {
+		/* found a match */
+		p->q_next = item->q_next;
 
-      if (!item->q_next)
-         queue->tail = p;
+		if (!item->q_next)
+			queue->tail = p;
 
-      item->q_next = NULL;
-      queue->count--;
+		item->q_next = NULL;
+		queue->count--;
 
-      return (item);
-   }
+		return (item);
+	}
 
-   return (NULL);
+	return (NULL);
 }
 
 /****************************************************************************/
@@ -3677,19 +3009,20 @@
 /*                                                                          */
 /****************************************************************************/
 static inline void
-ips_putq_wait_head(ips_wait_queue_t *queue, Scsi_Cmnd *item) {
-   METHOD_TRACE("ips_putq_wait_head", 1);
+ips_putq_wait_head(ips_wait_queue_t * queue, Scsi_Cmnd * item)
+{
+	METHOD_TRACE("ips_putq_wait_head", 1);
 
-   if (!item)
-      return ;
+	if (!item)
+		return;
 
-   item->host_scribble = (char *) queue->head;
-   queue->head = item;
+	item->host_scribble = (char *) queue->head;
+	queue->head = item;
 
-   if (!queue->tail)
-      queue->tail = item;
+	if (!queue->tail)
+		queue->tail = item;
 
-   queue->count++;
+	queue->count++;
 }
 
 /****************************************************************************/
@@ -3704,23 +3037,24 @@
 /*                                                                          */
 /****************************************************************************/
 static inline void
-ips_putq_wait_tail(ips_wait_queue_t *queue, Scsi_Cmnd *item) {
-   METHOD_TRACE("ips_putq_wait_tail", 1);
+ips_putq_wait_tail(ips_wait_queue_t * queue, Scsi_Cmnd * item)
+{
+	METHOD_TRACE("ips_putq_wait_tail", 1);
 
-   if (!item)
-      return ;
+	if (!item)
+		return;
 
-   item->host_scribble = NULL;
+	item->host_scribble = NULL;
 
-   if (queue->tail)
-      queue->tail->host_scribble = (char *)item;
+	if (queue->tail)
+		queue->tail->host_scribble = (char *) item;
 
-   queue->tail = item;
+	queue->tail = item;
 
-   if (!queue->head)
-      queue->head = item;
+	if (!queue->head)
+		queue->head = item;
 
-   queue->count++;
+	queue->count++;
 }
 
 /****************************************************************************/
@@ -3735,26 +3069,27 @@
 /*                                                                          */
 /****************************************************************************/
 static inline Scsi_Cmnd *
-ips_removeq_wait_head(ips_wait_queue_t *queue) {
-   Scsi_Cmnd  *item;
+ips_removeq_wait_head(ips_wait_queue_t * queue)
+{
+	Scsi_Cmnd *item;
 
-   METHOD_TRACE("ips_removeq_wait_head", 1);
+	METHOD_TRACE("ips_removeq_wait_head", 1);
 
-   item = queue->head;
+	item = queue->head;
 
-   if (!item) {
-      return (NULL);
-   }
+	if (!item) {
+		return (NULL);
+	}
 
-   queue->head = (Scsi_Cmnd *) item->host_scribble;
-   item->host_scribble = NULL;
+	queue->head = (Scsi_Cmnd *) item->host_scribble;
+	item->host_scribble = NULL;
 
-   if (queue->tail == item)
-      queue->tail = NULL;
+	if (queue->tail == item)
+		queue->tail = NULL;
 
-   queue->count--;
+	queue->count--;
 
-   return (item);
+	return (item);
 }
 
 /****************************************************************************/
@@ -3769,37 +3104,38 @@
 /*                                                                          */
 /****************************************************************************/
 static inline Scsi_Cmnd *
-ips_removeq_wait(ips_wait_queue_t *queue, Scsi_Cmnd *item) {
-   Scsi_Cmnd  *p;
+ips_removeq_wait(ips_wait_queue_t * queue, Scsi_Cmnd * item)
+{
+	Scsi_Cmnd *p;
 
-   METHOD_TRACE("ips_removeq_wait", 1);
+	METHOD_TRACE("ips_removeq_wait", 1);
 
-   if (!item)
-      return (NULL);
+	if (!item)
+		return (NULL);
 
-   if (item == queue->head) {
-      return (ips_removeq_wait_head(queue));
-   }
+	if (item == queue->head) {
+		return (ips_removeq_wait_head(queue));
+	}
 
-   p = queue->head;
+	p = queue->head;
 
-   while ((p) && (item != (Scsi_Cmnd *) p->host_scribble))
-      p = (Scsi_Cmnd *) p->host_scribble;
+	while ((p) && (item != (Scsi_Cmnd *) p->host_scribble))
+		p = (Scsi_Cmnd *) p->host_scribble;
 
-   if (p) {
-      /* found a match */
-      p->host_scribble = item->host_scribble;
+	if (p) {
+		/* found a match */
+		p->host_scribble = item->host_scribble;
 
-      if (!item->host_scribble)
-         queue->tail = p;
+		if (!item->host_scribble)
+			queue->tail = p;
 
-      item->host_scribble = NULL;
-      queue->count--;
+		item->host_scribble = NULL;
+		queue->count--;
 
-      return (item);
-   }
+		return (item);
+	}
 
-   return (NULL);
+	return (NULL);
 }
 
 /****************************************************************************/
@@ -3814,19 +3150,20 @@
 /*                                                                          */
 /****************************************************************************/
 static inline void
-ips_putq_copp_head(ips_copp_queue_t *queue, ips_copp_wait_item_t *item) {
-   METHOD_TRACE("ips_putq_copp_head", 1);
+ips_putq_copp_head(ips_copp_queue_t * queue, ips_copp_wait_item_t * item)
+{
+	METHOD_TRACE("ips_putq_copp_head", 1);
 
-   if (!item)
-      return ;
+	if (!item)
+		return;
 
-   item->next = queue->head;
-   queue->head = item;
+	item->next = queue->head;
+	queue->head = item;
 
-   if (!queue->tail)
-      queue->tail = item;
+	if (!queue->tail)
+		queue->tail = item;
 
-   queue->count++;
+	queue->count++;
 }
 
 /****************************************************************************/
@@ -3841,23 +3178,24 @@
 /*                                                                          */
 /****************************************************************************/
 static inline void
-ips_putq_copp_tail(ips_copp_queue_t *queue, ips_copp_wait_item_t *item) {
-   METHOD_TRACE("ips_putq_copp_tail", 1);
+ips_putq_copp_tail(ips_copp_queue_t * queue, ips_copp_wait_item_t * item)
+{
+	METHOD_TRACE("ips_putq_copp_tail", 1);
 
-   if (!item)
-      return ;
+	if (!item)
+		return;
 
-   item->next = NULL;
+	item->next = NULL;
 
-   if (queue->tail)
-      queue->tail->next = item;
+	if (queue->tail)
+		queue->tail->next = item;
 
-   queue->tail = item;
+	queue->tail = item;
 
-   if (!queue->head)
-      queue->head = item;
+	if (!queue->head)
+		queue->head = item;
 
-   queue->count++;
+	queue->count++;
 }
 
 /****************************************************************************/
@@ -3872,26 +3210,27 @@
 /*                                                                          */
 /****************************************************************************/
 static inline ips_copp_wait_item_t *
-ips_removeq_copp_head(ips_copp_queue_t *queue) {
-   ips_copp_wait_item_t *item;
+ips_removeq_copp_head(ips_copp_queue_t * queue)
+{
+	ips_copp_wait_item_t *item;
 
-   METHOD_TRACE("ips_removeq_copp_head", 1);
+	METHOD_TRACE("ips_removeq_copp_head", 1);
 
-   item = queue->head;
+	item = queue->head;
 
-   if (!item) {
-      return (NULL);
-   }
+	if (!item) {
+		return (NULL);
+	}
 
-   queue->head = item->next;
-   item->next = NULL;
+	queue->head = item->next;
+	item->next = NULL;
 
-   if (queue->tail == item)
-      queue->tail = NULL;
+	if (queue->tail == item)
+		queue->tail = NULL;
 
-   queue->count--;
+	queue->count--;
 
-   return (item);
+	return (item);
 }
 
 /****************************************************************************/
@@ -3906,37 +3245,38 @@
 /*                                                                          */
 /****************************************************************************/
 static inline ips_copp_wait_item_t *
-ips_removeq_copp(ips_copp_queue_t *queue, ips_copp_wait_item_t *item) {
-   ips_copp_wait_item_t *p;
+ips_removeq_copp(ips_copp_queue_t * queue, ips_copp_wait_item_t * item)
+{
+	ips_copp_wait_item_t *p;
 
-   METHOD_TRACE("ips_removeq_copp", 1);
+	METHOD_TRACE("ips_removeq_copp", 1);
 
-   if (!item)
-      return (NULL);
+	if (!item)
+		return (NULL);
 
-   if (item == queue->head) {
-      return (ips_removeq_copp_head(queue));
-   }
+	if (item == queue->head) {
+		return (ips_removeq_copp_head(queue));
+	}
 
-   p = queue->head;
+	p = queue->head;
 
-   while ((p) && (item != p->next))
-      p = p->next;
+	while ((p) && (item != p->next))
+		p = p->next;
 
-   if (p) {
-      /* found a match */
-      p->next = item->next;
+	if (p) {
+		/* found a match */
+		p->next = item->next;
 
-      if (!item->next)
-         queue->tail = p;
+		if (!item->next)
+			queue->tail = p;
 
-      item->next = NULL;
-      queue->count--;
+		item->next = NULL;
+		queue->count--;
 
-      return (item);
-   }
+		return (item);
+	}
 
-   return (NULL);
+	return (NULL);
 }
 
 /****************************************************************************/
@@ -3949,16 +3289,16 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ipsintr_blocking(ips_ha_t *ha, ips_scb_t *scb) {
-   METHOD_TRACE("ipsintr_blocking", 2);
+ipsintr_blocking(ips_ha_t * ha, ips_scb_t * scb)
+{
+	METHOD_TRACE("ipsintr_blocking", 2);
 
-   ips_freescb(ha, scb);
-   if ((ha->waitflag == TRUE) &&
-       (ha->cmd_in_progress == scb->cdb[0])) {
-      ha->waitflag = FALSE;
+	ips_freescb(ha, scb);
+	if ((ha->waitflag == TRUE) && (ha->cmd_in_progress == scb->cdb[0])) {
+		ha->waitflag = FALSE;
 
-      return ;
-   }
+		return;
+	}
 }
 
 /****************************************************************************/
@@ -3971,25 +3311,27 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ipsintr_done(ips_ha_t *ha, ips_scb_t *scb) {
-   METHOD_TRACE("ipsintr_done", 2);
+ipsintr_done(ips_ha_t * ha, ips_scb_t * scb)
+{
+	METHOD_TRACE("ipsintr_done", 2);
 
-   if (!scb) {
-      printk(KERN_WARNING "(%s%d) Spurious interrupt; scb NULL.\n",
-             ips_name, ha->host_num);
+	if (!scb) {
+		printk(KERN_WARNING "(%s%d) Spurious interrupt; scb NULL.\n",
+		       ips_name, ha->host_num);
 
-      return ;
-   }
+		return;
+	}
 
-   if (scb->scsi_cmd == NULL) {
-      /* unexpected interrupt */
-      printk(KERN_WARNING "(%s%d) Spurious interrupt; scsi_cmd not set.\n",
-             ips_name, ha->host_num);
+	if (scb->scsi_cmd == NULL) {
+		/* unexpected interrupt */
+		printk(KERN_WARNING
+		       "(%s%d) Spurious interrupt; scsi_cmd not set.\n",
+		       ips_name, ha->host_num);
 
-      return;
-   }
+		return;
+	}
 
-   ips_done(ha, scb);
+	ips_done(ha, scb);
 }
 
 /****************************************************************************/
@@ -4002,180 +3344,118 @@
 /*  ASSUMED to be called form within the request lock                       */
 /****************************************************************************/
 static void
-ips_done(ips_ha_t *ha, ips_scb_t *scb) {
-   int ret;
+ips_done(ips_ha_t * ha, ips_scb_t * scb)
+{
+	int ret;
 
-   METHOD_TRACE("ips_done", 1);
+	METHOD_TRACE("ips_done", 1);
 
-   if (!scb)
-      return ;
+	if (!scb)
+		return;
 
-   if ((scb->scsi_cmd) && (ips_is_passthru(scb->scsi_cmd))) {
-      ips_cleanup_passthru(ha, scb);
-      ha->num_ioctl--;
-   } else {
-      /*
-       * Check to see if this command had too much
-       * data and had to be broke up.  If so, queue
-       * the rest of the data and continue.
-       */
-      if ((scb->breakup) || (scb->sg_break)) {
-         /* we had a data breakup */
-         uint8_t bk_save;
-
-         bk_save = scb->breakup;
-         scb->breakup = 0;
-
-         if (scb->sg_count) {
-            /* S/G request */
-            struct scatterlist *sg;
-            int                 i;
-
-            sg = scb->scsi_cmd->request_buffer;
-
-            if (scb->sg_count == 1) {
-               if (sg_dma_len(sg) - (bk_save * ha->max_xfer) > ha->max_xfer) {
-                  /* Further breakup required */
-                  scb->data_len = ha->max_xfer;
-                  scb->data_busaddr = sg_dma_address(sg) + (bk_save * ha->max_xfer);
-                  scb->breakup = bk_save + 1;
-               } else {
-                  scb->data_len = sg_dma_len(sg) - (bk_save * ha->max_xfer);
-                  scb->data_busaddr = sg_dma_address(sg) + (bk_save * ha->max_xfer);
-               }
-
-               scb->dcdb.transfer_length = scb->data_len;
-               scb->sg_len = 0;
-            } else {
-               /* We're here because there was MORE than one s/g unit. */
-	            /* bk_save points to which sg unit to look at           */
-	            /* sg_break points to how far through this unit we are  */
-	            /* NOTE: We will not move from one sg to another here,  */
-               /*    just finish the one we are in.  Not the most      */
-               /*    efficient, but it keeps it from getting too hacky */
-
-		         /* IF sg_break is non-zero, then just work on this current sg piece, */
-               /* pointed to by bk_save                                             */
-               if (scb->sg_break) {
-                  scb->sg_len = 1;
-                  scb->sg_list[0].address = sg_dma_address(&sg[bk_save])
-                                            + ha->max_xfer*scb->sg_break;
-                  if (ha->max_xfer > sg_dma_len(&sg[bk_save]) - ha->max_xfer * scb->sg_break) 
-                     scb->sg_list[0].length = sg_dma_len(&sg[bk_save]) - ha->max_xfer * scb->sg_break;
-                  else 
-                     scb->sg_list[0].length = ha->max_xfer;
-                  scb->sg_break++;              /* MUST GO HERE for math below to work */
-                  scb->data_len = scb->sg_list[0].length;;
-
-                  if (sg_dma_len(&sg[bk_save]) <= ha->max_xfer * scb->sg_break ) {
-                     scb->sg_break = 0;         /* No more work in this unit */
-                     if (( bk_save + 1 ) >= scb->sg_count) 
-                        scb->breakup = 0;
-                     else
-                        scb->breakup = bk_save + 1;
-                  }
-               } else {
-			         /* ( sg_break == 0 ), so this is our first look at a new sg piece */
-                  if (sg_dma_len(&sg[bk_save]) > ha->max_xfer) {
-                     scb->sg_list[0].address = sg_dma_address(&sg[bk_save]);
-                     scb->sg_list[0].length = ha->max_xfer;
-                     scb->breakup = bk_save;
-                     scb->sg_break = 1;
-                     scb->data_len = ha->max_xfer;
-                     scb->sg_len = 1;
- 	          } else {
-	         /* OK, the next sg is a short one, so loop until full */
-                     scb->data_len = 0;
-                     scb->sg_len = 0;
-                     scb->sg_break = 0;
-                     /*   We're only doing full units here */
-                     for (i = bk_save; i < scb->sg_count; i++) {
-                        scb->sg_list[i - bk_save].address = sg_dma_address(&sg[i]);
-                        scb->sg_list[i - bk_save].length = cpu_to_le32(sg_dma_len(&sg[i]));
-                        if (scb->data_len + sg_dma_len(&sg[i]) > ha->max_xfer) {
-                           scb->breakup = i;  /* sneaky, if not more work, than breakup is 0 */
-                           break;
-                        }
-                        scb->data_len += sg_dma_len(&sg[i]);
-                        scb->sg_len++;           /* only if we didn't get too big */
-		  		         }
-			         }
-		         }
-
-               /* Also, we need to be sure we don't queue work ( breakup != 0 )
-                  if no more sg units for next time */
-               scb->dcdb.transfer_length = scb->data_len;
-               scb->data_busaddr = scb->sg_busaddr;
-            }
-                                              
-         } else {
-            /* Non S/G Request */
-            pci_unmap_single(ha->pcidev, scb->data_busaddr, scb->data_len,
-                             IPS_DMA_DIR(scb));
-            if ((scb->scsi_cmd->request_bufflen - (bk_save * ha->max_xfer)) > ha->max_xfer) {
-               /* Further breakup required */
-               scb->data_len = ha->max_xfer;
-               scb->data_busaddr = pci_map_single(ha->pcidev,
-                                           scb->scsi_cmd->request_buffer +
-                                           (bk_save * ha->max_xfer),
-                                           scb->data_len, IPS_DMA_DIR(scb));
-               scb->breakup = bk_save + 1;
-            } else {
-               scb->data_len = scb->scsi_cmd->request_bufflen - (bk_save * ha->max_xfer);
-               scb->data_busaddr = pci_map_single(ha->pcidev,
-                                           scb->scsi_cmd->request_buffer +
-                                           (bk_save * ha->max_xfer),
-                                           scb->data_len, IPS_DMA_DIR(scb));
-	    }
-
-            scb->dcdb.transfer_length = scb->data_len;
-            scb->sg_len = 0;
-         }
-
-         scb->dcdb.cmd_attribute |= ips_command_direction[scb->scsi_cmd->cmnd[0]];
-
-         if (!scb->dcdb.cmd_attribute & 0x3)
-            scb->dcdb.transfer_length = 0;
-
-         if (scb->data_len >= IPS_MAX_XFER) {
-            scb->dcdb.cmd_attribute |= IPS_TRANSFER64K;
-            scb->dcdb.transfer_length = 0;
-         }
-
-         ret = ips_send_cmd(ha, scb);
-
-         switch(ret) {
-         case IPS_FAILURE:
-            if (scb->scsi_cmd) {
-               scb->scsi_cmd->result = DID_ERROR << 16;
-               scb->scsi_cmd->scsi_done(scb->scsi_cmd);
-            }
-
-            ips_freescb(ha, scb);
-            break;
-         case IPS_SUCCESS_IMM:
-            if (scb->scsi_cmd) {
-               scb->scsi_cmd->result = DID_ERROR << 16;
-               scb->scsi_cmd->scsi_done(scb->scsi_cmd);
-            }
-
-            ips_freescb(ha, scb);
-            break;
-         default:
-            break;
-         } /* end case */
-
-         return ;
-      }
-   } /* end if passthru */
-
-   if (scb->bus) {
-      ha->dcdb_active[scb->bus-1] &= ~(1 << scb->target_id);
-   }
+	if ((scb->scsi_cmd) && (ips_is_passthru(scb->scsi_cmd))) {
+		ips_cleanup_passthru(ha, scb);
+		ha->num_ioctl--;
+	} else {
+		/*
+		 * Check to see if this command had too much
+		 * data and had to be broke up.  If so, queue
+		 * the rest of the data and continue.
+		 */
+		if ((scb->breakup) || (scb->sg_break)) {
+			/* we had a data breakup */
+			scb->data_len = 0;
+
+			if (scb->sg_count) {
+				/* S/G request */
+				struct scatterlist *sg;
+				int ips_sg_index = 0;
+				int sg_dma_index;
+
+				sg = scb->scsi_cmd->request_buffer;
+
+				/* Spin forward to last dma chunk */
+				sg_dma_index = scb->breakup;
+
+				/* Take care of possible partial on last chunk */
+				ips_fill_scb_sg_single(ha,
+						       sg_dma_address(&sg
+								      [sg_dma_index]),
+						       scb, ips_sg_index++,
+						       sg_dma_len(&sg
+								  [sg_dma_index]));
+
+				for (; sg_dma_index < scb->sg_count;
+				     sg_dma_index++) {
+					if (ips_fill_scb_sg_single
+					    (ha,
+					     sg_dma_address(&sg[sg_dma_index]),
+					     scb, ips_sg_index++,
+					     sg_dma_len(&sg[sg_dma_index])) < 0)
+						break;
+
+				}
+
+			} else {
+				/* Non S/G Request */
+				(void) ips_fill_scb_sg_single(ha,
+							      scb->
+							      data_busaddr +
+							      (scb->sg_break *
+							       ha->max_xfer),
+							      scb, 0,
+							      scb->scsi_cmd->
+							      request_bufflen -
+							      (scb->sg_break *
+							       ha->max_xfer));
+			}
+
+			scb->dcdb.transfer_length = scb->data_len;
+			scb->dcdb.cmd_attribute |=
+			    ips_command_direction[scb->scsi_cmd->cmnd[0]];
+
+			if (!(scb->dcdb.cmd_attribute & 0x3))
+				scb->dcdb.transfer_length = 0;
+
+			if (scb->data_len >= IPS_MAX_XFER) {
+				scb->dcdb.cmd_attribute |= IPS_TRANSFER64K;
+				scb->dcdb.transfer_length = 0;
+			}
+
+			ret = ips_send_cmd(ha, scb);
+
+			switch (ret) {
+			case IPS_FAILURE:
+				if (scb->scsi_cmd) {
+					scb->scsi_cmd->result = DID_ERROR << 16;
+					scb->scsi_cmd->scsi_done(scb->scsi_cmd);
+				}
+
+				ips_freescb(ha, scb);
+				break;
+			case IPS_SUCCESS_IMM:
+				if (scb->scsi_cmd) {
+					scb->scsi_cmd->result = DID_ERROR << 16;
+					scb->scsi_cmd->scsi_done(scb->scsi_cmd);
+				}
+
+				ips_freescb(ha, scb);
+				break;
+			default:
+				break;
+			}	/* end case */
+
+			return;
+		}
+	}			/* end if passthru */
+
+	if (scb->bus) {
+		ha->dcdb_active[scb->bus - 1] &= ~(1 << scb->target_id);
+	}
 
-   scb->scsi_cmd->scsi_done(scb->scsi_cmd);
+	scb->scsi_cmd->scsi_done(scb->scsi_cmd);
 
-   ips_freescb(ha, scb);
+	ips_freescb(ha, scb);
 }
 
 /****************************************************************************/
@@ -4188,118 +3468,130 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_map_status(ips_ha_t *ha, ips_scb_t *scb, ips_stat_t *sp) {
-   int       errcode;
-   int       device_error;
-   uint32_t  transfer_len;
-   IPS_DCDB_TABLE_TAPE *tapeDCDB;
-
-   METHOD_TRACE("ips_map_status", 1);
-
-   if (scb->bus) {
-      DEBUG_VAR(2, "(%s%d) Physical device error (%d %d %d): %x %x, Sense Key: %x, ASC: %x, ASCQ: %x",
-                ips_name,
-                ha->host_num,
-                scb->scsi_cmd->channel,
-                scb->scsi_cmd->target,
-                scb->scsi_cmd->lun,
-                scb->basic_status,
-                scb->extended_status,
-                scb->extended_status == IPS_ERR_CKCOND ? scb->dcdb.sense_info[2] & 0xf : 0,
-                scb->extended_status == IPS_ERR_CKCOND ? scb->dcdb.sense_info[12] : 0,
-                scb->extended_status == IPS_ERR_CKCOND ? scb->dcdb.sense_info[13] : 0);
-   }
-
-   /* default driver error */
-   errcode = DID_ERROR;
-   device_error = 0;
-
-   switch (scb->basic_status & IPS_GSC_STATUS_MASK) {
-   case IPS_CMD_TIMEOUT:
-      errcode = DID_TIME_OUT;
-      break;
-
-   case IPS_INVAL_OPCO:
-   case IPS_INVAL_CMD_BLK:
-   case IPS_INVAL_PARM_BLK:
-   case IPS_LD_ERROR:
-   case IPS_CMD_CMPLT_WERROR:
-      break;
-
-   case IPS_PHYS_DRV_ERROR:
-      switch (scb->extended_status) {
-      case IPS_ERR_SEL_TO:
-         if (scb->bus)
-            errcode = DID_NO_CONNECT;
-
-         break;
-
-      case IPS_ERR_OU_RUN:   
-         if ( ( scb->cmd.dcdb.op_code == IPS_CMD_EXTENDED_DCDB ) ||
-              ( scb->cmd.dcdb.op_code == IPS_CMD_EXTENDED_DCDB_SG ) ) {
-             tapeDCDB = ( IPS_DCDB_TABLE_TAPE * ) &scb->dcdb;
-             transfer_len = tapeDCDB->transfer_length;
-         } else {
-             transfer_len = ( uint32_t ) scb->dcdb.transfer_length;
-         }
-
-        if ((scb->bus) && (transfer_len < scb->data_len)) {
-            /* Underrun - set default to no error */
-            errcode = DID_OK;
-
-            /* Restrict access to physical DASD */
-            if ((scb->scsi_cmd->cmnd[0] == INQUIRY) &&
-                ((((char *) scb->scsi_cmd->buffer)[0] & 0x1f) == TYPE_DISK)) {
-               /* underflow -- no error               */
-               /* restrict access to physical DASD    */
-               errcode = DID_TIME_OUT;
-               break;
-            }
-         } else
-            errcode = DID_ERROR;
-
-         break;
-
-      case IPS_ERR_RECOVERY:
-         /* don't fail recovered errors */
-         if (scb->bus)
-            errcode = DID_OK;
-
-         break;
-
-      case IPS_ERR_HOST_RESET:
-      case IPS_ERR_DEV_RESET:
-         errcode = DID_RESET;
-         break;
-
-      case IPS_ERR_CKCOND:
-         if (scb->bus) {
-            if ((scb->cmd.dcdb.op_code == IPS_CMD_EXTENDED_DCDB) ||
-                (scb->cmd.dcdb.op_code == IPS_CMD_EXTENDED_DCDB_SG)) {
-               tapeDCDB = (IPS_DCDB_TABLE_TAPE *) &scb->dcdb;
-               memcpy(scb->scsi_cmd->sense_buffer, tapeDCDB->sense_info,
-                      sizeof(scb->scsi_cmd->sense_buffer));
-            } else {
-               memcpy(scb->scsi_cmd->sense_buffer, scb->dcdb.sense_info,
-                      sizeof(scb->scsi_cmd->sense_buffer));
-            }
-            device_error = 2; /* check condition */
-         }
-
-         errcode = DID_OK;
-
-         break;
-
-      default:
-         errcode = DID_ERROR;
-         break;
+ips_map_status(ips_ha_t * ha, ips_scb_t * scb, ips_stat_t * sp)
+{
+	int errcode;
+	int device_error;
+	uint32_t transfer_len;
+	IPS_DCDB_TABLE_TAPE *tapeDCDB;
+
+	METHOD_TRACE("ips_map_status", 1);
+
+	if (scb->bus) {
+		DEBUG_VAR(2,
+			  "(%s%d) Physical device error (%d %d %d): %x %x, Sense Key: %x, ASC: %x, ASCQ: %x",
+			  ips_name, ha->host_num, scb->scsi_cmd->channel,
+			  scb->scsi_cmd->target, scb->scsi_cmd->lun,
+			  scb->basic_status, scb->extended_status,
+			  scb->extended_status ==
+			  IPS_ERR_CKCOND ? scb->dcdb.sense_info[2] & 0xf : 0,
+			  scb->extended_status ==
+			  IPS_ERR_CKCOND ? scb->dcdb.sense_info[12] : 0,
+			  scb->extended_status ==
+			  IPS_ERR_CKCOND ? scb->dcdb.sense_info[13] : 0);
+	}
+
+	/* default driver error */
+	errcode = DID_ERROR;
+	device_error = 0;
+
+	switch (scb->basic_status & IPS_GSC_STATUS_MASK) {
+	case IPS_CMD_TIMEOUT:
+		errcode = DID_TIME_OUT;
+		break;
+
+	case IPS_INVAL_OPCO:
+	case IPS_INVAL_CMD_BLK:
+	case IPS_INVAL_PARM_BLK:
+	case IPS_LD_ERROR:
+	case IPS_CMD_CMPLT_WERROR:
+		break;
+
+	case IPS_PHYS_DRV_ERROR:
+		switch (scb->extended_status) {
+		case IPS_ERR_SEL_TO:
+			if (scb->bus)
+				errcode = DID_NO_CONNECT;
+
+			break;
+
+		case IPS_ERR_OU_RUN:
+			if ((scb->cmd.dcdb.op_code == IPS_CMD_EXTENDED_DCDB) ||
+			    (scb->cmd.dcdb.op_code == IPS_CMD_EXTENDED_DCDB_SG)) {
+				tapeDCDB = (IPS_DCDB_TABLE_TAPE *) & scb->dcdb;
+				transfer_len = tapeDCDB->transfer_length;
+			} else {
+				transfer_len =
+				    (uint32_t) scb->dcdb.transfer_length;
+			}
+
+			if ((scb->bus) && (transfer_len < scb->data_len)) {
+				/* Underrun - set default to no error */
+				errcode = DID_OK;
+
+				/* Restrict access to physical DASD */
+				if ((scb->scsi_cmd->cmnd[0] == INQUIRY) &&
+				    ((((char
+					*) scb->scsi_cmd->buffer)[0] & 0x1f) ==
+				     TYPE_DISK)) {
+					/* underflow -- no error               */
+					/* restrict access to physical DASD    */
+					errcode = DID_TIME_OUT;
+					break;
+				}
+			} else
+				errcode = DID_ERROR;
+
+			break;
+
+		case IPS_ERR_RECOVERY:
+			/* don't fail recovered errors */
+			if (scb->bus)
+				errcode = DID_OK;
+
+			break;
+
+		case IPS_ERR_HOST_RESET:
+		case IPS_ERR_DEV_RESET:
+			errcode = DID_RESET;
+			break;
+
+		case IPS_ERR_CKCOND:
+			if (scb->bus) {
+				if (
+				    (scb->cmd.dcdb.op_code ==
+				     IPS_CMD_EXTENDED_DCDB)
+				    || (scb->cmd.dcdb.op_code ==
+					IPS_CMD_EXTENDED_DCDB_SG)) {
+					tapeDCDB =
+					    (IPS_DCDB_TABLE_TAPE *) & scb->dcdb;
+					memcpy(scb->scsi_cmd->sense_buffer,
+					       tapeDCDB->sense_info,
+					       sizeof (scb->scsi_cmd->
+						       sense_buffer));
+				} else {
+					memcpy(scb->scsi_cmd->sense_buffer,
+					       scb->dcdb.sense_info,
+					       sizeof (scb->scsi_cmd->
+						       sense_buffer));
+				}
+				device_error = 2;	/* check condition */
+			}
+
+			errcode = DID_OK;
+
+			break;
+
+		default:
+			errcode = DID_ERROR;
+			break;
 
-      } /* end switch */
-   } /* end switch */
+		}		/* end switch */
+	}			/* end switch */
 
-   scb->scsi_cmd->result = device_error | (errcode << 16);
+	scb->scsi_cmd->result = device_error | (errcode << 16);
 
-   return (1);
+	return (1);
 }
 
 /****************************************************************************/
@@ -4314,25 +3606,90 @@
 /*   actually need to wait.                                                 */
 /****************************************************************************/
 static int
-ips_send_wait(ips_ha_t *ha, ips_scb_t *scb, int timeout, int intr) {
-   int       ret;
+ips_send_wait(ips_ha_t * ha, ips_scb_t * scb, int timeout, int intr)
+{
+	int ret;
 
-   METHOD_TRACE("ips_send_wait", 1);
+	METHOD_TRACE("ips_send_wait", 1);
 
-   if (intr != IPS_FFDC) {      /* Won't be Waiting if this is a Time Stamp */
-      ha->waitflag = TRUE;
-      ha->cmd_in_progress = scb->cdb[0];
-   }
-   scb->callback = ipsintr_blocking;
-   ret = ips_send_cmd(ha, scb);
+	if (intr != IPS_FFDC) {	/* Won't be Waiting if this is a Time Stamp */
+		ha->waitflag = TRUE;
+		ha->cmd_in_progress = scb->cdb[0];
+	}
+	scb->callback = ipsintr_blocking;
+	ret = ips_send_cmd(ha, scb);
 
-   if ((ret == IPS_FAILURE) || (ret == IPS_SUCCESS_IMM))
-      return (ret);
+	if ((ret == IPS_FAILURE) || (ret == IPS_SUCCESS_IMM))
+		return (ret);
 
-   if (intr != IPS_FFDC)       /* Don't Wait around if this is a Time Stamp */
-      ret = ips_wait(ha, timeout, intr);
+	if (intr != IPS_FFDC)	/* Don't Wait around if this is a Time Stamp */
+		ret = ips_wait(ha, timeout, intr);
 
-   return (ret);
+	return (ret);
+}
+
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_scmd_buf_write                                         */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*  Write data to Scsi_Cmnd request_buffer at proper offsets                */
+/****************************************************************************/
+static void
+ips_scmd_buf_write(Scsi_Cmnd * scmd, void *data, unsigned
+		   int count)
+{
+	if (scmd->use_sg) {
+		int i;
+		unsigned int min_cnt, xfer_cnt;
+		char *cdata = (char *) data;
+		struct scatterlist *sg = scmd->request_buffer;
+		for (i = 0, xfer_cnt = 0;
+		     (i < scmd->use_sg) && (xfer_cnt < count); i++) {
+			if (!IPS_SG_ADDRESS(&sg[i]))
+				return;
+			min_cnt = min(count - xfer_cnt, sg[i].length);
+			memcpy(IPS_SG_ADDRESS(&sg[i]), &cdata[xfer_cnt],
+			       min_cnt);
+			xfer_cnt += min_cnt;
+		}
+
+	} else {
+		unsigned int min_cnt = min(count, scmd->request_bufflen);
+		memcpy(scmd->request_buffer, data, min_cnt);
+	}
+}
+
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_scmd_buf_read                                          */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*  Copy data from a Scsi_Cmnd to a new, linear buffer                      */
+/****************************************************************************/
+static void
+ips_scmd_buf_read(Scsi_Cmnd * scmd, void *data, unsigned
+		  int count)
+{
+	if (scmd->use_sg) {
+		int i;
+		unsigned int min_cnt, xfer_cnt;
+		char *cdata = (char *) data;
+		struct scatterlist *sg = scmd->request_buffer;
+		for (i = 0, xfer_cnt = 0;
+		     (i < scmd->use_sg) && (xfer_cnt < count); i++) {
+			if (!IPS_SG_ADDRESS(&sg[i]))
+				return;
+			min_cnt = min(count - xfer_cnt, sg[i].length);
+			memcpy(&cdata[xfer_cnt], IPS_SG_ADDRESS(&sg[i]),
+			       min_cnt);
+			xfer_cnt += min_cnt;
+		}
+
+	} else {
+		unsigned int min_cnt = min(count, scmd->request_bufflen);
+		memcpy(data, scmd->request_buffer, min_cnt);
+	}
 }
 
 /****************************************************************************/
@@ -4345,288 +3702,402 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_send_cmd(ips_ha_t *ha, ips_scb_t *scb) {
-   int       ret;
-   char     *sp;
-   int       device_error;
-   IPS_DCDB_TABLE_TAPE *tapeDCDB;
-   int       TimeOut;
-
-   METHOD_TRACE("ips_send_cmd", 1);
-
-   ret = IPS_SUCCESS;
-
-   if (!scb->scsi_cmd) {
-      /* internal command */
-
-      if (scb->bus > 0) {
-         /* Controller commands can't be issued */
-         /* to real devices -- fail them        */
-         if ((ha->waitflag == TRUE) &&
-             (ha->cmd_in_progress == scb->cdb[0])) {
-            ha->waitflag = FALSE;
-         }
-
-         return (1);
-      }
-   } else if ((scb->bus == 0) && (!ips_is_passthru(scb->scsi_cmd))) {
-      /* command to logical bus -- interpret */
-      if(ha->scb_waitlist.count + ha->scb_activelist.count > 32)
-         mod_timer(&scb->scsi_cmd->eh_timeout, jiffies + 120 * HZ);
-      ret = IPS_SUCCESS_IMM;
-
-      switch (scb->scsi_cmd->cmnd[0]) {
-      case ALLOW_MEDIUM_REMOVAL:
-      case REZERO_UNIT:
-      case ERASE:
-      case WRITE_FILEMARKS:
-      case SPACE:
-         scb->scsi_cmd->result = DID_ERROR << 16;
-         break;
-
-      case START_STOP:
-         scb->scsi_cmd->result = DID_OK << 16;
-
-      case TEST_UNIT_READY:
-      case INQUIRY:
-         scb->cmd.logical_info.op_code = IPS_CMD_GET_LD_INFO;
-         scb->cmd.logical_info.command_id = IPS_COMMAND_ID(ha, scb);
-         scb->cmd.logical_info.reserved = 0;
-         scb->cmd.logical_info.reserved2 = 0;
-         scb->data_len = sizeof(ha->adapt->logical_drive_info);
-         scb->data_busaddr = pci_map_single(ha->pcidev,
-                                            &ha->adapt->logical_drive_info,
-                                            scb->data_len, IPS_DMA_DIR(scb));
-         scb->flags |= IPS_SCB_MAP_SINGLE;
-         scb->cmd.logical_info.buffer_addr = scb->data_busaddr;
-         ret = IPS_SUCCESS;
-         break;
-
-      case REQUEST_SENSE:
-         ips_reqsen(ha, scb);
-         scb->scsi_cmd->result = DID_OK << 16;
-         break;
-
-      case READ_6:
-      case WRITE_6:
-         if (!scb->sg_len) {
-            scb->cmd.basic_io.op_code =
-            (scb->scsi_cmd->cmnd[0] == READ_6) ? IPS_CMD_READ : IPS_CMD_WRITE;
-         } else {
-            scb->cmd.basic_io.op_code =
-            (scb->scsi_cmd->cmnd[0] == READ_6) ? IPS_CMD_READ_SG : IPS_CMD_WRITE_SG;
-         }
-
-         scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
-         scb->cmd.basic_io.log_drv = scb->target_id;
-         scb->cmd.basic_io.sg_count = scb->sg_len;
-         scb->cmd.basic_io.sg_addr = cpu_to_le32(scb->data_busaddr);
-
-         if (scb->cmd.basic_io.lba)
-            scb->cmd.basic_io.lba = cpu_to_le32(le32_to_cpu(scb->cmd.basic_io.lba) +
-                                                le16_to_cpu(scb->cmd.basic_io.sector_count));
-         else
-            scb->cmd.basic_io.lba = (((scb->scsi_cmd->cmnd[1] & 0x1f) << 16) |
-                                     (scb->scsi_cmd->cmnd[2] << 8) |
-                                     (scb->scsi_cmd->cmnd[3]));
-
-         scb->cmd.basic_io.sector_count = cpu_to_le16(scb->data_len / IPS_BLKSIZE);
-
-         if (le16_to_cpu(scb->cmd.basic_io.sector_count) == 0)
-            scb->cmd.basic_io.sector_count = cpu_to_le16(256);
-
-         scb->cmd.basic_io.reserved = 0;
-         ret = IPS_SUCCESS;
-         break;
-
-      case READ_10:
-      case WRITE_10:
-         if (!scb->sg_len) {
-            scb->cmd.basic_io.op_code =
-            (scb->scsi_cmd->cmnd[0] == READ_10) ? IPS_CMD_READ : IPS_CMD_WRITE;
-         } else {
-            scb->cmd.basic_io.op_code =
-            (scb->scsi_cmd->cmnd[0] == READ_10) ? IPS_CMD_READ_SG : IPS_CMD_WRITE_SG;
-         }
-
-         scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
-         scb->cmd.basic_io.log_drv = scb->target_id;
-         scb->cmd.basic_io.sg_count = scb->sg_len;
-         scb->cmd.basic_io.sg_addr = cpu_to_le32(scb->data_busaddr);
-
-         if (scb->cmd.basic_io.lba)
-            scb->cmd.basic_io.lba = cpu_to_le32(le32_to_cpu(scb->cmd.basic_io.lba) +
-                                                le16_to_cpu(scb->cmd.basic_io.sector_count));
-         else
-            scb->cmd.basic_io.lba = ((scb->scsi_cmd->cmnd[2] << 24) |
-                                     (scb->scsi_cmd->cmnd[3] << 16) |
-                                     (scb->scsi_cmd->cmnd[4] << 8) |
-                                     scb->scsi_cmd->cmnd[5]);
-
-         scb->cmd.basic_io.sector_count = cpu_to_le16(scb->data_len / IPS_BLKSIZE);
-
-         scb->cmd.basic_io.reserved = 0;
-
-         if (cpu_to_le16(scb->cmd.basic_io.sector_count) == 0) {
-            /*
-             * This is a null condition
-             * we don't have to do anything
-             * so just return
-             */
-            scb->scsi_cmd->result = DID_OK << 16;
-         } else
-            ret = IPS_SUCCESS;
-
-         break;
-
-      case RESERVE:
-      case RELEASE:
-         scb->scsi_cmd->result = DID_OK << 16;
-         break;
-
-      case MODE_SENSE:
-         scb->cmd.basic_io.op_code = IPS_CMD_ENQUIRY;
-         scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
-         scb->data_len = sizeof(*ha->enq);
-         scb->data_busaddr = pci_map_single(ha->pcidev, ha->enq,
-                                            scb->data_len, IPS_DMA_DIR(scb));
-         scb->cmd.basic_io.sg_addr = scb->data_busaddr;
-         scb->flags |= IPS_SCB_MAP_SINGLE;
-         ret = IPS_SUCCESS;
-         break;
-
-      case READ_CAPACITY:
-         scb->cmd.logical_info.op_code = IPS_CMD_GET_LD_INFO;
-         scb->cmd.logical_info.command_id = IPS_COMMAND_ID(ha, scb);
-         scb->cmd.logical_info.reserved = 0;
-         scb->cmd.logical_info.reserved2 = 0;
-         scb->cmd.logical_info.reserved3 = 0;
-         scb->data_len = sizeof(ha->adapt->logical_drive_info);
-         scb->data_busaddr = pci_map_single(ha->pcidev,
-                                            &ha->adapt->logical_drive_info,
-                                            scb->data_len, IPS_DMA_DIR(scb));
-         scb->flags |= IPS_SCB_MAP_SINGLE;
-         scb->cmd.logical_info.buffer_addr = scb->data_busaddr;
-         ret = IPS_SUCCESS;
-         break;
-
-      case SEND_DIAGNOSTIC:
-      case REASSIGN_BLOCKS:
-      case FORMAT_UNIT:
-      case SEEK_10:
-      case VERIFY:
-      case READ_DEFECT_DATA:
-      case READ_BUFFER:
-      case WRITE_BUFFER:
-         scb->scsi_cmd->result = DID_OK << 16;
-         break;
-
-      default:
-         /* Set the Return Info to appear like the Command was */
-         /* attempted, a Check Condition occurred, and Sense   */
-         /* Data indicating an Invalid CDB OpCode is returned. */
-         sp = (char *) scb->scsi_cmd->sense_buffer;
-         memset(sp, 0, sizeof(scb->scsi_cmd->sense_buffer));
-  
-         sp[0] = 0x70;             /* Error Code               */ 
-         sp[2] = ILLEGAL_REQUEST;  /* Sense Key 5 Illegal Req. */
-         sp[7] = 0x0A;             /* Additional Sense Length  */
-         sp[12] = 0x20;            /* ASC = Invalid OpCode     */
-         sp[13] = 0x00;            /* ASCQ                     */
-   
-         device_error = 2;         /* Indicate Check Condition */
-         scb->scsi_cmd->result = device_error | (DID_OK << 16);
-         break;
-      } /* end switch */
-   } /* end if */
-
-   if (ret == IPS_SUCCESS_IMM)
-      return (ret);
-
-   /* setup DCDB */
-   if (scb->bus > 0) {
-      if (!scb->sg_len)
-         scb->cmd.dcdb.op_code = IPS_CMD_DCDB;
-      else
-         scb->cmd.dcdb.op_code = IPS_CMD_DCDB_SG;
-
-      /* If we already know the Device is Not there, no need to attempt a Command   */
-      /* This also protects an NT FailOver Controller from getting CDB's sent to it */
-      if ( ha->conf->dev[scb->bus-1][scb->target_id].ucState == 0 ) {
-         scb->scsi_cmd->result = DID_NO_CONNECT << 16;
-         return (IPS_SUCCESS_IMM); 
-      }
-
-      ha->dcdb_active[scb->bus-1] |= (1 << scb->target_id);
-      scb->cmd.dcdb.command_id = IPS_COMMAND_ID(ha, scb);
-      scb->cmd.dcdb.dcdb_address = cpu_to_le32(scb->scb_busaddr +
-                                               (unsigned long)&scb->dcdb -
-                                               (unsigned long)scb);
-      scb->cmd.dcdb.reserved = 0;
-      scb->cmd.dcdb.reserved2 = 0;
-      scb->cmd.dcdb.reserved3 = 0;   
-
-      TimeOut = scb->scsi_cmd->timeout_per_command;
-
-      if (ha->subsys->param[4] & 0x00100000) {          /* If NEW Tape DCDB is Supported */
-         if (!scb->sg_len)
-            scb->cmd.dcdb.op_code = IPS_CMD_EXTENDED_DCDB;
-         else
-            scb->cmd.dcdb.op_code = IPS_CMD_EXTENDED_DCDB_SG;
- 
-         tapeDCDB = (IPS_DCDB_TABLE_TAPE *) &scb->dcdb; /* Use Same Data Area as Old DCDB Struct */
-         tapeDCDB->device_address = ((scb->bus - 1) << 4) | scb->target_id;
-         tapeDCDB->cmd_attribute |= IPS_DISCONNECT_ALLOWED;
-         tapeDCDB->cmd_attribute &= ~IPS_TRANSFER64K;   /* Always Turn OFF 64K Size Flag */
-
-         if (TimeOut) {
-            if (TimeOut < ( 10 * HZ ))                  
-                tapeDCDB->cmd_attribute |= IPS_TIMEOUT10;     /* TimeOut is 10 Seconds */
-            else if (TimeOut < (60 * HZ)) 
-                tapeDCDB->cmd_attribute |= IPS_TIMEOUT60;     /* TimeOut is 60 Seconds */
-            else if (TimeOut < (1200 * HZ)) 
-                tapeDCDB->cmd_attribute |= IPS_TIMEOUT20M;    /* TimeOut is 20 Minutes */
-         }
-
-         tapeDCDB->cdb_length = scb->scsi_cmd->cmd_len;
-         tapeDCDB->reserved_for_LUN = 0;
-         tapeDCDB->transfer_length = scb->data_len;
-         tapeDCDB->buffer_pointer = cpu_to_le32(scb->data_busaddr);
-         tapeDCDB->sg_count = scb->sg_len;
-         tapeDCDB->sense_length = sizeof(tapeDCDB->sense_info);
-         tapeDCDB->scsi_status = 0;
-         tapeDCDB->reserved = 0;
-         memcpy(tapeDCDB->scsi_cdb, scb->scsi_cmd->cmnd, scb->scsi_cmd->cmd_len);
-      } else {
-         scb->dcdb.device_address = ((scb->bus - 1) << 4) | scb->target_id;
-         scb->dcdb.cmd_attribute |= IPS_DISCONNECT_ALLOWED;
-
-         if (TimeOut) {
-            if (TimeOut < (10 * HZ))                  
-                scb->dcdb.cmd_attribute |= IPS_TIMEOUT10;     /* TimeOut is 10 Seconds */
-            else if (TimeOut < (60 * HZ)) 
-                scb->dcdb.cmd_attribute |= IPS_TIMEOUT60;     /* TimeOut is 60 Seconds */
-            else if (TimeOut < (1200 * HZ)) 
-                scb->dcdb.cmd_attribute |= IPS_TIMEOUT20M;    /* TimeOut is 20 Minutes */
-         }
-         
-         scb->dcdb.transfer_length = scb->data_len;
-         if ( scb->dcdb.cmd_attribute & IPS_TRANSFER64K ) 
-             scb->dcdb.transfer_length = 0;
-         scb->dcdb.buffer_pointer = cpu_to_le32(scb->data_busaddr);
-         scb->dcdb.cdb_length = scb->scsi_cmd->cmd_len;
-         scb->dcdb.sense_length = sizeof(scb->dcdb.sense_info);
-         scb->dcdb.sg_count = scb->sg_len;
-         scb->dcdb.reserved = 0;
-         memcpy(scb->dcdb.scsi_cdb, scb->scsi_cmd->cmnd, scb->scsi_cmd->cmd_len);
-         scb->dcdb.scsi_status = 0;
-         scb->dcdb.reserved2[0] = 0;
-         scb->dcdb.reserved2[1] = 0;
-         scb->dcdb.reserved2[2] = 0;
-      }
-   }
+ips_send_cmd(ips_ha_t * ha, ips_scb_t * scb)
+{
+	int ret;
+	char *sp;
+	int device_error;
+	IPS_DCDB_TABLE_TAPE *tapeDCDB;
+	int TimeOut;
+
+	METHOD_TRACE("ips_send_cmd", 1);
+
+	ret = IPS_SUCCESS;
+
+	if (!scb->scsi_cmd) {
+		/* internal command */
+
+		if (scb->bus > 0) {
+			/* Controller commands can't be issued */
+			/* to real devices -- fail them        */
+			if ((ha->waitflag == TRUE) &&
+			    (ha->cmd_in_progress == scb->cdb[0])) {
+				ha->waitflag = FALSE;
+			}
+
+			return (1);
+		}
+	} else if ((scb->bus == 0) && (!ips_is_passthru(scb->scsi_cmd))) {
+		/* command to logical bus -- interpret */
+		ret = IPS_SUCCESS_IMM;
+
+		switch (scb->scsi_cmd->cmnd[0]) {
+		case ALLOW_MEDIUM_REMOVAL:
+		case REZERO_UNIT:
+		case ERASE:
+		case WRITE_FILEMARKS:
+		case SPACE:
+			scb->scsi_cmd->result = DID_ERROR << 16;
+			break;
+
+		case START_STOP:
+			scb->scsi_cmd->result = DID_OK << 16;
+
+		case TEST_UNIT_READY:
+		case INQUIRY:
+			if (scb->target_id == IPS_ADAPTER_ID) {
+				/*
+				 * Either we have a TUR
+				 * or we have a SCSI inquiry
+				 */
+				if (scb->scsi_cmd->cmnd[0] == TEST_UNIT_READY)
+					scb->scsi_cmd->result = DID_OK << 16;
+
+				if (scb->scsi_cmd->cmnd[0] == INQUIRY) {
+					IPS_SCSI_INQ_DATA inquiry;
+
+					memset(&inquiry, 0,
+					       sizeof (IPS_SCSI_INQ_DATA));
+
+					inquiry.DeviceType =
+					    IPS_SCSI_INQ_TYPE_PROCESSOR;
+					inquiry.DeviceTypeQualifier =
+					    IPS_SCSI_INQ_LU_CONNECTED;
+					inquiry.Version = IPS_SCSI_INQ_REV2;
+					inquiry.ResponseDataFormat =
+					    IPS_SCSI_INQ_RD_REV2;
+					inquiry.AdditionalLength = 31;
+					inquiry.Flags[0] =
+					    IPS_SCSI_INQ_Address16;
+					inquiry.Flags[1] =
+					    IPS_SCSI_INQ_WBus16 |
+					    IPS_SCSI_INQ_Sync;
+					strncpy(inquiry.VendorId, "IBM     ",
+						8);
+					strncpy(inquiry.ProductId,
+						"SERVERAID       ", 16);
+					strncpy(inquiry.ProductRevisionLevel,
+						"1.00", 4);
+
+					ips_scmd_buf_write(scb->scsi_cmd,
+							   &inquiry,
+							   sizeof (inquiry));
+
+					scb->scsi_cmd->result = DID_OK << 16;
+				}
+			} else {
+				scb->cmd.logical_info.op_code =
+				    IPS_CMD_GET_LD_INFO;
+				scb->cmd.logical_info.command_id =
+				    IPS_COMMAND_ID(ha, scb);
+				scb->cmd.logical_info.reserved = 0;
+				scb->cmd.logical_info.reserved2 = 0;
+				scb->data_len =
+				    sizeof (ha->adapt->logical_drive_info);
+				scb->data_busaddr =
+				    pci_map_single(ha->pcidev,
+						   &ha->adapt->
+						   logical_drive_info,
+						   scb->data_len,
+						   IPS_DMA_DIR(scb));
+				scb->flags |= IPS_SCB_MAP_SINGLE;
+				scb->cmd.logical_info.buffer_addr =
+				    scb->data_busaddr;
+				ret = IPS_SUCCESS;
+			}
+
+			break;
+
+		case REQUEST_SENSE:
+			ips_reqsen(ha, scb);
+			scb->scsi_cmd->result = DID_OK << 16;
+			break;
+
+		case READ_6:
+		case WRITE_6:
+			if (!scb->sg_len) {
+				scb->cmd.basic_io.op_code =
+				    (scb->scsi_cmd->cmnd[0] ==
+				     READ_6) ? IPS_CMD_READ : IPS_CMD_WRITE;
+				scb->cmd.basic_io.enhanced_sg = 0;
+				scb->cmd.basic_io.sg_addr =
+				    cpu_to_le32(scb->data_busaddr);
+			} else {
+				scb->cmd.basic_io.op_code =
+				    (scb->scsi_cmd->cmnd[0] ==
+				     READ_6) ? IPS_CMD_READ_SG :
+				    IPS_CMD_WRITE_SG;
+				scb->cmd.basic_io.enhanced_sg =
+				    IPS_USE_ENH_SGLIST(ha) ? 0xFF : 0;
+				scb->cmd.basic_io.sg_addr =
+				    cpu_to_le32(scb->sg_busaddr);
+			}
+
+			scb->cmd.basic_io.segment_4G = 0;
+			scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
+			scb->cmd.basic_io.log_drv = scb->target_id;
+			scb->cmd.basic_io.sg_count = scb->sg_len;
+
+			if (scb->cmd.basic_io.lba)
+				scb->cmd.basic_io.lba =
+				    cpu_to_le32(le32_to_cpu
+						(scb->cmd.basic_io.lba) +
+						le16_to_cpu(scb->cmd.basic_io.
+							    sector_count));
+			else
+				scb->cmd.basic_io.lba =
+				    (((scb->
+				       scsi_cmd->cmnd[1] & 0x1f) << 16) | (scb->
+									   scsi_cmd->
+									   cmnd
+									   [2]
+									   << 8)
+				     | (scb->scsi_cmd->cmnd[3]));
+
+			scb->cmd.basic_io.sector_count =
+			    cpu_to_le16(scb->data_len / IPS_BLKSIZE);
+
+			if (le16_to_cpu(scb->cmd.basic_io.sector_count) == 0)
+				scb->cmd.basic_io.sector_count =
+				    cpu_to_le16(256);
+
+			ret = IPS_SUCCESS;
+			break;
+
+		case READ_10:
+		case WRITE_10:
+			if (!scb->sg_len) {
+				scb->cmd.basic_io.op_code =
+				    (scb->scsi_cmd->cmnd[0] ==
+				     READ_10) ? IPS_CMD_READ : IPS_CMD_WRITE;
+				scb->cmd.basic_io.enhanced_sg = 0;
+				scb->cmd.basic_io.sg_addr =
+				    cpu_to_le32(scb->data_busaddr);
+			} else {
+				scb->cmd.basic_io.op_code =
+				    (scb->scsi_cmd->cmnd[0] ==
+				     READ_10) ? IPS_CMD_READ_SG :
+				    IPS_CMD_WRITE_SG;
+				scb->cmd.basic_io.enhanced_sg =
+				    IPS_USE_ENH_SGLIST(ha) ? 0xFF : 0;
+				scb->cmd.basic_io.sg_addr =
+				    cpu_to_le32(scb->sg_busaddr);
+			}
+
+			scb->cmd.basic_io.segment_4G = 0;
+			scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
+			scb->cmd.basic_io.log_drv = scb->target_id;
+			scb->cmd.basic_io.sg_count = scb->sg_len;
+
+			if (scb->cmd.basic_io.lba)
+				scb->cmd.basic_io.lba =
+				    cpu_to_le32(le32_to_cpu
+						(scb->cmd.basic_io.lba) +
+						le16_to_cpu(scb->cmd.basic_io.
+							    sector_count));
+			else
+				scb->cmd.basic_io.lba =
+				    ((scb->
+				      scsi_cmd->cmnd[2] << 24) | (scb->
+								  scsi_cmd->
+								  cmnd[3] << 16)
+				     | (scb->scsi_cmd->cmnd[4] << 8) | scb->
+				     scsi_cmd->cmnd[5]);
+
+			scb->cmd.basic_io.sector_count =
+			    cpu_to_le16(scb->data_len / IPS_BLKSIZE);
+
+			if (cpu_to_le16(scb->cmd.basic_io.sector_count) == 0) {
+				/*
+				 * This is a null condition
+				 * we don't have to do anything
+				 * so just return
+				 */
+				scb->scsi_cmd->result = DID_OK << 16;
+			} else
+				ret = IPS_SUCCESS;
+
+			break;
+
+		case RESERVE:
+		case RELEASE:
+			scb->scsi_cmd->result = DID_OK << 16;
+			break;
+
+		case MODE_SENSE:
+			scb->cmd.basic_io.op_code = IPS_CMD_ENQUIRY;
+			scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
+			scb->cmd.basic_io.segment_4G = 0;
+			scb->cmd.basic_io.enhanced_sg = 0;
+			scb->data_len = sizeof (*ha->enq);
+			scb->data_busaddr = pci_map_single(ha->pcidev, ha->enq,
+							   scb->data_len,
+							   IPS_DMA_DIR(scb));
+			scb->cmd.basic_io.sg_addr = scb->data_busaddr;
+			scb->flags |= IPS_SCB_MAP_SINGLE;
+			ret = IPS_SUCCESS;
+			break;
+
+		case READ_CAPACITY:
+			scb->cmd.logical_info.op_code = IPS_CMD_GET_LD_INFO;
+			scb->cmd.logical_info.command_id =
+			    IPS_COMMAND_ID(ha, scb);
+			scb->cmd.logical_info.reserved = 0;
+			scb->cmd.logical_info.reserved2 = 0;
+			scb->cmd.logical_info.reserved3 = 0;
+			scb->data_len = sizeof (ha->adapt->logical_drive_info);
+			scb->data_busaddr = pci_map_single(ha->pcidev,
+							   &ha->adapt->
+							   logical_drive_info,
+							   scb->data_len,
+							   IPS_DMA_DIR(scb));
+			scb->flags |= IPS_SCB_MAP_SINGLE;
+			scb->cmd.logical_info.buffer_addr = scb->data_busaddr;
+			ret = IPS_SUCCESS;
+			break;
+
+		case SEND_DIAGNOSTIC:
+		case REASSIGN_BLOCKS:
+		case FORMAT_UNIT:
+		case SEEK_10:
+		case VERIFY:
+		case READ_DEFECT_DATA:
+		case READ_BUFFER:
+		case WRITE_BUFFER:
+			scb->scsi_cmd->result = DID_OK << 16;
+			break;
+
+		default:
+			/* Set the Return Info to appear like the Command was */
+			/* attempted, a Check Condition occurred, and Sense   */
+			/* Data indicating an Invalid CDB OpCode is returned. */
+			sp = (char *) scb->scsi_cmd->sense_buffer;
+			memset(sp, 0, sizeof (scb->scsi_cmd->sense_buffer));
+
+			sp[0] = 0x70;	/* Error Code               */
+			sp[2] = ILLEGAL_REQUEST;	/* Sense Key 5 Illegal Req. */
+			sp[7] = 0x0A;	/* Additional Sense Length  */
+			sp[12] = 0x20;	/* ASC = Invalid OpCode     */
+			sp[13] = 0x00;	/* ASCQ                     */
+
+			device_error = 2;	/* Indicate Check Condition */
+			scb->scsi_cmd->result = device_error | (DID_OK << 16);
+			break;
+		}		/* end switch */
+	}
+	/* end if */
+	if (ret == IPS_SUCCESS_IMM)
+		return (ret);
+
+	/* setup DCDB */
+	if (scb->bus > 0) {
+
+		/* If we already know the Device is Not there, no need to attempt a Command   */
+		/* This also protects an NT FailOver Controller from getting CDB's sent to it */
+		if (ha->conf->dev[scb->bus - 1][scb->target_id].ucState == 0) {
+			scb->scsi_cmd->result = DID_NO_CONNECT << 16;
+			return (IPS_SUCCESS_IMM);
+		}
+
+		ha->dcdb_active[scb->bus - 1] |= (1 << scb->target_id);
+		scb->cmd.dcdb.command_id = IPS_COMMAND_ID(ha, scb);
+		scb->cmd.dcdb.dcdb_address = cpu_to_le32(scb->scb_busaddr +
+							 (unsigned long) &scb->
+							 dcdb -
+							 (unsigned long) scb);
+		scb->cmd.dcdb.reserved = 0;
+		scb->cmd.dcdb.reserved2 = 0;
+		scb->cmd.dcdb.reserved3 = 0;
+		scb->cmd.dcdb.segment_4G = 0;
+		scb->cmd.dcdb.enhanced_sg = 0;
+
+		TimeOut = scb->scsi_cmd->timeout_per_command;
+
+		if (ha->subsys->param[4] & 0x00100000) {	/* If NEW Tape DCDB is Supported */
+			if (!scb->sg_len) {
+				scb->cmd.dcdb.op_code = IPS_CMD_EXTENDED_DCDB;
+			} else {
+				scb->cmd.dcdb.op_code =
+				    IPS_CMD_EXTENDED_DCDB_SG;
+				scb->cmd.dcdb.enhanced_sg =
+				    IPS_USE_ENH_SGLIST(ha) ? 0xFF : 0;
+			}
+
+			tapeDCDB = (IPS_DCDB_TABLE_TAPE *) & scb->dcdb;	/* Use Same Data Area as Old DCDB Struct */
+			tapeDCDB->device_address =
+			    ((scb->bus - 1) << 4) | scb->target_id;
+			tapeDCDB->cmd_attribute |= IPS_DISCONNECT_ALLOWED;
+			tapeDCDB->cmd_attribute &= ~IPS_TRANSFER64K;	/* Always Turn OFF 64K Size Flag */
+
+			if (TimeOut) {
+				if (TimeOut < (10 * HZ))
+					tapeDCDB->cmd_attribute |= IPS_TIMEOUT10;	/* TimeOut is 10 Seconds */
+				else if (TimeOut < (60 * HZ))
+					tapeDCDB->cmd_attribute |= IPS_TIMEOUT60;	/* TimeOut is 60 Seconds */
+				else if (TimeOut < (1200 * HZ))
+					tapeDCDB->cmd_attribute |= IPS_TIMEOUT20M;	/* TimeOut is 20 Minutes */
+			}
+
+			tapeDCDB->cdb_length = scb->scsi_cmd->cmd_len;
+			tapeDCDB->reserved_for_LUN = 0;
+			tapeDCDB->transfer_length = scb->data_len;
+			if (scb->cmd.dcdb.op_code == IPS_CMD_EXTENDED_DCDB_SG)
+				tapeDCDB->buffer_pointer =
+				    cpu_to_le32(scb->sg_busaddr);
+			else
+				tapeDCDB->buffer_pointer =
+				    cpu_to_le32(scb->data_busaddr);
+			tapeDCDB->sg_count = scb->sg_len;
+			tapeDCDB->sense_length = sizeof (tapeDCDB->sense_info);
+			tapeDCDB->scsi_status = 0;
+			tapeDCDB->reserved = 0;
+			memcpy(tapeDCDB->scsi_cdb, scb->scsi_cmd->cmnd,
+			       scb->scsi_cmd->cmd_len);
+		} else {
+			if (!scb->sg_len) {
+				scb->cmd.dcdb.op_code = IPS_CMD_DCDB;
+			} else {
+				scb->cmd.dcdb.op_code = IPS_CMD_DCDB_SG;
+				scb->cmd.dcdb.enhanced_sg =
+				    IPS_USE_ENH_SGLIST(ha) ? 0xFF : 0;
+			}
+
+			scb->dcdb.device_address =
+			    ((scb->bus - 1) << 4) | scb->target_id;
+			scb->dcdb.cmd_attribute |= IPS_DISCONNECT_ALLOWED;
+
+			if (TimeOut) {
+				if (TimeOut < (10 * HZ))
+					scb->dcdb.cmd_attribute |= IPS_TIMEOUT10;	/* TimeOut is 10 Seconds */
+				else if (TimeOut < (60 * HZ))
+					scb->dcdb.cmd_attribute |= IPS_TIMEOUT60;	/* TimeOut is 60 Seconds */
+				else if (TimeOut < (1200 * HZ))
+					scb->dcdb.cmd_attribute |= IPS_TIMEOUT20M;	/* TimeOut is 20 Minutes */
+			}
+
+			scb->dcdb.transfer_length = scb->data_len;
+			if (scb->dcdb.cmd_attribute & IPS_TRANSFER64K)
+				scb->dcdb.transfer_length = 0;
+			if (scb->cmd.dcdb.op_code == IPS_CMD_DCDB_SG)
+				scb->dcdb.buffer_pointer =
+				    cpu_to_le32(scb->sg_busaddr);
+			else
+				scb->dcdb.buffer_pointer =
+				    cpu_to_le32(scb->data_busaddr);
+			scb->dcdb.cdb_length = scb->scsi_cmd->cmd_len;
+			scb->dcdb.sense_length = sizeof (scb->dcdb.sense_info);
+			scb->dcdb.sg_count = scb->sg_len;
+			scb->dcdb.reserved = 0;
+			memcpy(scb->dcdb.scsi_cdb, scb->scsi_cmd->cmnd,
+			       scb->scsi_cmd->cmd_len);
+			scb->dcdb.scsi_status = 0;
+			scb->dcdb.reserved2[0] = 0;
+			scb->dcdb.reserved2[1] = 0;
+			scb->dcdb.reserved2[2] = 0;
+		}
+	}
 
-   return ((*ha->func.issue)(ha, scb));
+	return ((*ha->func.issue) (ha, scb));
 }
 
 /****************************************************************************/
@@ -4639,169 +4110,151 @@
 /*   Assumed to be called with the HA lock                                  */
 /****************************************************************************/
 static void
-ips_chkstatus(ips_ha_t *ha, IPS_STATUS *pstatus) {
-   ips_scb_t  *scb;
-   ips_stat_t *sp;
-   uint8_t     basic_status;
-   uint8_t     ext_status;
-   int         errcode;
-
-   METHOD_TRACE("ips_chkstatus", 1);
-
-   scb = &ha->scbs[pstatus->fields.command_id];
-   scb->basic_status = basic_status = pstatus->fields.basic_status & IPS_BASIC_STATUS_MASK;
-   scb->extended_status = ext_status = pstatus->fields.extended_status;
-
-   sp = &ha->sp;
-   sp->residue_len = 0;
-   sp->scb_addr = (void *) scb;
-
-   /* Remove the item from the active queue */
-   ips_removeq_scb(&ha->scb_activelist, scb);
-
-   if (!scb->scsi_cmd)
-      /* internal commands are handled in do_ipsintr */
-      return ;
-
-   DEBUG_VAR(2, "(%s%d) ips_chkstatus: cmd 0x%X id %d (%d %d %d)",
-             ips_name,
-             ha->host_num,
-             scb->cdb[0],
-             scb->cmd.basic_io.command_id,
-             scb->bus,
-             scb->target_id,
-             scb->lun);
-
-   if ((scb->scsi_cmd) && (ips_is_passthru(scb->scsi_cmd)))
-      /* passthru - just returns the raw result */
-      return ;
-
-   errcode = DID_OK;
-
-   if (((basic_status & IPS_GSC_STATUS_MASK) == IPS_CMD_SUCCESS) ||
-       ((basic_status & IPS_GSC_STATUS_MASK) == IPS_CMD_RECOVERED_ERROR)) {
-
-      if (scb->bus == 0) {
-         if ((basic_status & IPS_GSC_STATUS_MASK) == IPS_CMD_RECOVERED_ERROR) {
-            DEBUG_VAR(1, "(%s%d) Recovered Logical Drive Error OpCode: %x, BSB: %x, ESB: %x",
-                      ips_name, ha->host_num,
-                      scb->cmd.basic_io.op_code, basic_status, ext_status);
-         }
-
-         switch (scb->scsi_cmd->cmnd[0]) {
-         case ALLOW_MEDIUM_REMOVAL:
-         case REZERO_UNIT:
-         case ERASE:
-         case WRITE_FILEMARKS:
-         case SPACE:
-            errcode = DID_ERROR;
-            break;
-
-         case START_STOP:
-            break;
-
-         case TEST_UNIT_READY:
-            if (scb->target_id == IPS_ADAPTER_ID) 
-               break;
-
-            if (!ips_online(ha, scb)) {
-               errcode = DID_TIME_OUT;
-            }
-            break;
-
-         case INQUIRY:
-            if (scb->target_id == IPS_ADAPTER_ID) {
-               IPS_SCSI_INQ_DATA inquiry;
-
-               memset(&inquiry, 0, sizeof(IPS_SCSI_INQ_DATA));
-
-               inquiry.DeviceType = IPS_SCSI_INQ_TYPE_PROCESSOR;
-               inquiry.DeviceTypeQualifier = IPS_SCSI_INQ_LU_CONNECTED;
-               inquiry.Version = IPS_SCSI_INQ_REV2;
-               inquiry.ResponseDataFormat = IPS_SCSI_INQ_RD_REV2;
-               inquiry.AdditionalLength = 31;
-               inquiry.Flags[0] = IPS_SCSI_INQ_Address16;
-               inquiry.Flags[1] = IPS_SCSI_INQ_WBus16 | IPS_SCSI_INQ_Sync;
-               strncpy(inquiry.VendorId, "IBM     ", 8);
-               strncpy(inquiry.ProductId, "SERVERAID       ", 16);
-               strncpy(inquiry.ProductRevisionLevel, "1.00", 4);
-
-               memcpy(scb->scsi_cmd->request_buffer, &inquiry, scb->scsi_cmd->request_bufflen);
-
-               scb->scsi_cmd->result = DID_OK << 16;
-               break;
-            }
-
-            if (ips_online(ha, scb)) {
-               ips_inquiry(ha, scb);
-            } else {
-               errcode = DID_TIME_OUT;
-            }
-            break;
-
-         case REQUEST_SENSE:
-            ips_reqsen(ha, scb);
-            break;
-
-         case READ_6:
-         case WRITE_6:
-         case READ_10:
-         case WRITE_10:
-         case RESERVE:
-         case RELEASE:
-            break;
-
-         case MODE_SENSE:
-            if (!ips_online(ha, scb) || !ips_msense(ha, scb)) {
-               errcode = DID_ERROR;
-            }
-            break;
-
-         case READ_CAPACITY:
-            if (ips_online(ha, scb))
-               ips_rdcap(ha, scb);
-            else {
-               errcode = DID_TIME_OUT;
-            }
-            break;
-
-         case SEND_DIAGNOSTIC:
-         case REASSIGN_BLOCKS:
-            break;
-
-         case FORMAT_UNIT:
-            errcode = DID_ERROR;
-            break;
-
-         case SEEK_10:
-         case VERIFY:
-         case READ_DEFECT_DATA:
-         case READ_BUFFER:
-         case WRITE_BUFFER:
-            break;
-
-         default:
-            errcode = DID_ERROR;
-         } /* end switch */
-
-         scb->scsi_cmd->result = errcode << 16;
-      } else { /* bus == 0 */
-         /* restrict access to physical drives */
-         if ((scb->scsi_cmd->cmnd[0] == INQUIRY) &&
-             ((((char *) scb->scsi_cmd->buffer)[0] & 0x1f) == TYPE_DISK)) {
-
-            scb->scsi_cmd->result = DID_TIME_OUT << 16;
-         }
-      } /* else */
-   } else { /* recovered error / success */
-      if (scb->bus == 0) {
-         DEBUG_VAR(1, "(%s%d) Unrecovered Logical Drive Error OpCode: %x, BSB: %x, ESB: %x",
-                   ips_name, ha->host_num,
-                   scb->cmd.basic_io.op_code, basic_status, ext_status);
-      }
+ips_chkstatus(ips_ha_t * ha, IPS_STATUS * pstatus)
+{
+	ips_scb_t *scb;
+	ips_stat_t *sp;
+	uint8_t basic_status;
+	uint8_t ext_status;
+	int errcode;
+
+	METHOD_TRACE("ips_chkstatus", 1);
+
+	scb = &ha->scbs[pstatus->fields.command_id];
+	scb->basic_status = basic_status =
+	    pstatus->fields.basic_status & IPS_BASIC_STATUS_MASK;
+	scb->extended_status = ext_status = pstatus->fields.extended_status;
+
+	sp = &ha->sp;
+	sp->residue_len = 0;
+	sp->scb_addr = (void *) scb;
+
+	/* Remove the item from the active queue */
+	ips_removeq_scb(&ha->scb_activelist, scb);
+
+	if (!scb->scsi_cmd)
+		/* internal commands are handled in do_ipsintr */
+		return;
+
+	DEBUG_VAR(2, "(%s%d) ips_chkstatus: cmd 0x%X id %d (%d %d %d)",
+		  ips_name,
+		  ha->host_num,
+		  scb->cdb[0],
+		  scb->cmd.basic_io.command_id,
+		  scb->bus, scb->target_id, scb->lun);
+
+	if ((scb->scsi_cmd) && (ips_is_passthru(scb->scsi_cmd)))
+		/* passthru - just returns the raw result */
+		return;
+
+	errcode = DID_OK;
+
+	if (((basic_status & IPS_GSC_STATUS_MASK) == IPS_CMD_SUCCESS) ||
+	    ((basic_status & IPS_GSC_STATUS_MASK) == IPS_CMD_RECOVERED_ERROR)) {
+
+		if (scb->bus == 0) {
+			if ((basic_status & IPS_GSC_STATUS_MASK) ==
+			    IPS_CMD_RECOVERED_ERROR) {
+				DEBUG_VAR(1,
+					  "(%s%d) Recovered Logical Drive Error OpCode: %x, BSB: %x, ESB: %x",
+					  ips_name, ha->host_num,
+					  scb->cmd.basic_io.op_code,
+					  basic_status, ext_status);
+			}
+
+			switch (scb->scsi_cmd->cmnd[0]) {
+			case ALLOW_MEDIUM_REMOVAL:
+			case REZERO_UNIT:
+			case ERASE:
+			case WRITE_FILEMARKS:
+			case SPACE:
+				errcode = DID_ERROR;
+				break;
+
+			case START_STOP:
+				break;
+
+			case TEST_UNIT_READY:
+				if (!ips_online(ha, scb)) {
+					errcode = DID_TIME_OUT;
+				}
+				break;
+
+			case INQUIRY:
+				if (ips_online(ha, scb)) {
+					ips_inquiry(ha, scb);
+				} else {
+					errcode = DID_TIME_OUT;
+				}
+				break;
+
+			case REQUEST_SENSE:
+				ips_reqsen(ha, scb);
+				break;
+
+			case READ_6:
+			case WRITE_6:
+			case READ_10:
+			case WRITE_10:
+			case RESERVE:
+			case RELEASE:
+				break;
+
+			case MODE_SENSE:
+				if (!ips_online(ha, scb)
+				    || !ips_msense(ha, scb)) {
+					errcode = DID_ERROR;
+				}
+				break;
+
+			case READ_CAPACITY:
+				if (ips_online(ha, scb))
+					ips_rdcap(ha, scb);
+				else {
+					errcode = DID_TIME_OUT;
+				}
+				break;
+
+			case SEND_DIAGNOSTIC:
+			case REASSIGN_BLOCKS:
+				break;
+
+			case FORMAT_UNIT:
+				errcode = DID_ERROR;
+				break;
+
+			case SEEK_10:
+			case VERIFY:
+			case READ_DEFECT_DATA:
+			case READ_BUFFER:
+			case WRITE_BUFFER:
+				break;
+
+			default:
+				errcode = DID_ERROR;
+			}	/* end switch */
+
+			scb->scsi_cmd->result = errcode << 16;
+		} else {	/* bus == 0 */
+			/* restrict access to physical drives */
+			if ((scb->scsi_cmd->cmnd[0] == INQUIRY) &&
+			    ((((char *) scb->scsi_cmd->buffer)[0] & 0x1f) ==
+			     TYPE_DISK)) {
+
+				scb->scsi_cmd->result = DID_TIME_OUT << 16;
+			}
+		}		/* else */
+	} else {		/* recovered error / success */
+		if (scb->bus == 0) {
+			DEBUG_VAR(1,
+				  "(%s%d) Unrecovered Logical Drive Error OpCode: %x, BSB: %x, ESB: %x",
+				  ips_name, ha->host_num,
+				  scb->cmd.basic_io.op_code, basic_status,
+				  ext_status);
+		}
 
-      ips_map_status(ha, scb, sp);
-   } /* else */
+		ips_map_status(ha, scb, sp);
+	}			/* else */
 }
 
 /****************************************************************************/
@@ -4814,25 +4267,30 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_online(ips_ha_t *ha, ips_scb_t *scb) {
-   METHOD_TRACE("ips_online", 1);
-
-   if (scb->target_id >= IPS_MAX_LD)
-      return (0);
+ips_online(ips_ha_t * ha, ips_scb_t * scb)
+{
+	METHOD_TRACE("ips_online", 1);
 
-   if ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1) {
-      memset(&ha->adapt->logical_drive_info, 0, sizeof(ha->adapt->logical_drive_info));
+	if (scb->target_id >= IPS_MAX_LD)
+		return (0);
 
-      return (0);
-   }
-
-   if (ha->adapt->logical_drive_info.drive_info[scb->target_id].state != IPS_LD_OFFLINE &&
-       ha->adapt->logical_drive_info.drive_info[scb->target_id].state != IPS_LD_FREE &&
-       ha->adapt->logical_drive_info.drive_info[scb->target_id].state != IPS_LD_CRS &&
-       ha->adapt->logical_drive_info.drive_info[scb->target_id].state != IPS_LD_SYS)
-      return (1);
-   else
-      return (0);
+	if ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1) {
+		memset(&ha->adapt->logical_drive_info, 0,
+		       sizeof (ha->adapt->logical_drive_info));
+
+		return (0);
+	}
+
+	if (ha->adapt->logical_drive_info.drive_info[scb->target_id].state !=
+	    IPS_LD_OFFLINE
+	    && ha->adapt->logical_drive_info.drive_info[scb->target_id].state !=
+	    IPS_LD_FREE
+	    && ha->adapt->logical_drive_info.drive_info[scb->target_id].state !=
+	    IPS_LD_CRS
+	    && ha->adapt->logical_drive_info.drive_info[scb->target_id].state !=
+	    IPS_LD_SYS) return (1);
+	else
+		return (0);
 }
 
 /****************************************************************************/
@@ -4845,27 +4303,29 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_inquiry(ips_ha_t *ha, ips_scb_t *scb) {
-   IPS_SCSI_INQ_DATA inquiry;
+ips_inquiry(ips_ha_t * ha, ips_scb_t * scb)
+{
+	IPS_SCSI_INQ_DATA inquiry;
 
-   METHOD_TRACE("ips_inquiry", 1);
+	METHOD_TRACE("ips_inquiry", 1);
 
-   memset(&inquiry, 0, sizeof(IPS_SCSI_INQ_DATA));
+	memset(&inquiry, 0, sizeof (IPS_SCSI_INQ_DATA));
 
-   inquiry.DeviceType = IPS_SCSI_INQ_TYPE_DASD;
-   inquiry.DeviceTypeQualifier = IPS_SCSI_INQ_LU_CONNECTED;
-   inquiry.Version = IPS_SCSI_INQ_REV2;
-   inquiry.ResponseDataFormat = IPS_SCSI_INQ_RD_REV2;
-   inquiry.AdditionalLength = 31;
-   inquiry.Flags[0] = IPS_SCSI_INQ_Address16;
-   inquiry.Flags[1] = IPS_SCSI_INQ_WBus16 | IPS_SCSI_INQ_Sync;
-   strncpy(inquiry.VendorId, "IBM     ", 8);
-   strncpy(inquiry.ProductId, "SERVERAID       ", 16);
-   strncpy(inquiry.ProductRevisionLevel, "1.00", 4);
+	inquiry.DeviceType = IPS_SCSI_INQ_TYPE_DASD;
+	inquiry.DeviceTypeQualifier = IPS_SCSI_INQ_LU_CONNECTED;
+	inquiry.Version = IPS_SCSI_INQ_REV2;
+	inquiry.ResponseDataFormat = IPS_SCSI_INQ_RD_REV2;
+	inquiry.AdditionalLength = 31;
+	inquiry.Flags[0] = IPS_SCSI_INQ_Address16;
+	inquiry.Flags[1] =
+	    IPS_SCSI_INQ_WBus16 | IPS_SCSI_INQ_Sync | IPS_SCSI_INQ_CmdQue;
+	strncpy(inquiry.VendorId, "IBM     ", 8);
+	strncpy(inquiry.ProductId, "SERVERAID       ", 16);
+	strncpy(inquiry.ProductRevisionLevel, "1.00", 4);
 
-   memcpy(scb->scsi_cmd->request_buffer, &inquiry, scb->scsi_cmd->request_bufflen);
+	ips_scmd_buf_write(scb->scsi_cmd, &inquiry, sizeof (inquiry));
 
-   return (1);
+	return (1);
 }
 
 /****************************************************************************/
@@ -4878,20 +4338,24 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_rdcap(ips_ha_t *ha, ips_scb_t *scb) {
-   IPS_SCSI_CAPACITY *cap;
+ips_rdcap(ips_ha_t * ha, ips_scb_t * scb)
+{
+	IPS_SCSI_CAPACITY cap;
 
-   METHOD_TRACE("ips_rdcap", 1);
+	METHOD_TRACE("ips_rdcap", 1);
 
-   if (scb->scsi_cmd->bufflen < 8)
-      return (0);
+	if (scb->scsi_cmd->bufflen < 8)
+		return (0);
 
-   cap = (IPS_SCSI_CAPACITY *) scb->scsi_cmd->request_buffer;
+	cap.lba =
+	    cpu_to_be32(le32_to_cpu
+			(ha->adapt->logical_drive_info.
+			 drive_info[scb->target_id].sector_count) - 1);
+	cap.len = cpu_to_be32((uint32_t) IPS_BLKSIZE);
 
-   cap->lba = cpu_to_be32(le32_to_cpu(ha->adapt->logical_drive_info.drive_info[scb->target_id].sector_count) - 1);
-   cap->len = cpu_to_be32((uint32_t) IPS_BLKSIZE);
+	ips_scmd_buf_write(scb->scsi_cmd, &cap, sizeof (cap));
 
-   return (1);
+	return (1);
 }
 
 /****************************************************************************/
@@ -4904,72 +4368,78 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_msense(ips_ha_t *ha, ips_scb_t *scb) {
-   uint16_t               heads;
-   uint16_t               sectors;
-   uint32_t               cylinders;
-   IPS_SCSI_MODE_PAGE_DATA mdata;
-
-   METHOD_TRACE("ips_msense", 1);
-
-   if (le32_to_cpu(ha->enq->ulDriveSize[scb->target_id]) > 0x400000 &&
-       (ha->enq->ucMiscFlag & 0x8) == 0) {
-      heads = IPS_NORM_HEADS;
-      sectors = IPS_NORM_SECTORS;
-   } else {
-      heads = IPS_COMP_HEADS;
-      sectors = IPS_COMP_SECTORS;
-   }
-
-   cylinders = (le32_to_cpu(ha->enq->ulDriveSize[scb->target_id]) - 1) / (heads * sectors);
-
-   memset(&mdata, 0, sizeof(IPS_SCSI_MODE_PAGE_DATA));
-
-   mdata.hdr.BlockDescLength = 8;
-
-   switch (scb->scsi_cmd->cmnd[2] & 0x3f) {
-   case 0x03: /* page 3 */
-      mdata.pdata.pg3.PageCode = 3;
-      mdata.pdata.pg3.PageLength = sizeof(IPS_SCSI_MODE_PAGE3);
-      mdata.hdr.DataLength = 3 + mdata.hdr.BlockDescLength + mdata.pdata.pg3.PageLength;
-      mdata.pdata.pg3.TracksPerZone = 0;
-      mdata.pdata.pg3.AltSectorsPerZone = 0;
-      mdata.pdata.pg3.AltTracksPerZone = 0;
-      mdata.pdata.pg3.AltTracksPerVolume = 0;
-      mdata.pdata.pg3.SectorsPerTrack = cpu_to_be16(sectors);
-      mdata.pdata.pg3.BytesPerSector = cpu_to_be16(IPS_BLKSIZE);
-      mdata.pdata.pg3.Interleave = cpu_to_be16(1);
-      mdata.pdata.pg3.TrackSkew = 0;
-      mdata.pdata.pg3.CylinderSkew = 0;
-      mdata.pdata.pg3.flags = IPS_SCSI_MP3_SoftSector;
-      break;
-
-   case 0x4:
-      mdata.pdata.pg4.PageCode = 4;
-      mdata.pdata.pg4.PageLength = sizeof(IPS_SCSI_MODE_PAGE4);
-      mdata.hdr.DataLength = 3 + mdata.hdr.BlockDescLength + mdata.pdata.pg4.PageLength;
-      mdata.pdata.pg4.CylindersHigh = cpu_to_be16((cylinders >> 8) & 0xFFFF);
-      mdata.pdata.pg4.CylindersLow = (cylinders & 0xFF);
-      mdata.pdata.pg4.Heads = heads;
-      mdata.pdata.pg4.WritePrecompHigh = 0;
-      mdata.pdata.pg4.WritePrecompLow = 0;
-      mdata.pdata.pg4.ReducedWriteCurrentHigh = 0;
-      mdata.pdata.pg4.ReducedWriteCurrentLow = 0;
-      mdata.pdata.pg4.StepRate = cpu_to_be16(1);
-      mdata.pdata.pg4.LandingZoneHigh = 0;
-      mdata.pdata.pg4.LandingZoneLow = 0;
-      mdata.pdata.pg4.flags = 0;
-      mdata.pdata.pg4.RotationalOffset = 0;
-      mdata.pdata.pg4.MediumRotationRate = 0;
-      break;
-
-   default:
-      return (0);
-   } /* end switch */
+ips_msense(ips_ha_t * ha, ips_scb_t * scb)
+{
+	uint16_t heads;
+	uint16_t sectors;
+	uint32_t cylinders;
+	IPS_SCSI_MODE_PAGE_DATA mdata;
+
+	METHOD_TRACE("ips_msense", 1);
+
+	if (le32_to_cpu(ha->enq->ulDriveSize[scb->target_id]) > 0x400000 &&
+	    (ha->enq->ucMiscFlag & 0x8) == 0) {
+		heads = IPS_NORM_HEADS;
+		sectors = IPS_NORM_SECTORS;
+	} else {
+		heads = IPS_COMP_HEADS;
+		sectors = IPS_COMP_SECTORS;
+	}
+
+	cylinders =
+	    (le32_to_cpu(ha->enq->ulDriveSize[scb->target_id]) -
+	     1) / (heads * sectors);
+
+	memset(&mdata, 0, sizeof (IPS_SCSI_MODE_PAGE_DATA));
+
+	mdata.hdr.BlockDescLength = 8;
+
+	switch (scb->scsi_cmd->cmnd[2] & 0x3f) {
+	case 0x03:		/* page 3 */
+		mdata.pdata.pg3.PageCode = 3;
+		mdata.pdata.pg3.PageLength = sizeof (IPS_SCSI_MODE_PAGE3);
+		mdata.hdr.DataLength =
+		    3 + mdata.hdr.BlockDescLength + mdata.pdata.pg3.PageLength;
+		mdata.pdata.pg3.TracksPerZone = 0;
+		mdata.pdata.pg3.AltSectorsPerZone = 0;
+		mdata.pdata.pg3.AltTracksPerZone = 0;
+		mdata.pdata.pg3.AltTracksPerVolume = 0;
+		mdata.pdata.pg3.SectorsPerTrack = cpu_to_be16(sectors);
+		mdata.pdata.pg3.BytesPerSector = cpu_to_be16(IPS_BLKSIZE);
+		mdata.pdata.pg3.Interleave = cpu_to_be16(1);
+		mdata.pdata.pg3.TrackSkew = 0;
+		mdata.pdata.pg3.CylinderSkew = 0;
+		mdata.pdata.pg3.flags = IPS_SCSI_MP3_SoftSector;
+		break;
+
+	case 0x4:
+		mdata.pdata.pg4.PageCode = 4;
+		mdata.pdata.pg4.PageLength = sizeof (IPS_SCSI_MODE_PAGE4);
+		mdata.hdr.DataLength =
+		    3 + mdata.hdr.BlockDescLength + mdata.pdata.pg4.PageLength;
+		mdata.pdata.pg4.CylindersHigh =
+		    cpu_to_be16((cylinders >> 8) & 0xFFFF);
+		mdata.pdata.pg4.CylindersLow = (cylinders & 0xFF);
+		mdata.pdata.pg4.Heads = heads;
+		mdata.pdata.pg4.WritePrecompHigh = 0;
+		mdata.pdata.pg4.WritePrecompLow = 0;
+		mdata.pdata.pg4.ReducedWriteCurrentHigh = 0;
+		mdata.pdata.pg4.ReducedWriteCurrentLow = 0;
+		mdata.pdata.pg4.StepRate = cpu_to_be16(1);
+		mdata.pdata.pg4.LandingZoneHigh = 0;
+		mdata.pdata.pg4.LandingZoneLow = 0;
+		mdata.pdata.pg4.flags = 0;
+		mdata.pdata.pg4.RotationalOffset = 0;
+		mdata.pdata.pg4.MediumRotationRate = 0;
+		break;
+
+	default:
+		return (0);
+	}			/* end switch */
 
-   memcpy(scb->scsi_cmd->request_buffer, &mdata, scb->scsi_cmd->request_bufflen);
+	ips_scmd_buf_write(scb->scsi_cmd, &mdata, sizeof (mdata));
 
-   return (1);
+	return (1);
 }
 
 /****************************************************************************/
@@ -4982,21 +4452,23 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_reqsen(ips_ha_t *ha, ips_scb_t *scb) {
-   IPS_SCSI_REQSEN reqsen;
+ips_reqsen(ips_ha_t * ha, ips_scb_t * scb)
+{
+	IPS_SCSI_REQSEN reqsen;
 
-   METHOD_TRACE("ips_reqsen", 1);
+	METHOD_TRACE("ips_reqsen", 1);
 
-   memset(&reqsen, 0, sizeof(IPS_SCSI_REQSEN));
+	memset(&reqsen, 0, sizeof (IPS_SCSI_REQSEN));
 
-   reqsen.ResponseCode = IPS_SCSI_REQSEN_VALID | IPS_SCSI_REQSEN_CURRENT_ERR;
-   reqsen.AdditionalLength = 10;
-   reqsen.AdditionalSenseCode = IPS_SCSI_REQSEN_NO_SENSE;
-   reqsen.AdditionalSenseCodeQual = IPS_SCSI_REQSEN_NO_SENSE;
+	reqsen.ResponseCode =
+	    IPS_SCSI_REQSEN_VALID | IPS_SCSI_REQSEN_CURRENT_ERR;
+	reqsen.AdditionalLength = 10;
+	reqsen.AdditionalSenseCode = IPS_SCSI_REQSEN_NO_SENSE;
+	reqsen.AdditionalSenseCodeQual = IPS_SCSI_REQSEN_NO_SENSE;
 
-   memcpy(scb->scsi_cmd->request_buffer, &reqsen, scb->scsi_cmd->request_bufflen);
+	ips_scmd_buf_write(scb->scsi_cmd, &reqsen, sizeof (reqsen));
 
-   return (1);
+	return (1);
 }
 
 /****************************************************************************/
@@ -5009,60 +4481,63 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_free(ips_ha_t *ha) {
+ips_free(ips_ha_t * ha)
+{
 
-   METHOD_TRACE("ips_free", 1);
+	METHOD_TRACE("ips_free", 1);
 
-   if (ha) {
-      if (ha->enq) {
-         kfree(ha->enq);
-         ha->enq = NULL;
-      }
-
-      if (ha->conf) {
-         kfree(ha->conf);
-         ha->conf = NULL;
-      }
-
-      if (ha->adapt) {
-         pci_free_consistent(ha->pcidev,sizeof(IPS_ADAPTER)+ sizeof(IPS_IO_CMD),
-                             ha->adapt, ha->adapt->hw_status_start);
-         ha->adapt = NULL;
-      }
-
-      if (ha->nvram) {
-         kfree(ha->nvram);
-         ha->nvram = NULL;
-      }
-
-      if (ha->subsys) {
-         kfree(ha->subsys);
-         ha->subsys = NULL;
-      }
-
-      if (ha->ioctl_data) {
-         free_pages((unsigned long) ha->ioctl_data, ha->ioctl_order);
-         ha->ioctl_data = NULL;
-         ha->ioctl_datasize = 0;
-         ha->ioctl_order = 0;
-      }
-      ips_deallocatescbs(ha, ha->max_cmds);
-
-      /* free memory mapped (if applicable) */
-      if (ha->mem_ptr) {
-         iounmap(ha->ioremap_ptr);
-         ha->ioremap_ptr = NULL;
-         ha->mem_ptr = NULL;
-      }
-
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
-      if (ha->mem_addr) 
-          release_mem_region(ha->mem_addr, ha->mem_len);
-#endif
-      ha->mem_addr = 0;
+	if (ha) {
+		if (ha->enq) {
+			kfree(ha->enq);
+			ha->enq = NULL;
+		}
+
+		if (ha->conf) {
+			kfree(ha->conf);
+			ha->conf = NULL;
+		}
+
+		if (ha->adapt) {
+			pci_free_consistent(ha->pcidev,
+					    sizeof (IPS_ADAPTER) +
+					    sizeof (IPS_IO_CMD), ha->adapt,
+					    ha->adapt->hw_status_start);
+			ha->adapt = NULL;
+		}
+
+		if (ha->nvram) {
+			kfree(ha->nvram);
+			ha->nvram = NULL;
+		}
+
+		if (ha->subsys) {
+			kfree(ha->subsys);
+			ha->subsys = NULL;
+		}
+
+		if (ha->ioctl_data) {
+			free_pages((unsigned long) ha->ioctl_data,
+				   ha->ioctl_order);
+			ha->ioctl_data = NULL;
+			ha->ioctl_datasize = 0;
+			ha->ioctl_order = 0;
+		}
+		ips_deallocatescbs(ha, ha->max_cmds);
+
+		/* free memory mapped (if applicable) */
+		if (ha->mem_ptr) {
+			iounmap(ha->ioremap_ptr);
+			ha->ioremap_ptr = NULL;
+			ha->mem_ptr = NULL;
+		}
+
+		if (ha->mem_addr)
+			release_mem_region(ha->mem_addr, ha->mem_len);
+		ha->mem_addr = 0;
 
-   }
+	}
 }
+
 /****************************************************************************/
 /*                                                                          */
 /* Routine Name: ips_deallocatescbs                                         */
@@ -5073,15 +4548,18 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_deallocatescbs(ips_ha_t *ha, int cmds) {
-   if (ha->scbs) {
-      pci_free_consistent(ha->pcidev,sizeof(IPS_SG_LIST) * IPS_MAX_SG *
-                          cmds, ha->scbs->sg_list, ha->scbs->sg_busaddr);
-      pci_free_consistent(ha->pcidev, sizeof(ips_scb_t) * cmds,
-                          ha->scbs, ha->scbs->scb_busaddr);
-      ha->scbs = NULL;
-   } /* end if */
-return 1;
+ips_deallocatescbs(ips_ha_t * ha, int cmds)
+{
+	if (ha->scbs) {
+		pci_free_consistent(ha->pcidev,
+				    IPS_SGLIST_SIZE(ha) * IPS_MAX_SG * cmds,
+				    ha->scbs->sg_list.list,
+				    ha->scbs->sg_busaddr);
+		pci_free_consistent(ha->pcidev, sizeof (ips_scb_t) * cmds,
+				    ha->scbs, ha->scbs->scb_busaddr);
+		ha->scbs = NULL;
+	}			/* end if */
+	return 1;
 }
 
 /****************************************************************************/
@@ -5094,44 +4572,59 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_allocatescbs(ips_ha_t *ha) {
-   ips_scb_t *scb_p;
-   IPS_SG_LIST* ips_sg;
-   int        i;
-   dma_addr_t command_dma, sg_dma;
-   
-   METHOD_TRACE("ips_allocatescbs", 1);
-
-   /* Allocate memory for the SCBs */
-   ha->scbs = pci_alloc_consistent(ha->pcidev, ha->max_cmds * sizeof(ips_scb_t),
-	                           &command_dma);
-   if (ha->scbs == NULL)
-      return 0;
-   ips_sg = pci_alloc_consistent(ha->pcidev, sizeof(IPS_SG_LIST) * IPS_MAX_SG * 
-	                         ha->max_cmds, &sg_dma);
-   if(ips_sg == NULL){
-      pci_free_consistent(ha->pcidev,ha->max_cmds * sizeof(ips_scb_t),ha->scbs, command_dma);
-      return 0;
-   }
-
-   memset(ha->scbs, 0, ha->max_cmds * sizeof(ips_scb_t));
-
-   for (i = 0; i < ha->max_cmds; i++) {
-      scb_p = &ha->scbs[i];
-      scb_p->scb_busaddr = command_dma + sizeof(ips_scb_t) * i;
-      /* set up S/G list */
-      scb_p->sg_list = ips_sg + i * IPS_MAX_SG;
-      scb_p->sg_busaddr = sg_dma + sizeof(IPS_SG_LIST) * IPS_MAX_SG * i;
-
-      /* add to the free list */
-      if (i < ha->max_cmds - 1) {
-         scb_p->q_next = ha->scb_freelist;
-         ha->scb_freelist = scb_p;
-      }
-   }
+ips_allocatescbs(ips_ha_t * ha)
+{
+	ips_scb_t *scb_p;
+	IPS_SG_LIST ips_sg;
+	int i;
+	dma_addr_t command_dma, sg_dma;
+
+	METHOD_TRACE("ips_allocatescbs", 1);
+
+	/* Allocate memory for the SCBs */
+	ha->scbs =
+	    pci_alloc_consistent(ha->pcidev, ha->max_cmds * sizeof (ips_scb_t),
+				 &command_dma);
+	if (ha->scbs == NULL)
+		return 0;
+	ips_sg.list =
+	    pci_alloc_consistent(ha->pcidev,
+				 IPS_SGLIST_SIZE(ha) * IPS_MAX_SG *
+				 ha->max_cmds, &sg_dma);
+	if (ips_sg.list == NULL) {
+		pci_free_consistent(ha->pcidev,
+				    ha->max_cmds * sizeof (ips_scb_t), ha->scbs,
+				    command_dma);
+		return 0;
+	}
+
+	memset(ha->scbs, 0, ha->max_cmds * sizeof (ips_scb_t));
+
+	for (i = 0; i < ha->max_cmds; i++) {
+		scb_p = &ha->scbs[i];
+		scb_p->scb_busaddr = command_dma + sizeof (ips_scb_t) * i;
+		/* set up S/G list */
+		if (IPS_USE_ENH_SGLIST(ha)) {
+			scb_p->sg_list.enh_list =
+			    ips_sg.enh_list + i * IPS_MAX_SG;
+			scb_p->sg_busaddr =
+			    sg_dma + IPS_SGLIST_SIZE(ha) * IPS_MAX_SG * i;
+		} else {
+			scb_p->sg_list.std_list =
+			    ips_sg.std_list + i * IPS_MAX_SG;
+			scb_p->sg_busaddr =
+			    sg_dma + IPS_SGLIST_SIZE(ha) * IPS_MAX_SG * i;
+		}
+
+		/* add to the free list */
+		if (i < ha->max_cmds - 1) {
+			scb_p->q_next = ha->scb_freelist;
+			ha->scb_freelist = scb_p;
+		}
+	}
 
-   /* success */
-   return (1);
+	/* success */
+	return (1);
 }
 
 /****************************************************************************/
@@ -5144,36 +4637,37 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_init_scb(ips_ha_t *ha, ips_scb_t *scb) {
-   IPS_SG_LIST *sg_list;
-   uint32_t cmd_busaddr, sg_busaddr;
-   METHOD_TRACE("ips_init_scb", 1);
-
-   if (scb == NULL)
-      return ;
-
-   sg_list = scb->sg_list;
-   cmd_busaddr = scb->scb_busaddr;
-   sg_busaddr = scb->sg_busaddr;
-   /* zero fill */
-   memset(scb, 0, sizeof(ips_scb_t));
-   memset(ha->dummy, 0, sizeof(IPS_IO_CMD));
-
-   /* Initialize dummy command bucket */
-   ha->dummy->op_code = 0xFF;
-   ha->dummy->ccsar = cpu_to_le32(ha->adapt->hw_status_start
-                                      + sizeof(IPS_ADAPTER));
-   ha->dummy->command_id = IPS_MAX_CMDS;
-
-   /* set bus address of scb */
-   scb->scb_busaddr = cmd_busaddr;
-   scb->sg_busaddr = sg_busaddr;
-   scb->sg_list = sg_list;
-
-   /* Neptune Fix */
-   scb->cmd.basic_io.cccr = cpu_to_le32((uint32_t) IPS_BIT_ILE);
-   scb->cmd.basic_io.ccsar = cpu_to_le32(ha->adapt->hw_status_start
-                                           + sizeof(IPS_ADAPTER));
+ips_init_scb(ips_ha_t * ha, ips_scb_t * scb)
+{
+	IPS_SG_LIST sg_list;
+	uint32_t cmd_busaddr, sg_busaddr;
+	METHOD_TRACE("ips_init_scb", 1);
+
+	if (scb == NULL)
+		return;
+
+	sg_list.list = scb->sg_list.list;
+	cmd_busaddr = scb->scb_busaddr;
+	sg_busaddr = scb->sg_busaddr;
+	/* zero fill */
+	memset(scb, 0, sizeof (ips_scb_t));
+	memset(ha->dummy, 0, sizeof (IPS_IO_CMD));
+
+	/* Initialize dummy command bucket */
+	ha->dummy->op_code = 0xFF;
+	ha->dummy->ccsar = cpu_to_le32(ha->adapt->hw_status_start
+				       + sizeof (IPS_ADAPTER));
+	ha->dummy->command_id = IPS_MAX_CMDS;
+
+	/* set bus address of scb */
+	scb->scb_busaddr = cmd_busaddr;
+	scb->sg_busaddr = sg_busaddr;
+	scb->sg_list.list = sg_list.list;
+
+	/* Neptune Fix */
+	scb->cmd.basic_io.cccr = cpu_to_le32((uint32_t) IPS_BIT_ILE);
+	scb->cmd.basic_io.ccsar = cpu_to_le32(ha->adapt->hw_status_start
+					      + sizeof (IPS_ADAPTER));
 }
 
 /****************************************************************************/
@@ -5188,22 +4682,23 @@
 /*                                                                          */
 /****************************************************************************/
 static ips_scb_t *
-ips_getscb(ips_ha_t *ha) {
-   ips_scb_t     *scb;
+ips_getscb(ips_ha_t * ha)
+{
+	ips_scb_t *scb;
 
-   METHOD_TRACE("ips_getscb", 1);
+	METHOD_TRACE("ips_getscb", 1);
 
-   if ((scb = ha->scb_freelist) == NULL) {
+	if ((scb = ha->scb_freelist) == NULL) {
 
-      return (NULL);
-   }
+		return (NULL);
+	}
 
-   ha->scb_freelist = scb->q_next;
-   scb->q_next = NULL;
+	ha->scb_freelist = scb->q_next;
+	scb->q_next = NULL;
 
-   ips_init_scb(ha, scb);
+	ips_init_scb(ha, scb);
 
-   return (scb);
+	return (scb);
 }
 
 /****************************************************************************/
@@ -5218,22 +4713,22 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_freescb(ips_ha_t *ha, ips_scb_t *scb) {
+ips_freescb(ips_ha_t * ha, ips_scb_t * scb)
+{
 
-   METHOD_TRACE("ips_freescb", 1);
-   if(scb->flags & IPS_SCB_MAP_SG)
-      pci_unmap_sg(ha->pcidev, scb->scsi_cmd->request_buffer,
-                   scb->scsi_cmd->use_sg,
-                   IPS_DMA_DIR(scb));
-   else if(scb->flags & IPS_SCB_MAP_SINGLE)
-      pci_unmap_single(ha->pcidev, scb->data_busaddr, scb->data_len,
-                       IPS_DMA_DIR(scb));
-
-   /* check to make sure this is not our "special" scb */
-   if (IPS_COMMAND_ID(ha, scb) < (ha->max_cmds - 1)) {
-      scb->q_next = ha->scb_freelist;
-      ha->scb_freelist = scb;
-   }
+	METHOD_TRACE("ips_freescb", 1);
+	if (scb->flags & IPS_SCB_MAP_SG)
+		pci_unmap_sg(ha->pcidev, scb->scsi_cmd->request_buffer,
+			     scb->scsi_cmd->use_sg, IPS_DMA_DIR(scb));
+	else if (scb->flags & IPS_SCB_MAP_SINGLE)
+		pci_unmap_single(ha->pcidev, scb->data_busaddr, scb->data_len,
+				 IPS_DMA_DIR(scb));
+
+	/* check to make sure this is not our "special" scb */
+	if (IPS_COMMAND_ID(ha, scb) < (ha->max_cmds - 1)) {
+		scb->q_next = ha->scb_freelist;
+		ha->scb_freelist = scb;
+	}
 }
 
 /****************************************************************************/
@@ -5246,19 +4741,20 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_isinit_copperhead(ips_ha_t *ha) {
-   uint8_t scpr;
-   uint8_t isr;
-
-   METHOD_TRACE("ips_isinit_copperhead", 1);
-
-   isr = inb(ha->io_addr + IPS_REG_HISR);
-   scpr = inb(ha->io_addr + IPS_REG_SCPR);
-
-   if (((isr & IPS_BIT_EI) == 0) && ((scpr & IPS_BIT_EBM) == 0))
-       return (0);
-   else
-       return (1);
+ips_isinit_copperhead(ips_ha_t * ha)
+{
+	uint8_t scpr;
+	uint8_t isr;
+
+	METHOD_TRACE("ips_isinit_copperhead", 1);
+
+	isr = inb(ha->io_addr + IPS_REG_HISR);
+	scpr = inb(ha->io_addr + IPS_REG_SCPR);
+
+	if (((isr & IPS_BIT_EI) == 0) && ((scpr & IPS_BIT_EBM) == 0))
+		return (0);
+	else
+		return (1);
 }
 
 /****************************************************************************/
@@ -5271,19 +4767,20 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_isinit_copperhead_memio(ips_ha_t *ha) {
-   uint8_t isr=0;
-   uint8_t scpr;
-
-   METHOD_TRACE("ips_is_init_copperhead_memio", 1);
-
-   isr = readb(ha->mem_ptr + IPS_REG_HISR);
-   scpr = readb(ha->mem_ptr + IPS_REG_SCPR);
-
-   if (((isr & IPS_BIT_EI) == 0) && ((scpr & IPS_BIT_EBM) == 0))
-       return (0);
-   else
-       return (1);
+ips_isinit_copperhead_memio(ips_ha_t * ha)
+{
+	uint8_t isr = 0;
+	uint8_t scpr;
+
+	METHOD_TRACE("ips_is_init_copperhead_memio", 1);
+
+	isr = readb(ha->mem_ptr + IPS_REG_HISR);
+	scpr = readb(ha->mem_ptr + IPS_REG_SCPR);
+
+	if (((isr & IPS_BIT_EI) == 0) && ((scpr & IPS_BIT_EBM) == 0))
+		return (0);
+	else
+		return (1);
 }
 
 /****************************************************************************/
@@ -5296,21 +4793,22 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_isinit_morpheus(ips_ha_t *ha) {
-   uint32_t post;
-   uint32_t bits;
-
-   METHOD_TRACE("ips_is_init_morpheus", 1);
-
-   post = readl(ha->mem_ptr + IPS_REG_I960_MSG0);
-   bits = readl(ha->mem_ptr + IPS_REG_I2O_HIR);
-
-   if (post == 0)
-       return (0);
-   else if (bits & 0x3)
-       return (0);
-   else
-       return (1);
+ips_isinit_morpheus(ips_ha_t * ha)
+{
+	uint32_t post;
+	uint32_t bits;
+
+	METHOD_TRACE("ips_is_init_morpheus", 1);
+
+	post = readl(ha->mem_ptr + IPS_REG_I960_MSG0);
+	bits = readl(ha->mem_ptr + IPS_REG_I2O_HIR);
+
+	if (post == 0)
+		return (0);
+	else if (bits & 0x3)
+		return (0);
+	else
+		return (1);
 }
 
 /****************************************************************************/
@@ -5322,10 +4820,12 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_enable_int_copperhead(ips_ha_t *ha) {
-   METHOD_TRACE("ips_enable_int_copperhead", 1);
+ips_enable_int_copperhead(ips_ha_t * ha)
+{
+	METHOD_TRACE("ips_enable_int_copperhead", 1);
 
-   outb(ha->io_addr + IPS_REG_HISR, IPS_BIT_EI);
+	outb(ha->io_addr + IPS_REG_HISR, IPS_BIT_EI);
+	inb(ha->io_addr + IPS_REG_HISR);	// Ensure PCI Posting Completes
 }
 
 /****************************************************************************/
@@ -5337,10 +4837,12 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_enable_int_copperhead_memio(ips_ha_t *ha) {
-   METHOD_TRACE("ips_enable_int_copperhead_memio", 1);
+ips_enable_int_copperhead_memio(ips_ha_t * ha)
+{
+	METHOD_TRACE("ips_enable_int_copperhead_memio", 1);
 
-   writeb(IPS_BIT_EI, ha->mem_ptr + IPS_REG_HISR);
+	writeb(IPS_BIT_EI, ha->mem_ptr + IPS_REG_HISR);
+	readb(ha->mem_ptr + IPS_REG_HISR);	// Ensure PCI Posting Completes
 }
 
 /****************************************************************************/
@@ -5352,14 +4854,16 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_enable_int_morpheus(ips_ha_t *ha) {
-   uint32_t  Oimr;
+ips_enable_int_morpheus(ips_ha_t * ha)
+{
+	uint32_t Oimr;
 
-   METHOD_TRACE("ips_enable_int_morpheus", 1);
+	METHOD_TRACE("ips_enable_int_morpheus", 1);
 
-   Oimr = readl(ha->mem_ptr + IPS_REG_I960_OIMR);
-   Oimr &= ~0x08;
-   writel(Oimr, ha->mem_ptr + IPS_REG_I960_OIMR);
+	Oimr = readl(ha->mem_ptr + IPS_REG_I960_OIMR);
+	Oimr &= ~0x08;
+	writel(Oimr, ha->mem_ptr + IPS_REG_I960_OIMR);
+	readl(ha->mem_ptr + IPS_REG_I960_OIMR);	// Ensure PCI Posting Completes
 }
 
 /****************************************************************************/
@@ -5372,86 +4876,88 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_init_copperhead(ips_ha_t *ha) {
-   uint8_t  Isr;
-   uint8_t  Cbsp;
-   uint8_t  PostByte[IPS_MAX_POST_BYTES];
-   uint8_t  ConfigByte[IPS_MAX_CONFIG_BYTES];
-   int      i, j;
-
-   METHOD_TRACE("ips_init_copperhead", 1);
-
-   for (i = 0; i < IPS_MAX_POST_BYTES; i++) {
-      for (j = 0; j < 45; j++) {
-         Isr = inb(ha->io_addr + IPS_REG_HISR);
-         if (Isr & IPS_BIT_GHI)
-            break;
-
-         /* Delay for 1 Second */
-         MDELAY(IPS_ONE_SEC);
-       }
-
-      if (j >= 45)
-         /* error occurred */
-         return (0);
-
-      PostByte[i] = inb(ha->io_addr + IPS_REG_ISPR);
-      outb(Isr, ha->io_addr + IPS_REG_HISR);
-   }
-
-   if (PostByte[0] < IPS_GOOD_POST_STATUS) {
-      printk(KERN_WARNING "(%s%d) reset controller fails (post status %x %x).\n",
-             ips_name, ha->host_num, PostByte[0], PostByte[1]);
-
-      return (0);
-   }
-
-   for (i = 0; i < IPS_MAX_CONFIG_BYTES; i++) {
-      for (j = 0; j < 240; j++) {
-         Isr = inb(ha->io_addr + IPS_REG_HISR);
-         if (Isr & IPS_BIT_GHI)
-            break;
-
-         /* Delay for 1 Second */
-         MDELAY(IPS_ONE_SEC);
-      }
-
-      if (j >= 240)
-         /* error occurred */
-         return (0);
-
-      ConfigByte[i] = inb(ha->io_addr + IPS_REG_ISPR);
-      outb(Isr, ha->io_addr + IPS_REG_HISR);
-   }
-
-   for (i = 0; i < 240; i++) {
-      Cbsp = inb(ha->io_addr + IPS_REG_CBSP);
-
-      if ((Cbsp & IPS_BIT_OP) == 0)
-         break; 
-
-      /* Delay for 1 Second */
-      MDELAY(IPS_ONE_SEC);
-   }
-
-   if (i >= 240)
-      /* reset failed */
-      return (0);
-
-   /* setup CCCR */
-   outl(cpu_to_le32(0x1010), ha->io_addr + IPS_REG_CCCR);
-
-   /* Enable busmastering */
-   outb(IPS_BIT_EBM, ha->io_addr + IPS_REG_SCPR);
-
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      /* fix for anaconda64 */
-      outl(0, ha->io_addr + IPS_REG_NDAE);
+ips_init_copperhead(ips_ha_t * ha)
+{
+	uint8_t Isr;
+	uint8_t Cbsp;
+	uint8_t PostByte[IPS_MAX_POST_BYTES];
+	uint8_t ConfigByte[IPS_MAX_CONFIG_BYTES];
+	int i, j;
+
+	METHOD_TRACE("ips_init_copperhead", 1);
+
+	for (i = 0; i < IPS_MAX_POST_BYTES; i++) {
+		for (j = 0; j < 45; j++) {
+			Isr = inb(ha->io_addr + IPS_REG_HISR);
+			if (Isr & IPS_BIT_GHI)
+				break;
+
+			/* Delay for 1 Second */
+			MDELAY(IPS_ONE_SEC);
+		}
+
+		if (j >= 45)
+			/* error occurred */
+			return (0);
+
+		PostByte[i] = inb(ha->io_addr + IPS_REG_ISPR);
+		outb(Isr, ha->io_addr + IPS_REG_HISR);
+	}
+
+	if (PostByte[0] < IPS_GOOD_POST_STATUS) {
+		printk(KERN_WARNING
+		       "(%s%d) reset controller fails (post status %x %x).\n",
+		       ips_name, ha->host_num, PostByte[0], PostByte[1]);
+
+		return (0);
+	}
+
+	for (i = 0; i < IPS_MAX_CONFIG_BYTES; i++) {
+		for (j = 0; j < 240; j++) {
+			Isr = inb(ha->io_addr + IPS_REG_HISR);
+			if (Isr & IPS_BIT_GHI)
+				break;
+
+			/* Delay for 1 Second */
+			MDELAY(IPS_ONE_SEC);
+		}
+
+		if (j >= 240)
+			/* error occurred */
+			return (0);
+
+		ConfigByte[i] = inb(ha->io_addr + IPS_REG_ISPR);
+		outb(Isr, ha->io_addr + IPS_REG_HISR);
+	}
+
+	for (i = 0; i < 240; i++) {
+		Cbsp = inb(ha->io_addr + IPS_REG_CBSP);
+
+		if ((Cbsp & IPS_BIT_OP) == 0)
+			break;
+
+		/* Delay for 1 Second */
+		MDELAY(IPS_ONE_SEC);
+	}
+
+	if (i >= 240)
+		/* reset failed */
+		return (0);
+
+	/* setup CCCR */
+	outl(cpu_to_le32(0x1010), ha->io_addr + IPS_REG_CCCR);
+
+	/* Enable busmastering */
+	outb(IPS_BIT_EBM, ha->io_addr + IPS_REG_SCPR);
+
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		/* fix for anaconda64 */
+		outl(0, ha->io_addr + IPS_REG_NDAE);
 
-   /* Enable interrupts */
-   outb(IPS_BIT_EI, ha->io_addr + IPS_REG_HISR);
+	/* Enable interrupts */
+	outb(IPS_BIT_EI, ha->io_addr + IPS_REG_HISR);
 
-   return (1);
+	return (1);
 }
 
 /****************************************************************************/
@@ -5464,87 +4970,89 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_init_copperhead_memio(ips_ha_t *ha) {
-   uint8_t  Isr=0;
-   uint8_t  Cbsp;
-   uint8_t  PostByte[IPS_MAX_POST_BYTES];
-   uint8_t  ConfigByte[IPS_MAX_CONFIG_BYTES];
-   int      i, j;
-
-   METHOD_TRACE("ips_init_copperhead_memio", 1);
-
-   for (i = 0; i < IPS_MAX_POST_BYTES; i++) {
-      for (j = 0; j < 45; j++) {
-         Isr = readb(ha->mem_ptr + IPS_REG_HISR);
-         if (Isr & IPS_BIT_GHI)
-            break;
-
-         /* Delay for 1 Second */
-         MDELAY(IPS_ONE_SEC);
-      }
-
-      if (j >= 45)
-         /* error occurred */
-         return (0);
-
-      PostByte[i] = readb(ha->mem_ptr + IPS_REG_ISPR);
-      writeb(Isr, ha->mem_ptr + IPS_REG_HISR);
-   }
-
-   if (PostByte[0] < IPS_GOOD_POST_STATUS) {
-      printk(KERN_WARNING "(%s%d) reset controller fails (post status %x %x).\n",
-             ips_name, ha->host_num, PostByte[0], PostByte[1]);
-
-      return (0);
-   }
-
-   for (i = 0; i < IPS_MAX_CONFIG_BYTES; i++) {
-      for (j = 0; j < 240; j++) {
-         Isr = readb(ha->mem_ptr + IPS_REG_HISR);
-         if (Isr & IPS_BIT_GHI)
-            break;
-
-         /* Delay for 1 Second */
-         MDELAY(IPS_ONE_SEC);
-      }
-
-      if (j >= 240)
-         /* error occurred */
-         return (0);
-
-      ConfigByte[i] = readb(ha->mem_ptr + IPS_REG_ISPR);
-      writeb(Isr, ha->mem_ptr + IPS_REG_HISR);
-   }
-
-   for (i = 0; i < 240; i++) {
-      Cbsp = readb(ha->mem_ptr + IPS_REG_CBSP);
-
-      if ((Cbsp & IPS_BIT_OP) == 0)
-         break;
-
-      /* Delay for 1 Second */
-      MDELAY(IPS_ONE_SEC);
-   }
-
-   if (i >= 240)
-      /* error occurred */
-      return (0);
-
-   /* setup CCCR */
-   writel(0x1010, ha->mem_ptr + IPS_REG_CCCR);
-
-   /* Enable busmastering */
-   writeb(IPS_BIT_EBM, ha->mem_ptr + IPS_REG_SCPR);
-
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      /* fix for anaconda64 */
-      writel(0, ha->mem_ptr + IPS_REG_NDAE);
+ips_init_copperhead_memio(ips_ha_t * ha)
+{
+	uint8_t Isr = 0;
+	uint8_t Cbsp;
+	uint8_t PostByte[IPS_MAX_POST_BYTES];
+	uint8_t ConfigByte[IPS_MAX_CONFIG_BYTES];
+	int i, j;
+
+	METHOD_TRACE("ips_init_copperhead_memio", 1);
+
+	for (i = 0; i < IPS_MAX_POST_BYTES; i++) {
+		for (j = 0; j < 45; j++) {
+			Isr = readb(ha->mem_ptr + IPS_REG_HISR);
+			if (Isr & IPS_BIT_GHI)
+				break;
+
+			/* Delay for 1 Second */
+			MDELAY(IPS_ONE_SEC);
+		}
+
+		if (j >= 45)
+			/* error occurred */
+			return (0);
+
+		PostByte[i] = readb(ha->mem_ptr + IPS_REG_ISPR);
+		writeb(Isr, ha->mem_ptr + IPS_REG_HISR);
+	}
+
+	if (PostByte[0] < IPS_GOOD_POST_STATUS) {
+		printk(KERN_WARNING
+		       "(%s%d) reset controller fails (post status %x %x).\n",
+		       ips_name, ha->host_num, PostByte[0], PostByte[1]);
+
+		return (0);
+	}
+
+	for (i = 0; i < IPS_MAX_CONFIG_BYTES; i++) {
+		for (j = 0; j < 240; j++) {
+			Isr = readb(ha->mem_ptr + IPS_REG_HISR);
+			if (Isr & IPS_BIT_GHI)
+				break;
+
+			/* Delay for 1 Second */
+			MDELAY(IPS_ONE_SEC);
+		}
+
+		if (j >= 240)
+			/* error occurred */
+			return (0);
+
+		ConfigByte[i] = readb(ha->mem_ptr + IPS_REG_ISPR);
+		writeb(Isr, ha->mem_ptr + IPS_REG_HISR);
+	}
+
+	for (i = 0; i < 240; i++) {
+		Cbsp = readb(ha->mem_ptr + IPS_REG_CBSP);
+
+		if ((Cbsp & IPS_BIT_OP) == 0)
+			break;
+
+		/* Delay for 1 Second */
+		MDELAY(IPS_ONE_SEC);
+	}
+
+	if (i >= 240)
+		/* error occurred */
+		return (0);
+
+	/* setup CCCR */
+	writel(0x1010, ha->mem_ptr + IPS_REG_CCCR);
+
+	/* Enable busmastering */
+	writeb(IPS_BIT_EBM, ha->mem_ptr + IPS_REG_SCPR);
+
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		/* fix for anaconda64 */
+		writel(0, ha->mem_ptr + IPS_REG_NDAE);
 
-   /* Enable interrupts */
-   writeb(IPS_BIT_EI, ha->mem_ptr + IPS_REG_HISR);
+	/* Enable interrupts */
+	writeb(IPS_BIT_EI, ha->mem_ptr + IPS_REG_HISR);
 
-   /* if we get here then everything went OK */
-   return (1);
+	/* if we get here then everything went OK */
+	return (1);
 }
 
 /****************************************************************************/
@@ -5557,109 +5065,112 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_init_morpheus(ips_ha_t *ha) {
-   uint32_t  Post;
-   uint32_t  Config;
-   uint32_t  Isr;
-   uint32_t  Oimr;
-   int       i;
-
-   METHOD_TRACE("ips_init_morpheus", 1);
-
-   /* Wait up to 45 secs for Post */
-   for (i = 0; i < 45; i++) {
-      Isr = readl(ha->mem_ptr + IPS_REG_I2O_HIR);
-
-      if (Isr & IPS_BIT_I960_MSG0I)
-         break;
-
-      /* Delay for 1 Second */
-      MDELAY(IPS_ONE_SEC);
-   }
-
-   if (i >= 45) {
-      /* error occurred */
-      printk(KERN_WARNING "(%s%d) timeout waiting for post.\n",
-             ips_name, ha->host_num);
-
-      return (0);
-   }
-
-   Post = readl(ha->mem_ptr + IPS_REG_I960_MSG0);
-
-   if (Post == 0x4F00) {                          /* If Flashing the Battery PIC         */
-       printk(KERN_WARNING "Flashing Battery PIC, Please wait ...\n" );
-
-       /* Clear the interrupt bit */
-       Isr = (uint32_t) IPS_BIT_I960_MSG0I;
-       writel(Isr, ha->mem_ptr + IPS_REG_I2O_HIR);
-
-       for (i = 0; i < 120; i++) {                /*    Wait Up to 2 Min. for Completion */
-          Post = readl(ha->mem_ptr + IPS_REG_I960_MSG0);
-          if (Post != 0x4F00)
-              break;
-          /* Delay for 1 Second */
-          MDELAY(IPS_ONE_SEC);
-       }
-
-       if (i >= 120) {
-          printk(KERN_WARNING "(%s%d) timeout waiting for Battery PIC Flash\n",
-                 ips_name, ha->host_num);
-          return (0);
-       }
-
-   }
-
-   /* Clear the interrupt bit */
-   Isr = (uint32_t) IPS_BIT_I960_MSG0I;
-   writel(Isr, ha->mem_ptr + IPS_REG_I2O_HIR);
-
-   if (Post < (IPS_GOOD_POST_STATUS << 8)) {
-      printk(KERN_WARNING "(%s%d) reset controller fails (post status %x).\n",
-             ips_name, ha->host_num, Post);
-
-      return (0);
-   }
-
-   /* Wait up to 240 secs for config bytes */
-   for (i = 0; i < 240; i++) {
-      Isr = readl(ha->mem_ptr + IPS_REG_I2O_HIR);
-
-      if (Isr & IPS_BIT_I960_MSG1I)
-         break;
-
-      /* Delay for 1 Second */
-      MDELAY(IPS_ONE_SEC);
-   }
-
-   if (i >= 240) {
-      /* error occurred */
-      printk(KERN_WARNING "(%s%d) timeout waiting for config.\n",
-             ips_name, ha->host_num);
-
-      return (0);
-   }
-
-   Config = readl(ha->mem_ptr + IPS_REG_I960_MSG1);
-
-   /* Clear interrupt bit */
-   Isr = (uint32_t) IPS_BIT_I960_MSG1I;
-   writel(Isr, ha->mem_ptr + IPS_REG_I2O_HIR);
-
-   /* Turn on the interrupts */
-   Oimr = readl(ha->mem_ptr + IPS_REG_I960_OIMR);
-   Oimr &= ~0x8;
-   writel(Oimr, ha->mem_ptr + IPS_REG_I960_OIMR);
-
-   /* if we get here then everything went OK */
-
-   /* Since we did a RESET, an EraseStripeLock may be needed */
-   if (Post == 0xEF10) {
-      if ( (Config == 0x000F) || (Config == 0x0009) )
-         ha->requires_esl = 1;
-   }
+ips_init_morpheus(ips_ha_t * ha)
+{
+	uint32_t Post;
+	uint32_t Config;
+	uint32_t Isr;
+	uint32_t Oimr;
+	int i;
+
+	METHOD_TRACE("ips_init_morpheus", 1);
+
+	/* Wait up to 45 secs for Post */
+	for (i = 0; i < 45; i++) {
+		Isr = readl(ha->mem_ptr + IPS_REG_I2O_HIR);
+
+		if (Isr & IPS_BIT_I960_MSG0I)
+			break;
+
+		/* Delay for 1 Second */
+		MDELAY(IPS_ONE_SEC);
+	}
+
+	if (i >= 45) {
+		/* error occurred */
+		printk(KERN_WARNING "(%s%d) timeout waiting for post.\n",
+		       ips_name, ha->host_num);
+
+		return (0);
+	}
+
+	Post = readl(ha->mem_ptr + IPS_REG_I960_MSG0);
+
+	if (Post == 0x4F00) {	/* If Flashing the Battery PIC         */
+		printk(KERN_WARNING "Flashing Battery PIC, Please wait ...\n");
+
+		/* Clear the interrupt bit */
+		Isr = (uint32_t) IPS_BIT_I960_MSG0I;
+		writel(Isr, ha->mem_ptr + IPS_REG_I2O_HIR);
+
+		for (i = 0; i < 120; i++) {	/*    Wait Up to 2 Min. for Completion */
+			Post = readl(ha->mem_ptr + IPS_REG_I960_MSG0);
+			if (Post != 0x4F00)
+				break;
+			/* Delay for 1 Second */
+			MDELAY(IPS_ONE_SEC);
+		}
+
+		if (i >= 120) {
+			printk(KERN_WARNING
+			       "(%s%d) timeout waiting for Battery PIC Flash\n",
+			       ips_name, ha->host_num);
+			return (0);
+		}
+
+	}
+
+	/* Clear the interrupt bit */
+	Isr = (uint32_t) IPS_BIT_I960_MSG0I;
+	writel(Isr, ha->mem_ptr + IPS_REG_I2O_HIR);
+
+	if (Post < (IPS_GOOD_POST_STATUS << 8)) {
+		printk(KERN_WARNING
+		       "(%s%d) reset controller fails (post status %x).\n",
+		       ips_name, ha->host_num, Post);
+
+		return (0);
+	}
+
+	/* Wait up to 240 secs for config bytes */
+	for (i = 0; i < 240; i++) {
+		Isr = readl(ha->mem_ptr + IPS_REG_I2O_HIR);
+
+		if (Isr & IPS_BIT_I960_MSG1I)
+			break;
+
+		/* Delay for 1 Second */
+		MDELAY(IPS_ONE_SEC);
+	}
+
+	if (i >= 240) {
+		/* error occurred */
+		printk(KERN_WARNING "(%s%d) timeout waiting for config.\n",
+		       ips_name, ha->host_num);
+
+		return (0);
+	}
+
+	Config = readl(ha->mem_ptr + IPS_REG_I960_MSG1);
+
+	/* Clear interrupt bit */
+	Isr = (uint32_t) IPS_BIT_I960_MSG1I;
+	writel(Isr, ha->mem_ptr + IPS_REG_I2O_HIR);
+
+	/* Turn on the interrupts */
+	Oimr = readl(ha->mem_ptr + IPS_REG_I960_OIMR);
+	Oimr &= ~0x8;
+	writel(Oimr, ha->mem_ptr + IPS_REG_I960_OIMR);
+
+	/* if we get here then everything went OK */
+
+	/* Since we did a RESET, an EraseStripeLock may be needed */
+	if (Post == 0xEF10) {
+		if ((Config == 0x000F) || (Config == 0x0009))
+			ha->requires_esl = 1;
+	}
 
-   return (1);
+	return (1);
 }
 
 /****************************************************************************/
@@ -5672,38 +5183,39 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_reset_copperhead(ips_ha_t *ha) {
-   int reset_counter;
+ips_reset_copperhead(ips_ha_t * ha)
+{
+	int reset_counter;
 
-   METHOD_TRACE("ips_reset_copperhead", 1);
+	METHOD_TRACE("ips_reset_copperhead", 1);
 
-   DEBUG_VAR(1, "(%s%d) ips_reset_copperhead: io addr: %x, irq: %d",
-             ips_name, ha->host_num, ha->io_addr, ha->irq);
+	DEBUG_VAR(1, "(%s%d) ips_reset_copperhead: io addr: %x, irq: %d",
+		  ips_name, ha->host_num, ha->io_addr, ha->irq);
 
-   reset_counter = 0;
+	reset_counter = 0;
 
-   while (reset_counter < 2) {
-      reset_counter++;
+	while (reset_counter < 2) {
+		reset_counter++;
 
-      outb(IPS_BIT_RST, ha->io_addr + IPS_REG_SCPR);
+		outb(IPS_BIT_RST, ha->io_addr + IPS_REG_SCPR);
 
-      /* Delay for 1 Second */
-      MDELAY(IPS_ONE_SEC);
- 
-      outb(0, ha->io_addr + IPS_REG_SCPR);
+		/* Delay for 1 Second */
+		MDELAY(IPS_ONE_SEC);
 
-      /* Delay for 1 Second */
-      MDELAY(IPS_ONE_SEC);
-      
-      if ((*ha->func.init)(ha))
-         break;
-      else if (reset_counter >= 2) {
+		outb(0, ha->io_addr + IPS_REG_SCPR);
 
-         return (0);
-      }
-   }
+		/* Delay for 1 Second */
+		MDELAY(IPS_ONE_SEC);
 
-   return (1);
+		if ((*ha->func.init) (ha))
+			break;
+		else if (reset_counter >= 2) {
+
+			return (0);
+		}
+	}
+
+	return (1);
 }
 
 /****************************************************************************/
@@ -5716,38 +5228,39 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_reset_copperhead_memio(ips_ha_t *ha) {
-   int reset_counter;
+ips_reset_copperhead_memio(ips_ha_t * ha)
+{
+	int reset_counter;
 
-   METHOD_TRACE("ips_reset_copperhead_memio", 1);
+	METHOD_TRACE("ips_reset_copperhead_memio", 1);
 
-   DEBUG_VAR(1, "(%s%d) ips_reset_copperhead_memio: mem addr: %x, irq: %d",
-             ips_name, ha->host_num, ha->mem_addr, ha->irq);
+	DEBUG_VAR(1, "(%s%d) ips_reset_copperhead_memio: mem addr: %x, irq: %d",
+		  ips_name, ha->host_num, ha->mem_addr, ha->irq);
 
-   reset_counter = 0;
+	reset_counter = 0;
 
-   while (reset_counter < 2) {
-      reset_counter++;
+	while (reset_counter < 2) {
+		reset_counter++;
 
-      writeb(IPS_BIT_RST, ha->mem_ptr + IPS_REG_SCPR);
+		writeb(IPS_BIT_RST, ha->mem_ptr + IPS_REG_SCPR);
 
-      /* Delay for 1 Second */
-      MDELAY(IPS_ONE_SEC);
- 
-      writeb(0, ha->mem_ptr + IPS_REG_SCPR);
+		/* Delay for 1 Second */
+		MDELAY(IPS_ONE_SEC);
 
-      /* Delay for 1 Second */
-      MDELAY(IPS_ONE_SEC);
- 
-      if ((*ha->func.init)(ha))
-         break;
-      else if (reset_counter >= 2) {
+		writeb(0, ha->mem_ptr + IPS_REG_SCPR);
 
-         return (0);
-      }
-   }
+		/* Delay for 1 Second */
+		MDELAY(IPS_ONE_SEC);
 
-   return (1);
+		if ((*ha->func.init) (ha))
+			break;
+		else if (reset_counter >= 2) {
+
+			return (0);
+		}
+	}
+
+	return (1);
 }
 
 /****************************************************************************/
@@ -5760,37 +5273,38 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_reset_morpheus(ips_ha_t *ha) {
-   int           reset_counter;
-   uint8_t       junk;
+ips_reset_morpheus(ips_ha_t * ha)
+{
+	int reset_counter;
+	uint8_t junk;
+
+	METHOD_TRACE("ips_reset_morpheus", 1);
 
-   METHOD_TRACE("ips_reset_morpheus", 1);
+	DEBUG_VAR(1, "(%s%d) ips_reset_morpheus: mem addr: %x, irq: %d",
+		  ips_name, ha->host_num, ha->mem_addr, ha->irq);
 
-   DEBUG_VAR(1, "(%s%d) ips_reset_morpheus: mem addr: %x, irq: %d",
-             ips_name, ha->host_num, ha->mem_addr, ha->irq);
+	reset_counter = 0;
 
-   reset_counter = 0;
+	while (reset_counter < 2) {
+		reset_counter++;
 
-   while (reset_counter < 2) {
-      reset_counter++;
+		writel(0x80000000, ha->mem_ptr + IPS_REG_I960_IDR);
 
-      writel(0x80000000, ha->mem_ptr + IPS_REG_I960_IDR);
+		/* Delay for 5 Seconds */
+		MDELAY(5 * IPS_ONE_SEC);
 
-      /* Delay for 5 Seconds */
-      MDELAY(5 * IPS_ONE_SEC);
- 
-      /* Do a PCI config read to wait for adapter */
-      pci_read_config_byte(ha->pcidev, 4, &junk);
+		/* Do a PCI config read to wait for adapter */
+		pci_read_config_byte(ha->pcidev, 4, &junk);
 
-      if ((*ha->func.init)(ha))
-         break;
-      else if (reset_counter >= 2) {
+		if ((*ha->func.init) (ha))
+			break;
+		else if (reset_counter >= 2) {
 
-         return (0);
-      }
-   }
+			return (0);
+		}
+	}
 
-   return (1);
+	return (1);
 }
 
 /****************************************************************************/
@@ -5803,22 +5317,25 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_statinit(ips_ha_t *ha) {
-   uint32_t phys_status_start;
+ips_statinit(ips_ha_t * ha)
+{
+	uint32_t phys_status_start;
 
-   METHOD_TRACE("ips_statinit", 1);
+	METHOD_TRACE("ips_statinit", 1);
 
-   ha->adapt->p_status_start = ha->adapt->status;
-   ha->adapt->p_status_end = ha->adapt->status + IPS_MAX_CMDS;
-   ha->adapt->p_status_tail = ha->adapt->status;
-
-   phys_status_start = ha->adapt->hw_status_start;
-   outl(cpu_to_le32(phys_status_start), ha->io_addr + IPS_REG_SQSR);
-   outl(cpu_to_le32(phys_status_start + IPS_STATUS_Q_SIZE), ha->io_addr + IPS_REG_SQER);
-   outl(cpu_to_le32(phys_status_start + IPS_STATUS_SIZE), ha->io_addr + IPS_REG_SQHR);
-   outl(cpu_to_le32(phys_status_start), ha->io_addr + IPS_REG_SQTR);
+	ha->adapt->p_status_start = ha->adapt->status;
+	ha->adapt->p_status_end = ha->adapt->status + IPS_MAX_CMDS;
+	ha->adapt->p_status_tail = ha->adapt->status;
+
+	phys_status_start = ha->adapt->hw_status_start;
+	outl(cpu_to_le32(phys_status_start), ha->io_addr + IPS_REG_SQSR);
+	outl(cpu_to_le32(phys_status_start + IPS_STATUS_Q_SIZE),
+	     ha->io_addr + IPS_REG_SQER);
+	outl(cpu_to_le32(phys_status_start + IPS_STATUS_SIZE),
+	     ha->io_addr + IPS_REG_SQHR);
+	outl(cpu_to_le32(phys_status_start), ha->io_addr + IPS_REG_SQTR);
 
-   ha->adapt->hw_status_tail = phys_status_start;
+	ha->adapt->hw_status_tail = phys_status_start;
 }
 
 /****************************************************************************/
@@ -5831,22 +5348,24 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_statinit_memio(ips_ha_t *ha) {
-   uint32_t phys_status_start;
+ips_statinit_memio(ips_ha_t * ha)
+{
+	uint32_t phys_status_start;
 
-   METHOD_TRACE("ips_statinit_memio", 1);
+	METHOD_TRACE("ips_statinit_memio", 1);
 
-   ha->adapt->p_status_start = ha->adapt->status;
-   ha->adapt->p_status_end = ha->adapt->status + IPS_MAX_CMDS;
-   ha->adapt->p_status_tail = ha->adapt->status;
-
-   phys_status_start = ha->adapt->hw_status_start;
-   writel(phys_status_start, ha->mem_ptr + IPS_REG_SQSR);
-   writel(phys_status_start + IPS_STATUS_Q_SIZE, ha->mem_ptr + IPS_REG_SQER);
-   writel(phys_status_start + IPS_STATUS_SIZE, ha->mem_ptr + IPS_REG_SQHR);
-   writel(phys_status_start, ha->mem_ptr + IPS_REG_SQTR);
+	ha->adapt->p_status_start = ha->adapt->status;
+	ha->adapt->p_status_end = ha->adapt->status + IPS_MAX_CMDS;
+	ha->adapt->p_status_tail = ha->adapt->status;
+
+	phys_status_start = ha->adapt->hw_status_start;
+	writel(phys_status_start, ha->mem_ptr + IPS_REG_SQSR);
+	writel(phys_status_start + IPS_STATUS_Q_SIZE,
+	       ha->mem_ptr + IPS_REG_SQER);
+	writel(phys_status_start + IPS_STATUS_SIZE, ha->mem_ptr + IPS_REG_SQHR);
+	writel(phys_status_start, ha->mem_ptr + IPS_REG_SQTR);
 
-   ha->adapt->hw_status_tail = phys_status_start;
+	ha->adapt->hw_status_tail = phys_status_start;
 }
 
 /****************************************************************************/
@@ -5859,20 +5378,22 @@
 /*                                                                          */
 /****************************************************************************/
 static uint32_t
-ips_statupd_copperhead(ips_ha_t *ha) {
-   METHOD_TRACE("ips_statupd_copperhead", 1);
+ips_statupd_copperhead(ips_ha_t * ha)
+{
+	METHOD_TRACE("ips_statupd_copperhead", 1);
 
-   if (ha->adapt->p_status_tail != ha->adapt->p_status_end) {
-      ha->adapt->p_status_tail++;
-      ha->adapt->hw_status_tail += sizeof(IPS_STATUS);
-   } else {
-      ha->adapt->p_status_tail = ha->adapt->p_status_start;
-      ha->adapt->hw_status_tail = ha->adapt->hw_status_start;
-   }
+	if (ha->adapt->p_status_tail != ha->adapt->p_status_end) {
+		ha->adapt->p_status_tail++;
+		ha->adapt->hw_status_tail += sizeof (IPS_STATUS);
+	} else {
+		ha->adapt->p_status_tail = ha->adapt->p_status_start;
+		ha->adapt->hw_status_tail = ha->adapt->hw_status_start;
+	}
 
-   outl(cpu_to_le32(ha->adapt->hw_status_tail), ha->io_addr + IPS_REG_SQTR);
+	outl(cpu_to_le32(ha->adapt->hw_status_tail),
+	     ha->io_addr + IPS_REG_SQTR);
 
-   return (ha->adapt->p_status_tail->value);
+	return (ha->adapt->p_status_tail->value);
 }
 
 /****************************************************************************/
@@ -5885,20 +5406,21 @@
 /*                                                                          */
 /****************************************************************************/
 static uint32_t
-ips_statupd_copperhead_memio(ips_ha_t *ha) {
-   METHOD_TRACE("ips_statupd_copperhead_memio", 1);
+ips_statupd_copperhead_memio(ips_ha_t * ha)
+{
+	METHOD_TRACE("ips_statupd_copperhead_memio", 1);
 
-   if (ha->adapt->p_status_tail != ha->adapt->p_status_end) {
-      ha->adapt->p_status_tail++;
-      ha->adapt->hw_status_tail += sizeof(IPS_STATUS);
-   } else {
-      ha->adapt->p_status_tail = ha->adapt->p_status_start;
-      ha->adapt->hw_status_tail = ha->adapt->hw_status_start;
-   }
+	if (ha->adapt->p_status_tail != ha->adapt->p_status_end) {
+		ha->adapt->p_status_tail++;
+		ha->adapt->hw_status_tail += sizeof (IPS_STATUS);
+	} else {
+		ha->adapt->p_status_tail = ha->adapt->p_status_start;
+		ha->adapt->hw_status_tail = ha->adapt->hw_status_start;
+	}
 
-   writel(ha->adapt->hw_status_tail, ha->mem_ptr + IPS_REG_SQTR);
+	writel(ha->adapt->hw_status_tail, ha->mem_ptr + IPS_REG_SQTR);
 
-   return (ha->adapt->p_status_tail->value);
+	return (ha->adapt->p_status_tail->value);
 }
 
 /****************************************************************************/
@@ -5911,14 +5433,15 @@
 /*                                                                          */
 /****************************************************************************/
 static uint32_t
-ips_statupd_morpheus(ips_ha_t *ha) {
-   uint32_t val;
+ips_statupd_morpheus(ips_ha_t * ha)
+{
+	uint32_t val;
 
-   METHOD_TRACE("ips_statupd_morpheus", 1);
+	METHOD_TRACE("ips_statupd_morpheus", 1);
 
-   val = readl(ha->mem_ptr + IPS_REG_I2O_OUTMSGQ);
+	val = readl(ha->mem_ptr + IPS_REG_I2O_OUTMSGQ);
 
-   return (val);
+	return (val);
 }
 
 /****************************************************************************/
@@ -5931,50 +5454,49 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_issue_copperhead(ips_ha_t *ha, ips_scb_t *scb) {
-   uint32_t TimeOut;
-   uint32_t val;
-
-   METHOD_TRACE("ips_issue_copperhead", 1);
-
-   if (scb->scsi_cmd) {
-      DEBUG_VAR(2, "(%s%d) ips_issue: cmd 0x%X id %d (%d %d %d)",
-                ips_name,
-                ha->host_num,
-                scb->cdb[0],
-                scb->cmd.basic_io.command_id,
-                scb->bus,
-                scb->target_id,
-                scb->lun);
-   } else {
-      DEBUG_VAR(2, KERN_NOTICE "(%s%d) ips_issue: logical cmd id %d",
-                ips_name,
-                ha->host_num,
-                scb->cmd.basic_io.command_id);
-   }
-
-   TimeOut = 0;
-
-   while ((val = le32_to_cpu(inl(ha->io_addr + IPS_REG_CCCR))) & IPS_BIT_SEM) {
-      udelay(1000);
-
-      if (++TimeOut >= IPS_SEM_TIMEOUT) {
-         if (!(val & IPS_BIT_START_STOP))
-            break;
-
-         printk(KERN_WARNING "(%s%d) ips_issue val [0x%x].\n",
-                ips_name, ha->host_num, val);
-         printk(KERN_WARNING "(%s%d) ips_issue semaphore chk timeout.\n",
-                ips_name, ha->host_num);
-
-         return (IPS_FAILURE);
-      } /* end if */
-   } /* end while */
+ips_issue_copperhead(ips_ha_t * ha, ips_scb_t * scb)
+{
+	uint32_t TimeOut;
+	uint32_t val;
 
-   outl(cpu_to_le32(scb->scb_busaddr), ha->io_addr + IPS_REG_CCSAR);
-   outw(cpu_to_le32(IPS_BIT_START_CMD), ha->io_addr + IPS_REG_CCCR);
+	METHOD_TRACE("ips_issue_copperhead", 1);
 
-   return (IPS_SUCCESS);
+	if (scb->scsi_cmd) {
+		DEBUG_VAR(2, "(%s%d) ips_issue: cmd 0x%X id %d (%d %d %d)",
+			  ips_name,
+			  ha->host_num,
+			  scb->cdb[0],
+			  scb->cmd.basic_io.command_id,
+			  scb->bus, scb->target_id, scb->lun);
+	} else {
+		DEBUG_VAR(2, KERN_NOTICE "(%s%d) ips_issue: logical cmd id %d",
+			  ips_name, ha->host_num, scb->cmd.basic_io.command_id);
+	}
+
+	TimeOut = 0;
+
+	while ((val = le32_to_cpu(inl(ha->io_addr + IPS_REG_CCCR))) &
+	       IPS_BIT_SEM) {
+		udelay(1000);
+
+		if (++TimeOut >= IPS_SEM_TIMEOUT) {
+			if (!(val & IPS_BIT_START_STOP))
+				break;
+
+			printk(KERN_WARNING "(%s%d) ips_issue val [0x%x].\n",
+			       ips_name, ha->host_num, val);
+			printk(KERN_WARNING
+			       "(%s%d) ips_issue semaphore chk timeout.\n",
+			       ips_name, ha->host_num);
+
+			return (IPS_FAILURE);
+		}		/* end if */
+	}			/* end while */
+
+	outl(cpu_to_le32(scb->scb_busaddr), ha->io_addr + IPS_REG_CCSAR);
+	outw(cpu_to_le32(IPS_BIT_START_CMD), ha->io_addr + IPS_REG_CCCR);
+
+	return (IPS_SUCCESS);
 }
 
 /****************************************************************************/
@@ -5987,50 +5509,48 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_issue_copperhead_memio(ips_ha_t *ha, ips_scb_t *scb) {
-   uint32_t      TimeOut;
-   uint32_t      val;
-
-   METHOD_TRACE("ips_issue_copperhead_memio", 1);
-
-   if (scb->scsi_cmd) {
-      DEBUG_VAR(2, "(%s%d) ips_issue: cmd 0x%X id %d (%d %d %d)",
-                ips_name,
-                ha->host_num,
-                scb->cdb[0],
-                scb->cmd.basic_io.command_id,
-                scb->bus,
-                scb->target_id,
-                scb->lun);
-   } else {
-      DEBUG_VAR(2, "(%s%d) ips_issue: logical cmd id %d",
-                ips_name,
-                ha->host_num,
-                scb->cmd.basic_io.command_id);
-   }
-
-   TimeOut = 0;
-
-   while ((val = readl(ha->mem_ptr + IPS_REG_CCCR)) & IPS_BIT_SEM) {
-      udelay(1000);
-
-      if (++TimeOut >= IPS_SEM_TIMEOUT) {
-         if (!(val & IPS_BIT_START_STOP))
-            break;
-
-         printk(KERN_WARNING "(%s%d) ips_issue val [0x%x].\n",
-                ips_name, ha->host_num, val);
-         printk(KERN_WARNING "(%s%d) ips_issue semaphore chk timeout.\n",
-                ips_name, ha->host_num);
-
-         return (IPS_FAILURE);
-      } /* end if */
-   } /* end while */
+ips_issue_copperhead_memio(ips_ha_t * ha, ips_scb_t * scb)
+{
+	uint32_t TimeOut;
+	uint32_t val;
 
-   writel(scb->scb_busaddr, ha->mem_ptr + IPS_REG_CCSAR);
-   writel(IPS_BIT_START_CMD, ha->mem_ptr + IPS_REG_CCCR);
+	METHOD_TRACE("ips_issue_copperhead_memio", 1);
 
-   return (IPS_SUCCESS);
+	if (scb->scsi_cmd) {
+		DEBUG_VAR(2, "(%s%d) ips_issue: cmd 0x%X id %d (%d %d %d)",
+			  ips_name,
+			  ha->host_num,
+			  scb->cdb[0],
+			  scb->cmd.basic_io.command_id,
+			  scb->bus, scb->target_id, scb->lun);
+	} else {
+		DEBUG_VAR(2, "(%s%d) ips_issue: logical cmd id %d",
+			  ips_name, ha->host_num, scb->cmd.basic_io.command_id);
+	}
+
+	TimeOut = 0;
+
+	while ((val = readl(ha->mem_ptr + IPS_REG_CCCR)) & IPS_BIT_SEM) {
+		udelay(1000);
+
+		if (++TimeOut >= IPS_SEM_TIMEOUT) {
+			if (!(val & IPS_BIT_START_STOP))
+				break;
+
+			printk(KERN_WARNING "(%s%d) ips_issue val [0x%x].\n",
+			       ips_name, ha->host_num, val);
+			printk(KERN_WARNING
+			       "(%s%d) ips_issue semaphore chk timeout.\n",
+			       ips_name, ha->host_num);
+
+			return (IPS_FAILURE);
+		}		/* end if */
+	}			/* end while */
+
+	writel(scb->scb_busaddr, ha->mem_ptr + IPS_REG_CCSAR);
+	writel(IPS_BIT_START_CMD, ha->mem_ptr + IPS_REG_CCCR);
+
+	return (IPS_SUCCESS);
 }
 
 /****************************************************************************/
@@ -6043,29 +5563,26 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_issue_i2o(ips_ha_t *ha, ips_scb_t *scb) {
+ips_issue_i2o(ips_ha_t * ha, ips_scb_t * scb)
+{
 
-   METHOD_TRACE("ips_issue_i2o", 1);
+	METHOD_TRACE("ips_issue_i2o", 1);
 
-   if (scb->scsi_cmd) {
-      DEBUG_VAR(2, "(%s%d) ips_issue: cmd 0x%X id %d (%d %d %d)",
-                ips_name,
-                ha->host_num,
-                scb->cdb[0],
-                scb->cmd.basic_io.command_id,
-                scb->bus,
-                scb->target_id,
-                scb->lun);
-   } else {
-      DEBUG_VAR(2, "(%s%d) ips_issue: logical cmd id %d",
-                ips_name,
-                ha->host_num,
-                scb->cmd.basic_io.command_id);
-   }
+	if (scb->scsi_cmd) {
+		DEBUG_VAR(2, "(%s%d) ips_issue: cmd 0x%X id %d (%d %d %d)",
+			  ips_name,
+			  ha->host_num,
+			  scb->cdb[0],
+			  scb->cmd.basic_io.command_id,
+			  scb->bus, scb->target_id, scb->lun);
+	} else {
+		DEBUG_VAR(2, "(%s%d) ips_issue: logical cmd id %d",
+			  ips_name, ha->host_num, scb->cmd.basic_io.command_id);
+	}
 
-   outl(cpu_to_le32(scb->scb_busaddr), ha->io_addr + IPS_REG_I2O_INMSGQ);
+	outl(cpu_to_le32(scb->scb_busaddr), ha->io_addr + IPS_REG_I2O_INMSGQ);
 
-   return (IPS_SUCCESS);
+	return (IPS_SUCCESS);
 }
 
 /****************************************************************************/
@@ -6078,29 +5595,26 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_issue_i2o_memio(ips_ha_t *ha, ips_scb_t *scb) {
+ips_issue_i2o_memio(ips_ha_t * ha, ips_scb_t * scb)
+{
 
-   METHOD_TRACE("ips_issue_i2o_memio", 1);
+	METHOD_TRACE("ips_issue_i2o_memio", 1);
 
-   if (scb->scsi_cmd) {
-      DEBUG_VAR(2, "(%s%d) ips_issue: cmd 0x%X id %d (%d %d %d)",
-                ips_name,
-                ha->host_num,
-                scb->cdb[0],
-                scb->cmd.basic_io.command_id,
-                scb->bus,
-                scb->target_id,
-                scb->lun);
-   } else {
-      DEBUG_VAR(2, "(%s%d) ips_issue: logical cmd id %d",
-                ips_name,
-                ha->host_num,
-                scb->cmd.basic_io.command_id);
-   }
+	if (scb->scsi_cmd) {
+		DEBUG_VAR(2, "(%s%d) ips_issue: cmd 0x%X id %d (%d %d %d)",
+			  ips_name,
+			  ha->host_num,
+			  scb->cdb[0],
+			  scb->cmd.basic_io.command_id,
+			  scb->bus, scb->target_id, scb->lun);
+	} else {
+		DEBUG_VAR(2, "(%s%d) ips_issue: logical cmd id %d",
+			  ips_name, ha->host_num, scb->cmd.basic_io.command_id);
+	}
 
-   writel(scb->scb_busaddr, ha->mem_ptr + IPS_REG_I2O_INMSGQ);
+	writel(scb->scb_busaddr, ha->mem_ptr + IPS_REG_I2O_INMSGQ);
 
-   return (IPS_SUCCESS);
+	return (IPS_SUCCESS);
 }
 
 /****************************************************************************/
@@ -6113,26 +5627,27 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_isintr_copperhead(ips_ha_t *ha) {
-   uint8_t Isr;
+ips_isintr_copperhead(ips_ha_t * ha)
+{
+	uint8_t Isr;
+
+	METHOD_TRACE("ips_isintr_copperhead", 2);
 
-   METHOD_TRACE("ips_isintr_copperhead", 2);
+	Isr = inb(ha->io_addr + IPS_REG_HISR);
 
-   Isr = inb(ha->io_addr + IPS_REG_HISR);
+	if (Isr == 0xFF)
+		/* ?!?! Nothing really there */
+		return (0);
 
-   if (Isr == 0xFF)
-      /* ?!?! Nothing really there */
-      return (0);
-
-   if (Isr & IPS_BIT_SCE)
-      return (1);
-   else if (Isr & (IPS_BIT_SQO | IPS_BIT_GHI)) {
-      /* status queue overflow or GHI */
-      /* just clear the interrupt */
-      outb(Isr, ha->io_addr + IPS_REG_HISR);
-   }
+	if (Isr & IPS_BIT_SCE)
+		return (1);
+	else if (Isr & (IPS_BIT_SQO | IPS_BIT_GHI)) {
+		/* status queue overflow or GHI */
+		/* just clear the interrupt */
+		outb(Isr, ha->io_addr + IPS_REG_HISR);
+	}
 
-   return (0);
+	return (0);
 }
 
 /****************************************************************************/
@@ -6145,26 +5660,27 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_isintr_copperhead_memio(ips_ha_t *ha) {
-   uint8_t Isr;
+ips_isintr_copperhead_memio(ips_ha_t * ha)
+{
+	uint8_t Isr;
 
-   METHOD_TRACE("ips_isintr_memio", 2);
+	METHOD_TRACE("ips_isintr_memio", 2);
 
-   Isr = readb(ha->mem_ptr + IPS_REG_HISR);
+	Isr = readb(ha->mem_ptr + IPS_REG_HISR);
 
-   if (Isr == 0xFF)
-      /* ?!?! Nothing really there */
-      return (0);
-
-   if (Isr & IPS_BIT_SCE)
-      return (1);
-   else if (Isr & (IPS_BIT_SQO | IPS_BIT_GHI)) {
-      /* status queue overflow or GHI */
-      /* just clear the interrupt */
-      writeb(Isr, ha->mem_ptr + IPS_REG_HISR);
-   }
+	if (Isr == 0xFF)
+		/* ?!?! Nothing really there */
+		return (0);
 
-   return (0);
+	if (Isr & IPS_BIT_SCE)
+		return (1);
+	else if (Isr & (IPS_BIT_SQO | IPS_BIT_GHI)) {
+		/* status queue overflow or GHI */
+		/* just clear the interrupt */
+		writeb(Isr, ha->mem_ptr + IPS_REG_HISR);
+	}
+
+	return (0);
 }
 
 /****************************************************************************/
@@ -6177,17 +5693,18 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_isintr_morpheus(ips_ha_t *ha) {
-   uint32_t Isr;
+ips_isintr_morpheus(ips_ha_t * ha)
+{
+	uint32_t Isr;
 
-   METHOD_TRACE("ips_isintr_morpheus", 2);
+	METHOD_TRACE("ips_isintr_morpheus", 2);
 
-   Isr = readl(ha->mem_ptr + IPS_REG_I2O_HIR);
+	Isr = readl(ha->mem_ptr + IPS_REG_I2O_HIR);
 
-   if (Isr & IPS_BIT_I2O_OPQI)
-      return (1);
-   else
-      return (0);
+	if (Isr & IPS_BIT_I2O_OPQI)
+		return (1);
+	else
+		return (0);
 }
 
 /****************************************************************************/
@@ -6200,51 +5717,52 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_wait(ips_ha_t *ha, int time, int intr) {
-   int   ret;
-   int   done;
-
-   METHOD_TRACE("ips_wait", 1);
-
-   ret = IPS_FAILURE;
-   done = FALSE;
-
-   time *= IPS_ONE_SEC;                       /* convert seconds */
-
-   while ((time > 0) && (!done)) {
-      if (intr == IPS_INTR_ON) {
-         if (ha->waitflag == FALSE) {
-            ret = IPS_SUCCESS;
-            done = TRUE;
-            break;
-         }
-      } else if (intr == IPS_INTR_IORL) {
-         if (ha->waitflag == FALSE) {
-            /*
-             * controller generated an interrupt to
-             * acknowledge completion of the command
-             * and ips_intr() has serviced the interrupt.
-             */
-            ret = IPS_SUCCESS;
-            done = TRUE;
-            break;
-         }
-
-         /*
-          * NOTE: we already have the io_request_lock so
-          * even if we get an interrupt it won't get serviced
-          * until after we finish.
-          */
-
-         (*ha->func.intr)(ha);
-      } 
-
-      /* This looks like a very evil loop, but it only does this during start-up */
-      udelay(1000);        
-      time--;
-   }
+ips_wait(ips_ha_t * ha, int time, int intr)
+{
+	int ret;
+	int done;
+
+	METHOD_TRACE("ips_wait", 1);
 
-   return (ret);
+	ret = IPS_FAILURE;
+	done = FALSE;
+
+	time *= IPS_ONE_SEC;	/* convert seconds */
+
+	while ((time > 0) && (!done)) {
+		if (intr == IPS_INTR_ON) {
+			if (ha->waitflag == FALSE) {
+				ret = IPS_SUCCESS;
+				done = TRUE;
+				break;
+			}
+		} else if (intr == IPS_INTR_IORL) {
+			if (ha->waitflag == FALSE) {
+				/*
+				 * controller generated an interrupt to
+				 * acknowledge completion of the command
+				 * and ips_intr() has serviced the interrupt.
+				 */
+				ret = IPS_SUCCESS;
+				done = TRUE;
+				break;
+			}
+
+			/*
+			 * NOTE: we already have the io_request_lock so
+			 * even if we get an interrupt it won't get serviced
+			 * until after we finish.
+			 */
+
+			(*ha->func.intr) (ha);
+		}
+
+		/* This looks like a very evil loop, but it only does this during start-up */
+		udelay(1000);
+		time--;
+	}
+
+	return (ret);
 }
 
 /****************************************************************************/
@@ -6257,61 +5775,59 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_write_driver_status(ips_ha_t *ha, int intr) {
-   METHOD_TRACE("ips_write_driver_status", 1);
-
-   if (!ips_readwrite_page5(ha, FALSE, intr)) {
-      printk(KERN_WARNING "(%s%d) unable to read NVRAM page 5.\n",
-             ips_name, ha->host_num);
-
-      return (0);
-   }
-
-   /* check to make sure the page has a valid */
-   /* signature */
-   if (le32_to_cpu(ha->nvram->signature) != IPS_NVRAM_P5_SIG) {
-      DEBUG_VAR(1, "(%s%d) NVRAM page 5 has an invalid signature: %X.",
-                ips_name, ha->host_num, ha->nvram->signature);
-      ha->nvram->signature = IPS_NVRAM_P5_SIG;
-   }
-
-   DEBUG_VAR(2, "(%s%d) Ad Type: %d, Ad Slot: %d, BIOS: %c%c%c%c %c%c%c%c.",
-             ips_name, ha->host_num, le16_to_cpu(ha->nvram->adapter_type),
-             ha->nvram->adapter_slot,
-             ha->nvram->bios_high[0], ha->nvram->bios_high[1],
-             ha->nvram->bios_high[2], ha->nvram->bios_high[3],
-             ha->nvram->bios_low[0], ha->nvram->bios_low[1],
-             ha->nvram->bios_low[2], ha->nvram->bios_low[3]);
-
-   ips_get_bios_version(ha, intr);
-
-   /* change values (as needed) */
-   ha->nvram->operating_system = IPS_OS_LINUX;
-   ha->nvram->adapter_type = ha->ad_type;
-   strncpy((char *) ha->nvram->driver_high, IPS_VERSION_HIGH, 4);
-   strncpy((char *) ha->nvram->driver_low, IPS_VERSION_LOW, 4);
-   strncpy((char *) ha->nvram->bios_high, ha->bios_version, 4);
-   strncpy((char *) ha->nvram->bios_low, ha->bios_version + 4, 4);
-
-   ips_version_check(ha, intr);                           /* Check BIOS/FW/Driver Versions */
-
-   /* Save the First Copy of the Adapter Order that BIOS put in Page 5 */
-   if ( (InitState == 0) && (AdapterOrder[0] == 0) ) 
-      strncpy((char *) AdapterOrder, (char *) ha->nvram->adapter_order, sizeof(AdapterOrder) );
-
-   /* now update the page */
-   if (!ips_readwrite_page5(ha, TRUE, intr)) {
-      printk(KERN_WARNING "(%s%d) unable to write NVRAM page 5.\n",
-             ips_name, ha->host_num);
+ips_write_driver_status(ips_ha_t * ha, int intr)
+{
+	METHOD_TRACE("ips_write_driver_status", 1);
 
-      return (0);
-   }
+	if (!ips_readwrite_page5(ha, FALSE, intr)) {
+		printk(KERN_WARNING "(%s%d) unable to read NVRAM page 5.\n",
+		       ips_name, ha->host_num);
+
+		return (0);
+	}
+
+	/* check to make sure the page has a valid */
+	/* signature */
+	if (le32_to_cpu(ha->nvram->signature) != IPS_NVRAM_P5_SIG) {
+		DEBUG_VAR(1,
+			  "(%s%d) NVRAM page 5 has an invalid signature: %X.",
+			  ips_name, ha->host_num, ha->nvram->signature);
+		ha->nvram->signature = IPS_NVRAM_P5_SIG;
+	}
+
+	DEBUG_VAR(2,
+		  "(%s%d) Ad Type: %d, Ad Slot: %d, BIOS: %c%c%c%c %c%c%c%c.",
+		  ips_name, ha->host_num, le16_to_cpu(ha->nvram->adapter_type),
+		  ha->nvram->adapter_slot, ha->nvram->bios_high[0],
+		  ha->nvram->bios_high[1], ha->nvram->bios_high[2],
+		  ha->nvram->bios_high[3], ha->nvram->bios_low[0],
+		  ha->nvram->bios_low[1], ha->nvram->bios_low[2],
+		  ha->nvram->bios_low[3]);
+
+	ips_get_bios_version(ha, intr);
+
+	/* change values (as needed) */
+	ha->nvram->operating_system = IPS_OS_LINUX;
+	ha->nvram->adapter_type = ha->ad_type;
+	strncpy((char *) ha->nvram->driver_high, IPS_VERSION_HIGH, 4);
+	strncpy((char *) ha->nvram->driver_low, IPS_VERSION_LOW, 4);
+	strncpy((char *) ha->nvram->bios_high, ha->bios_version, 4);
+	strncpy((char *) ha->nvram->bios_low, ha->bios_version + 4, 4);
+
+	ips_version_check(ha, intr);	/* Check BIOS/FW/Driver Versions */
+
+	/* now update the page */
+	if (!ips_readwrite_page5(ha, TRUE, intr)) {
+		printk(KERN_WARNING "(%s%d) unable to write NVRAM page 5.\n",
+		       ips_name, ha->host_num);
 
-   /* IF NVRAM Page 5 is OK, Use it for Slot Number Info Because Linux Doesn't Do Slots */
-   ha->slot_num = ha->nvram->adapter_slot;
+		return (0);
+	}
 
+	/* IF NVRAM Page 5 is OK, Use it for Slot Number Info Because Linux Doesn't Do Slots */
+	ha->slot_num = ha->nvram->adapter_slot;
 
-   return (1);
+	return (1);
 }
 
 /****************************************************************************/
@@ -6324,39 +5840,40 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_read_adapter_status(ips_ha_t *ha, int intr) {
-   ips_scb_t *scb;
-   int        ret;
-
-   METHOD_TRACE("ips_read_adapter_status", 1);
-
-   scb = &ha->scbs[ha->max_cmds-1];
-
-   ips_init_scb(ha, scb);
-
-   scb->timeout = ips_cmd_timeout;
-   scb->cdb[0] = IPS_CMD_ENQUIRY;
-
-   scb->cmd.basic_io.op_code = IPS_CMD_ENQUIRY;
-   scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->cmd.basic_io.sg_count = 0;
-   scb->cmd.basic_io.lba = 0;
-   scb->cmd.basic_io.sector_count = 0;
-   scb->cmd.basic_io.log_drv = 0;
-   scb->cmd.basic_io.reserved = 0;
-   scb->data_len = sizeof(*ha->enq);
-   scb->data_busaddr = pci_map_single(ha->pcidev, ha->enq, scb->data_len,
-                                      IPS_DMA_DIR(scb));
-   scb->cmd.basic_io.sg_addr = scb->data_busaddr;
-   scb->flags |= IPS_SCB_MAP_SINGLE;
-
-   /* send command */
-   if (((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) == IPS_FAILURE) ||
-       (ret == IPS_SUCCESS_IMM) ||
-       ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1))
-      return (0);
+ips_read_adapter_status(ips_ha_t * ha, int intr)
+{
+	ips_scb_t *scb;
+	int ret;
+
+	METHOD_TRACE("ips_read_adapter_status", 1);
+
+	scb = &ha->scbs[ha->max_cmds - 1];
 
-   return (1);
+	ips_init_scb(ha, scb);
+
+	scb->timeout = ips_cmd_timeout;
+	scb->cdb[0] = IPS_CMD_ENQUIRY;
+
+	scb->cmd.basic_io.op_code = IPS_CMD_ENQUIRY;
+	scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->cmd.basic_io.sg_count = 0;
+	scb->cmd.basic_io.lba = 0;
+	scb->cmd.basic_io.sector_count = 0;
+	scb->cmd.basic_io.log_drv = 0;
+	scb->data_len = sizeof (*ha->enq);
+	scb->data_busaddr = pci_map_single(ha->pcidev, ha->enq, scb->data_len,
+					   IPS_DMA_DIR(scb));
+	scb->cmd.basic_io.sg_addr = scb->data_busaddr;
+	scb->flags |= IPS_SCB_MAP_SINGLE;
+
+	/* send command */
+	if (
+	    ((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) ==
+	     IPS_FAILURE) || (ret == IPS_SUCCESS_IMM)
+	    || ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1))
+		return (0);
+
+	return (1);
 }
 
 /****************************************************************************/
@@ -6369,39 +5886,40 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_read_subsystem_parameters(ips_ha_t *ha, int intr) {
-   ips_scb_t *scb;
-   int        ret;
-
-   METHOD_TRACE("ips_read_subsystem_parameters", 1);
-
-   scb = &ha->scbs[ha->max_cmds-1];
-
-   ips_init_scb(ha, scb);
-
-   scb->timeout = ips_cmd_timeout;
-   scb->cdb[0] = IPS_CMD_GET_SUBSYS;
-
-   scb->cmd.basic_io.op_code = IPS_CMD_GET_SUBSYS;
-   scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->cmd.basic_io.sg_count = 0;
-   scb->cmd.basic_io.lba = 0;
-   scb->cmd.basic_io.sector_count = 0;
-   scb->cmd.basic_io.log_drv = 0;
-   scb->cmd.basic_io.reserved = 0;
-   scb->data_len = sizeof(*ha->subsys);
-   scb->data_busaddr = pci_map_single(ha->pcidev, ha->subsys,
-                                      scb->data_len, IPS_DMA_DIR(scb));
-   scb->cmd.basic_io.sg_addr = scb->data_busaddr;
-   scb->flags |= IPS_SCB_MAP_SINGLE;
-
-   /* send command */
-   if (((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) == IPS_FAILURE) ||
-       (ret == IPS_SUCCESS_IMM) ||
-       ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1))
-      return (0);
+ips_read_subsystem_parameters(ips_ha_t * ha, int intr)
+{
+	ips_scb_t *scb;
+	int ret;
 
-   return (1);
+	METHOD_TRACE("ips_read_subsystem_parameters", 1);
+
+	scb = &ha->scbs[ha->max_cmds - 1];
+
+	ips_init_scb(ha, scb);
+
+	scb->timeout = ips_cmd_timeout;
+	scb->cdb[0] = IPS_CMD_GET_SUBSYS;
+
+	scb->cmd.basic_io.op_code = IPS_CMD_GET_SUBSYS;
+	scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->cmd.basic_io.sg_count = 0;
+	scb->cmd.basic_io.lba = 0;
+	scb->cmd.basic_io.sector_count = 0;
+	scb->cmd.basic_io.log_drv = 0;
+	scb->data_len = sizeof (*ha->subsys);
+	scb->data_busaddr = pci_map_single(ha->pcidev, ha->subsys,
+					   scb->data_len, IPS_DMA_DIR(scb));
+	scb->cmd.basic_io.sg_addr = scb->data_busaddr;
+	scb->flags |= IPS_SCB_MAP_SINGLE;
+
+	/* send command */
+	if (
+	    ((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) ==
+	     IPS_FAILURE) || (ret == IPS_SUCCESS_IMM)
+	    || ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1))
+		return (0);
+
+	return (1);
 }
 
 /****************************************************************************/
@@ -6414,51 +5932,53 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_read_config(ips_ha_t *ha, int intr) {
-   ips_scb_t *scb;
-   int        i;
-   int        ret;
-
-   METHOD_TRACE("ips_read_config", 1);
-
-   /* set defaults for initiator IDs */
-   for (i = 0; i < 4; i++)
-      ha->conf->init_id[i] = 7;
-
-   scb = &ha->scbs[ha->max_cmds-1];
-
-   ips_init_scb(ha, scb);
-
-   scb->timeout = ips_cmd_timeout;
-   scb->cdb[0] = IPS_CMD_READ_CONF;
-
-   scb->cmd.basic_io.op_code = IPS_CMD_READ_CONF;
-   scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->data_len = sizeof(*ha->conf);
-   scb->data_busaddr = pci_map_single(ha->pcidev, ha->conf,
-                                      scb->data_len, IPS_DMA_DIR(scb));
-   scb->cmd.basic_io.sg_addr = scb->data_busaddr;
-   scb->flags |= IPS_SCB_MAP_SINGLE;
-
-   /* send command */
-   if (((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) == IPS_FAILURE) ||
-       (ret == IPS_SUCCESS_IMM) ||
-       ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1)) {
-
-      memset(ha->conf, 0, sizeof(IPS_CONF));
-
-      /* reset initiator IDs */
-      for (i = 0; i < 4; i++)
-         ha->conf->init_id[i] = 7;
-
-      /* Allow Completed with Errors, so JCRM can access the Adapter to fix the problems */
-      if ((scb->basic_status & IPS_GSC_STATUS_MASK) == IPS_CMD_CMPLT_WERROR)   
-         return (1);                      
-      
-      return (0);
-   }
+ips_read_config(ips_ha_t * ha, int intr)
+{
+	ips_scb_t *scb;
+	int i;
+	int ret;
+
+	METHOD_TRACE("ips_read_config", 1);
 
-   return (1);
+	/* set defaults for initiator IDs */
+	for (i = 0; i < 4; i++)
+		ha->conf->init_id[i] = 7;
+
+	scb = &ha->scbs[ha->max_cmds - 1];
+
+	ips_init_scb(ha, scb);
+
+	scb->timeout = ips_cmd_timeout;
+	scb->cdb[0] = IPS_CMD_READ_CONF;
+
+	scb->cmd.basic_io.op_code = IPS_CMD_READ_CONF;
+	scb->cmd.basic_io.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->data_len = sizeof (*ha->conf);
+	scb->data_busaddr = pci_map_single(ha->pcidev, ha->conf,
+					   scb->data_len, IPS_DMA_DIR(scb));
+	scb->cmd.basic_io.sg_addr = scb->data_busaddr;
+	scb->flags |= IPS_SCB_MAP_SINGLE;
+
+	/* send command */
+	if (
+	    ((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) ==
+	     IPS_FAILURE) || (ret == IPS_SUCCESS_IMM)
+	    || ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1)) {
+
+		memset(ha->conf, 0, sizeof (IPS_CONF));
+
+		/* reset initiator IDs */
+		for (i = 0; i < 4; i++)
+			ha->conf->init_id[i] = 7;
+
+		/* Allow Completed with Errors, so JCRM can access the Adapter to fix the problems */
+		if ((scb->basic_status & IPS_GSC_STATUS_MASK) ==
+		    IPS_CMD_CMPLT_WERROR) return (1);
+
+		return (0);
+	}
+
+	return (1);
 }
 
 /****************************************************************************/
@@ -6471,42 +5991,44 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_readwrite_page5(ips_ha_t *ha, int write, int intr) {
-   ips_scb_t *scb;
-   int        ret;
-
-   METHOD_TRACE("ips_readwrite_page5", 1);
-
-   scb = &ha->scbs[ha->max_cmds-1];
-
-   ips_init_scb(ha, scb);
-
-   scb->timeout = ips_cmd_timeout;
-   scb->cdb[0] = IPS_CMD_RW_NVRAM_PAGE;
-
-   scb->cmd.nvram.op_code = IPS_CMD_RW_NVRAM_PAGE;
-   scb->cmd.nvram.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->cmd.nvram.page = 5;
-   scb->cmd.nvram.write = write;
-   scb->cmd.nvram.reserved = 0;
-   scb->cmd.nvram.reserved2 = 0;
-   scb->data_len = sizeof(*ha->nvram);
-   scb->data_busaddr = pci_map_single(ha->pcidev, ha->nvram,
-                                      scb->data_len, IPS_DMA_DIR(scb));
-   scb->cmd.nvram.buffer_addr = scb->data_busaddr;
-   scb->flags |= IPS_SCB_MAP_SINGLE;
-
-   /* issue the command */
-   if (((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) == IPS_FAILURE) ||
-       (ret == IPS_SUCCESS_IMM) ||
-       ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1)) {
+ips_readwrite_page5(ips_ha_t * ha, int write, int intr)
+{
+	ips_scb_t *scb;
+	int ret;
+
+	METHOD_TRACE("ips_readwrite_page5", 1);
+
+	scb = &ha->scbs[ha->max_cmds - 1];
 
-      memset(ha->nvram, 0, sizeof(IPS_NVRAM_P5));
+	ips_init_scb(ha, scb);
 
-      return (0);
-   }
+	scb->timeout = ips_cmd_timeout;
+	scb->cdb[0] = IPS_CMD_RW_NVRAM_PAGE;
+
+	scb->cmd.nvram.op_code = IPS_CMD_RW_NVRAM_PAGE;
+	scb->cmd.nvram.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->cmd.nvram.page = 5;
+	scb->cmd.nvram.write = write;
+	scb->cmd.nvram.reserved = 0;
+	scb->cmd.nvram.reserved2 = 0;
+	scb->data_len = sizeof (*ha->nvram);
+	scb->data_busaddr = pci_map_single(ha->pcidev, ha->nvram,
+					   scb->data_len, IPS_DMA_DIR(scb));
+	scb->cmd.nvram.buffer_addr = scb->data_busaddr;
+	scb->flags |= IPS_SCB_MAP_SINGLE;
+
+	/* issue the command */
+	if (
+	    ((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) ==
+	     IPS_FAILURE) || (ret == IPS_SUCCESS_IMM)
+	    || ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1)) {
 
-   return (1);
+		memset(ha->nvram, 0, sizeof (IPS_NVRAM_P5));
+
+		return (0);
+	}
+
+	return (1);
 }
 
 /****************************************************************************/
@@ -6519,54 +6041,57 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_clear_adapter(ips_ha_t *ha, int intr) {
-   ips_scb_t *scb;
-   int        ret;
-
-   METHOD_TRACE("ips_clear_adapter", 1);
-
-   scb = &ha->scbs[ha->max_cmds-1];
-
-   ips_init_scb(ha, scb);
-
-   scb->timeout = ips_reset_timeout;
-   scb->cdb[0] = IPS_CMD_CONFIG_SYNC;
-
-   scb->cmd.config_sync.op_code = IPS_CMD_CONFIG_SYNC;
-   scb->cmd.config_sync.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->cmd.config_sync.channel = 0;
-   scb->cmd.config_sync.source_target = IPS_POCL;
-   scb->cmd.config_sync.reserved = 0;
-   scb->cmd.config_sync.reserved2 = 0;
-   scb->cmd.config_sync.reserved3 = 0;
-
-   /* issue command */
-   if (((ret = ips_send_wait(ha, scb, ips_reset_timeout, intr)) == IPS_FAILURE) ||
-       (ret == IPS_SUCCESS_IMM) ||
-       ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1))
-      return (0);
-
-   /* send unlock stripe command */
-   ips_init_scb(ha, scb);
-
-   scb->cdb[0] = IPS_CMD_ERROR_TABLE;
-   scb->timeout = ips_reset_timeout;
-
-   scb->cmd.unlock_stripe.op_code = IPS_CMD_ERROR_TABLE;
-   scb->cmd.unlock_stripe.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->cmd.unlock_stripe.log_drv = 0;
-   scb->cmd.unlock_stripe.control = IPS_CSL;
-   scb->cmd.unlock_stripe.reserved = 0;
-   scb->cmd.unlock_stripe.reserved2 = 0;
-   scb->cmd.unlock_stripe.reserved3 = 0;
-
-   /* issue command */
-   if (((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) == IPS_FAILURE) ||
-       (ret == IPS_SUCCESS_IMM) ||
-       ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1))
-      return (0);
+ips_clear_adapter(ips_ha_t * ha, int intr)
+{
+	ips_scb_t *scb;
+	int ret;
+
+	METHOD_TRACE("ips_clear_adapter", 1);
+
+	scb = &ha->scbs[ha->max_cmds - 1];
+
+	ips_init_scb(ha, scb);
+
+	scb->timeout = ips_reset_timeout;
+	scb->cdb[0] = IPS_CMD_CONFIG_SYNC;
+
+	scb->cmd.config_sync.op_code = IPS_CMD_CONFIG_SYNC;
+	scb->cmd.config_sync.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->cmd.config_sync.channel = 0;
+	scb->cmd.config_sync.source_target = IPS_POCL;
+	scb->cmd.config_sync.reserved = 0;
+	scb->cmd.config_sync.reserved2 = 0;
+	scb->cmd.config_sync.reserved3 = 0;
+
+	/* issue command */
+	if (
+	    ((ret = ips_send_wait(ha, scb, ips_reset_timeout, intr)) ==
+	     IPS_FAILURE) || (ret == IPS_SUCCESS_IMM)
+	    || ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1))
+		return (0);
+
+	/* send unlock stripe command */
+	ips_init_scb(ha, scb);
+
+	scb->cdb[0] = IPS_CMD_ERROR_TABLE;
+	scb->timeout = ips_reset_timeout;
+
+	scb->cmd.unlock_stripe.op_code = IPS_CMD_ERROR_TABLE;
+	scb->cmd.unlock_stripe.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->cmd.unlock_stripe.log_drv = 0;
+	scb->cmd.unlock_stripe.control = IPS_CSL;
+	scb->cmd.unlock_stripe.reserved = 0;
+	scb->cmd.unlock_stripe.reserved2 = 0;
+	scb->cmd.unlock_stripe.reserved3 = 0;
+
+	/* issue command */
+	if (
+	    ((ret = ips_send_wait(ha, scb, ips_cmd_timeout, intr)) ==
+	     IPS_FAILURE) || (ret == IPS_SUCCESS_IMM)
+	    || ((scb->basic_status & IPS_GSC_STATUS_MASK) > 1))
+		return (0);
 
-   return (1);
+	return (1);
 }
 
 /****************************************************************************/
@@ -6579,27 +6104,28 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_ffdc_reset(ips_ha_t *ha, int intr) {
-   ips_scb_t *scb;
+ips_ffdc_reset(ips_ha_t * ha, int intr)
+{
+	ips_scb_t *scb;
 
-   METHOD_TRACE("ips_ffdc_reset", 1);
+	METHOD_TRACE("ips_ffdc_reset", 1);
 
-   scb = &ha->scbs[ha->max_cmds-1];
+	scb = &ha->scbs[ha->max_cmds - 1];
 
-   ips_init_scb(ha, scb);
+	ips_init_scb(ha, scb);
 
-   scb->timeout = ips_cmd_timeout;
-   scb->cdb[0] = IPS_CMD_FFDC;
-   scb->cmd.ffdc.op_code = IPS_CMD_FFDC;
-   scb->cmd.ffdc.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->cmd.ffdc.reset_count = ha->reset_count;
-   scb->cmd.ffdc.reset_type = 0x80;
+	scb->timeout = ips_cmd_timeout;
+	scb->cdb[0] = IPS_CMD_FFDC;
+	scb->cmd.ffdc.op_code = IPS_CMD_FFDC;
+	scb->cmd.ffdc.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->cmd.ffdc.reset_count = ha->reset_count;
+	scb->cmd.ffdc.reset_type = 0x80;
 
-   /* convert time to what the card wants */
-   ips_fix_ffdc_time(ha, scb, ha->last_ffdc);
+	/* convert time to what the card wants */
+	ips_fix_ffdc_time(ha, scb, ha->last_ffdc);
 
-   /* issue command */
-   ips_send_wait(ha, scb, ips_cmd_timeout, intr);
+	/* issue command */
+	ips_send_wait(ha, scb, ips_cmd_timeout, intr);
 }
 
 /****************************************************************************/
@@ -6612,30 +6138,30 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_ffdc_time(ips_ha_t *ha) {
-   ips_scb_t *scb;
+ips_ffdc_time(ips_ha_t * ha)
+{
+	ips_scb_t *scb;
 
-   METHOD_TRACE("ips_ffdc_time", 1);
+	METHOD_TRACE("ips_ffdc_time", 1);
 
-   DEBUG_VAR(1, "(%s%d) Sending time update.",
-             ips_name, ha->host_num);
+	DEBUG_VAR(1, "(%s%d) Sending time update.", ips_name, ha->host_num);
 
-   scb = &ha->scbs[ha->max_cmds-1];
+	scb = &ha->scbs[ha->max_cmds - 1];
 
-   ips_init_scb(ha, scb);
+	ips_init_scb(ha, scb);
 
-   scb->timeout = ips_cmd_timeout;
-   scb->cdb[0] = IPS_CMD_FFDC;
-   scb->cmd.ffdc.op_code = IPS_CMD_FFDC;
-   scb->cmd.ffdc.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->cmd.ffdc.reset_count = 0;
-   scb->cmd.ffdc.reset_type = 0x80;
+	scb->timeout = ips_cmd_timeout;
+	scb->cdb[0] = IPS_CMD_FFDC;
+	scb->cmd.ffdc.op_code = IPS_CMD_FFDC;
+	scb->cmd.ffdc.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->cmd.ffdc.reset_count = 0;
+	scb->cmd.ffdc.reset_type = 0x80;
 
-   /* convert time to what the card wants */
-   ips_fix_ffdc_time(ha, scb, ha->last_ffdc);
+	/* convert time to what the card wants */
+	ips_fix_ffdc_time(ha, scb, ha->last_ffdc);
 
-   /* issue command */
-   ips_send_wait(ha, scb, ips_cmd_timeout, IPS_FFDC);
+	/* issue command */
+	ips_send_wait(ha, scb, ips_cmd_timeout, IPS_FFDC);
 }
 
 /****************************************************************************/
@@ -6647,57 +6173,59 @@
 /*                                                                          */
 /****************************************************************************/
 static void
-ips_fix_ffdc_time(ips_ha_t *ha, ips_scb_t *scb, time_t current_time) {
-   long days;
-   long rem;
-   int  i;
-   int  year;
-   int  yleap;
-   int  year_lengths[2] = { IPS_DAYS_NORMAL_YEAR, IPS_DAYS_LEAP_YEAR };
-   int  month_lengths[12][2] = { {31, 31},
-                                 {28, 29},
-                                 {31, 31},
-                                 {30, 30},
-                                 {31, 31},
-                                 {30, 30},
-                                 {31, 31},
-                                 {31, 31},
-                                 {30, 30},
-                                 {31, 31},
-                                 {30, 30},
-                                 {31, 31} };
-
-   METHOD_TRACE("ips_fix_ffdc_time", 1);
-
-   days = current_time / IPS_SECS_DAY;
-   rem = current_time % IPS_SECS_DAY;
-
-   scb->cmd.ffdc.hour = (rem / IPS_SECS_HOUR);
-   rem = rem % IPS_SECS_HOUR;
-   scb->cmd.ffdc.minute = (rem / IPS_SECS_MIN);
-   scb->cmd.ffdc.second = (rem % IPS_SECS_MIN);
-
-   year = IPS_EPOCH_YEAR;
-   while (days < 0 || days >= year_lengths[yleap = IPS_IS_LEAP_YEAR(year)]) {
-      int newy;
-
-      newy = year + (days / IPS_DAYS_NORMAL_YEAR);
-      if (days < 0)
-         --newy;
-      days -= (newy - year) * IPS_DAYS_NORMAL_YEAR +
-         IPS_NUM_LEAP_YEARS_THROUGH(newy - 1) -
-         IPS_NUM_LEAP_YEARS_THROUGH(year - 1);
-      year = newy;
-   }
+ips_fix_ffdc_time(ips_ha_t * ha, ips_scb_t * scb, time_t current_time)
+{
+	long days;
+	long rem;
+	int i;
+	int year;
+	int yleap;
+	int year_lengths[2] = { IPS_DAYS_NORMAL_YEAR, IPS_DAYS_LEAP_YEAR };
+	int month_lengths[12][2] = { {31, 31},
+	{28, 29},
+	{31, 31},
+	{30, 30},
+	{31, 31},
+	{30, 30},
+	{31, 31},
+	{31, 31},
+	{30, 30},
+	{31, 31},
+	{30, 30},
+	{31, 31}
+	};
+
+	METHOD_TRACE("ips_fix_ffdc_time", 1);
+
+	days = current_time / IPS_SECS_DAY;
+	rem = current_time % IPS_SECS_DAY;
+
+	scb->cmd.ffdc.hour = (rem / IPS_SECS_HOUR);
+	rem = rem % IPS_SECS_HOUR;
+	scb->cmd.ffdc.minute = (rem / IPS_SECS_MIN);
+	scb->cmd.ffdc.second = (rem % IPS_SECS_MIN);
+
+	year = IPS_EPOCH_YEAR;
+	while (days < 0 || days >= year_lengths[yleap = IPS_IS_LEAP_YEAR(year)]) {
+		int newy;
+
+		newy = year + (days / IPS_DAYS_NORMAL_YEAR);
+		if (days < 0)
+			--newy;
+		days -= (newy - year) * IPS_DAYS_NORMAL_YEAR +
+		    IPS_NUM_LEAP_YEARS_THROUGH(newy - 1) -
+		    IPS_NUM_LEAP_YEARS_THROUGH(year - 1);
+		year = newy;
+	}
 
-   scb->cmd.ffdc.yearH = year / 100;
-   scb->cmd.ffdc.yearL = year % 100;
+	scb->cmd.ffdc.yearH = year / 100;
+	scb->cmd.ffdc.yearL = year % 100;
 
-   for (i = 0; days >= month_lengths[i][yleap]; ++i)
-      days -= month_lengths[i][yleap];
+	for (i = 0; days >= month_lengths[i][yleap]; ++i)
+		days -= month_lengths[i][yleap];
 
-   scb->cmd.ffdc.month = i + 1;
-   scb->cmd.ffdc.day = days + 1;
+	scb->cmd.ffdc.month = i + 1;
+	scb->cmd.ffdc.day = days + 1;
 }
 
 /****************************************************************************
@@ -6713,106 +6241,107 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_erase_bios(ips_ha_t *ha) {
-   int      timeout;
-   uint8_t  status=0;
-
-   METHOD_TRACE("ips_erase_bios", 1);
-
-   status = 0;
-
-   /* Clear the status register */
-   outl(0, ha->io_addr + IPS_REG_FLAP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   outb(0x50, ha->io_addr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   /* Erase Setup */
-   outb(0x20, ha->io_addr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   /* Erase Confirm */
-   outb(0xD0, ha->io_addr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   /* Erase Status */
-   outb(0x70, ha->io_addr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   timeout = 80000; /* 80 seconds */
-
-   while (timeout > 0) {
-      if (ha->revision_id == IPS_REVID_TROMBONE64) {
-         outl(0, ha->io_addr + IPS_REG_FLAP);
-         udelay(25); /* 25 us */
-      }
-
-      status = inb(ha->io_addr + IPS_REG_FLDP);
-
-      if (status & 0x80)
-         break;
-
-      MDELAY(1);
-      timeout--;
-   }
-
-   /* check for timeout */
-   if (timeout <= 0) {
-      /* timeout */
-
-      /* try to suspend the erase */
-      outb(0xB0, ha->io_addr + IPS_REG_FLDP);
-      if (ha->revision_id == IPS_REVID_TROMBONE64)
-         udelay(25); /* 25 us */
-
-      /* wait for 10 seconds */
-      timeout = 10000;
-      while (timeout > 0) {
-         if (ha->revision_id == IPS_REVID_TROMBONE64) {
-            outl(0, ha->io_addr + IPS_REG_FLAP);
-            udelay(25); /* 25 us */
-         }
-
-         status = inb(ha->io_addr + IPS_REG_FLDP);
-
-         if (status & 0xC0)
-            break;
-
-         MDELAY(1);
-         timeout--;
-      }
-
-      return (1);
-   }
-
-   /* check for valid VPP */
-   if (status & 0x08)
-      /* VPP failure */
-      return (1);
-
-   /* check for succesful flash */
-   if (status & 0x30)
-      /* sequence error */
-      return (1);
-
-   /* Otherwise, we were successful */
-   /* clear status */
-   outb(0x50, ha->io_addr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   /* enable reads */
-   outb(0xFF, ha->io_addr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
+ips_erase_bios(ips_ha_t * ha)
+{
+	int timeout;
+	uint8_t status = 0;
+
+	METHOD_TRACE("ips_erase_bios", 1);
+
+	status = 0;
 
-   return (0);
+	/* Clear the status register */
+	outl(0, ha->io_addr + IPS_REG_FLAP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	outb(0x50, ha->io_addr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	/* Erase Setup */
+	outb(0x20, ha->io_addr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	/* Erase Confirm */
+	outb(0xD0, ha->io_addr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	/* Erase Status */
+	outb(0x70, ha->io_addr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	timeout = 80000;	/* 80 seconds */
+
+	while (timeout > 0) {
+		if (ha->revision_id == IPS_REVID_TROMBONE64) {
+			outl(0, ha->io_addr + IPS_REG_FLAP);
+			udelay(25);	/* 25 us */
+		}
+
+		status = inb(ha->io_addr + IPS_REG_FLDP);
+
+		if (status & 0x80)
+			break;
+
+		MDELAY(1);
+		timeout--;
+	}
+
+	/* check for timeout */
+	if (timeout <= 0) {
+		/* timeout */
+
+		/* try to suspend the erase */
+		outb(0xB0, ha->io_addr + IPS_REG_FLDP);
+		if (ha->revision_id == IPS_REVID_TROMBONE64)
+			udelay(25);	/* 25 us */
+
+		/* wait for 10 seconds */
+		timeout = 10000;
+		while (timeout > 0) {
+			if (ha->revision_id == IPS_REVID_TROMBONE64) {
+				outl(0, ha->io_addr + IPS_REG_FLAP);
+				udelay(25);	/* 25 us */
+			}
+
+			status = inb(ha->io_addr + IPS_REG_FLDP);
+
+			if (status & 0xC0)
+				break;
+
+			MDELAY(1);
+			timeout--;
+		}
+
+		return (1);
+	}
+
+	/* check for valid VPP */
+	if (status & 0x08)
+		/* VPP failure */
+		return (1);
+
+	/* check for succesful flash */
+	if (status & 0x30)
+		/* sequence error */
+		return (1);
+
+	/* Otherwise, we were successful */
+	/* clear status */
+	outb(0x50, ha->io_addr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	/* enable reads */
+	outb(0xFF, ha->io_addr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	return (0);
 }
 
 /****************************************************************************/
@@ -6824,106 +6353,107 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_erase_bios_memio(ips_ha_t *ha) {
-   int      timeout;
-   uint8_t  status;
-
-   METHOD_TRACE("ips_erase_bios_memio", 1);
-
-   status = 0;
-
-   /* Clear the status register */
-   writel(0, ha->mem_ptr + IPS_REG_FLAP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   writeb(0x50, ha->mem_ptr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   /* Erase Setup */
-   writeb(0x20, ha->mem_ptr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   /* Erase Confirm */
-   writeb(0xD0, ha->mem_ptr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   /* Erase Status */
-   writeb(0x70, ha->mem_ptr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   timeout = 80000; /* 80 seconds */
-
-   while (timeout > 0) {
-      if (ha->revision_id == IPS_REVID_TROMBONE64) {
-         writel(0, ha->mem_ptr + IPS_REG_FLAP);
-         udelay(25); /* 25 us */
-      }
-
-      status = readb(ha->mem_ptr + IPS_REG_FLDP);
-
-      if (status & 0x80)
-         break;
-
-      MDELAY(1);
-      timeout--;
-   }
-
-   /* check for timeout */
-   if (timeout <= 0) {
-      /* timeout */
-
-      /* try to suspend the erase */
-      writeb(0xB0, ha->mem_ptr + IPS_REG_FLDP);
-      if (ha->revision_id == IPS_REVID_TROMBONE64)
-         udelay(25); /* 25 us */
-
-      /* wait for 10 seconds */
-      timeout = 10000;
-      while (timeout > 0) {
-         if (ha->revision_id == IPS_REVID_TROMBONE64) {
-            writel(0, ha->mem_ptr + IPS_REG_FLAP);
-            udelay(25); /* 25 us */
-         }
-
-         status = readb(ha->mem_ptr + IPS_REG_FLDP);
-
-         if (status & 0xC0)
-            break;
-
-         MDELAY(1);
-         timeout--;
-      }
-
-      return (1);
-   }
-
-   /* check for valid VPP */
-   if (status & 0x08)
-      /* VPP failure */
-      return (1);
-
-   /* check for succesful flash */
-   if (status & 0x30)
-      /* sequence error */
-      return (1);
-
-   /* Otherwise, we were successful */
-   /* clear status */
-   writeb(0x50, ha->mem_ptr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   /* enable reads */
-   writeb(0xFF, ha->mem_ptr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
+ips_erase_bios_memio(ips_ha_t * ha)
+{
+	int timeout;
+	uint8_t status;
+
+	METHOD_TRACE("ips_erase_bios_memio", 1);
+
+	status = 0;
 
-   return (0);
+	/* Clear the status register */
+	writel(0, ha->mem_ptr + IPS_REG_FLAP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	writeb(0x50, ha->mem_ptr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	/* Erase Setup */
+	writeb(0x20, ha->mem_ptr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	/* Erase Confirm */
+	writeb(0xD0, ha->mem_ptr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	/* Erase Status */
+	writeb(0x70, ha->mem_ptr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	timeout = 80000;	/* 80 seconds */
+
+	while (timeout > 0) {
+		if (ha->revision_id == IPS_REVID_TROMBONE64) {
+			writel(0, ha->mem_ptr + IPS_REG_FLAP);
+			udelay(25);	/* 25 us */
+		}
+
+		status = readb(ha->mem_ptr + IPS_REG_FLDP);
+
+		if (status & 0x80)
+			break;
+
+		MDELAY(1);
+		timeout--;
+	}
+
+	/* check for timeout */
+	if (timeout <= 0) {
+		/* timeout */
+
+		/* try to suspend the erase */
+		writeb(0xB0, ha->mem_ptr + IPS_REG_FLDP);
+		if (ha->revision_id == IPS_REVID_TROMBONE64)
+			udelay(25);	/* 25 us */
+
+		/* wait for 10 seconds */
+		timeout = 10000;
+		while (timeout > 0) {
+			if (ha->revision_id == IPS_REVID_TROMBONE64) {
+				writel(0, ha->mem_ptr + IPS_REG_FLAP);
+				udelay(25);	/* 25 us */
+			}
+
+			status = readb(ha->mem_ptr + IPS_REG_FLDP);
+
+			if (status & 0xC0)
+				break;
+
+			MDELAY(1);
+			timeout--;
+		}
+
+		return (1);
+	}
+
+	/* check for valid VPP */
+	if (status & 0x08)
+		/* VPP failure */
+		return (1);
+
+	/* check for succesful flash */
+	if (status & 0x30)
+		/* sequence error */
+		return (1);
+
+	/* Otherwise, we were successful */
+	/* clear status */
+	writeb(0x50, ha->mem_ptr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	/* enable reads */
+	writeb(0xFF, ha->mem_ptr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	return (0);
 }
 
 /****************************************************************************/
@@ -6935,84 +6465,86 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_program_bios(ips_ha_t *ha, char *buffer, uint32_t buffersize, uint32_t offset) {
-   int      i;
-   int      timeout;
-   uint8_t  status=0;
-
-   METHOD_TRACE("ips_program_bios", 1);
-
-   status = 0;
-
-   for (i = 0; i < buffersize; i++) {
-      /* write a byte */
-      outl(cpu_to_le32(i + offset), ha->io_addr + IPS_REG_FLAP);
-      if (ha->revision_id == IPS_REVID_TROMBONE64)
-         udelay(25); /* 25 us */
-
-      outb(0x40, ha->io_addr + IPS_REG_FLDP);
-      if (ha->revision_id == IPS_REVID_TROMBONE64)
-         udelay(25); /* 25 us */
-
-      outb(buffer[i], ha->io_addr + IPS_REG_FLDP);
-      if (ha->revision_id == IPS_REVID_TROMBONE64)
-         udelay(25); /* 25 us */
-
-      /* wait up to one second */
-      timeout = 1000;
-      while (timeout > 0) {
-         if (ha->revision_id == IPS_REVID_TROMBONE64) {
-            outl(0, ha->io_addr + IPS_REG_FLAP);
-            udelay(25); /* 25 us */
-         }
-
-         status = inb(ha->io_addr + IPS_REG_FLDP);
-
-         if (status & 0x80)
-            break;
-
-         MDELAY(1);
-         timeout--;
-      }
-
-      if (timeout == 0) {
-         /* timeout error */
-         outl(0, ha->io_addr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         outb(0xFF, ha->io_addr + IPS_REG_FLDP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         return (1);
-      }
-
-      /* check the status */
-      if (status & 0x18) {
-         /* programming error */
-         outl(0, ha->io_addr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         outb(0xFF, ha->io_addr + IPS_REG_FLDP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         return (1);
-      }
-   } /* end for */
-
-   /* Enable reading */
-   outl(0, ha->io_addr + IPS_REG_FLAP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   outb(0xFF, ha->io_addr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
+ips_program_bios(ips_ha_t * ha, char *buffer, uint32_t buffersize,
+		 uint32_t offset)
+{
+	int i;
+	int timeout;
+	uint8_t status = 0;
+
+	METHOD_TRACE("ips_program_bios", 1);
+
+	status = 0;
+
+	for (i = 0; i < buffersize; i++) {
+		/* write a byte */
+		outl(cpu_to_le32(i + offset), ha->io_addr + IPS_REG_FLAP);
+		if (ha->revision_id == IPS_REVID_TROMBONE64)
+			udelay(25);	/* 25 us */
+
+		outb(0x40, ha->io_addr + IPS_REG_FLDP);
+		if (ha->revision_id == IPS_REVID_TROMBONE64)
+			udelay(25);	/* 25 us */
+
+		outb(buffer[i], ha->io_addr + IPS_REG_FLDP);
+		if (ha->revision_id == IPS_REVID_TROMBONE64)
+			udelay(25);	/* 25 us */
+
+		/* wait up to one second */
+		timeout = 1000;
+		while (timeout > 0) {
+			if (ha->revision_id == IPS_REVID_TROMBONE64) {
+				outl(0, ha->io_addr + IPS_REG_FLAP);
+				udelay(25);	/* 25 us */
+			}
+
+			status = inb(ha->io_addr + IPS_REG_FLDP);
+
+			if (status & 0x80)
+				break;
+
+			MDELAY(1);
+			timeout--;
+		}
+
+		if (timeout == 0) {
+			/* timeout error */
+			outl(0, ha->io_addr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			outb(0xFF, ha->io_addr + IPS_REG_FLDP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			return (1);
+		}
+
+		/* check the status */
+		if (status & 0x18) {
+			/* programming error */
+			outl(0, ha->io_addr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			outb(0xFF, ha->io_addr + IPS_REG_FLDP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			return (1);
+		}
+	}			/* end for */
+
+	/* Enable reading */
+	outl(0, ha->io_addr + IPS_REG_FLAP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	outb(0xFF, ha->io_addr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
 
-   return (0);
+	return (0);
 }
 
 /****************************************************************************/
@@ -7024,84 +6556,86 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_program_bios_memio(ips_ha_t *ha, char *buffer, uint32_t buffersize, uint32_t offset) {
-   int      i;
-   int      timeout;
-   uint8_t  status=0;
-
-   METHOD_TRACE("ips_program_bios_memio", 1);
-
-   status = 0;
-
-   for (i = 0; i < buffersize; i++) {
-      /* write a byte */
-      writel(i + offset, ha->mem_ptr + IPS_REG_FLAP);
-      if (ha->revision_id == IPS_REVID_TROMBONE64)
-         udelay(25); /* 25 us */
-
-      writeb(0x40, ha->mem_ptr + IPS_REG_FLDP);
-      if (ha->revision_id == IPS_REVID_TROMBONE64)
-         udelay(25); /* 25 us */
-
-      writeb(buffer[i], ha->mem_ptr + IPS_REG_FLDP);
-      if (ha->revision_id == IPS_REVID_TROMBONE64)
-         udelay(25); /* 25 us */
-
-      /* wait up to one second */
-      timeout = 1000;
-      while (timeout > 0) {
-         if (ha->revision_id == IPS_REVID_TROMBONE64) {
-            writel(0, ha->mem_ptr + IPS_REG_FLAP);
-            udelay(25); /* 25 us */
-         }
-
-         status = readb(ha->mem_ptr + IPS_REG_FLDP);
-
-         if (status & 0x80)
-            break;
-
-         MDELAY(1);
-         timeout--;
-      }
-
-      if (timeout == 0) {
-         /* timeout error */
-         writel(0, ha->mem_ptr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         writeb(0xFF, ha->mem_ptr + IPS_REG_FLDP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         return (1);
-      }
-
-      /* check the status */
-      if (status & 0x18) {
-         /* programming error */
-         writel(0, ha->mem_ptr + IPS_REG_FLAP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         writeb(0xFF, ha->mem_ptr + IPS_REG_FLDP);
-         if (ha->revision_id == IPS_REVID_TROMBONE64)
-            udelay(25); /* 25 us */
-
-         return (1);
-      }
-   } /* end for */
-
-   /* Enable reading */
-   writel(0, ha->mem_ptr + IPS_REG_FLAP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   writeb(0xFF, ha->mem_ptr + IPS_REG_FLDP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
+ips_program_bios_memio(ips_ha_t * ha, char *buffer, uint32_t buffersize,
+		       uint32_t offset)
+{
+	int i;
+	int timeout;
+	uint8_t status = 0;
+
+	METHOD_TRACE("ips_program_bios_memio", 1);
+
+	status = 0;
+
+	for (i = 0; i < buffersize; i++) {
+		/* write a byte */
+		writel(i + offset, ha->mem_ptr + IPS_REG_FLAP);
+		if (ha->revision_id == IPS_REVID_TROMBONE64)
+			udelay(25);	/* 25 us */
+
+		writeb(0x40, ha->mem_ptr + IPS_REG_FLDP);
+		if (ha->revision_id == IPS_REVID_TROMBONE64)
+			udelay(25);	/* 25 us */
+
+		writeb(buffer[i], ha->mem_ptr + IPS_REG_FLDP);
+		if (ha->revision_id == IPS_REVID_TROMBONE64)
+			udelay(25);	/* 25 us */
+
+		/* wait up to one second */
+		timeout = 1000;
+		while (timeout > 0) {
+			if (ha->revision_id == IPS_REVID_TROMBONE64) {
+				writel(0, ha->mem_ptr + IPS_REG_FLAP);
+				udelay(25);	/* 25 us */
+			}
+
+			status = readb(ha->mem_ptr + IPS_REG_FLDP);
+
+			if (status & 0x80)
+				break;
+
+			MDELAY(1);
+			timeout--;
+		}
+
+		if (timeout == 0) {
+			/* timeout error */
+			writel(0, ha->mem_ptr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			writeb(0xFF, ha->mem_ptr + IPS_REG_FLDP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			return (1);
+		}
+
+		/* check the status */
+		if (status & 0x18) {
+			/* programming error */
+			writel(0, ha->mem_ptr + IPS_REG_FLAP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			writeb(0xFF, ha->mem_ptr + IPS_REG_FLDP);
+			if (ha->revision_id == IPS_REVID_TROMBONE64)
+				udelay(25);	/* 25 us */
+
+			return (1);
+		}
+	}			/* end for */
+
+	/* Enable reading */
+	writel(0, ha->mem_ptr + IPS_REG_FLAP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	writeb(0xFF, ha->mem_ptr + IPS_REG_FLDP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
 
-   return (0);
+	return (0);
 }
 
 /****************************************************************************/
@@ -7113,42 +6647,44 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_verify_bios(ips_ha_t *ha, char *buffer, uint32_t buffersize, uint32_t offset) {
-   uint8_t  checksum;
-   int      i;
-
-   METHOD_TRACE("ips_verify_bios", 1);
-
-   /* test 1st byte */
-   outl(0, ha->io_addr + IPS_REG_FLAP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   if (inb(ha->io_addr + IPS_REG_FLDP) != 0x55)
-      return (1);
-
-   outl(cpu_to_le32(1), ha->io_addr + IPS_REG_FLAP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-   if (inb(ha->io_addr + IPS_REG_FLDP) != 0xAA)
-      return (1);
-
-   checksum = 0xff;
-   for (i = 2; i < buffersize; i++) {
-
-      outl(cpu_to_le32(i + offset), ha->io_addr + IPS_REG_FLAP);
-      if (ha->revision_id == IPS_REVID_TROMBONE64)
-         udelay(25); /* 25 us */
-
-      checksum = (uint8_t) checksum + inb(ha->io_addr + IPS_REG_FLDP);
-   }
-
-   if (checksum != 0)
-      /* failure */
-      return (1);
-   else
-      /* success */
-      return (0);
+ips_verify_bios(ips_ha_t * ha, char *buffer, uint32_t buffersize,
+		uint32_t offset)
+{
+	uint8_t checksum;
+	int i;
+
+	METHOD_TRACE("ips_verify_bios", 1);
+
+	/* test 1st byte */
+	outl(0, ha->io_addr + IPS_REG_FLAP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	if (inb(ha->io_addr + IPS_REG_FLDP) != 0x55)
+		return (1);
+
+	outl(cpu_to_le32(1), ha->io_addr + IPS_REG_FLAP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+	if (inb(ha->io_addr + IPS_REG_FLDP) != 0xAA)
+		return (1);
+
+	checksum = 0xff;
+	for (i = 2; i < buffersize; i++) {
+
+		outl(cpu_to_le32(i + offset), ha->io_addr + IPS_REG_FLAP);
+		if (ha->revision_id == IPS_REVID_TROMBONE64)
+			udelay(25);	/* 25 us */
+
+		checksum = (uint8_t) checksum + inb(ha->io_addr + IPS_REG_FLDP);
+	}
+
+	if (checksum != 0)
+		/* failure */
+		return (1);
+	else
+		/* success */
+		return (0);
 }
 
 /****************************************************************************/
@@ -7160,42 +6696,45 @@
 /*                                                                          */
 /****************************************************************************/
 static int
-ips_verify_bios_memio(ips_ha_t *ha, char *buffer, uint32_t buffersize, uint32_t offset) {
-   uint8_t  checksum;
-   int      i;
-
-   METHOD_TRACE("ips_verify_bios_memio", 1);
-
-   /* test 1st byte */
-   writel(0, ha->mem_ptr + IPS_REG_FLAP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-
-   if (readb(ha->mem_ptr + IPS_REG_FLDP) != 0x55)
-      return (1);
-
-   writel(1, ha->mem_ptr + IPS_REG_FLAP);
-   if (ha->revision_id == IPS_REVID_TROMBONE64)
-      udelay(25); /* 25 us */
-   if (readb(ha->mem_ptr + IPS_REG_FLDP) != 0xAA)
-      return (1);
-
-   checksum = 0xff;
-   for (i = 2; i < buffersize; i++) {
-
-      writel(i + offset, ha->mem_ptr + IPS_REG_FLAP);
-      if (ha->revision_id == IPS_REVID_TROMBONE64)
-         udelay(25); /* 25 us */
-
-      checksum = (uint8_t) checksum + readb(ha->mem_ptr + IPS_REG_FLDP);
-   }
-
-   if (checksum != 0)
-      /* failure */
-      return (1);
-   else
-      /* success */
-      return (0);
+ips_verify_bios_memio(ips_ha_t * ha, char *buffer, uint32_t buffersize,
+		      uint32_t offset)
+{
+	uint8_t checksum;
+	int i;
+
+	METHOD_TRACE("ips_verify_bios_memio", 1);
+
+	/* test 1st byte */
+	writel(0, ha->mem_ptr + IPS_REG_FLAP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+
+	if (readb(ha->mem_ptr + IPS_REG_FLDP) != 0x55)
+		return (1);
+
+	writel(1, ha->mem_ptr + IPS_REG_FLAP);
+	if (ha->revision_id == IPS_REVID_TROMBONE64)
+		udelay(25);	/* 25 us */
+	if (readb(ha->mem_ptr + IPS_REG_FLDP) != 0xAA)
+		return (1);
+
+	checksum = 0xff;
+	for (i = 2; i < buffersize; i++) {
+
+		writel(i + offset, ha->mem_ptr + IPS_REG_FLAP);
+		if (ha->revision_id == IPS_REVID_TROMBONE64)
+			udelay(25);	/* 25 us */
+
+		checksum =
+		    (uint8_t) checksum + readb(ha->mem_ptr + IPS_REG_FLDP);
+	}
+
+	if (checksum != 0)
+		/* failure */
+		return (1);
+	else
+		/* success */
+		return (0);
 }
 
 /*---------------------------------------------------------------------------*/
@@ -7208,77 +6747,82 @@
 /*     Data is available.                                                    */
 /*                                                                           */
 /*---------------------------------------------------------------------------*/
-static void ips_version_check(ips_ha_t *ha, int intr) {
- IPS_VERSION_DATA VersionInfo;
- uint8_t  FirmwareVersion[ IPS_COMPAT_ID_LENGTH + 1 ];
- uint8_t  BiosVersion[ IPS_COMPAT_ID_LENGTH + 1];
- int      MatchError;
- int      rc;
- char     BiosString[10];
- char     FirmwareString[10];
-
- METHOD_TRACE("ips_version_check", 1);
-
- memset(FirmwareVersion, 0, IPS_COMPAT_ID_LENGTH + 1);
- memset(BiosVersion, 0, IPS_COMPAT_ID_LENGTH + 1);
-
- /* Get the Compatible BIOS Version from NVRAM Page 5 */
- memcpy(BiosVersion, ha->nvram->BiosCompatibilityID, IPS_COMPAT_ID_LENGTH);
- 
- rc = IPS_FAILURE;
- if (ha->subsys->param[4] & IPS_GET_VERSION_SUPPORT)  /* If Versioning is Supported */
- {
-     /* Get the Version Info with a Get Version Command */
-     rc = ips_get_version_info(ha, &VersionInfo, intr);
-     if  (rc == IPS_SUCCESS)
-        memcpy(FirmwareVersion, VersionInfo.compatibilityId, IPS_COMPAT_ID_LENGTH);
- }
-
- if  (rc != IPS_SUCCESS)      /* If Data Not Obtainable from a GetVersion Command */
- {
-     /* Get the Firmware Version from Enquiry Data */
-     memcpy(FirmwareVersion, ha->enq->CodeBlkVersion, IPS_COMPAT_ID_LENGTH);
- }
-
- /* printk(KERN_WARNING "Adapter's BIOS Version  = %s\n", BiosVersion);          */
- /* printk(KERN_WARNING "BIOS Compatible Version = %s\n", IPS_COMPAT_BIOS);      */
- /* printk(KERN_WARNING "Adapter's Firmware Version  = %s\n", FirmwareVersion);  */
- /* printk(KERN_WARNING "Firmware Compatible Version = %s \n", Compatable[ ha->nvram->adapter_type ]); */
-
- MatchError = 0;
-
- if  (strncmp(FirmwareVersion, Compatable[ ha->nvram->adapter_type ], IPS_COMPAT_ID_LENGTH) != 0)
-     MatchError = 1;
-
- if  (strncmp(BiosVersion, IPS_COMPAT_BIOS, IPS_COMPAT_ID_LENGTH) != 0)
-     MatchError = 1;
-
- ha->nvram->versioning = 1;          /* Indicate the Driver Supports Versioning */
-
- if  (MatchError)
- {
-     ha->nvram->version_mismatch = 1;
-     if (ips_cd_boot == 0)  
-     {
-       strncpy(&BiosString[0], ha->nvram->bios_high, 4);
-       strncpy(&BiosString[4], ha->nvram->bios_low, 4);
-       BiosString[8] = 0;
-
-       strncpy(&FirmwareString[0], ha->enq->CodeBlkVersion, 8);
-       FirmwareString[8] = 0;
-
-       printk(KERN_WARNING "Warning ! ! ! ServeRAID Version Mismatch\n");
-       printk(KERN_WARNING "Bios = %s, Firmware = %s, Device Driver = %s%s\n",
-                            BiosString, FirmwareString, IPS_VERSION_HIGH, IPS_VERSION_LOW );
-       printk(KERN_WARNING "These levels should match to avoid possible compatibility problems.\n" );
-     }
- }
- else
- {
-     ha->nvram->version_mismatch = 0;
- }
+static void
+ips_version_check(ips_ha_t * ha, int intr)
+{
+	IPS_VERSION_DATA VersionInfo;
+	uint8_t FirmwareVersion[IPS_COMPAT_ID_LENGTH + 1];
+	uint8_t BiosVersion[IPS_COMPAT_ID_LENGTH + 1];
+	int MatchError;
+	int rc;
+	char BiosString[10];
+	char FirmwareString[10];
+
+	METHOD_TRACE("ips_version_check", 1);
+
+	memset(FirmwareVersion, 0, IPS_COMPAT_ID_LENGTH + 1);
+	memset(BiosVersion, 0, IPS_COMPAT_ID_LENGTH + 1);
+
+	/* Get the Compatible BIOS Version from NVRAM Page 5 */
+	memcpy(BiosVersion, ha->nvram->BiosCompatibilityID,
+	       IPS_COMPAT_ID_LENGTH);
+
+	rc = IPS_FAILURE;
+	if (ha->subsys->param[4] & IPS_GET_VERSION_SUPPORT) {	/* If Versioning is Supported */
+		/* Get the Version Info with a Get Version Command */
+		rc = ips_get_version_info(ha, &VersionInfo, intr);
+		if (rc == IPS_SUCCESS)
+			memcpy(FirmwareVersion, VersionInfo.compatibilityId,
+			       IPS_COMPAT_ID_LENGTH);
+	}
+
+	if (rc != IPS_SUCCESS) {	/* If Data Not Obtainable from a GetVersion Command */
+		/* Get the Firmware Version from Enquiry Data */
+		memcpy(FirmwareVersion, ha->enq->CodeBlkVersion,
+		       IPS_COMPAT_ID_LENGTH);
+	}
+
+	/* printk(KERN_WARNING "Adapter's BIOS Version  = %s\n", BiosVersion);          */
+	/* printk(KERN_WARNING "BIOS Compatible Version = %s\n", IPS_COMPAT_BIOS);      */
+	/* printk(KERN_WARNING "Adapter's Firmware Version  = %s\n", FirmwareVersion);  */
+	/* printk(KERN_WARNING "Firmware Compatible Version = %s \n", Compatable[ ha->nvram->adapter_type ]); */
+
+	MatchError = 0;
+
+	if (strncmp
+	    (FirmwareVersion, Compatable[ha->nvram->adapter_type],
+	     IPS_COMPAT_ID_LENGTH) != 0)
+		MatchError = 1;
+
+	if (strncmp(BiosVersion, IPS_COMPAT_BIOS, IPS_COMPAT_ID_LENGTH) != 0)
+		MatchError = 1;
+
+	ha->nvram->versioning = 1;	/* Indicate the Driver Supports Versioning */
+
+	if (MatchError) {
+		ha->nvram->version_mismatch = 1;
+		if (ips_cd_boot == 0) {
+			strncpy(&BiosString[0], ha->nvram->bios_high, 4);
+			strncpy(&BiosString[4], ha->nvram->bios_low, 4);
+			BiosString[8] = 0;
+
+			strncpy(&FirmwareString[0], ha->enq->CodeBlkVersion, 8);
+			FirmwareString[8] = 0;
+
+			printk(KERN_WARNING
+			       "Warning ! ! ! ServeRAID Version Mismatch\n");
+			printk(KERN_WARNING
+			       "Bios = %s, Firmware = %s, Device Driver = %s%s\n",
+			       BiosString, FirmwareString, IPS_VERSION_HIGH,
+			       IPS_VERSION_LOW);
+			printk(KERN_WARNING
+			       "These levels should match to avoid possible compatibility problems.\n");
+		}
+	} else {
+		ha->nvram->version_mismatch = 0;
+	}
 
- return;
+	return;
 }
 
 /*---------------------------------------------------------------------------*/
@@ -7290,52 +6834,227 @@
 /*   Return Value:                                                           */
 /*     0 if Successful, else non-zero                                        */
 /*---------------------------------------------------------------------------*/
-static int ips_get_version_info(ips_ha_t *ha, IPS_VERSION_DATA *Buffer, int intr ) {
-   ips_scb_t *scb;
-   int        rc;
-
-   METHOD_TRACE("ips_get_version_info", 1);
-
-   memset(Buffer, 0, sizeof(IPS_VERSION_DATA));
-   scb = &ha->scbs[ha->max_cmds-1];
-
-   ips_init_scb(ha, scb);
-
-   scb->timeout = ips_cmd_timeout;
-   scb->cdb[0] = IPS_CMD_GET_VERSION_INFO;
-   scb->cmd.version_info.op_code = IPS_CMD_GET_VERSION_INFO;
-   scb->cmd.version_info.command_id = IPS_COMMAND_ID(ha, scb);
-   scb->cmd.version_info.reserved = 0;
-   scb->cmd.version_info.count = sizeof( IPS_VERSION_DATA);
-   scb->cmd.version_info.reserved2 = 0;
-   scb->data_len = sizeof(*Buffer);
-   scb->data_busaddr = pci_map_single(ha->pcidev, Buffer,
-                                      scb->data_len, IPS_DMA_DIR(scb));
-   scb->cmd.version_info.buffer_addr = scb->data_busaddr;
-   scb->flags |= IPS_SCB_MAP_SINGLE;
-
-   /* issue command */
-   rc = ips_send_wait(ha, scb, ips_cmd_timeout, intr);
-   return( rc );
-}
-
-  
-
-#if defined (MODULE) || (LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0))
-static Scsi_Host_Template driver_template = IPS;
-#include "scsi_module.c"
-#endif
+static int
+ips_get_version_info(ips_ha_t * ha, IPS_VERSION_DATA * Buffer, int intr)
+{
+	ips_scb_t *scb;
+	int rc;
+
+	METHOD_TRACE("ips_get_version_info", 1);
+
+	memset(Buffer, 0, sizeof (IPS_VERSION_DATA));
+	scb = &ha->scbs[ha->max_cmds - 1];
+
+	ips_init_scb(ha, scb);
 
-static int ips_abort_init(ips_ha_t *ha, struct Scsi_Host *sh, int index){
-   ha->active = 0;
-   ips_free(ha);
-   scsi_unregister(sh);
-   ips_ha[index] = 0;
-   ips_sh[index] = 0;
-   return -1;
+	scb->timeout = ips_cmd_timeout;
+	scb->cdb[0] = IPS_CMD_GET_VERSION_INFO;
+	scb->cmd.version_info.op_code = IPS_CMD_GET_VERSION_INFO;
+	scb->cmd.version_info.command_id = IPS_COMMAND_ID(ha, scb);
+	scb->cmd.version_info.reserved = 0;
+	scb->cmd.version_info.count = sizeof (IPS_VERSION_DATA);
+	scb->cmd.version_info.reserved2 = 0;
+	scb->data_len = sizeof (*Buffer);
+	scb->data_busaddr = pci_map_single(ha->pcidev, Buffer,
+					   scb->data_len, IPS_DMA_DIR(scb));
+	scb->cmd.version_info.buffer_addr = scb->data_busaddr;
+	scb->flags |= IPS_SCB_MAP_SINGLE;
+
+	/* issue command */
+	rc = ips_send_wait(ha, scb, ips_cmd_timeout, intr);
+	return (rc);
 }
 
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,0)
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_abort_init                                             */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*   cleanup routine for a failed adapter initialization                    */
+/****************************************************************************/
+static int
+ips_abort_init(ips_ha_t * ha, int index)
+{
+	ha->active = 0;
+	ips_free(ha);
+	ips_ha[index] = 0;
+	ips_sh[index] = 0;
+	return -1;
+}
+
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_shift_controllers                                      */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*   helper function for ordering adapters                                  */
+/****************************************************************************/
+static void
+ips_shift_controllers(int lowindex, int highindex)
+{
+	ips_ha_t *ha_sav = ips_ha[highindex];
+	struct Scsi_Host *sh_sav = ips_sh[highindex];
+	int i;
+
+	for (i = highindex; i > lowindex; i--) {
+		ips_ha[i] = ips_ha[i - 1];
+		ips_sh[i] = ips_sh[i - 1];
+		ips_ha[i]->host_num = i;
+	}
+	ha_sav->host_num = lowindex;
+	ips_ha[lowindex] = ha_sav;
+	ips_sh[lowindex] = sh_sav;
+}
+
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_order_controllers                                      */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*   place controllers is the "proper" boot order                           */
+/****************************************************************************/
+static void
+ips_order_controllers(void)
+{
+	int i, j, tmp, position = 0;
+	IPS_NVRAM_P5 *nvram;
+	if (!ips_ha[0])
+		return;
+	nvram = ips_ha[0]->nvram;
+
+	if (nvram->adapter_order[0]) {
+		for (i = 1; i <= nvram->adapter_order[0]; i++) {
+			for (j = position; j < ips_num_controllers; j++) {
+				switch (ips_ha[j]->ad_type) {
+				case IPS_ADTYPE_SERVERAID6M:
+					if (nvram->adapter_order[i] == 'M') {
+						ips_shift_controllers(position,
+								      j);
+						position++;
+					}
+					break;
+				case IPS_ADTYPE_SERVERAID4L:
+				case IPS_ADTYPE_SERVERAID4M:
+				case IPS_ADTYPE_SERVERAID4MX:
+				case IPS_ADTYPE_SERVERAID4LX:
+					if (nvram->adapter_order[i] == 'N') {
+						ips_shift_controllers(position,
+								      j);
+						position++;
+					}
+					break;
+				case IPS_ADTYPE_SERVERAID6I:
+				case IPS_ADTYPE_SERVERAID5I2:
+				case IPS_ADTYPE_SERVERAID5I1:
+					if (nvram->adapter_order[i] == 'S') {
+						ips_shift_controllers(position,
+								      j);
+						position++;
+					}
+					break;
+				case IPS_ADTYPE_SERVERAID:
+				case IPS_ADTYPE_SERVERAID2:
+				case IPS_ADTYPE_NAVAJO:
+				case IPS_ADTYPE_KIOWA:
+				case IPS_ADTYPE_SERVERAID3L:
+				case IPS_ADTYPE_SERVERAID3:
+				case IPS_ADTYPE_SERVERAID4H:
+					if (nvram->adapter_order[i] == 'A') {
+						ips_shift_controllers(position,
+								      j);
+						position++;
+					}
+					break;
+				default:
+					break;
+				}
+			}
+		}
+		/* if adapter_order[0], then ordering is complete */
+		return;
+	}
+	/* old bios, use older ordering */
+	tmp = 0;
+	for (i = position; i < ips_num_controllers; i++) {
+		if (ips_ha[i]->ad_type == IPS_ADTYPE_SERVERAID5I2 ||
+		    ips_ha[i]->ad_type == IPS_ADTYPE_SERVERAID5I1) {
+			ips_shift_controllers(position, i);
+			position++;
+			tmp = 1;
+		}
+	}
+	/* if there were no 5I cards, then don't do any extra ordering */
+	if (!tmp)
+		return;
+	for (i = position; i < ips_num_controllers; i++) {
+		if (ips_ha[i]->ad_type == IPS_ADTYPE_SERVERAID4L ||
+		    ips_ha[i]->ad_type == IPS_ADTYPE_SERVERAID4M ||
+		    ips_ha[i]->ad_type == IPS_ADTYPE_SERVERAID4LX ||
+		    ips_ha[i]->ad_type == IPS_ADTYPE_SERVERAID4MX) {
+			ips_shift_controllers(position, i);
+			position++;
+		}
+	}
+
+	return;
+}
+
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_register_scsi                                          */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*   perform any registration and setup with the scsi layer                 */
+/****************************************************************************/
+static int
+ips_register_scsi(int index)
+{
+	struct Scsi_Host *sh;
+	ips_ha_t *ha, *oldha;
+	sh = scsi_register(&ips_driver_template, sizeof (ips_ha_t));
+	if (!sh) {
+		printk(KERN_WARNING
+		       "Unable to register controller with SCSI subsystem\n");
+		return -1;
+	}
+	oldha = ips_ha[index];
+	ha = IPS_HA(sh);
+	memcpy(ha, oldha, sizeof (ips_ha_t));
+	free_irq(oldha->irq, oldha);
+	/* Install the interrupt handler with the new ha */
+	if (request_irq(ha->irq, do_ipsintr, SA_SHIRQ, ips_name, ha)) {
+		printk(KERN_WARNING "Unable to install interrupt handler\n");
+		scsi_unregister(sh);
+		return -1;
+	}
+
+	kfree(oldha);
+	ips_sh[index] = sh;
+	ips_ha[index] = ha;
+	scsi_set_pci_device(sh, ha->pcidev);
+
+	/* Store away needed values for later use */
+	sh->io_port = ha->io_addr;
+	sh->n_io_port = ha->io_addr ? 255 : 0;
+	sh->unique_id = (ha->io_addr) ? ha->io_addr : ha->mem_addr;
+	sh->irq = ha->irq;
+	sh->sg_tablesize = sh->hostt->sg_tablesize;
+	sh->can_queue = sh->hostt->can_queue;
+	sh->cmd_per_lun = sh->hostt->cmd_per_lun;
+	sh->unchecked_isa_dma = sh->hostt->unchecked_isa_dma;
+	sh->use_clustering = sh->hostt->use_clustering;
+
+#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,7)
+	sh->max_sectors = 128;
+#endif
+
+	sh->max_id = ha->ntargets;
+	sh->max_lun = ha->nlun;
+	sh->max_channel = ha->nbus - 1;
+	sh->can_queue = ha->max_cmds - 1;
+
+	return 0;
+}
 
 /*---------------------------------------------------------------------------*/
 /*   Routine Name: ips_remove_device                                         */
@@ -7343,24 +7062,64 @@
 /*   Routine Description:                                                    */
 /*     Remove one Adapter ( Hot Plugging )                                   */
 /*---------------------------------------------------------------------------*/
-static void ips_remove_device(struct pci_dev *pci_dev)
+static void
+ips_remove_device(struct pci_dev *pci_dev)
 {
-   int    i;
-   struct Scsi_Host *sh;
-   ips_ha_t *ha;                                                                 
-   
-   for (i = 0; i < IPS_MAX_ADAPTERS; i++) {
-      ha = ips_ha[i];
-      if (ha) {
-         if ( (pci_dev->bus->number == ha->pcidev->bus->number) &&
-              (pci_dev->devfn == ha->pcidev->devfn)) {
-            sh = ips_sh[i];
-            ips_release(sh);     
-         }
-      }
-   }
+	int i;
+	struct Scsi_Host *sh;
+	ips_ha_t *ha;
+
+	for (i = 0; i < IPS_MAX_ADAPTERS; i++) {
+		ha = ips_ha[i];
+		if (ha) {
+			if ((pci_dev->bus->number == ha->pcidev->bus->number) &&
+			    (pci_dev->devfn == ha->pcidev->devfn)) {
+				sh = ips_sh[i];
+				ips_release(sh);
+			}
+		}
+	}
 }
 
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_module_init                                            */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*   function called on module load                                         */
+/****************************************************************************/
+static int __init
+ips_module_init(void)
+{
+	if (pci_module_init(&ips_pci_driver) < 0)
+		return -ENODEV;
+	ips_driver_template.module = THIS_MODULE;
+	ips_order_controllers();
+	if (scsi_register_module(MODULE_SCSI_HA, &ips_driver_template)) {
+		pci_unregister_driver(&ips_pci_driver);
+		return -ENODEV;
+	}
+	register_reboot_notifier(&ips_notifier);
+	return 0;
+}
+
+/****************************************************************************/
+/*                                                                          */
+/* Routine Name: ips_module_exit                                            */
+/*                                                                          */
+/* Routine Description:                                                     */
+/*   function called on module unload                                       */
+/****************************************************************************/
+static void __exit
+ips_module_exit(void)
+{
+	scsi_unregister_module(MODULE_SCSI_HA, &ips_driver_template);
+	pci_unregister_driver(&ips_pci_driver);
+	unregister_reboot_notifier(&ips_notifier);
+}
+
+module_init(ips_module_init);
+module_exit(ips_module_exit);
 
 /*---------------------------------------------------------------------------*/
 /*   Routine Name: ips_insert_device                                         */
@@ -7371,40 +7130,28 @@
 /*   Return Value:                                                           */
 /*     0 if Successful, else non-zero                                        */
 /*---------------------------------------------------------------------------*/
-static int __devinit ips_insert_device(struct pci_dev *pci_dev, const struct pci_device_id *ent)
+static int __devinit
+ips_insert_device(struct pci_dev *pci_dev, const struct pci_device_id *ent)
 {
-    int  index;
-    int  rc;
+	int index;
+	int rc;
 
-    METHOD_TRACE("ips_insert_device", 1);
+	METHOD_TRACE("ips_insert_device", 1);
 
-    /* If we're still in Init State 0, and we've already found the Adapter */
-    /* Ordering Table, there is no reason to continue.                     */
-    if ( (InitState == 0) && (AdapterOrder[0]) ) 
-        return -1;
-    
-    if (pci_enable_device(pci_dev)) 
+	if (pci_enable_device(pci_dev))
 		return -1;
 
-    rc = ips_init_phase1(pci_dev, &index);
-    if (rc == SUCCESS)
-       rc = ips_init_phase2(index); 
-
-    /* If we're in Init State 0, we're done with the device for now. */
-    /* Release the device and don't count it.                        */
-    if ( InitState == 0 ) {
-        ips_remove_device(pci_dev);
-		return -1;
-    }
+	rc = ips_init_phase1(pci_dev, &index);
+	if (rc == SUCCESS)
+		rc = ips_init_phase2(index);
 
-    if (rc == SUCCESS)
-       ips_num_controllers++;
+	if (rc == SUCCESS)
+		ips_num_controllers++;
 
-    ips_next_controller = ips_num_controllers;
-    return rc;
+	ips_next_controller = ips_num_controllers;
+	return rc;
 }
 
-
 /*---------------------------------------------------------------------------*/
 /*   Routine Name: ips_init_phase1                                           */
 /*                                                                           */
@@ -7414,248 +7161,232 @@
 /*   Return Value:                                                           */
 /*     0 if Successful, else non-zero                                        */
 /*---------------------------------------------------------------------------*/
-static int ips_init_phase1( struct pci_dev *pci_dev, int *indexPtr )
-{         
-   struct Scsi_Host *sh;
-   ips_ha_t         *ha;
-   uint32_t          io_addr;
-   uint32_t          mem_addr;
-   uint32_t          io_len;
-   uint32_t          mem_len;
-   uint8_t           revision_id;
-   uint8_t           bus;
-   uint8_t           func;
-   uint8_t           irq;
-   uint16_t          subdevice_id;
-   int               j;
-   int               index; 
-   uint32_t          count;
-   dma_addr_t        dma_address;
-   char             *ioremap_ptr;
-   char             *mem_ptr;             
-   uint32_t          IsDead
-
-   METHOD_TRACE("ips_init_phase1", 1);
-   index = IPS_MAX_ADAPTERS;
-   for (j = 0; j < IPS_MAX_ADAPTERS; j++) {
-       if (ips_ha[j] ==0) {
-          index = j;
-          break;
-       }
-   }
-
-   if (index >= IPS_MAX_ADAPTERS)
-      return -1;
-   
-   /* stuff that we get in dev */
-    irq  = pci_dev->irq;
-    bus  = pci_dev->bus->number;
-    func = pci_dev->devfn;
-
-    /* Init MEM/IO addresses to 0 */
-    mem_addr = 0;
-    io_addr  = 0;
-    mem_len  = 0;
-    io_len   = 0;
-
-    for (j = 0; j < 2; j++) {
-       if (!pci_resource_start(pci_dev, j))
-          break;
-
-       if (pci_resource_flags(pci_dev, j) & IORESOURCE_IO) {
-          io_addr = pci_resource_start(pci_dev, j);
-          io_len = pci_resource_len(pci_dev, j);
-       } else {
-          mem_addr = pci_resource_start(pci_dev, j);
-          mem_len = pci_resource_len(pci_dev, j);
-       }
-    }
-
-    /* setup memory mapped area (if applicable) */
-    if (mem_addr) {
-       uint32_t base;
-       uint32_t offs;
-
-       if (check_mem_region(mem_addr, mem_len)) {
-          printk(KERN_WARNING "Couldn't allocate IO Memory space %x len %d.\n", mem_addr, mem_len);
-          return -1;
-          }
-
-       request_mem_region(mem_addr, mem_len, "ips");
-       base = mem_addr & PAGE_MASK;
-       offs = mem_addr - base;
-       ioremap_ptr = ioremap(base, PAGE_SIZE);
-       mem_ptr = ioremap_ptr + offs;
-    } else {
-       ioremap_ptr = NULL;
-       mem_ptr = NULL;
-    }
-
-    /* setup I/O mapped area (if applicable) */
-    if (io_addr) {
-       if (check_region(io_addr, io_len)) {
-          printk(KERN_WARNING "Couldn't allocate IO space %x len %d.\n", io_addr, io_len);
-          return -1;
-       }
-       request_region(io_addr, io_len, "ips");
-    }
-
-    /* get the revision ID */
-    if (pci_read_config_byte(pci_dev, PCI_REVISION_ID, &revision_id)) {
-       printk(KERN_WARNING "Can't get revision id.\n" );
-       return -1;
-    }
-
-    subdevice_id = pci_dev->subsystem_device;
-
-    /* found a controller */
-    sh = scsi_register(&driver_template, sizeof(ips_ha_t));
-#if LINUX_VERSION_CODE > LinuxVersionCode(2,5,0) 
-    pci_set_dma_mask(pci_dev, (u64)0xffffffff);
-    scsi_set_pci_device(sh, pci_dev);
-#endif
-    if (sh == NULL) {
-       printk(KERN_WARNING "Unable to register controller with SCSI subsystem\n" );
-       return -1;
-    }
-
-    ha = IPS_HA(sh);
-    memset(ha, 0, sizeof(ips_ha_t));
-    
-    ips_sh[index] = sh;
-    ips_ha[index] = ha;
-    ha->active = 1;
-
-    ha->enq = kmalloc(sizeof(IPS_ENQ), GFP_KERNEL);
-
-    if (!ha->enq) {
-       printk(KERN_WARNING "Unable to allocate host inquiry structure\n" );
-       return ips_abort_init(ha, sh, index);
-    }
-
-    ha->adapt = pci_alloc_consistent(pci_dev, sizeof(IPS_ADAPTER) +
-                                     sizeof(IPS_IO_CMD), &dma_address);
-    if (!ha->adapt) {
-       printk(KERN_WARNING "Unable to allocate host adapt & dummy structures\n");
-       return ips_abort_init(ha, sh, index);
-    }
-    ha->adapt->hw_status_start = dma_address;
-    ha->dummy = (void *)(ha->adapt + 1);
-
-    ha->conf = kmalloc(sizeof(IPS_CONF), GFP_KERNEL);
-
-    if (!ha->conf) {
-       printk(KERN_WARNING "Unable to allocate host conf structure\n" );
-       return ips_abort_init(ha, sh, index);
-    }
-
-    ha->nvram = kmalloc(sizeof(IPS_NVRAM_P5), GFP_KERNEL);
-
-    if (!ha->nvram) {
-       printk(KERN_WARNING "Unable to allocate host NVRAM structure\n" );
-       return ips_abort_init(ha, sh, index);
-    }
-
-    ha->subsys = kmalloc(sizeof(IPS_SUBSYS), GFP_KERNEL);
-
-    if (!ha->subsys) {
-       printk(KERN_WARNING "Unable to allocate host subsystem structure\n" );
-       return ips_abort_init(ha, sh, index);
-    }
-
-    for (count = PAGE_SIZE, ha->ioctl_order = 0;
-         count < ips_ioctlsize;
-         ha->ioctl_order++, count <<= 1);
-
-    ha->ioctl_data = (char *) __get_free_pages(GFP_KERNEL, ha->ioctl_order);
-    ha->ioctl_datasize = count;
-
-    if (!ha->ioctl_data) {
-       printk(KERN_WARNING "Unable to allocate IOCTL data\n" );
-       ha->ioctl_data = NULL;
-       ha->ioctl_order = 0;
-       ha->ioctl_datasize = 0;
-    }
-
-    /* Store away needed values for later use */
-    sh->io_port = io_addr;
-    sh->n_io_port = io_addr ? 255 : 0;
-    sh->unique_id = (io_addr) ? io_addr : mem_addr;
-    sh->irq = irq;
-    sh->select_queue_depths = ips_select_queue_depth;
-    sh->sg_tablesize = sh->hostt->sg_tablesize;
-    sh->can_queue = sh->hostt->can_queue;
-    sh->cmd_per_lun = sh->hostt->cmd_per_lun;
-    sh->unchecked_isa_dma = sh->hostt->unchecked_isa_dma;
-    sh->use_clustering = sh->hostt->use_clustering;
+static int
+ips_init_phase1(struct pci_dev *pci_dev, int *indexPtr)
+{
+	ips_ha_t *ha;
+	uint32_t io_addr;
+	uint32_t mem_addr;
+	uint32_t io_len;
+	uint32_t mem_len;
+	uint8_t revision_id;
+	uint8_t bus;
+	uint8_t func;
+	uint8_t irq;
+	uint16_t subdevice_id;
+	int j;
+	int index;
+	uint32_t count;
+	dma_addr_t dma_address;
+	char *ioremap_ptr;
+	char *mem_ptr;
+	uint32_t IsDead;
+
+	METHOD_TRACE("ips_init_phase1", 1);
+	index = IPS_MAX_ADAPTERS;
+	for (j = 0; j < IPS_MAX_ADAPTERS; j++) {
+		if (ips_ha[j] == 0) {
+			index = j;
+			break;
+		}
+	}
 
-#if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,7)
-    sh->max_sectors = 128;
-#endif                      
+	if (index >= IPS_MAX_ADAPTERS)
+		return -1;
 
-    /* Store info in HA structure */
-    ha->irq = irq;
-    ha->io_addr = io_addr;
-    ha->io_len = io_len;
-    ha->mem_addr = mem_addr;
-    ha->mem_len = mem_len;
-    ha->mem_ptr = mem_ptr;
-    ha->ioremap_ptr = ioremap_ptr;
-    ha->host_num = ( uint32_t) index;
-    ha->revision_id = revision_id;
-    ha->slot_num = PCI_SLOT(pci_dev->devfn);
-    ha->device_id = pci_dev->device;
-    ha->subdevice_id = subdevice_id;
-    ha->pcidev = pci_dev;
-
-    /*
-     * Setup Functions
-     */
-    ips_setup_funclist(ha);
-
-    if ( ( IPS_IS_MORPHEUS( ha ) ) || ( IPS_IS_MARCO( ha ) ) ) {
-        /* If Morpheus appears dead, reset it */
-        IsDead = readl( ha->mem_ptr + IPS_REG_I960_MSG1 );
-        if ( IsDead == 0xDEADBEEF ) {
-            ips_reset_morpheus( ha );
-        }
-    }
-
-    /*
-     * Initialize the card if it isn't already
-     */
-
-    if (!(*ha->func.isinit)(ha)) {
-       if (!(*ha->func.init)(ha)) {
-          /*
-           * Initialization failed
-           */
-          printk(KERN_WARNING "Unable to initialize controller\n" );
-          return ips_abort_init(ha, sh, index);
-       }
-    }
-
-    /* Install the interrupt handler */
-     if (request_irq(irq, do_ipsintr, SA_SHIRQ, ips_name, ha)) {
-       printk(KERN_WARNING "Unable to install interrupt handler\n" );
-       return ips_abort_init(ha, sh, index);
-    }
-
-    /*
-     * Allocate a temporary SCB for initialization
-     */
-    ha->max_cmds = 1;
-    if (!ips_allocatescbs(ha)) {
-       printk(KERN_WARNING "Unable to allocate a CCB\n" );
-       free_irq(ha->irq, ha);
-       return ips_abort_init(ha, sh, index);
-    }
+	/* stuff that we get in dev */
+	irq = pci_dev->irq;
+	bus = pci_dev->bus->number;
+	func = pci_dev->devfn;
+
+	/* Init MEM/IO addresses to 0 */
+	mem_addr = 0;
+	io_addr = 0;
+	mem_len = 0;
+	io_len = 0;
+
+	for (j = 0; j < 2; j++) {
+		if (!pci_resource_start(pci_dev, j))
+			break;
+
+		if (pci_resource_flags(pci_dev, j) & IORESOURCE_IO) {
+			io_addr = pci_resource_start(pci_dev, j);
+			io_len = pci_resource_len(pci_dev, j);
+		} else {
+			mem_addr = pci_resource_start(pci_dev, j);
+			mem_len = pci_resource_len(pci_dev, j);
+		}
+	}
+
+	/* setup memory mapped area (if applicable) */
+	if (mem_addr) {
+		uint32_t base;
+		uint32_t offs;
+
+		if (!request_mem_region(mem_addr, mem_len, "ips")) {
+			printk(KERN_WARNING
+			       "Couldn't allocate IO Memory space %x len %d.\n",
+			       mem_addr, mem_len);
+			return -1;
+		}
+
+		base = mem_addr & PAGE_MASK;
+		offs = mem_addr - base;
+		ioremap_ptr = ioremap(base, PAGE_SIZE);
+		mem_ptr = ioremap_ptr + offs;
+	} else {
+		ioremap_ptr = NULL;
+		mem_ptr = NULL;
+	}
+
+	/* setup I/O mapped area (if applicable) */
+	if (io_addr) {
+		if (!request_region(io_addr, io_len, "ips")) {
+			printk(KERN_WARNING
+			       "Couldn't allocate IO space %x len %d.\n",
+			       io_addr, io_len);
+			return -1;
+		}
+	}
+
+	/* get the revision ID */
+	if (pci_read_config_byte(pci_dev, PCI_REVISION_ID, &revision_id)) {
+		printk(KERN_WARNING "Can't get revision id.\n");
+		return -1;
+	}
 
-    *indexPtr = index;
-    return SUCCESS;
-}
+	subdevice_id = pci_dev->subsystem_device;
 
-#endif
+	/* found a controller */
+	ha = kmalloc(sizeof (ips_ha_t), GFP_KERNEL);
+	if (ha == NULL) {
+		printk(KERN_WARNING "Unable to allocate temporary ha struct\n");
+		return -1;
+	}
+
+	memset(ha, 0, sizeof (ips_ha_t));
+
+	ips_sh[index] = NULL;
+	ips_ha[index] = ha;
+	ha->active = 1;
+
+	/* Store info in HA structure */
+	ha->irq = irq;
+	ha->io_addr = io_addr;
+	ha->io_len = io_len;
+	ha->mem_addr = mem_addr;
+	ha->mem_len = mem_len;
+	ha->mem_ptr = mem_ptr;
+	ha->ioremap_ptr = ioremap_ptr;
+	ha->host_num = (uint32_t) index;
+	ha->revision_id = revision_id;
+	ha->slot_num = PCI_SLOT(pci_dev->devfn);
+	ha->device_id = pci_dev->device;
+	ha->subdevice_id = subdevice_id;
+	ha->pcidev = pci_dev;
+
+	/*
+	 * Set the pci_dev's dma_mask.  Not all adapters support 64bit
+	 * addressing so don't enable it if the adapter can't support
+	 * it!  Also, don't use 64bit addressing if dma addresses
+	 * are guaranteed to be < 4G.
+	 */
+	if (IPS_ENABLE_DMA64 && IPS_HAS_ENH_SGLIST(ha) &&
+	    !pci_set_dma_mask(ha->pcidev, (u64) 0xffffffffffffffff)) {
+		(ha)->flags |= IPS_HA_ENH_SG;
+	} else {
+		if (pci_set_dma_mask(ha->pcidev, (u64) 0xffffffff) != 0) {
+			printk(KERN_WARNING "Unable to set DMA Mask\n");
+			return ips_abort_init(ha, index);
+		}
+	}
+
+	ha->enq = kmalloc(sizeof (IPS_ENQ), IPS_INIT_GFP);
+
+	if (!ha->enq) {
+		printk(KERN_WARNING
+		       "Unable to allocate host inquiry structure\n");
+		return ips_abort_init(ha, index);
+	}
+
+	ha->adapt = pci_alloc_consistent(pci_dev, sizeof (IPS_ADAPTER) +
+					 sizeof (IPS_IO_CMD), &dma_address);
+	if (!ha->adapt) {
+		printk(KERN_WARNING
+		       "Unable to allocate host adapt & dummy structures\n");
+		return ips_abort_init(ha, index);
+	}
+	ha->adapt->hw_status_start = dma_address;
+	ha->dummy = (void *) (ha->adapt + 1);
+
+	ha->conf = kmalloc(sizeof (IPS_CONF), IPS_INIT_GFP);
+
+	if (!ha->conf) {
+		printk(KERN_WARNING "Unable to allocate host conf structure\n");
+		return ips_abort_init(ha, index);
+	}
+
+	ha->nvram = kmalloc(sizeof (IPS_NVRAM_P5), IPS_INIT_GFP);
+
+	if (!ha->nvram) {
+		printk(KERN_WARNING
+		       "Unable to allocate host NVRAM structure\n");
+		return ips_abort_init(ha, index);
+	}
+
+	ha->subsys = kmalloc(sizeof (IPS_SUBSYS), IPS_INIT_GFP);
+
+	if (!ha->subsys) {
+		printk(KERN_WARNING
+		       "Unable to allocate host subsystem structure\n");
+		return ips_abort_init(ha, index);
+	}
+
+	for (count = PAGE_SIZE, ha->ioctl_order = 0;
+	     count < ips_ioctlsize; ha->ioctl_order++, count <<= 1) ;
+
+	ha->ioctl_data =
+	    (char *) __get_free_pages(IPS_INIT_GFP, ha->ioctl_order);
+	ha->ioctl_datasize = count;
+
+	if (!ha->ioctl_data) {
+		printk(KERN_WARNING "Unable to allocate IOCTL data\n");
+		ha->ioctl_data = NULL;
+		ha->ioctl_order = 0;
+		ha->ioctl_datasize = 0;
+	}
+
+	/*
+	 * Setup Functions
+	 */
+	ips_setup_funclist(ha);
+
+	if ((IPS_IS_MORPHEUS(ha)) || (IPS_IS_MARCO(ha))) {
+		/* If Morpheus appears dead, reset it */
+		IsDead = readl(ha->mem_ptr + IPS_REG_I960_MSG1);
+		if (IsDead == 0xDEADBEEF) {
+			ips_reset_morpheus(ha);
+		}
+	}
+
+	/*
+	 * Initialize the card if it isn't already
+	 */
+
+	if (!(*ha->func.isinit) (ha)) {
+		if (!(*ha->func.init) (ha)) {
+			/*
+			 * Initialization failed
+			 */
+			printk(KERN_WARNING
+			       "Unable to initialize controller\n");
+			return ips_abort_init(ha, index);
+		}
+	}
+
+	*indexPtr = index;
+	return SUCCESS;
+}
 
 /*---------------------------------------------------------------------------*/
 /*   Routine Name: ips_init_phase2                                           */
@@ -7666,46 +7397,52 @@
 /*   Return Value:                                                           */
 /*     0 if Successful, else non-zero                                        */
 /*---------------------------------------------------------------------------*/
-static int ips_init_phase2( int index )
-{         
-    struct Scsi_Host *sh;
-    ips_ha_t         *ha;
-
-    ha = ips_ha[index];
-    sh = ips_sh[index];
-
-    METHOD_TRACE("ips_init_phase2", 1);
-    if (!ha->active) {
-       scsi_unregister(sh);
-       ips_ha[index] = NULL;
-       ips_sh[index] = NULL;
-       return -1;;
-    }
-
-    if (!ips_hainit(ha)) {
-       printk(KERN_WARNING "Unable to initialize controller\n" );
-       free_irq(ha->irq, ha);
-       return ips_abort_init(ha, sh, index);
-    }
-    /* Free the temporary SCB */
-    ips_deallocatescbs(ha, 1);
-
-    /* allocate CCBs */
-    if (!ips_allocatescbs(ha)) {
-       printk(KERN_WARNING "Unable to allocate CCBs\n" );
-       free_irq(ha->irq, ha);
-       return ips_abort_init(ha, sh, index);
-    }
-
-    /* finish setting values */
-    sh->max_id = ha->ntargets;
-    sh->max_lun = ha->nlun;
-    sh->max_channel = ha->nbus - 1;
-    sh->can_queue = ha->max_cmds-1;
+static int
+ips_init_phase2(int index)
+{
+	ips_ha_t *ha;
 
-    return SUCCESS;
-}
+	ha = ips_ha[index];
+
+	METHOD_TRACE("ips_init_phase2", 1);
+	if (!ha->active) {
+		ips_ha[index] = NULL;
+		return -1;
+	}
+
+	/* Install the interrupt handler */
+	if (request_irq(ha->irq, do_ipsintr, SA_SHIRQ, ips_name, ha)) {
+		printk(KERN_WARNING "Unable to install interrupt handler\n");
+		return ips_abort_init(ha, index);
+	}
+
+	/*
+	 * Allocate a temporary SCB for initialization
+	 */
+	ha->max_cmds = 1;
+	if (!ips_allocatescbs(ha)) {
+		printk(KERN_WARNING "Unable to allocate a CCB\n");
+		free_irq(ha->irq, ha);
+		return ips_abort_init(ha, index);
+	}
+
+	if (!ips_hainit(ha)) {
+		printk(KERN_WARNING "Unable to initialize controller\n");
+		free_irq(ha->irq, ha);
+		return ips_abort_init(ha, index);
+	}
+	/* Free the temporary SCB */
+	ips_deallocatescbs(ha, 1);
+
+	/* allocate CCBs */
+	if (!ips_allocatescbs(ha)) {
+		printk(KERN_WARNING "Unable to allocate CCBs\n");
+		free_irq(ha->irq, ha);
+		return ips_abort_init(ha, index);
+	}
 
+	return SUCCESS;
+}
 
 #if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,9)
 MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/drivers/scsi/ips.h linux-2.4.23-pre1/drivers/scsi/ips.h
--- linux-2.4.22/drivers/scsi/ips.h	2003-06-13 14:51:36.000000000 +0000
+++ linux-2.4.23-pre1/drivers/scsi/ips.h	2003-08-27 14:39:49.000000000 +0000
@@ -69,6 +69,13 @@
       #define LinuxVersionCode(x,y,z)  (((x)<<16)+((y)<<8)+(z))
    #endif
 
+   #if LINUX_VERSION_CODE >= LinuxVersionCode(2,4,20) || defined CONFIG_HIGHIO
+      #define IPS_HIGHIO
+      #define IPS_HIGHMEM_IO     .highmem_io = 1,
+   #else
+      #define IPS_HIGHMEM_IO
+   #endif
+
    #define IPS_HA(x)                   ((ips_ha_t *) x->hostdata)
    #define IPS_COMMAND_ID(ha, scb)     (int) (scb - ha->scbs)
    #define IPS_IS_TROMBONE(ha)         (((ha->device_id == IPS_DEVICEID_COPPERHEAD) && \
@@ -86,10 +93,42 @@
                                          ((IPS_IS_TROMBONE(ha) || IPS_IS_CLARINET(ha)) && \
                                           (ips_force_memio))) ? 1 : 0)
 
+    #define IPS_HAS_ENH_SGLIST(ha)    (IPS_IS_MORPHEUS(ha) || IPS_IS_MARCO(ha))
+    #define IPS_USE_ENH_SGLIST(ha)    ((ha)->flags & IPS_HA_ENH_SG)
+    #define IPS_SGLIST_SIZE(ha)       (IPS_USE_ENH_SGLIST(ha) ? \
+                                         sizeof(IPS_ENH_SG_LIST) : sizeof(IPS_STD_SG_LIST))
+
+   #if LINUX_VERSION_CODE < LinuxVersionCode(2,4,4)
+      #define pci_set_dma_mask(dev,mask) ( mask > 0xffffffff ? 1:0 )
+      #define scsi_set_pci_device(sh,dev) (0)
+   #endif
+
    #ifndef MDELAY
       #define MDELAY mdelay
    #endif
-   
+
+   #ifndef min
+      #define min(x,y) ((x) < (y) ? x : y)
+   #endif
+
+   #define pci_dma_lo32(a)         (a & 0xffffffff)
+
+   #if (BITS_PER_LONG > 32) || (defined CONFIG_HIGHMEM64G && defined IPS_HIGHIO)
+      #define IPS_ENABLE_DMA64        (1)
+      #define pci_dma_hi32(a)         (a >> 32)
+   #else
+      #define IPS_ENABLE_DMA64        (0)
+      #define pci_dma_hi32(a)         (0)
+   #endif
+
+   #if defined(__ia64__)
+      #define IPS_ATOMIC_GFP	(GFP_DMA | GFP_ATOMIC)
+      #define IPS_INIT_GFP	GFP_DMA
+   #else
+      #define IPS_ATOMIC_GFP    GFP_ATOMIC
+      #define IPS_INIT_GFP	GFP_KERNEL
+   #endif
+
    /*
     * Adapter address map equates
     */
@@ -354,6 +393,12 @@
    #define IPS_SCSI_MP3_AllocateSurface 0x08
 
    /*
+    * HA Flags
+    */
+
+   #define IPS_HA_ENH_SG                0x1
+
+   /*
     * SCB Flags
     */
    #define IPS_SCB_MAP_SG               0x00008
@@ -390,93 +435,45 @@
    /*
     * Scsi_Host Template
     */
-#if LINUX_VERSION_CODE < LinuxVersionCode(2,4,0)
- #define IPS {                            \
-    next : NULL,                          \
-    module : NULL,                        \
-    proc_info : NULL,                     \
-    proc_dir : NULL,                      \
-    name : NULL,                          \
-    detect : ips_detect,                  \
-    release : ips_release,                \
-    info : ips_info,                      \
-    command : NULL,                       \
-    queuecommand : ips_queue,             \
-    eh_strategy_handler : NULL,           \
-    eh_abort_handler : ips_eh_abort,      \
-    eh_device_reset_handler : NULL,       \
-    eh_bus_reset_handler : NULL,          \
-    eh_host_reset_handler : ips_eh_reset, \
-    abort : NULL,                         \
-    reset : NULL,                         \
-    slave_attach : NULL,                  \
-    bios_param : ips_biosparam,           \
-    can_queue : 0,                        \
-    this_id: -1,                          \
-    sg_tablesize : IPS_MAX_SG,            \
-    cmd_per_lun: 16,                      \
-    present : 0,                          \
-    unchecked_isa_dma : 0,                \
-    use_clustering : ENABLE_CLUSTERING,   \
-    use_new_eh_code : 1                   \
-}
-#elif LINUX_VERSION_CODE < LinuxVersionCode(2,5,0)
- #define IPS {                            \
-    next : NULL,                          \
-    module : NULL,                        \
-    proc_info : NULL,                     \
-    name : NULL,                          \
-    detect : ips_detect,                  \
-    release : ips_release,                \
-    info : ips_info,                      \
-    command : NULL,                       \
-    queuecommand : ips_queue,             \
-    eh_strategy_handler : NULL,           \
-    eh_abort_handler : ips_eh_abort,      \
-    eh_device_reset_handler : NULL,       \
-    eh_bus_reset_handler : NULL,          \
-    eh_host_reset_handler : ips_eh_reset, \
-    abort : NULL,                         \
-    reset : NULL,                         \
-    slave_attach : NULL,                  \
-    bios_param : ips_biosparam,           \
-    can_queue : 0,                        \
-    this_id: -1,                          \
-    sg_tablesize : IPS_MAX_SG,            \
-    cmd_per_lun: 16,                      \
-    present : 0,                          \
-    unchecked_isa_dma : 0,                \
-    use_clustering : ENABLE_CLUSTERING,   \
-    use_new_eh_code : 1                   \
+#if LINUX_VERSION_CODE < LinuxVersionCode(2,5,0)
+   static void ips_select_queue_depth(struct Scsi_Host *, Scsi_Device *);
+#define IPS {	\
+	.detect				= ips_detect,	\
+	.release			= ips_release,	\
+	.info				= ips_info,	\
+	.queuecommand			= ips_queue,	\
+	.eh_abort_handler		= ips_eh_abort,	\
+	.eh_host_reset_handler		= ips_eh_reset,	\
+	.bios_param			= ips_biosparam,\
+	.select_queue_depths		= ips_select_queue_depth, \
+	.can_queue			= 0,		\
+	.this_id			= -1,		\
+	.sg_tablesize			= IPS_MAX_SG,	\
+	.cmd_per_lun			= 16,		\
+	.present			= 0,		\
+	.unchecked_isa_dma		= 0,		\
+	.use_clustering			= ENABLE_CLUSTERING,\
+	.use_new_eh_code		= 1, \
+	IPS_HIGHMEM_IO \
 }
 #else
- #define IPS {                            \
-    next : NULL,                          \
-    module : NULL,                        \
-    proc_info : NULL,                     \
-    name : NULL,                          \
-    detect : ips_detect,                  \
-    release : ips_release,                \
-    info : ips_info,                      \
-    command : NULL,                       \
-    queuecommand : ips_queue,             \
-    eh_strategy_handler : NULL,           \
-    eh_abort_handler : ips_eh_abort,      \
-    eh_device_reset_handler : NULL,       \
-    eh_bus_reset_handler : NULL,          \
-    eh_host_reset_handler : ips_eh_reset, \
-    abort : NULL,                         \
-    reset : NULL,                         \
-    slave_attach : NULL,                  \
-    bios_param : ips_biosparam,           \
-    can_queue : 0,                        \
-    this_id: -1,                          \
-    sg_tablesize : IPS_MAX_SG,            \
-    cmd_per_lun: 16,                      \
-    present : 0,                          \
-    unchecked_isa_dma : 0,                \
-    use_clustering : ENABLE_CLUSTERING,   \
-    highmem_io : 1                        \
+#define IPS {	\
+	.detect			= ips_detect,		\
+	.release		= ips_release,		\
+	.info			= ips_info,		\
+	.queuecommand		= ips_queue,		\
+	.eh_abort_handler	= ips_eh_abort,		\
+	.eh_host_reset_handler	= ips_eh_reset,		\
+	.slave_configure	= ips_slave_configure,	\
+	.bios_param		= ips_biosparam,	\
+	.can_queue		= 0,			\
+	.this_id		= -1,			\
+	.sg_tablesize		= IPS_MAX_SG,		\
+	.cmd_per_lun		= 3,			\
+	.present		= 0,			\
+	.unchecked_isa_dma	= 0,			\
+	.use_clustering		= ENABLE_CLUSTERING,	\
+	.highmem_io		= 1 \
 }
 #endif
 
@@ -491,7 +488,8 @@
    uint32_t lba;
    uint32_t sg_addr;
    uint16_t sector_count;
-   uint16_t reserved;
+   uint8_t  segment_4G;
+   uint8_t  enhanced_sg;
    uint32_t ccsar;
    uint32_t cccr;
 } IPS_IO_CMD, *PIPS_IO_CMD;
@@ -542,7 +540,9 @@
    uint16_t reserved;
    uint32_t reserved2;
    uint32_t dcdb_address;
-   uint32_t reserved3;
+   uint16_t reserved3;
+   uint8_t  segment_4G;
+   uint8_t  enhanced_sg;
    uint32_t ccsar;
    uint32_t cccr;
 } IPS_DCDB_CMD, *PIPS_DCDB_CMD;
@@ -986,7 +986,20 @@
 typedef struct ips_sglist {
    uint32_t address;
    uint32_t length;
-} IPS_SG_LIST, *PIPS_SG_LIST;
+} IPS_STD_SG_LIST;
+
+typedef struct ips_enh_sglist {
+   uint32_t address_lo;
+   uint32_t address_hi;
+   uint32_t length;
+   uint32_t reserved;
+} IPS_ENH_SG_LIST;
+
+typedef union {
+   void             *list;
+   IPS_STD_SG_LIST  *std_list;
+   IPS_ENH_SG_LIST  *enh_list;
+} IPS_SG_LIST;
 
 typedef struct _IPS_INFOSTR {
    char *buffer;
@@ -1086,6 +1099,7 @@
    char              *ioctl_data;         /* IOCTL data area            */
    uint32_t           ioctl_datasize;     /* IOCTL data size            */
    uint32_t           cmd_in_progress;    /* Current command in progress*/
+   int                flags;              /*                            */
    uint8_t            waitflag;           /* are we waiting for cmd     */
    uint8_t            active;
    int                ioctl_reset;        /* IOCTL Requested Reset Flag */
@@ -1133,7 +1147,7 @@
    uint32_t          sg_len;
    uint32_t          flags;
    uint32_t          op_code;
-   IPS_SG_LIST      *sg_list;
+   IPS_SG_LIST       sg_list;
    Scsi_Cmnd        *scsi_cmd;
    struct ips_scb   *q_next;
    ips_scb_callback  callback;
@@ -1194,11 +1208,13 @@
 
 #define IPS_VER_MAJOR 6
 #define IPS_VER_MAJOR_STRING "6"
-#define IPS_VER_MINOR 00
-#define IPS_VER_MINOR_STRING "00"
-#define IPS_VER_BUILD 26
-#define IPS_VER_BUILD_STRING "26"
-#define IPS_VER_STRING "6.00.26"
+#define IPS_VER_MINOR 10
+#define IPS_VER_MINOR_STRING "10"
+#define IPS_VER_BUILD 24
+#define IPS_VER_BUILD_STRING "24"
+#define IPS_VER_STRING "6.10.24"
+#define IPS_RELEASE_ID 0x00010000
+#define IPS_BUILD_IDENT 1250
 #define IPS_LEGALCOPYRIGHT_STRING "(C) Copyright IBM Corp. 1994, 2003. All Rights Reserved."
 #define IPS_ADAPTECCOPYRIGHT_STRING "(c) Copyright Adaptec, Inc. 2002 to present. All Rights Reserved."
 #define IPS_NT_LEGALCOPYRIGHT_STRING "(C) Copyright IBM Corp. 1994, 2003."
@@ -1207,31 +1223,33 @@
 #define IPS_VER_SERVERAID1 "2.25.01"
 #define IPS_VER_SERVERAID2 "2.88.13"
 #define IPS_VER_NAVAJO "2.88.13"
-#define IPS_VER_SERVERAID3 "6.00.26"
-#define IPS_VER_SERVERAID4H "6.00.26"
-#define IPS_VER_SERVERAID4MLx "6.00.26"
-#define IPS_VER_SARASOTA "6.00.26"
-#define IPS_VER_MARCO "6.00.26"
+#define IPS_VER_SERVERAID3 "6.10.24"
+#define IPS_VER_SERVERAID4H "6.10.24"
+#define IPS_VER_SERVERAID4MLx "6.10.24"
+#define IPS_VER_SARASOTA "6.10.24"
+#define IPS_VER_MARCO "6.10.24"
+#define IPS_VER_SEBRING "6.10.24"
 
 /* Compatability IDs for various adapters */
 #define IPS_COMPAT_UNKNOWN ""
-#define IPS_COMPAT_CURRENT "MR600"
+#define IPS_COMPAT_CURRENT "SB610"
 #define IPS_COMPAT_SERVERAID1 "2.25.01"
 #define IPS_COMPAT_SERVERAID2 "2.88.13"
 #define IPS_COMPAT_NAVAJO  "2.88.13"
 #define IPS_COMPAT_KIOWA "2.88.13"
-#define IPS_COMPAT_SERVERAID3H  "MR600"
-#define IPS_COMPAT_SERVERAID3L  "MR600"
-#define IPS_COMPAT_SERVERAID4H  "MR600"
-#define IPS_COMPAT_SERVERAID4M  "MR600"
-#define IPS_COMPAT_SERVERAID4L  "MR600"
-#define IPS_COMPAT_SERVERAID4Mx "MR600"
-#define IPS_COMPAT_SERVERAID4Lx "MR600"
-#define IPS_COMPAT_SARASOTA     "MR600"
-#define IPS_COMPAT_MARCO        "MR600"
-#define IPS_COMPAT_BIOS "MR600"
+#define IPS_COMPAT_SERVERAID3H  "SB610"
+#define IPS_COMPAT_SERVERAID3L  "SB610"
+#define IPS_COMPAT_SERVERAID4H  "SB610"
+#define IPS_COMPAT_SERVERAID4M  "SB610"
+#define IPS_COMPAT_SERVERAID4L  "SB610"
+#define IPS_COMPAT_SERVERAID4Mx "SB610"
+#define IPS_COMPAT_SERVERAID4Lx "SB610"
+#define IPS_COMPAT_SARASOTA     "SB610"
+#define IPS_COMPAT_MARCO        "SB610"
+#define IPS_COMPAT_SEBRING      "SB610"
+#define IPS_COMPAT_BIOS "SB610"
 
-#define IPS_COMPAT_MAX_ADAPTER_TYPE 15
+#define IPS_COMPAT_MAX_ADAPTER_TYPE 16
 #define IPS_COMPAT_ID_LENGTH 8
 
 #define IPS_DEFINE_COMPAT_TABLE(tablename) \
@@ -1250,7 +1268,8 @@
       IPS_COMPAT_SERVERAID4Lx, \
       IPS_COMPAT_SARASOTA,         /* one-channel variety of SARASOTA */  \
       IPS_COMPAT_SARASOTA,         /* two-channel variety of SARASOTA */  \
-      IPS_COMPAT_MARCO \
+      IPS_COMPAT_MARCO, \
+      IPS_COMPAT_SEBRING \
    }
 
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/buffer.c linux-2.4.23-pre1/fs/buffer.c
--- linux-2.4.22/fs/buffer.c	2003-08-25 11:44:43.000000000 +0000
+++ linux-2.4.23-pre1/fs/buffer.c	2003-08-27 14:40:39.000000000 +0000
@@ -612,7 +612,7 @@
 	if (buffer_attached(bh))
 		list_del(&bh->b_inode_buffers);
 	set_buffer_attached(bh);
-	list_add(&bh->b_inode_buffers, list);
+	list_add_tail(&bh->b_inode_buffers, list);
 	spin_unlock(&lru_list_lock);
 }
 
@@ -1749,7 +1749,7 @@
 		if (!buffer_mapped(bh)) {
 			if (iblock < lblock) {
 				if (get_block(inode, iblock, bh, 0))
-					continue;
+					SetPageError(page);
 			}
 			if (!buffer_mapped(bh)) {
 				memset(kmap(page) + i*blocksize, 0, blocksize);
@@ -1769,10 +1769,11 @@
 
 	if (!nr) {
 		/*
-		 * all buffers are uptodate - we can set the page
-		 * uptodate as well.
+		 * All buffers are uptodate - we can set the page uptodate
+		 * as well. But not if get_block() returned an error.
 		 */
-		SetPageUptodate(page);
+		if (!PageError(page))
+			SetPageUptodate(page);
 		UnlockPage(page);
 		return 0;
 	}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jbd/transaction.c linux-2.4.23-pre1/fs/jbd/transaction.c
--- linux-2.4.22/fs/jbd/transaction.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jbd/transaction.c	2003-08-27 14:39:57.000000000 +0000
@@ -1581,9 +1581,6 @@
 	assert_spin_locked(&journal_datalist_lock);
 	transaction = jh->b_transaction;
 
-#ifdef __SMP__
-	J_ASSERT (current->lock_depth >= 0);
-#endif
 	J_ASSERT_JH(jh, jh->b_jlist < BJ_Types);
 
 	if (jh->b_jlist != BJ_None)
@@ -2016,9 +2013,6 @@
 
 	assert_spin_locked(&journal_datalist_lock);
 	
-#ifdef __SMP__
-	J_ASSERT (current->lock_depth >= 0);
-#endif
 	J_ASSERT_JH(jh, jh->b_jlist < BJ_Types);
 	J_ASSERT_JH(jh, jh->b_transaction == transaction ||
 				jh->b_transaction == 0);
@@ -2108,9 +2102,6 @@
 	int was_dirty = 0;
 
 	assert_spin_locked(&journal_datalist_lock);
-#ifdef __SMP__
-	J_ASSERT_JH(jh, current->lock_depth >= 0);
-#endif
 	/* If the buffer is now unused, just drop it. */
 	if (jh->b_next_transaction == NULL) {
 		__journal_unfile_buffer(jh);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/inode.c linux-2.4.23-pre1/fs/jfs/inode.c
--- linux-2.4.22/fs/jfs/inode.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/inode.c	2003-08-27 14:39:59.000000000 +0000
@@ -149,7 +149,7 @@
 	rc = txCommit(tid, 1, &inode, wait ? COMMIT_SYNC : 0);
 	txEnd(tid);
 	up(&JFS_IP(inode)->commit_sem);
-	return -rc;
+	return rc;
 }
 
 void jfs_write_inode(struct inode *inode, int wait)
@@ -303,7 +303,7 @@
 		else
 			IREAD_UNLOCK(ip);
 	}
-	return -rc;
+	return rc;
 }
 
 static int jfs_writepage(struct page *page)
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_btree.h linux-2.4.23-pre1/fs/jfs/jfs_btree.h
--- linux-2.4.22/fs/jfs/jfs_btree.h	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_btree.h	2003-08-27 14:40:26.000000000 +0000
@@ -81,7 +81,7 @@
 		} else {\
 			P = NULL;\
 			jfs_err("bread failed!");\
-			RC = EIO;\
+			RC = -EIO;\
 		}\
 	}\
 }
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_dmap.c linux-2.4.23-pre1/fs/jfs/jfs_dmap.c
--- linux-2.4.22/fs/jfs/jfs_dmap.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_dmap.c	2003-08-27 14:39:55.000000000 +0000
@@ -189,8 +189,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOMEM	- insufficient memory
- *      EIO	- i/o error
+ *      -ENOMEM	- insufficient memory
+ *      -EIO	- i/o error
  */
 int dbMount(struct inode *ipbmap)
 {
@@ -205,7 +205,7 @@
 	/* allocate memory for the in-memory bmap descriptor */
 	bmp = kmalloc(sizeof(struct bmap), GFP_KERNEL);
 	if (bmp == NULL)
-		return (ENOMEM);
+		return -ENOMEM;
 
 	/* read the on-disk bmap descriptor. */
 	mp = read_metapage(ipbmap,
@@ -213,7 +213,7 @@
 			   PSIZE, 0);
 	if (mp == NULL) {
 		kfree(bmp);
-		return (EIO);
+		return -EIO;
 	}
 
 	/* copy the on-disk bmap descriptor to its in-memory version. */
@@ -268,7 +268,7 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      EIO	- i/o error
+ *      -EIO	- i/o error
  */
 int dbUnmount(struct inode *ipbmap, int mounterror)
 {
@@ -316,7 +316,7 @@
 			   PSIZE, 0);
 	if (mp == NULL) {
 		jfs_err("dbSync: read_metapage failed!");
-		return (EIO);
+		return -EIO;
 	}
 	/* copy the in-memory version of the bmap to the on-disk version */
 	dbmp_le = (struct dbmap *) mp->data;
@@ -368,7 +368,7 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      EIO	- i/o error
+ *      -EIO	- i/o error
  */
 int dbFree(struct inode *ip, s64 blkno, s64 nblocks)
 {
@@ -414,7 +414,7 @@
 		mp = read_metapage(ipbmap, lblkno, PSIZE, 0);
 		if (mp == NULL) {
 			IREAD_UNLOCK(ipbmap);
-			return (EIO);
+			return -EIO;
 		}
 		dp = (struct dmap *) mp->data;
 
@@ -463,7 +463,7 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      EIO	- i/o error
+ *      -EIO	- i/o error
  */
 int
 dbUpdatePMap(struct inode *ipbmap,
@@ -503,7 +503,7 @@
 			mp = read_metapage(bmp->db_ipbmap, lblkno, PSIZE,
 					   0);
 			if (mp == NULL)
-				return (EIO);
+				return -EIO;
 		}
 		dp = (struct dmap *) mp->data;
 
@@ -737,8 +737,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  */
 int dbAlloc(struct inode *ip, s64 hint, s64 nblocks, s64 * results)
 {
@@ -758,7 +758,7 @@
 #ifdef _STILL_TO_PORT
 	/* DASD limit check                                     F226941 */
 	if (OVER_LIMIT(ip, nblocks))
-		return ENOSPC;
+		return -ENOSPC;
 #endif				/* _STILL_TO_PORT */
 
 	/* get the log2 number of blocks to be allocated.
@@ -828,7 +828,7 @@
 
 		/* get the buffer for the dmap containing the hint.
 		 */
-		rc = EIO;
+		rc = -EIO;
 		lblkno = BLKTODMAP(blkno, bmp->db_l2nbperpage);
 		mp = read_metapage(ipbmap, lblkno, PSIZE, 0);
 		if (mp == NULL)
@@ -840,7 +840,7 @@
 		 * blocks beginning at the hint.
 		 */
 		if ((rc = dbAllocNext(bmp, dp, blkno, (int) nblocks))
-		    != ENOSPC) {
+		    != -ENOSPC) {
 			if (rc == 0) {
 				*results = blkno;
 				DBALLOC(bmp->db_DBmap, bmp->db_mapsize,
@@ -869,7 +869,7 @@
 		 */
 		if ((rc =
 		     dbAllocNear(bmp, dp, blkno, (int) nblocks, l2nb, results))
-		    != ENOSPC) {
+		    != -ENOSPC) {
 			if (rc == 0) {
 				DBALLOC(bmp->db_DBmap, bmp->db_mapsize,
 					*results, nblocks);
@@ -884,7 +884,7 @@
 		 * the same dmap as the hint.
 		 */
 		if ((rc = dbAllocDmapLev(bmp, dp, (int) nblocks, l2nb, results))
-		    != ENOSPC) {
+		    != -ENOSPC) {
 			if (rc == 0) {
 				DBALLOC(bmp->db_DBmap, bmp->db_mapsize,
 					*results, nblocks);
@@ -904,7 +904,7 @@
 	 */
 	IWRITE_LOCK(ipbmap);
 	if ((rc = dbAllocAG(bmp, agno, nblocks, l2nb, results))
-	    != ENOSPC) {
+	    != -ENOSPC) {
 		if (rc == 0)
 			DBALLOC(bmp->db_DBmap, bmp->db_mapsize,
 				*results, nblocks);
@@ -923,7 +923,7 @@
 	/* Try to allocate within this allocation group.  if that fails, try to
 	 * allocate anywhere in the map.
 	 */
-	if ((rc = dbAllocAG(bmp, agno, nblocks, l2nb, results)) == ENOSPC)
+	if ((rc = dbAllocAG(bmp, agno, nblocks, l2nb, results)) == -ENOSPC)
 		rc = dbAllocAny(bmp, nblocks, l2nb, results);
 	if (rc == 0) {
 		DBALLOC(bmp->db_DBmap, bmp->db_mapsize, *results, nblocks);
@@ -953,8 +953,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  */
 int dbAllocExact(struct inode *ip, s64 blkno, int nblocks)
 {
@@ -976,13 +976,13 @@
 	 */
 	if (nblocks <= 0 || nblocks > BPERDMAP || blkno >= bmp->db_mapsize) {
 		IREAD_UNLOCK(ipbmap);
-		return EINVAL;
+		return -EINVAL;
 	}
 
 	if (nblocks > ((s64) 1 << bmp->db_maxfreebud)) {
 		/* the free space is no longer available */
 		IREAD_UNLOCK(ipbmap);
-		return ENOSPC;
+		return -ENOSPC;
 	}
 
 	/* read in the dmap covering the extent */
@@ -990,7 +990,7 @@
 	mp = read_metapage(ipbmap, lblkno, PSIZE, 0);
 	if (mp == NULL) {
 		IREAD_UNLOCK(ipbmap);
-		return (EIO);
+		return -EIO;
 	}
 	dp = (struct dmap *) mp->data;
 
@@ -1038,8 +1038,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  */
 int
 dbReAlloc(struct inode *ip,
@@ -1053,7 +1053,7 @@
 		*results = blkno;
 		return (0);
 	} else {
-		if (rc != ENOSPC)
+		if (rc != -ENOSPC)
 			return (rc);
 	}
 
@@ -1087,8 +1087,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  */
 int dbExtend(struct inode *ip, s64 blkno, s64 nblocks, s64 addnblocks)
 {
@@ -1106,7 +1106,7 @@
 	 */
 	if (((rel_block = blkno & (sbi->nbperpage - 1))) &&
 	    (rel_block + nblocks + addnblocks > sbi->nbperpage))
-		return (ENOSPC);
+		return -ENOSPC;
 
 	/* get the last block of the current allocation */
 	lastblkno = blkno + nblocks - 1;
@@ -1133,7 +1133,7 @@
 	if (addnblocks > BPERDMAP || extblkno >= bmp->db_mapsize ||
 	    (extblkno & (bmp->db_agsize - 1)) == 0) {
 		IREAD_UNLOCK(ipbmap);
-		return (ENOSPC);
+		return -ENOSPC;
 	}
 
 	/* get the buffer for the dmap containing the first block
@@ -1143,7 +1143,7 @@
 	mp = read_metapage(ipbmap, lblkno, PSIZE, 0);
 	if (mp == NULL) {
 		IREAD_UNLOCK(ipbmap);
-		return (EIO);
+		return -EIO;
 	}
 
 	DBALLOCCK(bmp->db_DBmap, bmp->db_mapsize, blkno, nblocks);
@@ -1164,7 +1164,7 @@
 	} else {
 		/* we were not successful */
 		release_metapage(mp);
-		assert(rc == ENOSPC || rc == EIO);
+		assert(rc == -ENOSPC || rc == -EIO);
 	}
 
 	return (rc);
@@ -1185,8 +1185,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  *
  * serialization: IREAD_LOCK(ipbmap) held on entry/exit;
  */
@@ -1212,13 +1212,13 @@
 	 * this dmap.
 	 */
 	if (dbitno + nblocks > BPERDMAP)
-		return (ENOSPC);
+		return -ENOSPC;
 
 	/* check if the starting leaf indicates that anything
 	 * is free.
 	 */
 	if (leaf[word] == NOFREE)
-		return (ENOSPC);
+		return -ENOSPC;
 
 	/* check the dmaps words corresponding to block range to see
 	 * if the block range is free.  not all bits of the first and
@@ -1247,7 +1247,7 @@
 			 */
 			mask = (ONES << (DBWORD - nb) >> wbitno);
 			if ((mask & ~le32_to_cpu(dp->wmap[word])) != mask)
-				return (ENOSPC);
+				return -ENOSPC;
 
 			word += 1;
 		} else {
@@ -1265,7 +1265,7 @@
 				/* does the leaf describe any free space ?
 				 */
 				if (leaf[word] < BUDMIN)
-					return (ENOSPC);
+					return -ENOSPC;
 
 				/* determine the l2 number of bits provided
 				 * by this leaf.
@@ -1311,8 +1311,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  *
  * serialization: IREAD_LOCK(ipbmap) held on entry/exit;
  */
@@ -1360,7 +1360,7 @@
 		return (rc);
 	}
 
-	return (ENOSPC);
+	return -ENOSPC;
 }
 
 
@@ -1413,8 +1413,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  *
  * note: IWRITE_LOCK(ipmap) held on entry/exit;
  */
@@ -1457,8 +1457,8 @@
 	if (bmp->db_agsize == BPERDMAP
 	    || bmp->db_agfree[agno] == bmp->db_agsize) {
 		rc = dbAllocCtl(bmp, nblocks, l2nb, blkno, results);
-		/* assert(!(rc == ENOSPC && bmp->db_agfree[agno] == bmp->db_agsize)); */
-		if ((rc == ENOSPC) &&
+		/* assert(!(rc == -ENOSPC && bmp->db_agfree[agno] == bmp->db_agsize)); */
+		if ((rc == -ENOSPC) &&
 		    (bmp->db_agfree[agno] == bmp->db_agsize)) {
 			jfs_err("dbAllocAG: removed assert, but still need to "
 				"debug here\nblkno = 0x%Lx, nblocks = 0x%Lx",
@@ -1474,7 +1474,7 @@
 	lblkno = BLKTOCTL(blkno, bmp->db_l2nbperpage, bmp->db_aglevel);
 	mp = read_metapage(bmp->db_ipbmap, lblkno, PSIZE, 0);
 	if (mp == NULL)
-		return (EIO);
+		return -EIO;
 	dcp = (struct dmapctl *) mp->data;
 	budmin = dcp->budmin;
 
@@ -1547,7 +1547,7 @@
 			if ((rc =
 			     dbFindCtl(bmp, l2nb, bmp->db_aglevel - 1,
 				       &blkno))) {
-				assert(rc != ENOSPC);
+				assert(rc != -ENOSPC);
 				return (rc);
 			}
 		}
@@ -1555,16 +1555,16 @@
 		/* allocate the blocks.
 		 */
 		rc = dbAllocCtl(bmp, nblocks, l2nb, blkno, results);
-		assert(rc != ENOSPC);
+		assert(rc != -ENOSPC);
 		return (rc);
 	}
 
 	/* no space in the allocation group.  release the buffer and
-	 * return ENOSPC.
+	 * return -ENOSPC.
 	 */
 	release_metapage(mp);
 
-	return (ENOSPC);
+	return -ENOSPC;
 }
 
 
@@ -1589,8 +1589,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  *
  * serialization: IWRITE_LOCK(ipbmap) held on entry/exit;
  */
@@ -1611,7 +1611,7 @@
 	/* allocate the blocks.
 	 */
 	rc = dbAllocCtl(bmp, nblocks, l2nb, blkno, results);
-	assert(rc != ENOSPC);
+	assert(rc != -ENOSPC);
 	return (rc);
 }
 
@@ -1639,8 +1639,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  *
  * serialization: IWRITE_LOCK(ipbmap) held on entry/exit;
  */
@@ -1664,7 +1664,7 @@
 		lblkno = BLKTOCTL(b, bmp->db_l2nbperpage, lev);
 		mp = read_metapage(bmp->db_ipbmap, lblkno, PSIZE, 0);
 		if (mp == NULL)
-			return (EIO);
+			return -EIO;
 		dcp = (struct dmapctl *) mp->data;
 		budmin = dcp->budmin;
 
@@ -1683,7 +1683,7 @@
 		 */
 		if (rc) {
 			assert(lev == level);
-			return (ENOSPC);
+			return -ENOSPC;
 		}
 
 		/* adjust the block number to reflect the location within
@@ -1746,8 +1746,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  *
  * serialization: IWRITE_LOCK(ipbmap) held on entry/exit;
  */
@@ -1767,7 +1767,7 @@
 		lblkno = BLKTODMAP(blkno, bmp->db_l2nbperpage);
 		mp = read_metapage(bmp->db_ipbmap, lblkno, PSIZE, 0);
 		if (mp == NULL)
-			return (EIO);
+			return -EIO;
 		dp = (struct dmap *) mp->data;
 
 		/* try to allocate the blocks.
@@ -1794,7 +1794,7 @@
 		lblkno = BLKTODMAP(b, bmp->db_l2nbperpage);
 		mp = read_metapage(bmp->db_ipbmap, lblkno, PSIZE, 0);
 		if (mp == NULL) {
-			rc = EIO;
+			rc = -EIO;
 			goto backout;
 		}
 		dp = (struct dmap *) mp->data;
@@ -1891,8 +1891,8 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient disk resources
- *      EIO	- i/o error
+ *      -ENOSPC	- insufficient disk resources
+ *      -EIO	- i/o error
  *
  * serialization: IREAD_LOCK(ipbmap), e.g., from dbAlloc(), or 
  *	IWRITE_LOCK(ipbmap), e.g., dbAllocCtl(), held on entry/exit;
@@ -1912,7 +1912,7 @@
 	 * returns the index of the leaf at which free space was found.
 	 */
 	if (dbFindLeaf((dmtree_t *) & dp->tree, l2nb, &leafidx))
-		return (ENOSPC);
+		return -ENOSPC;
 
 	/* determine the block number within the file system corresponding
 	 * to the leaf at which free space was found.
@@ -1957,7 +1957,7 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      EIO	- i/o error
+ *      -EIO	- i/o error
  *
  * serialization: IREAD_LOCK(ipbmap) or IWRITE_LOCK(ipbmap) held on entry/exit;
  */
@@ -2012,7 +2012,7 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      EIO	- i/o error
+ *      -EIO	- i/o error
  *
  * serialization: IREAD_LOCK(ipbmap) or IWRITE_LOCK(ipbmap) held on entry/exit;
  */
@@ -2392,7 +2392,7 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      EIO	- i/o error
+ *      -EIO	- i/o error
  *
  * serialization: IREAD_LOCK(ipbmap) or IWRITE_LOCK(ipbmap) held on entry/exit;
  */
@@ -2412,7 +2412,7 @@
 	lblkno = BLKTOCTL(blkno, bmp->db_l2nbperpage, level);
 	mp = read_metapage(bmp->db_ipbmap, lblkno, PSIZE, 0);
 	if (mp == NULL)
-		return (EIO);
+		return -EIO;
 	dcp = (struct dmapctl *) mp->data;
 
 	/* determine the leaf number corresponding to the block and
@@ -2835,7 +2835,7 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      ENOSPC	- insufficient free blocks. 
+ *      -ENOSPC	- insufficient free blocks. 
  */
 static int dbFindLeaf(dmtree_t * tp, int l2nb, int *leafidx)
 {
@@ -2845,7 +2845,7 @@
 	 * sufficient free space.
 	 */
 	if (l2nb > tp->dmt_stree[ROOT])
-		return (ENOSPC);
+		return -ENOSPC;
 
 	/* sufficient free space available. now search down the tree
 	 * starting at the next level for the leftmost leaf that
@@ -3066,7 +3066,7 @@
  * RETURN VALUES:
  *      none
  */
-void fsDirty()
+void fsDirty(void)
 {
 	printk("fsDirty(): bye-bye\n");
 	assert(0);
@@ -3089,7 +3089,7 @@
  *
  * RETURN VALUES:
  *      0	- success
- *      EIO	- i/o error
+ *      -EIO	- i/o error
  */
 int dbAllocBottomUp(struct inode *ip, s64 blkno, s64 nblocks)
 {
@@ -3120,7 +3120,7 @@
 		mp = read_metapage(ipbmap, lblkno, PSIZE, 0);
 		if (mp == NULL) {
 			IREAD_UNLOCK(ipbmap);
-			return (EIO);
+			return -EIO;
 		}
 		dp = (struct dmap *) mp->data;
 
@@ -3530,7 +3530,7 @@
 	return 0;
 
       errout:
-	return EIO;
+	return -EIO;
 }
 
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_dtree.c linux-2.4.23-pre1/fs/jfs/jfs_dtree.c
--- linux-2.4.22/fs/jfs/jfs_dtree.c	2003-08-25 11:44:43.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_dtree.c	2003-08-27 14:41:26.000000000 +0000
@@ -134,7 +134,7 @@
 			BT_PUTPAGE(MP);\
 			updateSuper((IP)->i_sb, FM_DIRTY);\
 			MP = NULL;\
-			RC = EIO;\
+			RC = -EIO;\
 		}\
 	}\
 }
@@ -404,7 +404,7 @@
 		     xtInsert(tid, ip, 0, 0, sbi->nbperpage,
 			      &xaddr, 0))) {
 			jfs_warn("add_index: xtInsert failed!");
-			return -1;
+			return -EPERM;
 		}
 		ip->i_size = PSIZE;
 		ip->i_blocks += LBLK2PBLK(sb, sbi->nbperpage);
@@ -412,7 +412,7 @@
 		if ((mp = get_index_page(ip, 0)) == 0) {
 			jfs_err("add_index: get_metapage failed!");
 			xtTruncate(tid, ip, 0, COMMIT_PWMAP);
-			return -1;
+			return -EPERM;
 		}
 		tlck = txLock(tid, ip, mp, tlckDATA);
 		llck = (struct linelock *) & tlck->lock;
@@ -447,7 +447,7 @@
 			      &xaddr, 0))) {
 			jfs_warn("add_index: xtInsert failed!");
 			jfs_ip->next_index--;
-			return -1;
+			return -EPERM;
 		}
 		ip->i_size += PSIZE;
 		ip->i_blocks += LBLK2PBLK(sb, sbi->nbperpage);
@@ -461,7 +461,7 @@
 
 	if (mp == 0) {
 		jfs_err("add_index: get/read_metapage failed!");
-		return -1;
+		return -EPERM;
 	}
 
 	lock_index(tid, ip, mp, index);
@@ -588,7 +588,7 @@
 	    (wchar_t *) kmalloc((JFS_NAME_MAX + 1) * sizeof(wchar_t),
 				GFP_NOFS);
 	if (ciKey.name == 0) {
-		rc = ENOMEM;
+		rc = -ENOMEM;
 		goto dtSearch_Exit2;
 	}
 
@@ -674,7 +674,7 @@
 					 */
 					if (flag == JFS_CREATE) {
 						*data = inumber;
-						rc = EEXIST;
+						rc = -EEXIST;
 						goto out;
 					}
 
@@ -684,7 +684,7 @@
 					if ((flag == JFS_REMOVE ||
 					     flag == JFS_RENAME) &&
 					    *data != inumber) {
-						rc = ESTALE;
+						rc = -ESTALE;
 						goto out;
 					}
 
@@ -732,7 +732,7 @@
 			 */
 			if (flag == JFS_LOOKUP || flag == JFS_REMOVE ||
 			    flag == JFS_RENAME) {
-				rc = ENOENT;
+				rc = -ENOENT;
 				goto out;
 			}
 
@@ -770,7 +770,7 @@
 			 */
 			jfs_err("stack overrun in dtSearch!");
 			updateSuper(sb, FM_DIRTY);
-			rc = EIO;
+			rc = -EIO;
 			goto out;
 		}
 		btstack->nsplit++;
@@ -840,7 +840,7 @@
 	if (DO_INDEX(ip)) {
 		if (JFS_IP(ip)->next_index == DIREND) {
 			DT_PUTPAGE(mp);
-			return EMLINK;
+			return -EMLINK;
 		}
 		n = NDTLEAF(name->namlen);
 		data.leaf.tid = tid;
@@ -953,7 +953,7 @@
 				GFP_NOFS);
 	if (key.name == 0) {
 		DT_PUTPAGE(smp);
-		rc = ENOMEM;
+		rc = -ENOMEM;
 		goto dtSplitUp_Exit;
 	}
 
@@ -1328,7 +1328,7 @@
 	rbn = addressPXD(pxd);
 	rmp = get_metapage(ip, rbn, PSIZE, 1);
 	if (rmp == NULL)
-		return EIO;
+		return -EIO;
 
 	jfs_info("dtSplitPage: ip:0x%p smp:0x%p rmp:0x%p", ip, smp, rmp);
 
@@ -1579,7 +1579,7 @@
 
 	ip->i_blocks += LBLK2PBLK(sb, lengthPXD(pxd));
 
-	return 0;
+	return rc;
 }
 
 
@@ -2628,7 +2628,7 @@
 		 * descend down to leftmost child page
 		 */
 		if (p->header.flag & BT_LEAF)
-			return ESTALE;
+			return -ESTALE;
 
 		/* get the leftmost entry */
 		stbl = DT_GETSTBL(p);
@@ -2666,7 +2666,7 @@
 		bn = le64_to_cpu(p->header.next);
 	else {
 		DT_PUTPAGE(mp);
-		return ESTALE;
+		return -ESTALE;
 	}
 
 	/* unpin current page */
@@ -3068,7 +3068,7 @@
 			}
 
 			if ((rc = dtReadFirst(ip, &btstack)))
-				return -rc;
+				return rc;
 
 			DT_GETSEARCH(ip, btstack.top, bn, mp, p, index);
 		}
@@ -3268,7 +3268,7 @@
 		DT_GETPAGE(ip, bn, mp, PSIZE, p, rc);
 		if (rc) {
 			free_page(dirent_buf);
-			return -rc;
+			return rc;
 		}
 	}
 
@@ -4434,8 +4434,8 @@
  *	flag	- JFS_RENAME
  *
  * RETURNS:
- *	ESTALE	- If entry found does not match orig_ino passed in
- *	ENOENT	- If no entry can be found to match key
+ *	-ESTALE	- If entry found does not match orig_ino passed in
+ *	-ENOENT	- If no entry can be found to match key
  *	0	- If successfully modified entry
  */
 int dtModify(tid_t tid, struct inode *ip,
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_extent.c linux-2.4.23-pre1/fs/jfs/jfs_extent.c
--- linux-2.4.22/fs/jfs/jfs_extent.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_extent.c	2003-08-27 14:40:40.000000000 +0000
@@ -83,8 +83,8 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      EIO	- i/o error.
- *      ENOSPC	- insufficient disk resources.
+ *      -EIO	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
  */
 int
 extAlloc(struct inode *ip, s64 xlen, s64 pno, xad_t * xp, boolean_t abnr)
@@ -208,8 +208,8 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      EIO	- i/o error.
- *      ENOSPC	- insufficient disk resources.
+ *      -EIO	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
  */
 int extRealloc(struct inode *ip, s64 nxlen, xad_t * xp, boolean_t abnr)
 {
@@ -351,7 +351,7 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      EIO	- i/o error.
+ *      -EIO	- i/o error.
  */
 int extHint(struct inode *ip, s64 offset, xad_t * xp)
 {
@@ -422,8 +422,8 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      EIO	- i/o error.
- *      ENOSPC	- insufficient disk resources.
+ *      -EIO	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
  */
 int extRecord(struct inode *ip, xad_t * xp)
 {
@@ -437,7 +437,7 @@
 	rc = xtUpdate(0, ip, xp);
 
 	up(&JFS_IP(ip)->commit_sem);
-	return (rc);
+	return rc;
 }
 
 
@@ -454,8 +454,8 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      EIO	- i/o error.
- *      ENOSPC	- insufficient disk resources.
+ *      -EIO	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
  */
 int extFill(struct inode *ip, xad_t * xp)
 {
@@ -506,8 +506,8 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      EIO	- i/o error.
- *      ENOSPC	- insufficient disk resources.
+ *      -EIO	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
  */
 static int
 extBalloc(struct inode *ip, s64 hint, s64 * nblocks, s64 * blkno)
@@ -536,7 +536,7 @@
 		/* if something other than an out of space error,
 		 * stop and return this error.
 		 */
-		if (rc != ENOSPC)
+		if (rc != -ENOSPC)
 			return (rc);
 
 		/* decrease the allocation request size */
@@ -597,8 +597,8 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      EIO	- i/o error.
- *      ENOSPC	- insufficient disk resources.
+ *      -EIO	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
  */
 static int
 extBrealloc(struct inode *ip,
@@ -611,7 +611,7 @@
 		*newblkno = blkno;
 		return (0);
 	} else {
-		if (rc != ENOSPC)
+		if (rc != -ENOSPC)
 			return (rc);
 	}
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_filsys.h linux-2.4.23-pre1/fs/jfs/jfs_filsys.h
--- linux-2.4.22/fs/jfs/jfs_filsys.h	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_filsys.h	2003-08-27 14:39:14.000000000 +0000
@@ -1,5 +1,5 @@
 /*
- *   Copyright (c) International Business Machines Corp., 2000-2001
+ *   Copyright (c) International Business Machines Corp., 2000-2003
  *
  *   This program is free software;  you can redistribute it and/or modify
  *   it under the terms of the GNU General Public License as published by
@@ -29,6 +29,9 @@
 /*
  *	 file system option (superblock flag)
  */
+/* mount time flag to disable journaling to disk */
+#define JFS_NOINTEGRITY 0x00000010
+
 /* platform option (conditional compilation) */
 #define JFS_AIX		0x80000000	/* AIX support */
 /*	POSIX name/directory  support */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_imap.c linux-2.4.23-pre1/fs/jfs/jfs_imap.c
--- linux-2.4.22/fs/jfs/jfs_imap.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_imap.c	2003-08-27 14:40:28.000000000 +0000
@@ -120,8 +120,8 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      ENOMEM  - insufficient free virtual memory.
- *      EIO  	- i/o error.
+ *      -ENOMEM  - insufficient free virtual memory.
+ *      -EIO  	- i/o error.
  */
 int diMount(struct inode *ipimap)
 {
@@ -137,7 +137,7 @@
 	imap = (struct inomap *) kmalloc(sizeof(struct inomap), GFP_KERNEL);
 	if (imap == NULL) {
 		jfs_err("diMount: kmalloc returned NULL!");
-		return (ENOMEM);
+		return -ENOMEM;
 	}
 
 	/* read the on-disk inode map control structure. */
@@ -147,7 +147,7 @@
 			   PSIZE, 0);
 	if (mp == NULL) {
 		kfree(imap);
-		return (EIO);
+		return -EIO;
 	}
 
 	/* copy the on-disk version to the in-memory version. */
@@ -206,8 +206,8 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      ENOMEM  - insufficient free virtual memory.
- *      EIO  	- i/o error.
+ *      -ENOMEM  - insufficient free virtual memory.
+ *      -EIO  	- i/o error.
  */
 int diUnmount(struct inode *ipimap, int mounterror)
 {
@@ -253,7 +253,7 @@
 			  PSIZE, 0);
 	if (mp == NULL) {
 		jfs_err("diSync: get_metapage failed!");
-		return EIO;
+		return -EIO;
 	}
 
 	/* copy the in-memory version to the on-disk version */
@@ -318,8 +318,8 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      EIO  	- i/o error.
- *      ENOMEM	- insufficient memory
+ *      -EIO  	- i/o error.
+ *      -ENOMEM	- insufficient memory
  *      
  */
 int diRead(struct inode *ip)
@@ -364,7 +364,7 @@
 	if ((lengthPXD(&iagp->inoext[extno]) != imap->im_nbperiext) ||
 	    (addressPXD(&iagp->inoext[extno]) == 0)) {
 		release_metapage(mp);
-		return ESTALE;
+		return -ESTALE;
 	}
 
 	/* get disk block number of the page within the inode extent
@@ -399,7 +399,7 @@
 	mp = read_metapage(ipimap, pageno << sbi->l2nbperpage, PSIZE, 1);
 	if (mp == 0) {
 		jfs_err("diRead: read_metapage failed");
-		return EIO;
+		return -EIO;
 	}
 
 	/* locate the the disk inode requested */
@@ -409,9 +409,9 @@
 	if (ip->i_ino != le32_to_cpu(dp->di_number)) {
 		jfs_err("diRead: i_ino != di_number");
 		updateSuper(ip->i_sb, FM_DIRTY);
-		rc = EIO;
+		rc = -EIO;
 	} else if (le32_to_cpu(dp->di_nlink) == 0)
-		rc = ESTALE;
+		rc = -ESTALE;
 	else
 		/* copy the disk inode to the in-memory inode */
 		rc = copy_from_dinode(dp, ip);
@@ -617,7 +617,7 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      EIO  	- i/o error.
+ *      -EIO  	- i/o error.
  */
 int diWrite(tid_t tid, struct inode *ip)
 {
@@ -676,7 +676,7 @@
       retry:
 	mp = read_metapage(ipimap, pageno << sbi->l2nbperpage, PSIZE, 1);
 	if (mp == 0)
-		return (EIO);
+		return -EIO;
 
 	/* get the pointer to the disk inode */
 	dp = (struct dinode *) mp->data;
@@ -890,7 +890,7 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      EIO  	- i/o error.
+ *      -EIO  	- i/o error.
  */
 int diFree(struct inode *ip)
 {
@@ -928,7 +928,7 @@
 			(uint) inum, iagno, imap->im_nextiag);
 		dump_mem("imap", imap, 32);
 		updateSuper(ip->i_sb, FM_DIRTY);
-		return EIO;
+		return -EIO;
 	}
 
 	/* get the allocation group for this ino.
@@ -977,7 +977,7 @@
 		IREAD_UNLOCK(ipimap);
 		AG_UNLOCK(imap, agno);
 		updateSuper(ip->i_sb, FM_DIRTY);
-		return EIO;
+		return -EIO;
 	}
 	/*
 	 *      inode extent still has some inodes or below low water mark:
@@ -1367,8 +1367,8 @@
  *
  * RETURN VALUES:
  *      0       - success.
- *      ENOSPC 	- insufficient disk resources.
- *      EIO  	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
+ *      -EIO  	- i/o error.
  */
 int diAlloc(struct inode *pip, boolean_t dir, struct inode *ip)
 {
@@ -1476,7 +1476,7 @@
 				rc = diAllocBit(imap, iagp, ino);
 				IREAD_UNLOCK(ipimap);
 				if (rc) {
-					assert(rc == EIO);
+					assert(rc == -EIO);
 				} else {
 					/* set the results of the allocation
 					 * and write the iag.
@@ -1553,7 +1553,7 @@
 				rc = diAllocBit(imap, iagp, ino);
 				IREAD_UNLOCK(ipimap);
 				if (rc) {
-					assert(rc == EIO);
+					assert(rc == -EIO);
 				} else {
 					/* set the results of the allocation
 					 * and write the iag.
@@ -1589,10 +1589,10 @@
 					 * new extent, try to allocate the
 					 * disk inode from somewhere else.
 					 */
-					if (rc == ENOSPC)
+					if (rc == -ENOSPC)
 						break;
 
-					assert(rc == EIO);
+					assert(rc == -EIO);
 				} else {
 					/* set the results of the allocation
 					 * and write the iag.
@@ -1631,7 +1631,7 @@
 
 	AG_UNLOCK(imap, agno);
 
-	if (rc != ENOSPC)
+	if (rc != -ENOSPC)
 		return (rc);
 
 	/*
@@ -1667,8 +1667,8 @@
  *
  * RETURN VALUES:
  *      0       - success.
- *      ENOSPC 	- insufficient disk resources.
- *      EIO  	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
+ *      -EIO  	- i/o error.
  */
 static int
 diAllocAG(struct inomap * imap, int agno, boolean_t dir, struct inode *ip)
@@ -1684,7 +1684,7 @@
 	if (numfree > numinos) {
 		jfs_err("diAllocAG: numfree > numinos");
 		updateSuper(ip->i_sb, FM_DIRTY);
-		return EIO;
+		return -EIO;
 	}
 
 	/* determine if we should allocate a new extent of free inodes
@@ -1707,7 +1707,7 @@
 		 * below to allocate a free and existing (already backed)
 		 * inode from the ag.
 		 */
-		if ((rc = diAllocExt(imap, agno, ip)) != ENOSPC)
+		if ((rc = diAllocExt(imap, agno, ip)) != -ENOSPC)
 			return (rc);
 	}
 
@@ -1738,8 +1738,8 @@
  *
  * RETURN VALUES:
  *      0       - success.
- *      ENOSPC 	- insufficient disk resources.
- *      EIO  	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
+ *      -EIO  	- i/o error.
  */
 static int
 diAllocAny(struct inomap * imap, int agno, boolean_t dir, struct inode *ip)
@@ -1758,7 +1758,7 @@
 
 		AG_UNLOCK(imap, ag);
 
-		if (rc != ENOSPC)
+		if (rc != -ENOSPC)
 			return (rc);
 	}
 
@@ -1771,13 +1771,13 @@
 
 		AG_UNLOCK(imap, ag);
 
-		if (rc != ENOSPC)
+		if (rc != -ENOSPC)
 			return (rc);
 	}
 
 	/* no free disk inodes.
 	 */
-	return (ENOSPC);
+	return -ENOSPC;
 }
 
 
@@ -1803,8 +1803,8 @@
  *
  * RETURN VALUES:
  *      0       - success.
- *      ENOSPC 	- insufficient disk resources.
- *      EIO  	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
+ *      -EIO  	- i/o error.
  */
 static int diAllocIno(struct inomap * imap, int agno, struct inode *ip)
 {
@@ -1815,7 +1815,7 @@
 	/* check if there are iags on the ag's free inode list.
 	 */
 	if ((iagno = imap->im_agctl[agno].inofree) < 0)
-		return (ENOSPC);
+		return -ENOSPC;
 
 	/* obtain read lock on imap inode */
 	IREAD_LOCK(imap->im_ipimap);
@@ -1837,7 +1837,7 @@
 		jfs_err("  agno = %d, iagno = %d", agno, iagno);
 		dump_mem("iag", iagp, 64);
 		updateSuper(ip->i_sb, FM_DIRTY);
-		return EIO;
+		return -EIO;
 	}
 
 	/* scan the free inode summary map to find an extent
@@ -1913,8 +1913,8 @@
  *
  * RETURN VALUES:
  *      0       - success.
- *      ENOSPC 	- insufficient disk resources.
- *      EIO  	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
+ *      -EIO  	- i/o error.
  */
 static int diAllocExt(struct inomap * imap, int agno, struct inode *ip)
 {
@@ -2018,8 +2018,8 @@
  *
  * RETURN VALUES:
  *      0       - success.
- *      ENOSPC 	- insufficient disk resources.
- *      EIO  	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
+ *      -EIO  	- i/o error.
  */
 static int diAllocBit(struct inomap * imap, struct iag * iagp, int ino)
 {
@@ -2158,8 +2158,8 @@
  *
  * RETURN VALUES:
  *      0       - success.
- *      ENOSPC 	- insufficient disk resources.
- *      EIO  	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
+ *      -EIO  	- i/o error.
  */
 static int diNewExt(struct inomap * imap, struct iag * iagp, int extno)
 {
@@ -2272,7 +2272,7 @@
 		 */
 		dmp = get_metapage(ipimap, blkno + i, PSIZE, 1);
 		if (dmp == NULL) {
-			rc = EIO;
+			rc = -EIO;
 			goto error_out;
 		}
 		dp = (struct dinode *) dmp->data;
@@ -2418,8 +2418,8 @@
  *
  * RETURN VALUES:
  *      0       - success.
- *      ENOSPC 	- insufficient disk resources.
- *      EIO  	- i/o error.
+ *      -ENOSPC	- insufficient disk resources.
+ *      -EIO  	- i/o error.
  *
  * serialization: 
  *	AG lock held on entry/exit;
@@ -2490,7 +2490,7 @@
 			/* release the inode map lock */
 			IWRITE_UNLOCK(ipimap);
 
-			rc = ENOSPC;
+			rc = -ENOSPC;
 			goto out;
 		}
 
@@ -2521,7 +2521,7 @@
 			/* release the inode map lock */
 			IWRITE_UNLOCK(ipimap);
 
-			rc = EIO;
+			rc = -EIO;
 			goto out;
 		}
 		iagp = (struct iag *) mp->data;
@@ -2553,7 +2553,7 @@
 			/* release the inode map lock */
 			IWRITE_UNLOCK(ipimap);
 
-			rc = EIO;
+			rc = -EIO;
 			goto out;
 		}
 
@@ -2619,7 +2619,7 @@
 	/* read the iag */
 	if ((rc = diIAGRead(imap, iagno, &mp))) {
 		IREAD_UNLOCK(ipimap);
-		rc = EIO;
+		rc = -EIO;
 		goto out;
 	}
 	iagp = (struct iag *) mp->data;
@@ -2658,7 +2658,7 @@
  *
  * RETURN VALUES:
  *      0       - success.
- *      EIO  	- i/o error.
+ *      -EIO  	- i/o error.
  */
 static int diIAGRead(struct inomap * imap, int iagno, struct metapage ** mpp)
 {
@@ -2671,7 +2671,7 @@
 	/* read the iag. */
 	*mpp = read_metapage(ipimap, blkno, PSIZE, 0);
 	if (*mpp == NULL) {
-		return (EIO);
+		return -EIO;
 	}
 
 	return (0);
@@ -2718,7 +2718,8 @@
  *	is_free	- If TRUE indicates inode should be marked freed, otherwise
  *		  indicates inode should be marked allocated.
  *
- * RETURNS: 0 for success
+ * RETURN VALUES: 
+ *		0 for success
  */
 int
 diUpdatePMap(struct inode *ipimap,
@@ -3016,7 +3017,7 @@
  *
  * RETURN VALUES:
  *      0       - success
- *      ENOMEM	- insufficient memory
+ *      -ENOMEM	- insufficient memory
  */
 static int copy_from_dinode(struct dinode * dip, struct inode *ip)
 {
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_incore.h linux-2.4.23-pre1/fs/jfs/jfs_incore.h
--- linux-2.4.22/fs/jfs/jfs_incore.h	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_incore.h	2003-08-27 14:41:21.000000000 +0000
@@ -1,5 +1,5 @@
 /*
- *   Copyright (c) International Business Machines Corp., 2000-2002
+ *   Copyright (c) International Business Machines Corp., 2000-2003
  *   Portions Copyright (c) Christoph Hellwig, 2001-2002
  *
  *   This program is free software;  you can redistribute it and/or modify
@@ -126,32 +126,34 @@
  * JFS-private superblock information.
  */
 struct jfs_sb_info {
-	unsigned long	mntflag;	/* 4: aggregate attributes	*/
-	struct inode	*ipbmap;	/* 4: block map inode		*/
-	struct inode	*ipaimap;	/* 4: aggregate inode map inode	*/
-	struct inode	*ipaimap2;	/* 4: secondary aimap inode	*/
-	struct inode	*ipimap;	/* 4: aggregate inode map inode	*/
-	struct jfs_log	*log;		/* 4: log			*/
-	short		bsize;		/* 2: logical block size	*/
-	short		l2bsize;	/* 2: log2 logical block size	*/
-	short		nbperpage;	/* 2: blocks per page		*/
-	short		l2nbperpage;	/* 2: log2 blocks per page	*/
-	short		l2niperblk;	/* 2: log2 inodes per page	*/
-	kdev_t		logdev;		/* 2: external log device	*/
+	unsigned long	mntflag;	/* aggregate attributes	*/
+	struct inode	*ipbmap;	/* block map inode		*/
+	struct inode	*ipaimap;	/* aggregate inode map inode	*/
+	struct inode	*ipaimap2;	/* secondary aimap inode	*/
+	struct inode	*ipimap;	/* aggregate inode map inode	*/
+	struct jfs_log	*log;		/* log			*/
+	short		bsize;		/* logical block size	*/
+	short		l2bsize;	/* log2 logical block size	*/
+	short		nbperpage;	/* blocks per page		*/
+	short		l2nbperpage;	/* log2 blocks per page	*/
+	short		l2niperblk;	/* log2 inodes per page	*/
+	kdev_t		logdev;		/* external log device	*/
 	uint		aggregate;	/* volume identifier in log record */
-	pxd_t		logpxd;		/* 8: pxd describing log	*/
-	pxd_t		fsckpxd;	/* 8: pxd describing fsck wkspc */
-	pxd_t		ait2;		/* 8: pxd describing AIT copy	*/
-	char		uuid[16];	/* 16: 128-bit uuid for volume	*/
-	char		loguuid[16];	/* 16: 128-bit uuid for log	*/
+	pxd_t		logpxd;		/* pxd describing log	*/
+	pxd_t		fsckpxd;	/* pxd describing fsck wkspc */
+	pxd_t		ait2;		/* pxd describing AIT copy	*/
+	char		uuid[16];	/* 128-bit uuid for volume	*/
+	char		loguuid[16];	/* 128-bit uuid for log	*/
 	/* Formerly in ipimap */
-	uint		gengen;		/* 4: inode generation generator*/
-	uint		inostamp;	/* 4: shows inode belongs to fileset*/
+	uint		gengen;		/* inode generation generator*/
+	uint		inostamp;	/* shows inode belongs to fileset*/
 
         /* Formerly in ipbmap */
-	struct bmap	*bmap;		/* 4: incore bmap descriptor	*/
-	struct nls_table *nls_tab;	/* 4: current codepage		*/
-	uint		state;		/* 4: mount/recovery state	*/
+	struct bmap	*bmap;		/* incore bmap descriptor	*/
+	struct nls_table *nls_tab;	/* current codepage		*/
+	uint		state;		/* mount/recovery state	*/
+	unsigned long	flag;		/* mount time flags */
+	uint		p_state;	/* state prior to going no integrity */
 };
 
 static inline struct jfs_inode_info *JFS_IP(struct inode *inode)
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_logmgr.c linux-2.4.23-pre1/fs/jfs/jfs_logmgr.c
--- linux-2.4.22/fs/jfs/jfs_logmgr.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_logmgr.c	2003-08-27 14:40:28.000000000 +0000
@@ -1,5 +1,5 @@
 /*
- *   Copyright (c) International Business Machines Corp., 2000-2002
+ *   Copyright (c) International Business Machines Corp., 2000-2003
  *   Portions Copyright (c) Christoph Hellwig, 2001-2002
  *
  *   This program is free software;  you can redistribute it and/or modify
@@ -666,7 +666,7 @@
 	/* group committed already ? */
 	if (tblk->flag & tblkGC_COMMITTED) {
 		if (tblk->flag & tblkGC_ERROR)
-			rc = EIO;
+			rc = -EIO;
 
 		LOGGC_UNLOCK(log);
 		return rc;
@@ -700,7 +700,7 @@
 
 	if (tblk->flag & tblkGC_COMMITTED) {
 		if (tblk->flag & tblkGC_ERROR)
-			rc = EIO;
+			rc = -EIO;
 
 		LOGGC_UNLOCK(log);
 		return rc;
@@ -716,7 +716,7 @@
 
 	/* removed from commit queue */
 	if (tblk->flag & tblkGC_ERROR)
-		rc = EIO;
+		rc = -EIO;
 
 	LOGGC_UNLOCK(log);
 	return rc;
@@ -1064,7 +1064,7 @@
 	struct jfs_log *log;
 
 	if (!(log = kmalloc(sizeof(struct jfs_log), GFP_KERNEL)))
-		return ENOMEM;
+		return -ENOMEM;
 	memset(log, 0, sizeof(struct jfs_log));
 	init_waitqueue_head(&log->syncwait);
 
@@ -1106,12 +1106,11 @@
 	 */
 
 	if (!(bdev = bdget(kdev_t_to_nr(JFS_SBI(sb)->logdev)))) {
-		rc = ENODEV;
+		rc = -ENODEV;
 		goto free;
 	}
 
 	if ((rc = blkdev_get(bdev, FMODE_READ|FMODE_WRITE, 0, BDEV_FS))) {
-		rc = -rc;
 		goto free;
 	}
 
@@ -1164,7 +1163,7 @@
  * PARAMETER:	log	- log structure
  *
  * RETURN:	0	- if ok
- *		EINVAL	- bad log magic number or superblock dirty
+ *		-EINVAL	- bad log magic number or superblock dirty
  *		error returned from logwait()
  *			
  * serialization: single first open thread
@@ -1206,21 +1205,21 @@
 
 	if (logsuper->magic != cpu_to_le32(LOGMAGIC)) {
 		jfs_warn("*** Log Format Error ! ***");
-		rc = EINVAL;
+		rc = -EINVAL;
 		goto errout20;
 	}
 
 	/* logredo() should have been run successfully. */
 	if (logsuper->state != cpu_to_le32(LOGREDONE)) {
 		jfs_warn("*** Log Is Dirty ! ***");
-		rc = EINVAL;
+		rc = -EINVAL;
 		goto errout20;
 	}
 
 	/* initialize log inode from log superblock */
 	if (test_bit(log_INLINELOG,&log->flag)) {
 		if (log->size != le32_to_cpu(logsuper->size)) {
-			rc = EINVAL;
+			rc = -EINVAL;
 			goto errout20;
 		}
 		jfs_info("lmLogInit: inline log:0x%p base:0x%Lx size:0x%x",
@@ -1239,6 +1238,15 @@
 	log->page = le32_to_cpu(logsuper->end) / LOGPSIZE;
 	log->eor = le32_to_cpu(logsuper->end) - (LOGPSIZE * log->page);
 
+	/* check for disabled journaling to disk */
+	if (JFS_SBI(log->sb)->flag & JFS_NOINTEGRITY) {
+		log->no_integrity = 1;
+		log->ni_page = log->page;
+		log->ni_eor = log->eor;
+	}
+	else
+		log->no_integrity = 0;
+
 	/*
 	 * initialize for log append write mode
 	 */
@@ -1519,6 +1527,14 @@
 	lrd.type = cpu_to_le16(LOG_SYNCPT);
 	lrd.length = 0;
 	lrd.log.syncpt.sync = 0;
+	
+	/* check for disabled journaling to disk */
+	if (JFS_SBI(log->sb)->flag & JFS_NOINTEGRITY) {
+		log->no_integrity = 0;
+		log->page = log->ni_page;
+		log->eor = log->ni_eor;
+	}
+
 	lsn = lmWriteRecord(log, NULL, &lrd, NULL);
 	bp = log->bp;
 	lp = (struct logpage *) bp->l_ldata;
@@ -1593,7 +1609,7 @@
 		if (i == MAX_ACTIVE) {
 			jfs_warn("Too many file systems sharing journal!");
 			lbmFree(bpsuper);
-			return EMFILE;	/* Is there a better rc? */
+			return -EMFILE;	/* Is there a better rc? */
 		}
 	} else {
 		for (i = 0; i < MAX_ACTIVE; i++)
@@ -1604,7 +1620,7 @@
 		if (i == MAX_ACTIVE) {
 			jfs_warn("Somebody stomped on the journal!");
 			lbmFree(bpsuper);
-			return EIO;
+			return -EIO;
 		}
 		
 	}
@@ -1701,7 +1717,7 @@
 
       error:
 	lbmLogShutdown(log);
-	return (ENOMEM);
+	return -ENOMEM;
 }
 
 
@@ -1974,7 +1990,12 @@
 	set_bit(BH_Req, &bp->l_bh.b_state);
 	bp->l_bh.b_rdev = bp->l_bh.b_dev;
 	bp->l_bh.b_rsector = bp->l_blkno << (bp->l_log->l2bsize - 9);
-	generic_make_request(WRITE, &bp->l_bh);
+
+	if (bp->l_log->no_integrity)
+		/* don't really do I/O */
+		lbmIODone(&bp->l_bh, 1);
+	 else
+		generic_make_request(WRITE, &bp->l_bh);
 
 	INCREMENT(lmStat.submitted);
 	run_task_queue(&tq_disk);
@@ -1995,7 +2016,7 @@
 
 	LCACHE_SLEEP_COND(bp->l_ioevent, (bp->l_flag & lbmDONE), flags);
 
-	rc = (bp->l_flag & lbmERROR) ? EIO : 0;
+	rc = (bp->l_flag & lbmERROR) ? -EIO : 0;
 
 	if (flag & lbmFREE)
 		lbmfree(bp);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_logmgr.h linux-2.4.23-pre1/fs/jfs/jfs_logmgr.h
--- linux-2.4.22/fs/jfs/jfs_logmgr.h	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_logmgr.h	2003-08-27 14:42:04.000000000 +0000
@@ -1,5 +1,5 @@
 /*
- *   Copyright (c) International Business Machines Corp., 2000-2002
+ *   Copyright (c) International Business Machines Corp., 2000-2003
  *   Portions Copyright (c) Christoph Hellwig, 2001-2002
  *
  *   This program is free software;  you can redistribute it and/or modify
@@ -417,6 +417,10 @@
 	struct lbuf *wqueue;	/* 4: log pageout queue */
 	int count;		/* 4: count */
 	char uuid[16];		/* 16: 128-bit uuid of log device */
+
+	int no_integrity;	/* flag to disable journaling to disk */
+	int ni_page;		/* backup of page for nointegrity option */
+	int ni_eor;		/* backup of eor for nointegrity option */
 };
 
 /*
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_mount.c linux-2.4.23-pre1/fs/jfs/jfs_mount.c
--- linux-2.4.22/fs/jfs/jfs_mount.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_mount.c	2003-08-27 14:39:56.000000000 +0000
@@ -1,5 +1,5 @@
 /*
- *   Copyright (c) International Business Machines Corp., 2000-2002
+ *   Copyright (c) International Business Machines Corp., 2000-2003
  *
  *   This program is free software;  you can redistribute it and/or modify
  *   it under the terms of the GNU General Public License as published by
@@ -72,11 +72,11 @@
  *
  * PARAMETER:	sb	- super block
  *
- * RETURN:	EBUSY	- device already mounted or open for write
- *		EBUSY	- cvrdvp already mounted;
- *		EBUSY	- mount table full
- *		ENOTDIR	- cvrdvp not directory on a device mount
- *		ENXIO	- device open failure
+ * RETURN:	-EBUSY	- device already mounted or open for write
+ *		-EBUSY	- cvrdvp already mounted;
+ *		-EBUSY	- mount table full
+ *		-ENOTDIR- cvrdvp not directory on a device mount
+ *		-ENXIO	- device open failure
  */
 int jfs_mount(struct super_block *sb)
 {
@@ -98,7 +98,7 @@
 	ipaimap = diReadSpecial(sb, AGGREGATE_I, 0);
 	if (ipaimap == NULL) {
 		jfs_err("jfs_mount: Faild to read AGGREGATE_I");
-		rc = EIO;
+		rc = -EIO;
 		goto errout20;
 	}
 	sbi->ipaimap = ipaimap;
@@ -118,7 +118,7 @@
 	 */
 	ipbmap = diReadSpecial(sb, BMAP_I, 0);
 	if (ipbmap == NULL) {
-		rc = EIO;
+		rc = -EIO;
 		goto errout22;
 	}
 
@@ -149,7 +149,7 @@
 		ipaimap2 = diReadSpecial(sb, AGGREGATE_I, 1);
 		if (ipaimap2 == 0) {
 			jfs_err("jfs_mount: Faild to read AGGREGATE_I");
-			rc = EIO;
+			rc = -EIO;
 			goto errout35;
 		}
 		sbi->ipaimap2 = ipaimap2;
@@ -178,7 +178,7 @@
 	if (ipimap == NULL) {
 		jfs_err("jfs_mount: Failed to read FILESYSTEM_I");
 		/* open fileset secondary inode allocation map */
-		rc = EIO;
+		rc = -EIO;
 		goto errout40;
 	}
 	jfs_info("jfs_mount: ipimap:0x%p", ipimap);
@@ -327,8 +327,7 @@
 	/* validate fs signature */
 	if (strncmp(j_sb->s_magic, JFS_MAGIC, 4) ||
 	    j_sb->s_version > cpu_to_le32(JFS_VERSION)) {
-		//rc = EFORMAT;
-		rc = EINVAL;
+		rc = -EINVAL;
 		goto out;
 	}
 
@@ -336,7 +335,7 @@
 #ifdef _JFS_4K
 	if (bsize != PSIZE) {
 		jfs_err("Currently only 4K block size supported!");
-		rc = EINVAL;
+		rc = -EINVAL;
 		goto out;
 	}
 #endif				/* _JFS_4K */
@@ -372,7 +371,7 @@
 	if (j_sb->s_state != cpu_to_le32(FM_CLEAN) &&
 	    !(sb->s_flags & MS_RDONLY)) {
 		jfs_err("jfs_mount: Mount Failure: File System Dirty.");
-		rc = EINVAL;
+		rc = -EINVAL;
 		goto out;
 	}
 
@@ -421,12 +420,20 @@
 	struct buffer_head *bh;
 	int rc;
 
-	/*
-	 * Only fsck can fix dirty state
-	 */
-	if (sbi->state == FM_DIRTY)
+	if (sbi->flag & JFS_NOINTEGRITY) {
+		if (state == FM_DIRTY) {
+			sbi->p_state = state;
+			return 0;
+		} else if (state == FM_MOUNT) {
+			sbi->p_state = sbi->state;
+			state = FM_DIRTY;
+		} else if (state == FM_CLEAN) {
+			state = sbi->p_state;
+		} else
+			jfs_err("updateSuper: bad state");
+	} else if (sbi->state == FM_DIRTY)
 		return 0;
-
+	
 	if ((rc = readSuper(sb, &bh)))
 		return rc;
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_txnmgr.c linux-2.4.23-pre1/fs/jfs/jfs_txnmgr.c
--- linux-2.4.22/fs/jfs/jfs_txnmgr.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_txnmgr.c	2003-08-27 14:39:50.000000000 +0000
@@ -1,5 +1,5 @@
 /*
- *   Copyright (c) International Business Machines Corp., 2000-2002
+ *   Copyright (c) International Business Machines Corp., 2000-2003
  *   Portions Copyright (c) Christoph Hellwig, 2001-2002
  *
  *   This program is free software;  you can redistribute it and/or modify
@@ -177,7 +177,7 @@
 	       struct tlock * tlck);
 void mapLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
 	    struct tlock * tlck);
-void txAbortCommit(struct commit * cd, int exval);
+static void txAbortCommit(struct commit * cd);
 static void txAllocPMap(struct inode *ip, struct maplock * maplock,
 			struct tblock * tblk);
 void txForce(struct tblock * tblk);
@@ -256,7 +256,7 @@
 	size = sizeof(struct tblock) * nTxBlock;
 	TxBlock = (struct tblock *) vmalloc(size);
 	if (TxBlock == NULL)
-		return ENOMEM;
+		return -ENOMEM;
 
 	for (k = 1; k < nTxBlock - 1; k++) {
 		TxBlock[k].next = k + 1;
@@ -282,7 +282,7 @@
 	TxLock = (struct tlock *) vmalloc(size);
 	if (TxLock == NULL) {
 		vfree(TxBlock);
-		return ENOMEM;
+		return -ENOMEM;
 	}
 
 	/* initialize tlock table */
@@ -1099,7 +1099,7 @@
 	     struct inode **iplist,	/* list of inode to commit */
 	     int flag)
 {
-	int rc = 0, rc1 = 0;
+	int rc = 0;
 	struct commit cd;
 	struct jfs_log *log;
 	struct tblock *tblk;
@@ -1114,7 +1114,7 @@
 	jfs_info("txCommit, tid = %d, flag = %d", tid, flag);
 	/* is read-only file system ? */
 	if (isReadOnly(iplist[0])) {
-		rc = EROFS;
+		rc = -EROFS;
 		goto TheEnd;
 	}
 
@@ -1297,9 +1297,7 @@
 
       out:
 	if (rc != 0)
-		txAbortCommit(&cd, rc);
-	else
-		rc = rc1;
+		txAbortCommit(&cd);
 
       TheEnd:
 	jfs_info("txCommit: tid = %d, returning %d", tid, rc);
@@ -2654,14 +2652,13 @@
  * log age of page-frames in memory for which caller has
  * are reset to 0 (to avoid logwarap).
  */
-void txAbortCommit(struct commit * cd, int exval)
+static void txAbortCommit(struct commit * cd)
 {
 	struct tblock *tblk;
 	tid_t tid;
 	lid_t lid, next;
 	struct metapage *mp;
 
-	assert(exval == EIO || exval == ENOMEM);
 	jfs_warn("txAbortCommit: cd:0x%p", cd);
 
 	/*
@@ -2718,7 +2715,7 @@
 		/* We must have gotten ahead of the user thread
 		 */
 		jfs_info("txLazyCommit: tblk 0x%p not unlocked", tblk);
-		schedule();
+		yield();
 	}
 
 	jfs_info("txLazyCommit: processing tblk 0x%p", tblk);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_unicode.c linux-2.4.23-pre1/fs/jfs/jfs_unicode.c
--- linux-2.4.22/fs/jfs/jfs_unicode.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_unicode.c	2003-08-27 14:40:48.000000000 +0000
@@ -68,8 +68,7 @@
 			jfs_err("jfs_strtoUCS: char2uni returned %d.", charlen);
 			jfs_err("charset = %s, char = 0x%x",
 				codepage->charset, (unsigned char) *from);
-			to[i] = 0x003f;	/* a question mark */
-			charlen = 1;
+			return charlen;
 		}
 	}
 
@@ -89,16 +88,21 @@
 	int length = dentry->d_name.len;
 
 	if (length > JFS_NAME_MAX)
-		return ENAMETOOLONG;
+		return -ENAMETOOLONG;
 
 	uniName->name =
 	    kmalloc((length + 1) * sizeof(wchar_t), GFP_NOFS);
 
 	if (uniName->name == NULL)
-		return ENOSPC;
+		return -ENOSPC;
 
 	uniName->namlen = jfs_strtoUCS(uniName->name, dentry->d_name.name,
 				       length, nls_tab);
 
+	if (uniName->namlen < 0) {
+		kfree(uniName->name);
+		return uniName->namlen;
+	}
+
 	return 0;
 }
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/jfs_xtree.c linux-2.4.23-pre1/fs/jfs/jfs_xtree.c
--- linux-2.4.22/fs/jfs/jfs_xtree.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/jfs_xtree.c	2003-08-27 14:41:53.000000000 +0000
@@ -73,7 +73,7 @@
 			BT_PUTPAGE(MP);\
 			updateSuper((IP)->i_sb, FM_DIRTY);\
 			MP = NULL;\
-                        RC = EIO;\
+                        RC = -EIO;\
                 }\
         }\
 }
@@ -814,7 +814,7 @@
 	/* This test must follow XT_GETSEARCH since mp must be valid if
 	 * we branch to out: */
 	if (cmp == 0) {
-		rc = EEXIST;
+		rc = -EEXIST;
 		goto out;
 	}
 
@@ -1033,7 +1033,7 @@
 	    xtSplitRoot(tid, ip, split, &rmp) :
 	    xtSplitPage(tid, ip, split, &rmp, &rbn);
 	if (rc)
-		return EIO;
+		return -EIO;
 
 	XT_PUTPAGE(smp);
 
@@ -1238,7 +1238,7 @@
 	rbn = addressPXD(pxd);
 	rmp = get_metapage(ip, rbn, PSIZE, 1);
 	if (rmp == NULL)
-		return EIO;
+		return -EIO;
 
 	jfs_info("xtSplitPage: ip:0x%p smp:0x%p rmp:0x%p", ip, smp, rmp);
 
@@ -1485,7 +1485,7 @@
 	rbn = addressPXD(pxd);
 	rmp = get_metapage(ip, rbn, PSIZE, 1);
 	if (rmp == NULL)
-		return EIO;
+		return -EIO;
 
 	jfs_info("xtSplitRoot: ip:0x%p rmp:0x%p", ip, rmp);
 
@@ -2409,7 +2409,7 @@
 	XT_GETSEARCH(ip, btstack.top, bn, mp, p, index);
 
 	if (cmp == 0) {
-		rc = EEXIST;
+		rc = -EEXIST;
 		goto out;
 	}
 //insert:
@@ -2557,7 +2557,7 @@
 	if (cmp) {
 		/* unpin the leaf page */
 		XT_PUTPAGE(mp);
-		return ENOENT;
+		return -ENOENT;
 	}
 
 	/*
@@ -2788,7 +2788,7 @@
 	/* validate extent offset */
 	offset = xoff << JFS_SBI(ip->i_sb)->l2bsize;
 	if (offset >= ip->i_size)
-		return ESTALE;	/* stale extent */
+		return -ESTALE;	/* stale extent */
 
 	jfs_info("xtRelocate: xtype:%d xoff:0x%lx xlen:0x%x xaddr:0x%lx:0x%lx",
 		 xtype, (ulong) xoff, xlen, (ulong) oxaddr, (ulong) nxaddr);
@@ -2804,7 +2804,7 @@
 			return rc;
 		if (cmp) {
 			XT_PUTPAGE(pmp);
-			return ESTALE;
+			return -ESTALE;
 		}
 
 		/* retrieve search result */
@@ -2814,7 +2814,7 @@
 		xad = &pp->xad[index];
 		if (addressXAD(xad) != oxaddr || lengthXAD(xad) != xlen) {
 			XT_PUTPAGE(pmp);
-			return ESTALE;
+			return -ESTALE;
 		}
 	} else {		/* (xtype == XTPAGE) */
 
@@ -2824,7 +2824,7 @@
 			return rc;
 		if (cmp) {
 			XT_PUTPAGE(pmp);
-			return ESTALE;
+			return -ESTALE;
 		}
 
 		/* retrieve search result */
@@ -3127,7 +3127,7 @@
 		if (rc)
 			return rc;
 		if (p->header.flag & BT_LEAF)
-			return ESTALE;
+			return -ESTALE;
 
 		lim = le16_to_cpu(p->header.nextindex) - XTENTRYSTART;
 
@@ -3439,7 +3439,7 @@
       getPage:
 	XT_GETPAGE(ip, bn, mp, PSIZE, p, rc);
 	if (rc)
-		return -rc;
+		return rc;
 
 	/* process entries backward from last index */
 	index = le16_to_cpu(p->header.nextindex) - 1;
@@ -3667,7 +3667,7 @@
 	bn = parent->bn;
 	XT_GETPAGE(ip, bn, mp, PSIZE, p, rc);
 	if (rc)
-		return -rc;
+		return rc;
 
 	index = parent->index;
 
@@ -3924,7 +3924,7 @@
 		xoff = (committed_size >> JFS_SBI(ip->i_sb)->l2bsize) - 1;
 		rc = xtSearch(ip, xoff, &cmp, &btstack, 0);
 		if (rc)
-			return -rc;
+			return rc;
 		assert(cmp == 0);
 		XT_GETSEARCH(ip, btstack.top, bn, mp, p, index);
 	} else {
@@ -3941,7 +3941,7 @@
       getPage:
 		XT_GETPAGE(ip, bn, mp, PSIZE, p, rc);
 		if (rc)
-			return -rc;
+			return rc;
 
 		/* process entries backward from last index */
 		index = le16_to_cpu(p->header.nextindex) - 1;
@@ -3986,7 +3986,7 @@
 	bn = parent->bn;
 	XT_GETPAGE(ip, bn, mp, PSIZE, p, rc);
 	if (rc)
-		return -rc;
+		return rc;
 
 	index = parent->index;
 
@@ -4225,8 +4225,7 @@
  *      at the current entry at the current subtree root page
  *
  */
-int xtGather(t)
-btree_t *t;
+int xtGather(btree_t *t)
 {
 	int rc = 0;
 	xtpage_t *p;
@@ -4312,7 +4311,7 @@
 			bn = parent->bn;
 			XT_GETPAGE(ip, bn, mp, PSIZE, p, rc);
 			if (rc)
-				return EIO;
+				return -EIO;
 
 			/* first subroot page which
 			 * covers all new allocated blocks
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/namei.c linux-2.4.23-pre1/fs/jfs/namei.c
--- linux-2.4.22/fs/jfs/namei.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/namei.c	2003-08-27 14:39:36.000000000 +0000
@@ -83,7 +83,7 @@
 	 */
 	ip = ialloc(dip, mode);
 	if (ip == NULL) {
-		rc = ENOSPC;
+		rc = -ENOSPC;
 		goto out2;
 	}
 
@@ -116,7 +116,7 @@
 	ino = ip->i_ino;
 	if ((rc = dtInsert(tid, dip, &dname, &ino, &btstack))) {
 		jfs_err("jfs_create: dtInsert returned %d", rc);
-		if (rc == EIO)
+		if (rc == -EIO)
 			txAbort(tid, 1);	/* Marks Filesystem dirty */
 		else
 			txAbort(tid, 0);	/* Filesystem full */
@@ -151,8 +151,8 @@
 
       out1:
 
-	jfs_info("jfs_create: rc:%d", -rc);
-	return -rc;
+	jfs_info("jfs_create: rc:%d", rc);
+	return rc;
 }
 
 
@@ -186,7 +186,7 @@
 
 	/* link count overflow on parent directory ? */
 	if (dip->i_nlink == JFS_LINK_MAX) {
-		rc = EMLINK;
+		rc = -EMLINK;
 		goto out1;
 	}
 
@@ -204,7 +204,7 @@
 	 */
 	ip = ialloc(dip, S_IFDIR | mode);
 	if (ip == NULL) {
-		rc = ENOSPC;
+		rc = -ENOSPC;
 		goto out2;
 	}
 
@@ -238,7 +238,7 @@
 	if ((rc = dtInsert(tid, dip, &dname, &ino, &btstack))) {
 		jfs_err("jfs_mkdir: dtInsert returned %d", rc);
 
-		if (rc == EIO)
+		if (rc == -EIO)
 			txAbort(tid, 1);	/* Marks Filesystem dirty */
 		else
 			txAbort(tid, 0);	/* Filesystem full */
@@ -276,8 +276,8 @@
 
       out1:
 
-	jfs_info("jfs_mkdir: rc:%d", -rc);
-	return -rc;
+	jfs_info("jfs_mkdir: rc:%d", rc);
+	return rc;
 }
 
 /*
@@ -288,8 +288,8 @@
  * PARAMETER:	dip 	- parent inode
  *		dentry	- child directory dentry
  *
- * RETURN:	EINVAL	- if name is . or ..
- *		EINVAL  - if . or .. exist but are invalid.
+ * RETURN:	-EINVAL	- if name is . or ..
+ *		-EINVAL  - if . or .. exist but are invalid.
  *		errors from subroutines
  *
  * note:
@@ -313,7 +313,7 @@
 
 	/* directory must be empty to be removed */
 	if (!dtEmpty(ip)) {
-		rc = ENOTEMPTY;
+		rc = -ENOTEMPTY;
 		goto out;
 	}
 
@@ -339,7 +339,7 @@
 	ino = ip->i_ino;
 	if ((rc = dtDelete(tid, dip, &dname, &ino, JFS_REMOVE))) {
 		jfs_err("jfs_rmdir: dtDelete returned %d", rc);
-		if (rc == EIO)
+		if (rc == -EIO)
 			txAbort(tid, 1);
 		txEnd(tid);
 		up(&JFS_IP(dip)->commit_sem);
@@ -399,7 +399,7 @@
 
       out:
 	jfs_info("jfs_rmdir: rc:%d", rc);
-	return -rc;
+	return rc;
 }
 
 /*
@@ -455,7 +455,7 @@
 	ino = ip->i_ino;
 	if ((rc = dtDelete(tid, dip, &dname, &ino, JFS_REMOVE))) {
 		jfs_err("jfs_unlink: dtDelete returned %d", rc);
-		if (rc == EIO)
+		if (rc == -EIO)
 			txAbort(tid, 1);	/* Marks FS Dirty */
 		txEnd(tid);
 		up(&JFS_IP(dip)->commit_sem);
@@ -485,7 +485,7 @@
 			up(&JFS_IP(dip)->commit_sem);
 			up(&JFS_IP(ip)->commit_sem);
 			IWRITE_UNLOCK(ip);
-			rc = -new_size;		/* We return -rc */
+			rc = new_size;
 			goto out1;
 		}
 		tblk = tid_to_tblock(tid);
@@ -521,7 +521,7 @@
 		new_size = xtTruncate_pmap(tid, ip, new_size);
 		if (new_size < 0) {
 			txAbort(tid, 1);	/* Marks FS Dirty */
-			rc = -new_size;		/* We return -rc */
+			rc = new_size;
 		} else
 			rc = txCommit(tid, 2, &iplist[0], COMMIT_SYNC);
 		txEnd(tid);
@@ -547,8 +547,8 @@
       out1:
 	free_UCSname(&dname);
       out:
-	jfs_info("jfs_unlink: rc:%d", -rc);
-	return -rc;
+	jfs_info("jfs_unlink: rc:%d", rc);
+	return rc;
 }
 
 /*
@@ -573,7 +573,7 @@
  * PARAMETERS:	cd	- pointer to commit data structure.
  *			  current inode is the one to truncate.
  *
- * RETURN :	Errors from subroutines
+ * RETURN:	Errors from subroutines
  */
 s64 commitZeroLink(tid_t tid, struct inode *ip)
 {
@@ -767,7 +767,7 @@
 	down(&JFS_IP(ip)->commit_sem);
 
 	if (ip->i_nlink == JFS_LINK_MAX) {
-		rc = EMLINK;
+		rc = -EMLINK;
 		goto out;
 	}
 
@@ -805,7 +805,7 @@
 	up(&JFS_IP(ip)->commit_sem);
 
 	jfs_info("jfs_link: rc:%d", rc);
-	return -rc;
+	return rc;
 }
 
 /*
@@ -863,7 +863,7 @@
 	 */
 	ip = ialloc(dip, S_IFLNK | 0777);
 	if (ip == NULL) {
-		rc = ENOSPC;
+		rc = -ENOSPC;
 		goto out2;
 	}
 
@@ -955,7 +955,7 @@
 				if (mp == NULL) {
 					dtDelete(tid, dip, &dname, &ino,
 						 JFS_REMOVE);
-					rc = EIO;
+					rc = -EIO;
 					goto out3;
 				}
 				memcpy(mp->data, name, copy_size);
@@ -975,7 +975,7 @@
 			ip->i_blocks = LBLK2PBLK(sb, xlen);
 		} else {
 			dtDelete(tid, dip, &dname, &ino, JFS_REMOVE);
-			rc = ENOSPC;
+			rc = -ENOSPC;
 			goto out3;
 		}
 	}
@@ -1017,8 +1017,8 @@
 	free_UCSname(&dname);
 
       out1:
-	jfs_info("jfs_symlink: rc:%d", -rc);
-	return -rc;
+	jfs_info("jfs_symlink: rc:%d", rc);
+	return rc;
 }
 
 
@@ -1067,7 +1067,7 @@
 	 */
 	rc = dtSearch(old_dir, &old_dname, &ino, &btstack, JFS_LOOKUP);
 	if (rc || (ino != old_ip->i_ino)) {
-		rc = ENOENT;
+		rc = -ENOENT;
 		goto out3;
 	}
 
@@ -1077,26 +1077,26 @@
 	rc = dtSearch(new_dir, &new_dname, &ino, &btstack, JFS_LOOKUP);
 	if (rc == 0) {
 		if ((new_ip == 0) || (ino != new_ip->i_ino)) {
-			rc = ESTALE;
+			rc = -ESTALE;
 			goto out3;
 		}
-	} else if (rc != ENOENT)
+	} else if (rc != -ENOENT)
 		goto out3;
 	else if (new_ip) {
 		/* no entry exists, but one was expected */
-		rc = ESTALE;
+		rc = -ESTALE;
 		goto out3;
 	}
 
 	if (S_ISDIR(old_ip->i_mode)) {
 		if (new_ip) {
 			if (!dtEmpty(new_ip)) {
-				rc = ENOTEMPTY;
+				rc = -ENOTEMPTY;
 				goto out3;
 			}
 		} else if ((new_dir != old_dir) &&
 			   (new_dir->i_nlink == JFS_LINK_MAX)) {
-			rc = EMLINK;
+			rc = -EMLINK;
 			goto out3;
 		}
 	} else if (new_ip)
@@ -1134,7 +1134,7 @@
 			/* free block resources */
 			if ((new_size = commitZeroLink(tid, new_ip)) < 0) {
 				txAbort(tid, 1);	/* Marks FS Dirty */
-				rc = -new_size;		/* We return -rc */
+				rc = new_size;		
 				goto out4;
 			}
 			tblk = tid_to_tblock(tid);
@@ -1251,7 +1251,7 @@
 		new_size = xtTruncate_pmap(tid, new_ip, new_size);
 		if (new_size < 0) {
 			txAbort(tid, 1);
-			rc = -new_size;		/* We return -rc */
+			rc = new_size;		
 		} else
 			rc = txCommit(tid, 1, &new_ip, COMMIT_SYNC);
 		txEnd(tid);
@@ -1278,7 +1278,7 @@
 	}
 
 	jfs_info("jfs_rename: returning %d", rc);
-	return -rc;
+	return rc;
 }
 
 
@@ -1305,7 +1305,7 @@
 
 	ip = ialloc(dir, mode);
 	if (ip == NULL) {
-		rc = ENOSPC;
+		rc = -ENOSPC;
 		goto out1;
 	}
 
@@ -1354,7 +1354,7 @@
 
       out:
 	jfs_info("jfs_mknod: returning %d", rc);
-	return -rc;
+	return rc;
 }
 
 static struct dentry *jfs_lookup(struct inode *dip, struct dentry *dentry)
@@ -1377,15 +1377,15 @@
 	else {
 		if ((rc =
 		     get_UCSname(&key, dentry, JFS_SBI(dip->i_sb)->nls_tab)))
-			return ERR_PTR(-rc);
+			return ERR_PTR(rc);
 		rc = dtSearch(dip, &key, &inum, &btstack, JFS_LOOKUP);
 		free_UCSname(&key);
-		if (rc == ENOENT) {
+		if (rc == -ENOENT) {
 			d_add(dentry, NULL);
 			return ERR_PTR(0);
 		} else if (rc) {
 			jfs_err("jfs_lookup: dtSearch returned %d", rc);
-			return ERR_PTR(-rc);
+			return ERR_PTR(rc);
 		}
 	}
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/resize.c linux-2.4.23-pre1/fs/jfs/resize.c
--- linux-2.4.22/fs/jfs/resize.c	2003-08-25 11:44:43.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/resize.c	2003-08-27 14:41:46.000000000 +0000
@@ -184,7 +184,7 @@
 
 	/* file system cannot be shrinked */
 	if (newFSSize < bmp->db_mapsize) {
-		rc = EINVAL;
+		rc = -EINVAL;
 		goto out;
 	}
 
@@ -317,8 +317,8 @@
 	t64 = dbMapFileSizeToMapSize(ipbmap);
 	if (mapSize > t64) {
 		printk(KERN_ERR "jfs_extendfs: mapSize (0x%Lx) > t64 (0x%Lx)\n",
-		       (long long)mapSize, (long long)t64);
-		rc = EIO;
+		       (long long) mapSize, (long long) t64);
+		rc = -EIO;
 		goto error_out;
 	}
 	nblocks = min(t64 - mapSize, XSize);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/super.c linux-2.4.23-pre1/fs/jfs/super.c
--- linux-2.4.22/fs/jfs/super.c	2003-08-25 11:44:43.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/super.c	2003-08-27 14:42:04.000000000 +0000
@@ -1,5 +1,5 @@
 /*
- *   Copyright (c) International Business Machines Corp., 2000-2002
+ *   Copyright (c) International Business Machines Corp., 2000-2003
  *   Portions Copyright (c) Christoph Hellwig, 2001-2002
  *
  *   This program is free software;  you can redistribute it and/or modify
@@ -142,7 +142,8 @@
 	return 0;
 }
 
-static int parse_options(char *options, struct super_block *sb, s64 *newLVSize)
+static int parse_options(char *options, struct super_block *sb, s64 *newLVSize,
+			 int *flag)
 {
 	void *nls_map = NULL;
 	char *this_char;
@@ -158,7 +159,11 @@
 			continue;
 		if ((value = strchr(this_char, '=')) != NULL)
 			*value++ = 0;
-		if (!strcmp(this_char, "iocharset")) {
+		if (!strcmp(this_char, "integrity")) {
+			*flag &= ~JFS_NOINTEGRITY;
+		} else 	if (!strcmp(this_char, "nointegrity")) {
+			*flag |= JFS_NOINTEGRITY;
+		} else if (!strcmp(this_char, "iocharset")) {
 			if (!value || !*value)
 				goto needs_arg;
 			if (nls_map)	/* specified iocharset twice! */
@@ -208,8 +213,9 @@
 {
 	s64 newLVSize = 0;
 	int rc = 0;
+	int flag = JFS_SBI(sb)->flag;
 
-	if (!parse_options(data, sb, &newLVSize)) {
+	if (!parse_options(data, sb, &newLVSize, &flag)) {
 		return -EINVAL;
 	}
 	if (newLVSize) {
@@ -223,10 +229,24 @@
 			return rc;
 	}
 
-	if ((sb->s_flags & MS_RDONLY) && !(*flags & MS_RDONLY))
+	if ((sb->s_flags & MS_RDONLY) && !(*flags & MS_RDONLY)) {
+		JFS_SBI(sb)->flag = flag;
 		return jfs_mount_rw(sb, 1);
-	else if ((!(sb->s_flags & MS_RDONLY)) && (*flags & MS_RDONLY))
-		return jfs_umount_rw(sb);
+	}
+	if ((!(sb->s_flags & MS_RDONLY)) && (*flags & MS_RDONLY)) {
+		rc = jfs_umount_rw(sb);
+		JFS_SBI(sb)->flag = flag;
+		return rc;
+	}
+	if ((JFS_SBI(sb)->flag & JFS_NOINTEGRITY) != (flag & JFS_NOINTEGRITY))
+		if (!(sb->s_flags & MS_RDONLY)) {
+			rc = jfs_umount_rw(sb);
+			if (rc)
+				return rc;
+			JFS_SBI(sb)->flag = flag;
+			return jfs_mount_rw(sb, 1);
+		}
+	JFS_SBI(sb)->flag = flag;
 
 	return 0;
 }
@@ -238,6 +258,7 @@
 	struct inode *inode;
 	int rc;
 	s64 newLVSize = 0;
+	int flag;
 
 	jfs_info("In jfs_read_super s_dev=0x%x s_flags=0x%lx", sb->s_dev,
 		 sb->s_flags);
@@ -248,10 +269,12 @@
 	memset(sbi, 0, sizeof (struct jfs_sb_info));
 	sb->u.generic_sbp = sbi;
 
-	if (!parse_options((char *) data, sb, &newLVSize)) {
+	flag = 0;
+	if (!parse_options((char *) data, sb, &newLVSize, &flag)) {
 		kfree(sbi);
 		return NULL;
 	}
+	sbi->flag = flag;
 
 	if (newLVSize) {
 		printk(KERN_ERR "resize option for remount only\n");
@@ -483,7 +506,7 @@
 	metapage_exit();
 free_slab:
 	kmem_cache_destroy(jfs_inode_cachep);
-	return -rc;
+	return rc;
 }
 
 static void __exit exit_jfs_fs(void)
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/jfs/xattr.c linux-2.4.23-pre1/fs/jfs/xattr.c
--- linux-2.4.22/fs/jfs/xattr.c	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/fs/jfs/xattr.c	2003-08-27 14:39:24.000000000 +0000
@@ -182,7 +182,7 @@
 		 * used for an inline EA.
 		 */
 		if (!(ji->mode2 & INLINEEA) && !(ji->ea.flag & DXD_INLINE))
-			return -1;
+			return -EPERM;
 
 		DXDsize(ea, size);
 		DXDlength(ea, 0);
@@ -252,7 +252,7 @@
 
 	rc = dbAlloc(ip, INOHINT(ip), nblocks, &blkno);
 	if (rc)
-		return -rc;
+		return rc;
 
 	/*
 	 * Now have nblocks worth of storage to stuff into the FEALIST.
@@ -513,7 +513,7 @@
 		rc = dbAlloc(inode, INOHINT(inode), (s64) blocks_needed,
 			     &blkno);
 		if (rc)
-			return -rc;
+			return rc;
 
 		DXDlength(&ea_buf->new_ea, blocks_needed);
 		DXDaddress(&ea_buf->new_ea, blkno);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/fs/namespace.c linux-2.4.23-pre1/fs/namespace.c
--- linux-2.4.22/fs/namespace.c	2003-06-13 14:51:37.000000000 +0000
+++ linux-2.4.23-pre1/fs/namespace.c	2003-08-27 14:40:46.000000000 +0000
@@ -763,7 +763,7 @@
 		return -EPERM;
 	}
 
-	new_ns = kmalloc(sizeof(struct namespace *), GFP_KERNEL);
+	new_ns = kmalloc(sizeof(struct namespace), GFP_KERNEL);
 	if (!new_ns)
 		goto out;
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-i386/cpufeature.h linux-2.4.23-pre1/include/asm-i386/cpufeature.h
--- linux-2.4.22/include/asm-i386/cpufeature.h	2003-08-25 11:44:43.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-i386/cpufeature.h	2003-08-27 14:41:01.000000000 +0000
@@ -10,9 +10,9 @@
 /* Sample usage: CPU_FEATURE_P(cpu.x86_capability, FPU) */
 #define CPU_FEATURE_P(CAP, FEATURE) test_bit(CAP, X86_FEATURE_##FEATURE ##_BIT)
 
-#define NCAPINTS	4	/* Currently we have 4 32-bit words worth of info */
+#define NCAPINTS	6	/* Currently we have 6 32-bit words worth of info */
 
-/* Intel-defined CPU features, CPUID level 0x00000001, word 0 */
+/* Intel-defined CPU features, CPUID level 0x00000001 (edx), word 0 */
 #define X86_FEATURE_FPU		(0*32+ 0) /* Onboard FPU */
 #define X86_FEATURE_VME		(0*32+ 1) /* Virtual Mode Extensions */
 #define X86_FEATURE_DE		(0*32+ 2) /* Debugging Extensions */
@@ -47,6 +47,7 @@
 /* AMD-defined CPU features, CPUID level 0x80000001, word 1 */
 /* Don't duplicate feature flags which are redundant with Intel! */
 #define X86_FEATURE_SYSCALL	(1*32+11) /* SYSCALL/SYSRET */
+#define X86_FEATURE_MP		(1*32+19) /* MP Capable. */
 #define X86_FEATURE_MMXEXT	(1*32+22) /* AMD MMX extensions */
 #define X86_FEATURE_LM		(1*32+29) /* Long Mode (x86-64) */
 #define X86_FEATURE_3DNOWEXT	(1*32+30) /* AMD 3DNow! extensions */
@@ -63,10 +64,19 @@
 #define X86_FEATURE_K6_MTRR	(3*32+ 1) /* AMD K6 nonstandard MTRRs */
 #define X86_FEATURE_CYRIX_ARR	(3*32+ 2) /* Cyrix ARRs (= MTRRs) */
 #define X86_FEATURE_CENTAUR_MCR	(3*32+ 3) /* Centaur MCRs (= MTRRs) */
+/* cpu types for specific tunings: */
+#define X86_FEATURE_K8		(3*32+ 4) /* Opteron, Athlon64 */
+#define X86_FEATURE_K7		(3*32+ 5) /* Athlon */
+#define X86_FEATURE_P3		(3*32+ 6) /* P3 */
+#define X86_FEATURE_P4		(3*32+ 7) /* P4 */
 
-/* Intel defined CPU features, CPUID level 0x00000001 (ecx), word 4 */
+/* Intel-defined CPU features, CPUID level 0x00000001 (ecx), word 4 */
 #define X86_FEATURE_EST		(4*32+ 7) /* Enhanced SpeedStep */
 
+/* VIA/Cyrix/Centaur-defined CPU features, CPUID level 0xC0000001, word 5 */
+#define X86_FEATURE_XSTORE	(5*32+ 2) /* on-CPU RNG present (xstore insn) */
+
+
 #define cpu_has(c, bit)		test_bit(bit, (c)->x86_capability)
 #define boot_cpu_has(bit)	test_bit(bit, boot_cpu_data.x86_capability)
 
@@ -77,7 +87,9 @@
 #define cpu_has_tsc		boot_cpu_has(X86_FEATURE_TSC)
 #define cpu_has_pae		boot_cpu_has(X86_FEATURE_PAE)
 #define cpu_has_pge		boot_cpu_has(X86_FEATURE_PGE)
+#define cpu_has_sse2		boot_cpu_has(X86_FEATURE_XMM2)
 #define cpu_has_apic		boot_cpu_has(X86_FEATURE_APIC)
+#define cpu_has_sep		boot_cpu_has(X86_FEATURE_SEP)
 #define cpu_has_mtrr		boot_cpu_has(X86_FEATURE_MTRR)
 #define cpu_has_mmx		boot_cpu_has(X86_FEATURE_MMX)
 #define cpu_has_fxsr		boot_cpu_has(X86_FEATURE_FXSR)
@@ -87,6 +99,7 @@
 #define cpu_has_k6_mtrr		boot_cpu_has(X86_FEATURE_K6_MTRR)
 #define cpu_has_cyrix_arr	boot_cpu_has(X86_FEATURE_CYRIX_ARR)
 #define cpu_has_centaur_mcr	boot_cpu_has(X86_FEATURE_CENTAUR_MCR)
+#define cpu_has_xstore		boot_cpu_has(X86_FEATURE_XSTORE)
 
 #endif /* __ASM_I386_CPUFEATURE_H */
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-i386/hardirq.h linux-2.4.23-pre1/include/asm-i386/hardirq.h
--- linux-2.4.22/include/asm-i386/hardirq.h	2001-11-22 19:46:19.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-i386/hardirq.h	2003-08-27 14:41:13.000000000 +0000
@@ -67,6 +67,8 @@
 {
 	++local_irq_count(cpu);
 
+	smp_mb();
+
 	while (test_bit(0,&global_irq_lock)) {
 		cpu_relax();
 	}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-i386/msr.h linux-2.4.23-pre1/include/asm-i386/msr.h
--- linux-2.4.22/include/asm-i386/msr.h	2003-08-25 11:44:43.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-i386/msr.h	2003-08-27 14:39:14.000000000 +0000
@@ -113,6 +113,7 @@
 /* VIA Cyrix defined MSRs*/
 #define MSR_VIA_FCR			0x1107
 #define MSR_VIA_LONGHAUL		0x110a
+#define MSR_VIA_RNG			0x110b
 #define MSR_VIA_BCR2			0x1147
 
 /* Transmeta defined MSRs */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-sparc/pgtsrmmu.h linux-2.4.23-pre1/include/asm-sparc/pgtsrmmu.h
--- linux-2.4.22/include/asm-sparc/pgtsrmmu.h	2000-07-18 19:29:47.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-sparc/pgtsrmmu.h	2003-08-27 14:40:05.000000000 +0000
@@ -9,6 +9,9 @@
 
 #include <asm/page.h>
 
+/* Number of contexts is implementation-dependent; 64k is the most we support */
+#define SRMMU_MAX_CONTEXTS    65536
+
 /* PMD_SHIFT determines the size of the area a second-level page table can map */
 #define SRMMU_PMD_SHIFT         18
 #define SRMMU_PMD_SIZE          (1UL << SRMMU_PMD_SHIFT)
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-sparc64/asi.h linux-2.4.23-pre1/include/asm-sparc64/asi.h
--- linux-2.4.22/include/asm-sparc64/asi.h	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-sparc64/asi.h	2003-08-27 14:39:48.000000000 +0000
@@ -36,10 +36,12 @@
 #define ASI_PCACHE_DATA		0x31 /* (III) PCache data RAM diag		*/
 #define ASI_PCACHE_TAG		0x32 /* (III) PCache tag RAM diag		*/
 #define ASI_PCACHE_SNOOP_TAG	0x33 /* (III) PCache snoop tag RAM diag		*/
+#define ASI_QUAD_LDD_PHYS	0x34 /* (III+) PADDR, qword load		*/
 #define ASI_WCACHE_VALID_BITS	0x38 /* (III) WCache Valid Bits diag		*/
 #define ASI_WCACHE_DATA		0x39 /* (III) WCache data RAM diag		*/
 #define ASI_WCACHE_TAG		0x3a /* (III) WCache tag RAM diag		*/
 #define ASI_WCACHE_SNOOP_TAG	0x3b /* (III) WCache snoop tag RAM diag		*/
+#define ASI_QUAD_LDD_PHYS_L	0x3c /* (III+) PADDR, qword load, little endian	*/
 #define ASI_SRAM_FAST_INIT	0x40 /* (III+) Fast SRAM init			*/
 #define ASI_DCACHE_INVALIDATE	0x42 /* (III) DCache Invalidate diag		*/
 #define ASI_DCACHE_UTAG		0x43 /* (III) DCache uTag diag			*/
@@ -51,6 +53,7 @@
 #define ASI_INTR_DISPATCH_STAT	0x48 /* IRQ vector dispatch status		*/
 #define ASI_INTR_RECEIVE	0x49 /* IRQ vector receive status		*/
 #define ASI_UPA_CONFIG		0x4a /* UPA config space			*/
+#define ASI_JBUS_CONFIG		0x4a /* (IIIi) JBUS Config Register		*/
 #define ASI_SAFARI_CONFIG	0x4a /* (III) Safari Config Register		*/
 #define ASI_SAFARI_ADDRESS	0x4a /* (III) Safari Address Register		*/
 #define ASI_ESTATE_ERROR_EN	0x4b /* E-cache error enable space		*/
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-sparc64/chafsr.h linux-2.4.23-pre1/include/asm-sparc64/chafsr.h
--- linux-2.4.22/include/asm-sparc64/chafsr.h	2001-04-12 19:10:25.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-sparc64/chafsr.h	2003-08-27 14:41:01.000000000 +0000
@@ -4,10 +4,54 @@
 
 /* Cheetah Asynchronous Fault Status register, ASI=0x4C VA<63:0>=0x0 */
 
+/* Comments indicate which processor variants on which the bit definition
+ * is valid.  Codes are:
+ * ch	-->	cheetah
+ * ch+	-->	cheetah plus
+ * jp	-->	jalapeno
+ */
+
 /* All bits of this register except M_SYNDROME and E_SYNDROME are
  * read, write 1 to clear.  M_SYNDROME and E_SYNDROME are read-only.
  */
 
+/* Software bit set by linux trap handlers to indicate that the trap was
+ * signalled at %tl >= 1.
+ */
+#define CHAFSR_TL1		(1UL << 63UL) /* n/a */
+
+/* Unmapped error from system bus for prefetch queue or
+ * store queue read operation
+ */
+#define CHPAFSR_DTO		(1UL << 59UL) /* ch+ */
+
+/* Bus error from system bus for prefetch queue or store queue
+ * read operation
+ */
+#define CHPAFSR_DBERR		(1UL << 58UL) /* ch+ */
+
+/* Hardware corrected E-cache Tag ECC error */
+#define CHPAFSR_THCE		(1UL << 57UL) /* ch+ */
+/* System interface protocol error, hw timeout caused */
+#define JPAFSR_JETO		(1UL << 57UL) /* jp */
+
+/* SW handled correctable E-cache Tag ECC error */
+#define CHPAFSR_TSCE		(1UL << 56UL) /* ch+ */
+/* Parity error on system snoop results */
+#define JPAFSR_SCE		(1UL << 56UL) /* jp */
+
+/* Uncorrectable E-cache Tag ECC error */
+#define CHPAFSR_TUE		(1UL << 55UL) /* ch+ */
+/* System interface protocol error, illegal command detected */
+#define JPAFSR_JEIC		(1UL << 55UL) /* jp */
+
+/* Uncorrectable system bus data ECC error due to prefetch
+ * or store fill request
+ */
+#define CHPAFSR_DUE		(1UL << 54UL) /* ch+ */
+/* System interface protocol error, illegal ADTYPE detected */
+#define JPAFSR_JEIT		(1UL << 54UL) /* jp */
+
 /* Multiple errors of the same type have occurred.  This bit is set when
  * an uncorrectable error or a SW correctable error occurs and the status
  * bit to report that error is already set.  When multiple errors of
@@ -22,12 +66,12 @@
  * subunit will be logged.  All errors in subsequent 16-byte subunits
  * from the same 64-byte transaction are ignored.
  */
-#define CHAFSR_ME		0x0020000000000000
+#define CHAFSR_ME		(1UL << 53UL) /* ch,ch+,jp */
 
 /* Privileged state error has occurred.  This is a capture of PSTATE.PRIV
  * at the time the error is detected.
  */
-#define CHAFSR_PRIV		0x0010000000000000
+#define CHAFSR_PRIV		(1UL << 52UL) /* ch,ch+,jp */
 
 /* The following bits 51 (CHAFSR_PERR) to 33 (CHAFSR_CE) are sticky error
  * bits and record the most recently detected errors.  Bits accumulate
@@ -38,74 +82,123 @@
  * pin when this event occurs and it also logs a specific cause code
  * into a JTAG scannable flop.
  */
-#define CHAFSR_PERR		0x0008000000000000
+#define CHAFSR_PERR		(1UL << 51UL) /* ch,ch+,jp */
 
 /* Internal processor error.  The processor asserts its' ERROR
  * pin when this event occurs and it also logs a specific cause code
  * into a JTAG scannable flop.
  */
-#define CHAFSR_IERR		0x0004000000000000
+#define CHAFSR_IERR		(1UL << 50UL) /* ch,ch+,jp */
 
 /* System request parity error on incoming address */
-#define CHAFSR_ISAP		0x0002000000000000
+#define CHAFSR_ISAP		(1UL << 49UL) /* ch,ch+,jp */
 
 /* HW Corrected system bus MTAG ECC error */
-#define CHAFSR_EMC		0x0001000000000000
+#define CHAFSR_EMC		(1UL << 48UL) /* ch,ch+ */
+/* Parity error on L2 cache tag SRAM */
+#define JPAFSR_ETP		(1UL << 48UL) /* jp */
 
 /* Uncorrectable system bus MTAG ECC error */
-#define CHAFSR_EMU		0x0000800000000000
+#define CHAFSR_EMU		(1UL << 47UL) /* ch,ch+ */
+/* Out of range memory error has occurred */
+#define JPAFSR_OM		(1UL << 47UL) /* jp */
 
 /* HW Corrected system bus data ECC error for read of interrupt vector */
-#define CHAFSR_IVC		0x0000400000000000
+#define CHAFSR_IVC		(1UL << 46UL) /* ch,ch+ */
+/* Error due to unsupported store */
+#define JPAFSR_UMS		(1UL << 46UL) /* jp */
 
 /* Uncorrectable system bus data ECC error for read of interrupt vector */
-#define CHAFSR_IVU		0x0000200000000000
+#define CHAFSR_IVU		(1UL << 45UL) /* ch,ch+,jp */
 
 /* Unmappeed error from system bus */
-#define CHAFSR_TO		0x0000100000000000
+#define CHAFSR_TO		(1UL << 44UL) /* ch,ch+,jp */
 
 /* Bus error response from system bus */
-#define CHAFSR_BERR		0x0000080000000000
+#define CHAFSR_BERR		(1UL << 43UL) /* ch,ch+,jp */
 
 /* SW Correctable E-cache ECC error for instruction fetch or data access
  * other than block load.
  */
-#define CHAFSR_UCC		0x0000040000000000
+#define CHAFSR_UCC		(1UL << 42UL) /* ch,ch+,jp */
 
 /* Uncorrectable E-cache ECC error for instruction fetch or data access
  * other than block load.
  */
-#define CHAFSR_UCU		0x0000020000000000
+#define CHAFSR_UCU		(1UL << 41UL) /* ch,ch+,jp */
 
 /* Copyout HW Corrected ECC error */
-#define CHAFSR_CPC		0x0000010000000000
+#define CHAFSR_CPC		(1UL << 40UL) /* ch,ch+,jp */
 
 /* Copyout Uncorrectable ECC error */
-#define CHAFSR_CPU		0x0000008000000000
+#define CHAFSR_CPU		(1UL << 39UL) /* ch,ch+,jp */
 
 /* HW Corrected ECC error from E-cache for writeback */
-#define CHAFSR_WDC		0x0000004000000000
+#define CHAFSR_WDC		(1UL << 38UL) /* ch,ch+,jp */
 
 /* Uncorrectable ECC error from E-cache for writeback */
-#define CHAFSR_WDU		0x0000002000000000
+#define CHAFSR_WDU		(1UL << 37UL) /* ch,ch+,jp */
 
 /* HW Corrected ECC error from E-cache for store merge or block load */
-#define CHAFSR_EDC		0x0000001000000000
+#define CHAFSR_EDC		(1UL << 36UL) /* ch,ch+,jp */
 
 /* Uncorrectable ECC error from E-cache for store merge or block load */
-#define CHAFSR_EDU		0x0000000800000000
+#define CHAFSR_EDU		(1UL << 35UL) /* ch,ch+,jp */
 
 /* Uncorrectable system bus data ECC error for read of memory or I/O */
-#define CHAFSR_UE		0x0000000400000000
+#define CHAFSR_UE		(1UL << 34UL) /* ch,ch+,jp */
 
 /* HW Corrected system bus data ECC error for read of memory or I/O */
-#define CHAFSR_CE		0x0000000200000000
+#define CHAFSR_CE		(1UL << 33UL) /* ch,ch+,jp */
+
+/* Uncorrectable ECC error from remote cache/memory */
+#define JPAFSR_RUE		(1UL << 32UL) /* jp */
+
+/* Correctable ECC error from remote cache/memory */
+#define JPAFSR_RCE		(1UL << 31UL) /* jp */
+
+/* JBUS parity error on returned read data */
+#define JPAFSR_BP		(1UL << 30UL) /* jp */
+
+/* JBUS parity error on data for writeback or block store */
+#define JPAFSR_WBP		(1UL << 29UL) /* jp */
+
+/* Foreign read to DRAM incurring correctable ECC error */
+#define JPAFSR_FRC		(1UL << 28UL) /* jp */
+
+/* Foreign read to DRAM incurring uncorrectable ECC error */
+#define JPAFSR_FRU		(1UL << 27UL) /* jp */
 
 #define CHAFSR_ERRORS		(CHAFSR_PERR | CHAFSR_IERR | CHAFSR_ISAP | CHAFSR_EMC | \
 				 CHAFSR_EMU | CHAFSR_IVC | CHAFSR_IVU | CHAFSR_TO | \
 				 CHAFSR_BERR | CHAFSR_UCC | CHAFSR_UCU | CHAFSR_CPC | \
 				 CHAFSR_CPU | CHAFSR_WDC | CHAFSR_WDU | CHAFSR_EDC | \
 				 CHAFSR_EDU | CHAFSR_UE | CHAFSR_CE)
+#define CHPAFSR_ERRORS		(CHPAFSR_DTO | CHPAFSR_DBERR | CHPAFSR_THCE | \
+				 CHPAFSR_TSCE | CHPAFSR_TUE | CHPAFSR_DUE | \
+				 CHAFSR_PERR | CHAFSR_IERR | CHAFSR_ISAP | CHAFSR_EMC | \
+				 CHAFSR_EMU | CHAFSR_IVC | CHAFSR_IVU | CHAFSR_TO | \
+				 CHAFSR_BERR | CHAFSR_UCC | CHAFSR_UCU | CHAFSR_CPC | \
+				 CHAFSR_CPU | CHAFSR_WDC | CHAFSR_WDU | CHAFSR_EDC | \
+				 CHAFSR_EDU | CHAFSR_UE | CHAFSR_CE)
+#define JPAFSR_ERRORS		(JPAFSR_JETO | JPAFSR_SCE | JPAFSR_JEIC | \
+				 JPAFSR_JEIT | CHAFSR_PERR | CHAFSR_IERR | \
+				 CHAFSR_ISAP | JPAFSR_ETP | JPAFSR_OM | \
+				 JPAFSR_UMS | CHAFSR_IVU | CHAFSR_TO | \
+				 CHAFSR_BERR | CHAFSR_UCC | CHAFSR_UCU | \
+				 CHAFSR_CPC | CHAFSR_CPU | CHAFSR_WDC | \
+				 CHAFSR_WDU | CHAFSR_EDC | CHAFSR_EDU | \
+				 CHAFSR_UE | CHAFSR_CE | JPAFSR_RUE | \
+				 JPAFSR_RCE | JPAFSR_BP | JPAFSR_WBP | \
+				 JPAFSR_FRC | JPAFSR_FRU)
+
+/* Active JBUS request signal when error occurred */
+#define JPAFSR_JBREQ		(0x7UL << 24UL) /* jp */
+#define JPAFSR_JBREQ_SHIFT	24UL
+
+/* L2 cache way information */
+#define JPAFSR_ETW		(0x3UL << 22UL) /* jp */
+#define JPAFSR_ETW_SHIFT	22UL
 
 /* System bus MTAG ECC syndrome.  This field captures the status of the
  * first occurrence of the highest-priority error according to the M_SYND
@@ -113,8 +206,12 @@
  * for which the M_SYND is reported, is cleared, the contents of the M_SYND
  * field will be unchanged by will be unfrozen for further error capture.
  */
-#define CHAFSR_M_SYNDROME	0x00000000000f0000
-#define CHAFSR_M_SYNDROME_SHIFT	16
+#define CHAFSR_M_SYNDROME	(0xfUL << 16UL) /* ch,ch+,jp */
+#define CHAFSR_M_SYNDROME_SHIFT	16UL
+
+/* Agenid Id of the foreign device causing the UE/CE errors */
+#define JPAFSR_AID		(0x1fUL << 9UL) /* jp */
+#define JPAFSR_AID_SHIFT	9UL
 
 /* System bus or E-cache data ECC syndrome.  This field captures the status
  * of the first occurrence of the highest-priority error according to the
@@ -122,8 +219,8 @@
  * error for which the E_SYND is reported, is cleare, the contents of the E_SYND
  * field will be unchanged but will be unfrozen for further error capture.
  */
-#define CHAFSR_E_SYNDROME	0x00000000000001ff
-#define CHAFSR_E_SYNDROME_SHIFT	0
+#define CHAFSR_E_SYNDROME	(0x1ffUL << 0UL) /* ch,ch+,jp */
+#define CHAFSR_E_SYNDROME_SHIFT	0UL
 
 /* The AFSR must be explicitly cleared by software, it is not cleared automatically
  * by a read.  Writes to bits <51:33> with bits set will clear the corresponding
@@ -142,9 +239,4 @@
  * also apply to the M_SYNDROME and E_SYNDROME fields of the AFSR.
  */
 
-/* Software bit set by linux trap handlers to indicate that the trap was
- * signalled at %tl >= 1.
- */
-#define CHAFSR_TL1		0x8000000000000000
-
 #endif /* _SPARC64_CHAFSR_H */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-sparc64/head.h linux-2.4.23-pre1/include/asm-sparc64/head.h
--- linux-2.4.22/include/asm-sparc64/head.h	2003-06-13 14:51:38.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-sparc64/head.h	2003-08-27 14:40:08.000000000 +0000
@@ -9,10 +9,12 @@
 #define	PTREGS_OFF	(STACK_BIAS + STACKFRAME_SZ)
 
 #define __CHEETAH_ID	0x003e0014
+#define __JALAPENO_ID	0x003e0016
 
 #define CHEETAH_MANUF		0x003e
 #define CHEETAH_IMPL		0x0014
 #define CHEETAH_PLUS_IMPL	0x0015
+#define JALAPENO_IMPL		0x0016
 
 #define BRANCH_IF_CHEETAH_BASE(tmp1,tmp2,label)	\
 	rdpr	%ver, %tmp1;			\
@@ -23,6 +25,15 @@
 	be,pn	%icc, label;			\
 	 nop;
 
+#define BRANCH_IF_JALAPENO(tmp1,tmp2,label)	\
+	rdpr	%ver, %tmp1;			\
+	sethi	%hi(__JALAPENO_ID), %tmp2;	\
+	srlx	%tmp1, 32, %tmp1;		\
+	or	%tmp2, %lo(__JALAPENO_ID), %tmp2;\
+	cmp	%tmp1, %tmp2;			\
+	be,pn	%icc, label;			\
+	 nop;
+
 #define BRANCH_IF_CHEETAH_PLUS_OR_FOLLOWON(tmp1,tmp2,label)	\
 	rdpr	%ver, %tmp1;			\
 	srlx	%tmp1, (32 + 16), %tmp2;	\
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-sparc64/io.h linux-2.4.23-pre1/include/asm-sparc64/io.h
--- linux-2.4.22/include/asm-sparc64/io.h	2002-02-25 19:38:13.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-sparc64/io.h	2003-08-27 14:41:34.000000000 +0000
@@ -413,7 +413,7 @@
  */
 #define ioremap(__offset, __size)	((void *)(__offset))
 #define ioremap_nocache(X,Y)		ioremap((X),(Y))
-#define iounmap(__addr)			do { } while(0)
+#define iounmap(__addr)			do { (void)(__addr); } while(0)
 
 /* Similarly for SBUS. */
 #define sbus_ioremap(__res, __offset, __size, __name) \
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-sparc64/irq.h linux-2.4.23-pre1/include/asm-sparc64/irq.h
--- linux-2.4.22/include/asm-sparc64/irq.h	2003-06-13 14:51:38.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-sparc64/irq.h	2003-08-27 14:40:36.000000000 +0000
@@ -76,6 +76,7 @@
 /* IMAP/ICLR register defines */
 #define IMAP_VALID		0x80000000	/* IRQ Enabled		*/
 #define IMAP_TID_UPA		0x7c000000	/* UPA TargetID		*/
+#define IMAP_TID_JBUS		0x7c000000	/* JBUS TargetID	*/
 #define IMAP_AID_SAFARI		0x7c000000	/* Safari AgentID	*/
 #define IMAP_NID_SAFARI		0x03e00000	/* Safari NodeID	*/
 #define IMAP_IGN		0x000007c0	/* IRQ Group Number	*/
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-sparc64/isa.h linux-2.4.23-pre1/include/asm-sparc64/isa.h
--- linux-2.4.22/include/asm-sparc64/isa.h	2001-05-16 17:31:27.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-sparc64/isa.h	2003-08-27 14:41:41.000000000 +0000
@@ -32,6 +32,11 @@
 #define linux_prom_isa_ranges linux_prom_ebus_ranges
 	struct linux_prom_isa_ranges	isa_ranges[PROMREG_MAX];
 	int			num_isa_ranges;
+#define linux_prom_isa_intmap	linux_prom_ebus_intmap
+	struct linux_prom_isa_intmap	isa_intmap[PROMREG_MAX];
+	int			num_isa_intmap;
+#define linux_prom_isa_intmask	linux_prom_ebus_intmask
+	struct linux_prom_isa_intmap	isa_intmask;
 };
 
 extern struct isa_bridge	*isa_chain;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-sparc64/pbm.h linux-2.4.23-pre1/include/asm-sparc64/pbm.h
--- linux-2.4.22/include/asm-sparc64/pbm.h	2001-08-15 02:57:29.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-sparc64/pbm.h	2003-08-27 14:42:05.000000000 +0000
@@ -128,6 +128,25 @@
 	/* PCI controller we sit under. */
 	struct pci_controller_info	*parent;
 
+	/* Physical address base of controller registers. */
+	unsigned long			controller_regs;
+
+	/* Physical address base of PBM registers. */
+	unsigned long			pbm_regs;
+
+	/* Opaque 32-bit system bus Port ID. */
+	u32				portid;
+
+	/* Chipset version information. */
+	int				chip_type;
+#define PBM_CHIP_TYPE_SABRE		1
+#define PBM_CHIP_TYPE_PSYCHO		2
+#define PBM_CHIP_TYPE_SCHIZO		3
+#define PBM_CHIP_TYPE_SCHIZO_PLUS	4
+#define PBM_CHIP_TYPE_TOMATILLO		5
+	int				chip_version;
+	int				chip_revision;
+
 	/* Name used for top-level resources. */
 	char				name[64];
 
@@ -139,6 +158,7 @@
 	struct linux_prom_pci_intmap	pbm_intmap[PROM_PCIIMAP_MAX];
 	int				num_pbm_intmap;
 	struct linux_prom_pci_intmask	pbm_intmask;
+	u64				ino_bitmap;
 
 	/* PBM I/O and Memory space resources. */
 	struct resource			io_space;
@@ -170,12 +190,6 @@
 	/* List of all PCI controllers. */
 	struct pci_controller_info	*next;
 
-	/* Physical address base of controller registers. */
-	unsigned long			controller_regs;
-
-	/* Opaque 32-bit system bus Port ID. */
-	u32				portid;
-
 	/* Each controller gets a unique index, used mostly for
 	 * error logging purposes.
 	 */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-sparc64/smp.h linux-2.4.23-pre1/include/asm-sparc64/smp.h
--- linux-2.4.22/include/asm-sparc64/smp.h	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-sparc64/smp.h	2003-08-27 14:40:04.000000000 +0000
@@ -87,11 +87,19 @@
 extern __inline__ int hard_smp_processor_id(void)
 {
 	if (tlb_type == cheetah || tlb_type == cheetah_plus) {
-		unsigned long safari_config;
-		__asm__ __volatile__("ldxa [%%g0] %1, %0"
-				     : "=r" (safari_config)
-				     : "i" (ASI_SAFARI_CONFIG));
-		return ((safari_config >> 17) & 0x3ff);
+		unsigned long cfg, ver;
+		__asm__ __volatile__("rdpr %%ver, %0" : "=r" (ver));
+		if ((ver >> 32) == 0x003e0016) {
+			__asm__ __volatile__("ldxa [%%g0] %1, %0"
+					     : "=r" (cfg)
+					     : "i" (ASI_JBUS_CONFIG));
+			return ((cfg >> 17) & 0x1f);
+		} else {
+			__asm__ __volatile__("ldxa [%%g0] %1, %0"
+					     : "=r" (cfg)
+					     : "i" (ASI_SAFARI_CONFIG));
+			return ((cfg >> 17) & 0x3ff);
+		}
 	} else if (this_is_starfire != 0) {
 		return starfire_hard_smp_processor_id();
 	} else {
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/asm-x86_64/io_apic.h linux-2.4.23-pre1/include/asm-x86_64/io_apic.h
--- linux-2.4.22/include/asm-x86_64/io_apic.h	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/include/asm-x86_64/io_apic.h	2003-08-27 14:42:00.000000000 +0000
@@ -148,6 +148,6 @@
 extern int io_apic_get_unique_id (int ioapic, int apic_id);
 extern int io_apic_get_version (int ioapic);
 extern int io_apic_get_redir_entries (int ioapic);
-extern int io_apic_set_pci_routing (int ioapic, int pin, int irq);
+extern int io_apic_set_pci_routing (int ioapic, int pin, int irq, int, int);
 
 #endif
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/agp_backend.h linux-2.4.23-pre1/include/linux/agp_backend.h
--- linux-2.4.22/include/linux/agp_backend.h	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/agp_backend.h	2003-08-27 14:41:23.000000000 +0000
@@ -55,6 +55,8 @@
 	INTEL_I855_PM,
 	INTEL_I860,
 	INTEL_I865_G,
+	INTEL_I7205,
+	INTEL_I7505,
 	VIA_GENERIC,
 	VIA_VP3,
 	VIA_MVP3,
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/console.h linux-2.4.23-pre1/include/linux/console.h
--- linux-2.4.22/include/linux/console.h	2003-06-13 14:51:38.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/console.h	2003-08-27 14:40:21.000000000 +0000
@@ -113,6 +113,7 @@
 extern void release_console_sem(void);
 extern void console_conditional_schedule(void);
 extern void console_unblank(void);
+extern void disable_console_blank(void);
 
 /* VESA Blanking Levels */
 #define VESA_NO_BLANKING        0
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/ethtool.h linux-2.4.23-pre1/include/linux/ethtool.h
--- linux-2.4.22/include/linux/ethtool.h	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/ethtool.h	2003-08-27 14:39:50.000000000 +0000
@@ -97,7 +97,7 @@
 	u32	rx_max_coalesced_frames;
 
 	/* Same as above two parameters, except that these values
-	 * apply while an IRQ is being services by the host.  Not
+	 * apply while an IRQ is being serviced by the host.  Not
 	 * all cards support this feature and the values are ignored
 	 * in that case.
 	 */
@@ -119,7 +119,7 @@
 	u32	tx_max_coalesced_frames;
 
 	/* Same as above two parameters, except that these values
-	 * apply while an IRQ is being services by the host.  Not
+	 * apply while an IRQ is being serviced by the host.  Not
 	 * all cards support this feature and the values are ignored
 	 * in that case.
 	 */
@@ -250,6 +250,101 @@
 	u64	data[0];
 };
 
+struct net_device;
+
+/* Some generic methods drivers may use in their ethtool_ops */
+u32 ethtool_op_get_link(struct net_device *dev);
+u32 ethtool_op_get_tx_csum(struct net_device *dev);
+u32 ethtool_op_get_sg(struct net_device *dev);
+int ethtool_op_set_sg(struct net_device *dev, u32 data);
+
+/**
+ * &ethtool_ops - Alter and report network device settings
+ * get_settings: Get device-specific settings
+ * set_settings: Set device-specific settings
+ * get_drvinfo: Report driver information
+ * get_regs: Get device registers
+ * get_wol: Report whether Wake-on-Lan is enabled
+ * set_wol: Turn Wake-on-Lan on or off
+ * get_msglevel: Report driver message level
+ * set_msglevel: Set driver message level
+ * nway_reset: Restart autonegotiation
+ * get_link: Get link status
+ * get_eeprom: Read data from the device EEPROM
+ * set_eeprom: Write data to the device EEPROM
+ * get_coalesce: Get interrupt coalescing parameters
+ * set_coalesce: Set interrupt coalescing parameters
+ * get_ringparam: Report ring sizes
+ * set_ringparam: Set ring sizes
+ * get_pauseparam: Report pause parameters
+ * set_pauseparam: Set pause paramters
+ * get_rx_csum: Report whether receive checksums are turned on or off
+ * set_rx_csum: Turn receive checksum on or off
+ * get_tx_csum: Report whether transmit checksums are turned on or off
+ * set_tx_csum: Turn transmit checksums on or off
+ * get_sg: Report whether scatter-gather is enabled
+ * set_sg: Turn scatter-gather on or off
+ * self_test: Run specified self-tests
+ * get_strings: Return a set of strings that describe the requested objects 
+ * phys_id: Identify the device
+ * get_stats: Return statistics about the device
+ *
+ * Description:
+ *
+ * get_settings:
+ *	@get_settings is passed an &ethtool_cmd to fill in.  It returns
+ *	an negative errno or zero.
+ *
+ * set_settings:
+ *	@set_settings is passed an &ethtool_cmd and should attempt to set
+ *	all the settings this device supports.  It may return an error value
+ *	if something goes wrong (otherwise 0).
+ *
+ * get_eeprom:
+ *	Should fill in the magic field.  Don't need to check len for zero
+ *	or wraparound but must check offset + len < size.  Fill in the data
+ *	argument with the eeprom values from offset to offset + len.  Update
+ *	len to the amount read.  Returns an error or zero.
+ *
+ * set_eeprom:
+ *	Should validate the magic field.  Don't need to check len for zero
+ *	or wraparound but must check offset + len < size.  Update len to
+ *	the amount written.  Returns an error or zero.
+ */
+struct ethtool_ops {
+	int	(*get_settings)(struct net_device *, struct ethtool_cmd *);
+	int	(*set_settings)(struct net_device *, struct ethtool_cmd *);
+	void	(*get_drvinfo)(struct net_device *, struct ethtool_drvinfo *);
+	int	(*get_regs_len)(struct net_device *);
+	void	(*get_regs)(struct net_device *, struct ethtool_regs *, void *);
+	void	(*get_wol)(struct net_device *, struct ethtool_wolinfo *);
+	int	(*set_wol)(struct net_device *, struct ethtool_wolinfo *);
+	u32	(*get_msglevel)(struct net_device *);
+	void	(*set_msglevel)(struct net_device *, u32);
+	int	(*nway_reset)(struct net_device *);
+	u32	(*get_link)(struct net_device *);
+	int	(*get_eeprom)(struct net_device *, struct ethtool_eeprom *, u8 *);
+	int	(*set_eeprom)(struct net_device *, struct ethtool_eeprom *, u8 *);
+	int	(*get_coalesce)(struct net_device *, struct ethtool_coalesce *);
+	int	(*set_coalesce)(struct net_device *, struct ethtool_coalesce *);
+	void	(*get_ringparam)(struct net_device *, struct ethtool_ringparam *);
+	int	(*set_ringparam)(struct net_device *, struct ethtool_ringparam *);
+	void	(*get_pauseparam)(struct net_device *, struct ethtool_pauseparam*);
+	int	(*set_pauseparam)(struct net_device *, struct ethtool_pauseparam*);
+	u32	(*get_rx_csum)(struct net_device *);
+	int	(*set_rx_csum)(struct net_device *, u32);
+	u32	(*get_tx_csum)(struct net_device *);
+	int	(*set_tx_csum)(struct net_device *, u32);
+	u32	(*get_sg)(struct net_device *);
+	int	(*set_sg)(struct net_device *, u32);
+	int	(*self_test_count)(struct net_device *);
+	void	(*self_test)(struct net_device *, struct ethtool_test *, u64 *);
+	void	(*get_strings)(struct net_device *, u32 stringset, u8 *);
+	int	(*phys_id)(struct net_device *, u32);
+	int	(*get_stats_count)(struct net_device *);
+	void	(*get_ethtool_stats)(struct net_device *, struct ethtool_stats *, u64 *);
+};
+
 /* CMDs currently supported */
 #define ETHTOOL_GSET		0x00000001 /* Get settings. */
 #define ETHTOOL_SSET		0x00000002 /* Set settings. */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/interrupt.h linux-2.4.23-pre1/include/linux/interrupt.h
--- linux-2.4.22/include/linux/interrupt.h	2003-06-13 14:51:38.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/interrupt.h	2003-08-27 14:39:12.000000000 +0000
@@ -12,6 +12,12 @@
 #include <asm/ptrace.h>
 #include <asm/system.h>
 
+/* For 2.6.x compatibility */
+typedef void irqreturn_t;
+#define IRQ_NONE
+#define IRQ_HANDLED
+#define IRQ_RETVAL(x)
+
 struct irqaction {
 	void (*handler)(int, void *, struct pt_regs *);
 	unsigned long flags;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/ipv6.h linux-2.4.23-pre1/include/linux/ipv6.h
--- linux-2.4.22/include/linux/ipv6.h	2001-11-22 19:47:11.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/ipv6.h	2003-08-27 14:40:58.000000000 +0000
@@ -70,7 +70,7 @@
 	__u32			bitmap;		/* strict/loose bit map */
 	struct in6_addr		addr[0];
 
-#define rt0_type		rt_hdr.type;
+#define rt0_type		rt_hdr.type
 };
 
 /*
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/ipv6_route.h linux-2.4.23-pre1/include/linux/ipv6_route.h
--- linux-2.4.22/include/linux/ipv6_route.h	1998-08-28 02:33:08.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/ipv6_route.h	2003-08-27 14:39:44.000000000 +0000
@@ -25,6 +25,7 @@
 #define RTF_DEFAULT	0x00010000	/* default - learned via ND	*/
 #define RTF_ALLONLINK	0x00020000	/* fallback, no routers on link	*/
 #define RTF_ADDRCONF	0x00040000	/* addrconf route - RA		*/
+#define RTF_PREFIX_RT	0x00080000	/* A prefix only route - RA	*/
 
 #define RTF_NONEXTHOP	0x00200000	/* route with no nexthop	*/
 #define RTF_EXPIRES	0x00400000
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/lvm.h linux-2.4.23-pre1/include/linux/lvm.h
--- linux-2.4.22/include/linux/lvm.h	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/lvm.h	2003-08-27 14:39:16.000000000 +0000
@@ -80,8 +80,8 @@
 #ifndef _LVM_H_INCLUDE
 #define _LVM_H_INCLUDE
 
-#define LVM_RELEASE_NAME "1.0.5+"
-#define LVM_RELEASE_DATE "22/07/2002"
+#define LVM_RELEASE_NAME "1.0.7"
+#define LVM_RELEASE_DATE "28/03/2003"
 
 #define	_LVM_KERNEL_H_VERSION	"LVM "LVM_RELEASE_NAME" ("LVM_RELEASE_DATE")"
 
@@ -94,7 +94,7 @@
 #define	LVM_TOTAL_RESET
 
 #ifdef __KERNEL__
-#undef LVM_HD_NAME /* display nice names in /proc/partitions */
+#undef LVM_HD_NAME		/* display nice names in /proc/partitions */
 
 /* lots of debugging output (see driver source)
    #define DEBUG_LVM_GET_INFO
@@ -118,7 +118,7 @@
    causes problems on some platforms. It's not nice but then
    neither is the alternative. */
 struct list_head {
-        struct list_head *next, *prev;
+	struct list_head *next, *prev;
 };
 #define __KERNEL__
 #include <linux/kdev_t.h>
@@ -258,9 +258,9 @@
 #define	LVM_PE_T_MAX		( ( 1 << ( sizeof ( uint16_t) * 8)) - 2)
 
 #define	LVM_LV_SIZE_MAX(a)	( ( long long) LVM_PE_T_MAX * (a)->pe_size > ( long long) 1024*1024/SECTOR_SIZE*1024*1024 ? ( long long) 1024*1024/SECTOR_SIZE*1024*1024 : ( long long) LVM_PE_T_MAX * (a)->pe_size)
-#define	LVM_MIN_PE_SIZE		( 8192L / SECTOR_SIZE) /* 8 KB in sectors */
+#define	LVM_MIN_PE_SIZE		( 8192L / SECTOR_SIZE)	/* 8 KB in sectors */
 #define	LVM_MAX_PE_SIZE		( 16L * 1024L * 1024L / SECTOR_SIZE * 1024)	/* 16GB in sectors */
-#define	LVM_DEFAULT_PE_SIZE	( 4096L * 1024 / SECTOR_SIZE)	/* 4 MB in sectors */
+#define	LVM_DEFAULT_PE_SIZE	( 32768L * 1024 / SECTOR_SIZE)	/* 32 MB in sectors */
 #define	LVM_DEFAULT_STRIPE_SIZE	16L	/* 16 KB  */
 #define	LVM_MIN_STRIPE_SIZE	( PAGE_SIZE/SECTOR_SIZE)	/* PAGESIZE in sectors */
 #define	LVM_MAX_STRIPE_SIZE	( 512L * 1024 / SECTOR_SIZE)	/* 512 KB in sectors */
@@ -416,9 +416,9 @@
 typedef struct lv_block_exception_v1 {
 	struct list_head hash;
 	uint32_t rsector_org;
-	kdev_t   rdev_org;
+	kdev_t rdev_org;
 	uint32_t rsector_new;
-	kdev_t   rdev_new;
+	kdev_t rdev_new;
 } lv_block_exception_t;
 
 /* disk stored pe information */
@@ -462,7 +462,7 @@
 	uint pe_stale;		/* for future use */
 	pe_disk_t *pe;		/* HM */
 	struct block_device *bd;
-	char pv_uuid[UUID_LEN+1];
+	char pv_uuid[UUID_LEN + 1];
 
 #ifndef __KERNEL__
 	uint32_t pe_start;	/* in sectors */
@@ -473,7 +473,7 @@
 /* disk */
 typedef struct pv_disk_v2 {
 	uint8_t id[2];		/* Identifier */
-	uint16_t version;		/* HM lvm version */
+	uint16_t version;	/* HM lvm version */
 	lvm_disk_data_t pv_on_disk;
 	lvm_disk_data_t vg_on_disk;
 	lvm_disk_data_t pv_uuidlist_on_disk;
@@ -486,14 +486,14 @@
 	uint32_t pv_number;
 	uint32_t pv_status;
 	uint32_t pv_allocatable;
-	uint32_t pv_size;		/* HM */
+	uint32_t pv_size;	/* HM */
 	uint32_t lv_cur;
 	uint32_t pe_size;
 	uint32_t pe_total;
 	uint32_t pe_allocated;
-	
+
 	/* new in struct version 2 */
-	uint32_t pe_start;	        /* in sectors */
+	uint32_t pe_start;	/* in sectors */
 
 } pv_disk_t;
 
@@ -567,8 +567,8 @@
 	uint32_t lv_snapshot_hash_table_size;
 	uint32_t lv_snapshot_hash_mask;
 	wait_queue_head_t lv_snapshot_wait;
-	int	lv_snapshot_use_rate;
-	struct vg_v3	*vg;
+	int lv_snapshot_use_rate;
+	struct vg_v3 *vg;
 
 	uint lv_allocated_snapshot_le;
 #else
@@ -582,14 +582,14 @@
 	uint8_t vg_name[NAME_LEN];
 	uint32_t lv_access;
 	uint32_t lv_status;
-	uint32_t lv_open;		/* HM */
-	uint32_t lv_dev;		/* HM */
+	uint32_t lv_open;	/* HM */
+	uint32_t lv_dev;	/* HM */
 	uint32_t lv_number;	/* HM */
 	uint32_t lv_mirror_copies;	/* for future use */
 	uint32_t lv_recovery;	/*       "        */
 	uint32_t lv_schedule;	/*       "        */
 	uint32_t lv_size;
-	uint32_t lv_snapshot_minor;/* minor number of original */
+	uint32_t lv_snapshot_minor;	/* minor number of original */
 	uint16_t lv_chunk_size;	/* chunk size of snapshot */
 	uint16_t dummy;
 	uint32_t lv_allocated_le;
@@ -626,7 +626,7 @@
 	struct proc_dir_entry *proc;
 	pv_t *pv[ABS_MAX_PV + 1];	/* physical volume struct pointers */
 	lv_t *lv[ABS_MAX_LV + 1];	/* logical  volume struct pointers */
-	char vg_uuid[UUID_LEN+1];	/* volume group UUID */
+	char vg_uuid[UUID_LEN + 1];	/* volume group UUID */
 #ifdef __KERNEL__
 	struct proc_dir_entry *vg_dir_pde;
 	struct proc_dir_entry *lv_subdir_pde;
@@ -640,20 +640,20 @@
 /* disk */
 typedef struct vg_disk_v2 {
 	uint8_t vg_uuid[UUID_LEN];	/* volume group UUID */
-	uint8_t vg_name_dummy[NAME_LEN-UUID_LEN];	/* rest of v1 VG name */
+	uint8_t vg_name_dummy[NAME_LEN - UUID_LEN];	/* rest of v1 VG name */
 	uint32_t vg_number;	/* volume group number */
 	uint32_t vg_access;	/* read/write */
 	uint32_t vg_status;	/* active or not */
-	uint32_t lv_max;		/* maximum logical volumes */
-	uint32_t lv_cur;		/* current logical volumes */
-	uint32_t lv_open;		/* open    logical volumes */
-	uint32_t pv_max;		/* maximum physical volumes */
-	uint32_t pv_cur;		/* current physical volumes FU */
-	uint32_t pv_act;		/* active physical volumes */
+	uint32_t lv_max;	/* maximum logical volumes */
+	uint32_t lv_cur;	/* current logical volumes */
+	uint32_t lv_open;	/* open    logical volumes */
+	uint32_t pv_max;	/* maximum physical volumes */
+	uint32_t pv_cur;	/* current physical volumes FU */
+	uint32_t pv_act;	/* active physical volumes */
 	uint32_t dummy;
 	uint32_t vgda;		/* volume group descriptor arrays FU */
-	uint32_t pe_size;		/* physical extent size in sectors */
-	uint32_t pe_total;		/* total of physical extents */
+	uint32_t pe_size;	/* physical extent size in sectors */
+	uint32_t pe_total;	/* total of physical extents */
 	uint32_t pe_allocated;	/* allocated physical extents */
 	uint32_t pvg_total;	/* physical volume groups FU */
 } vg_disk_t;
@@ -712,40 +712,44 @@
 
 /* Request structure LV_SNAPSHOT_USE_RATE */
 typedef struct {
-	int	block;
-	int	rate;
+	int block;
+	int rate;
 } lv_snapshot_use_rate_req_t;
 
 
 
 /* useful inlines */
-static inline ulong round_up(ulong n, ulong size) {
+static inline ulong round_up(ulong n, ulong size)
+{
 	size--;
 	return (n + size) & ~size;
 }
 
-static inline ulong div_up(ulong n, ulong size) {
+static inline ulong div_up(ulong n, ulong size)
+{
 	return round_up(n, size) / size;
 }
 
 /* FIXME: nasty capital letters */
-static int inline LVM_GET_COW_TABLE_CHUNKS_PER_PE(vg_t *vg, lv_t *lv) {
+static int inline LVM_GET_COW_TABLE_CHUNKS_PER_PE(vg_t * vg, lv_t * lv)
+{
 	return vg->pe_size / lv->lv_chunk_size;
 }
 
-static int inline LVM_GET_COW_TABLE_ENTRIES_PER_PE(vg_t *vg, lv_t *lv) {
+static int inline LVM_GET_COW_TABLE_ENTRIES_PER_PE(vg_t * vg, lv_t * lv)
+{
 	ulong chunks = vg->pe_size / lv->lv_chunk_size;
 	ulong entry_size = sizeof(lv_COW_table_disk_t);
 	ulong chunk_size = lv->lv_chunk_size * SECTOR_SIZE;
 	ulong entries = (vg->pe_size * SECTOR_SIZE) /
-		(entry_size + chunk_size);
+	    (entry_size + chunk_size);
 
-	if(chunks < 2)
+	if (chunks < 2)
 		return 0;
 
-	for(; entries; entries--)
-		if((div_up(entries * entry_size, chunk_size) + entries) <=
-		   chunks)
+	for (; entries; entries--)
+		if ((div_up(entries * entry_size, chunk_size) + entries) <=
+		    chunks)
 			break;
 
 	return entries;
@@ -753,4 +757,3 @@
 
 
 #endif				/* #ifndef _LVM_H_INCLUDE */
-
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/netdevice.h linux-2.4.23-pre1/include/linux/netdevice.h
--- linux-2.4.22/include/linux/netdevice.h	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/netdevice.h	2003-08-27 14:41:45.000000000 +0000
@@ -41,6 +41,7 @@
 
 struct divert_blk;
 struct vlan_group;
+struct ethtool_ops;
 
 #define HAVE_ALLOC_NETDEV		/* feature macro: alloc_xxxdev
 					   functions are available. */
@@ -290,6 +291,8 @@
 	 * See <net/iw_handler.h> for details. Jean II */
 	struct iw_handler_def *	wireless_handlers;
 
+	struct ethtool_ops *ethtool_ops;
+
 	/*
 	 * This marks the end of the "visible" part of the structure. All
 	 * fields hereafter are internal to the system, and may change at
@@ -601,6 +604,7 @@
 #define HAVE_NETIF_RECEIVE_SKB 1
 extern int		netif_receive_skb(struct sk_buff *skb);
 extern int		dev_ioctl(unsigned int cmd, void *);
+extern int		dev_ethtool(struct ifreq *);
 extern int		dev_change_flags(struct net_device *, unsigned);
 extern void		dev_queue_xmit_nit(struct sk_buff *skb, struct net_device *dev);
 
@@ -789,6 +793,7 @@
 	local_irq_save(flags);
 	if (!test_bit(__LINK_STATE_RX_SCHED, &dev->state)) BUG();
 	list_del(&dev->poll_list);
+	smp_mb__before_clear_bit();
 	clear_bit(__LINK_STATE_RX_SCHED, &dev->state);
 	local_irq_restore(flags);
 }
@@ -801,6 +806,8 @@
 extern void		fc_setup(struct net_device *dev);
 extern void		fc_freedev(struct net_device *dev);
 /* Support for loadable net-drivers */
+extern struct net_device *alloc_netdev(int sizeof_priv, const char *name,
+				       void (*setup)(struct net_device *));
 extern int		register_netdev(struct net_device *dev);
 extern void		unregister_netdev(struct net_device *dev);
 /* Functions used for multicast support */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/pci_ids.h linux-2.4.23-pre1/include/linux/pci_ids.h
--- linux-2.4.22/include/linux/pci_ids.h	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/pci_ids.h	2003-08-27 14:40:21.000000000 +0000
@@ -810,6 +810,7 @@
 #define PCI_DEVICE_ID_SUN_SCHIZO	0x8001
 #define PCI_DEVICE_ID_SUN_SABRE		0xa000
 #define PCI_DEVICE_ID_SUN_HUMMINGBIRD	0xa001
+#define PCI_DEVICE_ID_SUN_TOMATILLO	0xa801
 
 #define PCI_VENDOR_ID_CMD		0x1095
 #define PCI_DEVICE_ID_SII_1210SA	0x0240
@@ -1672,6 +1673,7 @@
 
 #define PCI_VENDOR_ID_ALTIMA		0x173b
 #define PCI_DEVICE_ID_ALTIMA_AC1000	0x03e8
+#define PCI_DEVICE_ID_ALTIMA_AC1001	0x03e9
 #define PCI_DEVICE_ID_ALTIMA_AC9100	0x03ea
 
 #define PCI_VENDOR_ID_SYMPHONY		0x1c1c
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/pkt_sched.h linux-2.4.23-pre1/include/linux/pkt_sched.h
--- linux-2.4.22/include/linux/pkt_sched.h	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/pkt_sched.h	2003-08-27 14:41:00.000000000 +0000
@@ -45,7 +45,7 @@
 
 struct tc_estimator
 {
-	char		interval;
+	signed char	interval;
 	unsigned char	ewma_log;
 };
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/rtnetlink.h linux-2.4.23-pre1/include/linux/rtnetlink.h
--- linux-2.4.22/include/linux/rtnetlink.h	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/rtnetlink.h	2003-08-27 14:41:23.000000000 +0000
@@ -167,6 +167,7 @@
 #define RTM_F_NOTIFY		0x100	/* Notify user of route change	*/
 #define RTM_F_CLONED		0x200	/* This route is cloned		*/
 #define RTM_F_EQUALIZE		0x400	/* Multipath equalizer: NI	*/
+#define RTM_F_PREFIX		0x800	/* Prefix addresses		*/
 
 /* Reserved table identifiers */
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/sonypi.h linux-2.4.23-pre1/include/linux/sonypi.h
--- linux-2.4.22/include/linux/sonypi.h	2003-06-13 14:51:39.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/sonypi.h	2003-08-27 14:40:09.000000000 +0000
@@ -94,6 +94,8 @@
 #define SONYPI_EVENT_MEMORYSTICK_INSERT		54
 #define SONYPI_EVENT_MEMORYSTICK_EJECT		55
 #define SONYPI_EVENT_ANYBUTTON_RELEASED		56
+#define SONYPI_EVENT_BATTERY_INSERT		57
+#define SONYPI_EVENT_BATTERY_REMOVE		58
 
 /* get/set brightness */
 #define SONYPI_IOCGBRT		_IOR('v', 0, __u8)
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/sysctl.h linux-2.4.23-pre1/include/linux/sysctl.h
--- linux-2.4.22/include/linux/sysctl.h	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/sysctl.h	2003-08-27 14:39:13.000000000 +0000
@@ -146,6 +146,7 @@
 	VM_MAX_MAP_COUNT=11,	/* int: Maximum number of active map areas */
 	VM_MIN_READAHEAD=12,    /* Min file readahead */
 	VM_MAX_READAHEAD=13,    /* Max file readahead */
+	VM_PAGEBUF=17,		/* struct: Control pagebuf parameters */
 };
 
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/linux/threads.h linux-2.4.23-pre1/include/linux/threads.h
--- linux-2.4.22/include/linux/threads.h	2002-02-25 19:38:13.000000000 +0000
+++ linux-2.4.23-pre1/include/linux/threads.h	2003-08-27 14:39:14.000000000 +0000
@@ -9,9 +9,9 @@
  */
  
 #ifdef CONFIG_SMP
-#define NR_CPUS	32		/* Max processors that can be running in SMP */
+#define NR_CPUS	CONFIG_NR_CPUS
 #else
-#define NR_CPUS 1
+#define NR_CPUS	1
 #endif
 
 #define MIN_THREADS_LEFT_FOR_ROOT 4
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/net/ip_vs.h linux-2.4.23-pre1/include/net/ip_vs.h
--- linux-2.4.22/include/net/ip_vs.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/include/net/ip_vs.h	2003-08-27 14:39:35.000000000 +0000
@@ -0,0 +1,932 @@
+/*
+ *      IP Virtual Server
+ *      data structure and functionality definitions
+ */
+
+#ifndef _IP_VS_H
+#define _IP_VS_H
+
+#include <asm/types.h>          /* For __uXX types */
+
+#define IP_VS_VERSION_CODE            0x01000A
+#define NVERSION(version)                       \
+	(version >> 16) & 0xFF,                 \
+	(version >> 8) & 0xFF,                  \
+	version & 0xFF
+
+/*
+ *      Virtual Service Flags
+ */
+#define IP_VS_SVC_F_PERSISTENT        0x0001    /* persistent port */
+#define IP_VS_SVC_F_HASHED            0x0002    /* hashed entry */
+
+/*
+ *      Destination Server Flags
+ */
+#define IP_VS_DEST_F_AVAILABLE        0x0001    /* Available tag */
+
+/*
+ *      IPVS sync daemon states
+ */
+#define IP_VS_STATE_NONE    0           /* daemon is stopped */
+#define IP_VS_STATE_MASTER  1           /* started as master */
+#define IP_VS_STATE_BACKUP  2           /* started as backup */
+
+/*
+ *      IPVS socket options
+ */
+#define IP_VS_BASE_CTL		(64+1024+64)		/* base */
+
+#define IP_VS_SO_SET_NONE	IP_VS_BASE_CTL	        /* just peek */
+#define IP_VS_SO_SET_INSERT	(IP_VS_BASE_CTL+1)
+#define IP_VS_SO_SET_ADD	(IP_VS_BASE_CTL+2)
+#define IP_VS_SO_SET_EDIT	(IP_VS_BASE_CTL+3)
+#define IP_VS_SO_SET_DEL	(IP_VS_BASE_CTL+4)
+#define IP_VS_SO_SET_FLUSH	(IP_VS_BASE_CTL+5)
+#define IP_VS_SO_SET_LIST	(IP_VS_BASE_CTL+6)
+#define IP_VS_SO_SET_ADDDEST	(IP_VS_BASE_CTL+7)
+#define IP_VS_SO_SET_DELDEST	(IP_VS_BASE_CTL+8)
+#define IP_VS_SO_SET_EDITDEST	(IP_VS_BASE_CTL+9)
+#define IP_VS_SO_SET_TIMEOUTS	(IP_VS_BASE_CTL+10)
+#define IP_VS_SO_SET_STARTDAEMON (IP_VS_BASE_CTL+11)
+#define IP_VS_SO_SET_STOPDAEMON (IP_VS_BASE_CTL+12)
+#define IP_VS_SO_SET_RESTORE    (IP_VS_BASE_CTL+13)
+#define IP_VS_SO_SET_SAVE       (IP_VS_BASE_CTL+14)
+#define IP_VS_SO_SET_ZERO	(IP_VS_BASE_CTL+15)
+#define IP_VS_SO_SET_MAX	IP_VS_SO_SET_ZERO
+
+#define IP_VS_SO_GET_VERSION	IP_VS_BASE_CTL
+#define IP_VS_SO_GET_INFO	(IP_VS_BASE_CTL+1)
+#define IP_VS_SO_GET_SERVICES	(IP_VS_BASE_CTL+2)
+#define IP_VS_SO_GET_SERVICE	(IP_VS_BASE_CTL+3)
+#define IP_VS_SO_GET_DESTS	(IP_VS_BASE_CTL+4)
+#define IP_VS_SO_GET_DEST	(IP_VS_BASE_CTL+5)	/* not used now */
+#define IP_VS_SO_GET_TIMEOUTS	(IP_VS_BASE_CTL+6)
+#define IP_VS_SO_GET_DAEMON	(IP_VS_BASE_CTL+7)
+#define IP_VS_SO_GET_MAX	IP_VS_SO_GET_DAEMON
+
+
+/*
+ *      IPVS Connection Flags
+ */
+#define IP_VS_CONN_F_FWD_MASK         0x0007    /* mask for the fwd methods */
+#define IP_VS_CONN_F_MASQ	      0x0000    /* masquerading */
+#define IP_VS_CONN_F_LOCALNODE	      0x0001    /* local node */
+#define IP_VS_CONN_F_TUNNEL	      0x0002    /* tunneling */
+#define IP_VS_CONN_F_DROUTE           0x0003    /* direct routing */
+#define IP_VS_CONN_F_BYPASS           0x0004    /* cache bypass */
+#define IP_VS_CONN_F_HASHED	      0x0040	/* hashed entry */
+#define IP_VS_CONN_F_NOOUTPUT         0x0080    /* no output packets */
+#define IP_VS_CONN_F_INACTIVE         0x0100    /* not established */
+#define IP_VS_CONN_F_OUT_SEQ          0x0200    /* must do output seq adjust */
+#define IP_VS_CONN_F_IN_SEQ           0x0400    /* must do input seq adjust */
+#define IP_VS_CONN_F_SEQ_MASK         0x0600    /* in/out sequence mask */
+#define IP_VS_CONN_F_NO_CPORT         0x0800    /* no client port set yet */
+
+/* Move it to better place one day, for now keep it unique */
+#define NFC_IPVS_PROPERTY	0x10000
+
+#define IP_VS_SCHEDNAME_MAXLEN         16
+#define IP_VS_IFNAME_MAXLEN            16
+
+struct ip_vs_rule_user {
+	/* global options */
+	int             tcp_timeout;    /* timeout values */
+	int             tcp_fin_timeout;
+	int             udp_timeout;
+	int             state;          /* sync daemon state */
+	char            mcast_ifn[IP_VS_IFNAME_MAXLEN];
+					/* multicast interface name */
+
+	/* virtual service options */
+	u_int16_t	protocol;
+	u_int32_t	vaddr;          /* virtual address */
+	u_int16_t	vport;
+	u_int32_t       vfwmark;        /* firwall mark of virtual service*/
+	char            sched_name[IP_VS_SCHEDNAME_MAXLEN];
+	unsigned	vs_flags;       /* virtual service flags */
+	unsigned        timeout;        /* persistent timeout in ticks */
+	u_int32_t	netmask;        /* persistent netmask */
+
+	/* destination specific options */
+	u_int32_t	daddr;          /* destination address */
+	u_int16_t	dport;
+	unsigned        conn_flags;     /* destination flags */
+	int             weight;         /* destination weight */
+};
+
+
+/*
+ *	IPVS statistics object (for user space)
+ */
+struct ip_vs_stats_user
+{
+	__u32                   conns;          /* connections scheduled */
+	__u32                   inpkts;         /* incoming packets */
+	__u32                   outpkts;        /* outgoing packets */
+	__u64                   inbytes;        /* incoming bytes */
+	__u64                   outbytes;       /* outgoing bytes */
+
+	__u32			cps;		/* current connection rate */
+	__u32			inpps;		/* current in packet rate */
+	__u32			outpps;		/* current out packet rate */
+	__u32			inbps;		/* current in byte rate */
+	__u32			outbps;		/* current out byte rate */
+};
+
+
+/* The argument to IP_VS_SO_GET_INFO */
+struct ip_vs_getinfo {
+	/* version number */
+	unsigned int	version;
+
+	/* size of connection hash table */
+	unsigned int	size;
+
+	/* number of virtual services */
+	unsigned int	num_services;
+};
+
+/* The argument to IP_VS_SO_GET_SERVICE */
+struct ip_vs_service_user {
+	/* which service: user fills this in */
+	u_int16_t	protocol;
+	u_int32_t	addr;           /* virtual address */
+	u_int16_t	port;
+	u_int32_t       fwmark;         /* firwall mark of virtual service */
+
+	/* service options */
+	char            sched_name[IP_VS_SCHEDNAME_MAXLEN];
+	unsigned	flags;          /* virtual service flags */
+	unsigned        timeout;        /* persistent timeout in ticks */
+	u_int32_t	netmask;        /* persistent netmask */
+
+	/* number of real servers */
+	unsigned int    num_dests;
+
+	/* statistics */
+	struct ip_vs_stats_user stats;
+};
+
+struct ip_vs_dest_user {
+	u_int32_t	addr;           /* destination address */
+	u_int16_t	port;
+	unsigned	flags;		/* destination flags */
+	int		weight;         /* destination weight */
+	u_int32_t	activeconns;	/* active connections */
+	u_int32_t	inactconns;	/* inactive connections */
+
+	/* statistics */
+	struct ip_vs_stats_user stats;
+};
+
+/* The argument to IP_VS_SO_GET_DESTS */
+struct ip_vs_get_dests {
+	/* which service: user fills this in */
+	u_int16_t	protocol;
+	u_int32_t	addr;           /* virtual address */
+	u_int16_t	port;
+	u_int32_t       fwmark;         /* firwall mark of virtual service */
+
+	/* number of real servers */
+	unsigned int    num_dests;
+
+	/* the real servers */
+	struct ip_vs_dest_user entrytable[0];
+};
+
+/* The argument to IP_VS_SO_GET_SERVICES */
+struct ip_vs_get_services {
+	/* number of virtual services */
+	unsigned int num_services;
+
+	/* service table */
+	struct ip_vs_service_user entrytable[0];
+};
+
+/* The argument to IP_VS_SO_GET_TIMEOUTS */
+struct ip_vs_timeout_user {
+	int             tcp_timeout;
+	int             tcp_fin_timeout;
+	int             udp_timeout;
+};
+
+/* The argument to IP_VS_SO_GET_DAEMON */
+struct ip_vs_daemon_user {
+	int	state;				/* sync daemon state */
+	char	mcast_ifn[IP_VS_IFNAME_MAXLEN];	/* multicast interface name */
+};
+
+
+#ifdef __KERNEL__
+
+#include <linux/config.h>
+#include <linux/list.h>                 /* for struct list_head */
+#include <linux/spinlock.h>             /* for struct rwlock_t */
+#include <linux/skbuff.h>               /* for struct sk_buff */
+#include <linux/ip.h>                   /* for struct iphdr */
+#include <asm/atomic.h>                 /* for struct atomic_t */
+#include <linux/netdevice.h>		/* for struct neighbour; */
+#include <net/dst.h>			/* for struct dst_entry */
+#include <net/route.h>			/* for ip_route_output */
+#include <net/tcp.h>
+#include <net/udp.h>
+
+
+#ifdef CONFIG_IP_VS_DEBUG
+extern int ip_vs_get_debug_level(void);
+#define IP_VS_DBG(level, msg...)			\
+    do {						\
+	    if (level <= ip_vs_get_debug_level())	\
+		    printk(KERN_DEBUG "IPVS: " msg);	\
+    } while (0)
+#define IP_VS_DBG_RL(msg...)				\
+    do {						\
+	    if (net_ratelimit())			\
+		    printk(KERN_DEBUG "IPVS: " msg);	\
+    } while (0)
+#else	/* NO DEBUGGING at ALL */
+#define IP_VS_DBG(level, msg...)  do {} while (0)
+#define IP_VS_DBG_RL(msg...)  do {} while (0)
+#endif
+
+#define IP_VS_BUG() BUG()
+#define IP_VS_ERR(msg...) printk(KERN_ERR "IPVS: " msg)
+#define IP_VS_INFO(msg...) printk(KERN_INFO "IPVS: " msg)
+#define IP_VS_WARNING(msg...) \
+	printk(KERN_WARNING "IPVS: " msg)
+#define IP_VS_ERR_RL(msg...)				\
+    do {						\
+	    if (net_ratelimit())			\
+		    printk(KERN_ERR "IPVS: " msg);	\
+    } while (0)
+
+#ifdef CONFIG_IP_VS_DEBUG
+#define EnterFunction(level)						\
+    do {								\
+	    if (level <= ip_vs_get_debug_level())			\
+		    printk(KERN_DEBUG "Enter: %s, %s line %i\n",	\
+			   __FUNCTION__, __FILE__, __LINE__);		\
+    } while (0)
+#define LeaveFunction(level)                                            \
+    do {                                                                \
+	    if (level <= ip_vs_get_debug_level())                       \
+			printk(KERN_DEBUG "Leave: %s, %s line %i\n",    \
+			       __FUNCTION__, __FILE__, __LINE__);       \
+    } while (0)
+#else
+#define EnterFunction(level)   do {} while (0)
+#define LeaveFunction(level)   do {} while (0)
+#endif
+
+
+/*
+ *      The port number of FTP service (in network order).
+ */
+#define FTPPORT  __constant_htons(21)
+#define FTPDATA  __constant_htons(20)
+
+
+/*
+ *      IPVS sysctl variables under the /proc/sys/net/ipv4/vs/
+ */
+#define NET_IPV4_VS              21
+
+enum {
+	NET_IPV4_VS_DEBUG_LEVEL=1,
+	NET_IPV4_VS_AMEMTHRESH=2,
+	NET_IPV4_VS_AMDROPRATE=3,
+	NET_IPV4_VS_DROP_ENTRY=4,
+	NET_IPV4_VS_DROP_PACKET=5,
+	NET_IPV4_VS_SECURE_TCP=6,
+	NET_IPV4_VS_TO_ES=7,
+	NET_IPV4_VS_TO_SS=8,
+	NET_IPV4_VS_TO_SR=9,
+	NET_IPV4_VS_TO_FW=10,
+	NET_IPV4_VS_TO_TW=11,
+	NET_IPV4_VS_TO_CL=12,
+	NET_IPV4_VS_TO_CW=13,
+	NET_IPV4_VS_TO_LA=14,
+	NET_IPV4_VS_TO_LI=15,
+	NET_IPV4_VS_TO_SA=16,
+	NET_IPV4_VS_TO_UDP=17,
+	NET_IPV4_VS_TO_ICMP=18,
+	NET_IPV4_VS_LBLC_EXPIRE=19,
+	NET_IPV4_VS_LBLCR_EXPIRE=20,
+	NET_IPV4_VS_CACHE_BYPASS=22,
+	NET_IPV4_VS_EXPIRE_NODEST_CONN=23,
+	NET_IPV4_VS_SYNC_THRESHOLD=24,
+	NET_IPV4_VS_NAT_ICMP_SEND=25,
+	NET_IPV4_VS_LAST
+};
+
+
+/*
+ *      IPVS State Values
+ */
+enum {
+	IP_VS_S_NONE = 0,
+	IP_VS_S_ESTABLISHED,
+	IP_VS_S_SYN_SENT,
+	IP_VS_S_SYN_RECV,
+	IP_VS_S_FIN_WAIT,
+	IP_VS_S_TIME_WAIT,
+	IP_VS_S_CLOSE,
+	IP_VS_S_CLOSE_WAIT,
+	IP_VS_S_LAST_ACK,
+	IP_VS_S_LISTEN,
+	IP_VS_S_SYNACK,
+	IP_VS_S_UDP,
+	IP_VS_S_ICMP,
+	IP_VS_S_LAST
+};
+
+
+struct ip_vs_timeout_table {
+	atomic_t refcnt;
+	int scale;
+	int timeout[IP_VS_S_LAST+1];
+};
+
+
+/*
+ *	Transport protocol header
+ */
+union ip_vs_tphdr {
+	unsigned char *raw;
+	struct udphdr *uh;
+	struct tcphdr *th;
+	struct icmphdr *icmph;
+	__u16 *portp;
+};
+
+
+/*
+ *	Delta sequence info structure
+ *	Each ip_vs_conn has 2 (output AND input seq. changes).
+ *      Only used in the VS/NAT.
+ */
+struct ip_vs_seq {
+	__u32           init_seq;       /* Add delta from this seq */
+	__u32           delta;          /* Delta in sequence numbers */
+	__u32           previous_delta; /* Delta in sequence numbers
+					   before last resized pkt */
+};
+
+
+/*
+ *	IPVS statistics object
+ */
+struct ip_vs_stats
+{
+	__u32                   conns;          /* connections scheduled */
+	__u32                   inpkts;         /* incoming packets */
+	__u32                   outpkts;        /* outgoing packets */
+	__u64                   inbytes;        /* incoming bytes */
+	__u64                   outbytes;       /* outgoing bytes */
+
+	__u32			cps;		/* current connection rate */
+	__u32			inpps;		/* current in packet rate */
+	__u32			outpps;		/* current out packet rate */
+	__u32			inbps;		/* current in byte rate */
+	__u32			outbps;		/* current out byte rate */
+
+	spinlock_t              lock;           /* spin lock */
+};
+
+
+/*
+ *	IP_VS structure allocated for each dynamically scheduled connection
+ */
+struct ip_vs_conn {
+	struct list_head        c_list;         /* hashed list heads */
+
+	/* Protocol, addresses and port numbers */
+	__u32                   caddr;          /* client address */
+	__u32                   vaddr;          /* virtual address */
+	__u32                   daddr;          /* destination address */
+	__u16                   cport;
+	__u16                   vport;
+	__u16                   dport;
+	__u16                   protocol;       /* Which protocol (TCP/UDP) */
+
+	/* counter and timer */
+	atomic_t		refcnt;		/* reference count */
+	struct timer_list	timer;		/* Expiration timer */
+	volatile unsigned long	timeout;	/* timeout */
+	struct ip_vs_timeout_table *timeout_table;
+
+	/* Flags and state transition */
+	spinlock_t              lock;           /* lock for state transition */
+	volatile __u16          flags;          /* status flags */
+	volatile __u16          state;          /* state info */
+
+	/* Control members */
+	struct ip_vs_conn       *control;       /* Master control connection */
+	atomic_t                n_control;      /* Number of controlled ones */
+	struct ip_vs_dest       *dest;          /* real server */
+	atomic_t                in_pkts;        /* incoming packet counter */
+
+	/* packet transmitter for different forwarding methods */
+	int (*packet_xmit)(struct sk_buff *skb, struct ip_vs_conn *cp);
+
+	/* Note: we can group the following members into a structure,
+	   in order to save more space, and the following members are
+	   only used in VS/NAT anyway */
+	struct ip_vs_app        *app;           /* bound ip_vs_app object */
+	void                    *app_data;      /* Application private data */
+	struct ip_vs_seq        in_seq;         /* incoming seq. struct */
+	struct ip_vs_seq        out_seq;        /* outgoing seq. struct */
+};
+
+
+/*
+ *	The information about the virtual service offered to the net
+ *	and the forwarding entries
+ */
+struct ip_vs_service {
+	struct list_head	s_list;   /* for normal service table */
+	struct list_head	f_list;   /* for fwmark-based service table */
+	atomic_t		refcnt;   /* reference counter */
+	atomic_t		usecnt;   /* use counter */
+
+	__u16			protocol; /* which protocol (TCP/UDP) */
+	__u32			addr;	  /* IP address for virtual service */
+	__u16			port;	  /* port number for the service */
+	__u32                   fwmark;   /* firewall mark of the service */
+	unsigned		flags;	  /* service status flags */
+	unsigned		timeout;  /* persistent timeout in ticks */
+	__u32			netmask;  /* grouping granularity */
+
+	struct list_head	destinations;  /* real server d-linked list */
+	__u32			num_dests;     /* number of servers */
+	struct ip_vs_stats      stats;         /* statistics for the service */
+
+	/* for scheduling */
+	struct ip_vs_scheduler	*scheduler;    /* bound scheduler object */
+	rwlock_t		sched_lock;    /* lock sched_data */
+	void			*sched_data;   /* scheduler application data */
+};
+
+
+/*
+ *	The real server destination forwarding entry
+ *	with ip address, port number, and so on.
+ */
+struct ip_vs_dest {
+	struct list_head	n_list;   /* for the dests in the service */
+	struct list_head	d_list;   /* for table with all the dests */
+
+	__u32			addr;	  /* IP address of real server */
+	__u16			port;	  /* port number of the service */
+	unsigned		flags;	  /* dest status flags */
+	atomic_t		weight;	  /* server weight */
+	atomic_t		conn_flags;	/* flags to copy to conn */
+	atomic_t		activeconns;	/* active connections */
+	atomic_t		inactconns;     /* inactive connections */
+	atomic_t		refcnt;	        /* reference counter */
+	struct ip_vs_stats      stats;          /* statistics */
+
+	/* for destination cache */
+	spinlock_t		dst_lock;	/* lock dst_cache */
+	struct dst_entry	*dst_cache;	/* destination cache entry */
+	u32			dst_rtos;	/* RT_TOS(tos) for dst */
+
+	/* for virtual service */
+	struct ip_vs_service    *svc;     /* service that it belongs to */
+	__u16			protocol; /* which protocol (TCP/UDP) */
+	__u32			vaddr;	  /* IP address for virtual service */
+	__u16			vport;	  /* port number for the service */
+	__u32                   vfwmark;  /* firewall mark of the service */
+};
+
+
+/*
+ *	The scheduler object
+ */
+struct ip_vs_scheduler {
+	struct list_head        n_list;   /* d-linked list head */
+	char			*name;    /* scheduler name */
+	atomic_t                refcnt;   /* reference counter */
+	struct module		*module;  /* THIS_MODULE/NULL */
+
+	/* scheduler initializing service */
+	int (*init_service)(struct ip_vs_service *svc);
+	/* scheduling service finish */
+	int (*done_service)(struct ip_vs_service *svc);
+	/* scheduler updating service */
+	int (*update_service)(struct ip_vs_service *svc);
+
+	/* selecting a server from the given service */
+	struct ip_vs_dest* (*schedule)(struct ip_vs_service *svc,
+				       struct iphdr *iph);
+};
+
+
+/*
+ *	The application module object
+ */
+struct ip_vs_app
+{
+	struct list_head        n_list;   /* d-linked list head */
+	char                    *name;    /* name of application module */
+	unsigned                type;     /* type = proto<<16 | port
+					     (host byte order)*/
+	struct module		*module;  /* THIS_MODULE/NULL */
+
+	/* ip_vs_app initializer */
+	int (*init_conn)(struct ip_vs_app *, struct ip_vs_conn *);
+	/* ip_vs_app finish */
+	int (*done_conn)(struct ip_vs_app *, struct ip_vs_conn *);
+	/* output hook */
+	int (*pkt_out)(struct ip_vs_app *,
+		       struct ip_vs_conn *, struct sk_buff *);
+	/* input hook */
+	int (*pkt_in)(struct ip_vs_app *,
+		      struct ip_vs_conn *, struct sk_buff *);
+};
+
+
+/*
+ *      IPVS core functions
+ *      (from ip_vs_core.c)
+ */
+extern const char *ip_vs_proto_name(unsigned proto);
+extern unsigned int check_for_ip_vs_out(struct sk_buff **skb_p,
+					int (*okfn)(struct sk_buff *));
+
+
+/*
+ *     ip_vs_conn handling functions
+ *     (from ip_vs_conn.c)
+ */
+
+/*
+ *     IPVS connection entry hash table
+ */
+#ifndef CONFIG_IP_VS_TAB_BITS
+#define CONFIG_IP_VS_TAB_BITS   12
+#endif
+/* make sure that IP_VS_CONN_TAB_BITS is located in [8, 20] */
+#if CONFIG_IP_VS_TAB_BITS < 8
+#define IP_VS_CONN_TAB_BITS	8
+#endif
+#if CONFIG_IP_VS_TAB_BITS > 20
+#define IP_VS_CONN_TAB_BITS	20
+#endif
+#if 8 <= CONFIG_IP_VS_TAB_BITS && CONFIG_IP_VS_TAB_BITS <= 20
+#define IP_VS_CONN_TAB_BITS	CONFIG_IP_VS_TAB_BITS
+#endif
+#define IP_VS_CONN_TAB_SIZE     (1 << IP_VS_CONN_TAB_BITS)
+#define IP_VS_CONN_TAB_MASK     (IP_VS_CONN_TAB_SIZE - 1)
+
+#define VS_STATE_INPUT	        0
+#define VS_STATE_OUTPUT	        4
+#define VS_STATE_INPUT_ONLY	8
+
+extern struct ip_vs_timeout_table vs_timeout_table;
+extern struct ip_vs_timeout_table vs_timeout_table_dos;
+
+extern struct ip_vs_conn *ip_vs_conn_in_get
+(int protocol, __u32 s_addr, __u16 s_port, __u32 d_addr, __u16 d_port);
+extern struct ip_vs_conn *ip_vs_conn_out_get
+(int protocol, __u32 s_addr, __u16 s_port, __u32 d_addr, __u16 d_port);
+
+/* put back the conn without restarting its timer */
+static inline void __ip_vs_conn_put(struct ip_vs_conn *cp)
+{
+	atomic_dec(&cp->refcnt);
+}
+extern void ip_vs_conn_put(struct ip_vs_conn *cp);
+
+extern struct ip_vs_conn *
+ip_vs_conn_new(int proto, __u32 caddr, __u16 cport, __u32 vaddr, __u16 vport,
+	       __u32 daddr, __u16 dport, unsigned flags,
+	       struct ip_vs_dest *dest);
+extern void ip_vs_conn_expire_now(struct ip_vs_conn *cp);
+
+extern const char * ip_vs_state_name(int state);
+extern int ip_vs_set_state(struct ip_vs_conn *cp, int state_off,
+			   struct iphdr *iph, void *tp);
+extern int ip_vs_conn_listen(struct ip_vs_conn *cp);
+extern int ip_vs_check_template(struct ip_vs_conn *ct);
+extern void ip_vs_secure_tcp_set(int on);
+extern void ip_vs_random_dropentry(void);
+extern int ip_vs_conn_init(void);
+extern void ip_vs_conn_cleanup(void);
+
+static inline void ip_vs_control_del(struct ip_vs_conn *cp)
+{
+	struct ip_vs_conn *ctl_cp = cp->control;
+	if (!ctl_cp) {
+		IP_VS_ERR("request control DEL for uncontrolled: "
+			  "%d.%d.%d.%d:%d to %d.%d.%d.%d:%d\n",
+			  NIPQUAD(cp->caddr),ntohs(cp->cport),
+			  NIPQUAD(cp->vaddr),ntohs(cp->vport));
+		return;
+	}
+
+	IP_VS_DBG(7, "DELeting control for: "
+		  "cp.dst=%d.%d.%d.%d:%d ctl_cp.dst=%d.%d.%d.%d:%d\n",
+		  NIPQUAD(cp->caddr),ntohs(cp->cport),
+		  NIPQUAD(ctl_cp->caddr),ntohs(ctl_cp->cport));
+
+	cp->control = NULL;
+	if (atomic_read(&ctl_cp->n_control) == 0) {
+		IP_VS_ERR("BUG control DEL with n=0 : "
+			  "%d.%d.%d.%d:%d to %d.%d.%d.%d:%d\n",
+			  NIPQUAD(cp->caddr),ntohs(cp->cport),
+			  NIPQUAD(cp->vaddr),ntohs(cp->vport));
+		return;
+	}
+	atomic_dec(&ctl_cp->n_control);
+}
+
+static inline void
+ip_vs_control_add(struct ip_vs_conn *cp, struct ip_vs_conn *ctl_cp)
+{
+	if (cp->control) {
+		IP_VS_ERR("request control ADD for already controlled: "
+			  "%d.%d.%d.%d:%d to %d.%d.%d.%d:%d\n",
+			  NIPQUAD(cp->caddr),ntohs(cp->cport),
+			  NIPQUAD(cp->vaddr),ntohs(cp->vport));
+		ip_vs_control_del(cp);
+	}
+
+	IP_VS_DBG(7, "ADDing control for: "
+		  "cp.dst=%d.%d.%d.%d:%d ctl_cp.dst=%d.%d.%d.%d:%d\n",
+		  NIPQUAD(cp->caddr),ntohs(cp->cport),
+		  NIPQUAD(ctl_cp->caddr),ntohs(ctl_cp->cport));
+
+	cp->control = ctl_cp;
+	atomic_inc(&ctl_cp->n_control);
+}
+
+
+/*
+ *      IPVS application functions
+ *      (from ip_vs_app.c)
+ */
+#define IP_VS_APP_MAX_PORTS  8
+extern int register_ip_vs_app(struct ip_vs_app *mapp,
+			      unsigned short proto, __u16 port);
+extern int unregister_ip_vs_app(struct ip_vs_app *mapp);
+extern struct ip_vs_app * ip_vs_bind_app(struct ip_vs_conn *cp);
+extern int ip_vs_unbind_app(struct ip_vs_conn *cp);
+extern int ip_vs_app_pkt_out(struct ip_vs_conn *, struct sk_buff *skb);
+extern int ip_vs_app_pkt_in(struct ip_vs_conn *, struct sk_buff *skb);
+extern int ip_vs_skb_replace(struct sk_buff *skb, int pri,
+			     char *o_buf, int o_len, char *n_buf, int n_len);
+extern int ip_vs_app_init(void);
+extern void ip_vs_app_cleanup(void);
+
+
+/*
+ *      Registering/unregistering scheduler functions
+ *      (from ip_vs_sched.c)
+ */
+extern int register_ip_vs_scheduler(struct ip_vs_scheduler *scheduler);
+extern int unregister_ip_vs_scheduler(struct ip_vs_scheduler *scheduler);
+extern int ip_vs_bind_scheduler(struct ip_vs_service *svc,
+				struct ip_vs_scheduler *scheduler);
+extern int ip_vs_unbind_scheduler(struct ip_vs_service *svc);
+extern struct ip_vs_scheduler *ip_vs_scheduler_get(const char *sched_name);
+extern void ip_vs_scheduler_put(struct ip_vs_scheduler *scheduler);
+
+
+/*
+ *      IPVS control data and functions
+ *      (from ip_vs_ctl.c)
+ */
+extern int sysctl_ip_vs_cache_bypass;
+extern int sysctl_ip_vs_expire_nodest_conn;
+extern int sysctl_ip_vs_sync_threshold;
+extern int sysctl_ip_vs_nat_icmp_send;
+extern struct ip_vs_stats ip_vs_stats;
+
+extern struct ip_vs_service *ip_vs_service_get(__u32 fwmark,
+					       __u16 protocol,
+					       __u32 vaddr, __u16 vport);
+static inline void ip_vs_service_put(struct ip_vs_service *svc)
+{
+	atomic_dec(&svc->usecnt);
+}
+
+extern struct ip_vs_dest *
+ip_vs_lookup_real_service(__u16 protocol, __u32 daddr, __u16 dport);
+extern void ip_vs_random_dropentry(void);
+extern int ip_vs_control_init(void);
+extern void ip_vs_control_cleanup(void);
+
+
+/*
+ *      IPVS sync daemon data and function prototypes
+ *      (from ip_vs_sync.c)
+ */
+extern volatile int ip_vs_sync_state;
+extern char ip_vs_mcast_ifn[IP_VS_IFNAME_MAXLEN];
+extern int start_sync_thread(int state, char *mcast_ifn);
+extern int stop_sync_thread(void);
+extern void ip_vs_sync_conn(struct ip_vs_conn *cp);
+
+
+/*
+ *      IPVS rate estimator prototypes (from ip_vs_est.c)
+ */
+extern int ip_vs_new_estimator(struct ip_vs_stats *stats);
+extern void ip_vs_kill_estimator(struct ip_vs_stats *stats);
+extern void ip_vs_zero_estimator(struct ip_vs_stats *stats);
+
+
+/*
+ *	This is a simple mechanism to ignore packets when
+ *	we are loaded. Just set ip_vs_drop_rate to 'n' and
+ *	we start to drop 1/rate of the packets
+ */
+extern int ip_vs_drop_rate;
+extern int ip_vs_drop_counter;
+
+static __inline__ int ip_vs_todrop(void)
+{
+	if (!ip_vs_drop_rate) return 0;
+	if (--ip_vs_drop_counter > 0) return 0;
+	ip_vs_drop_counter = ip_vs_drop_rate;
+	return 1;
+}
+
+
+/*
+ *      ip_vs_fwd_tag returns the forwarding tag of the connection
+ */
+#define IP_VS_FWD_METHOD(cp)  (cp->flags & IP_VS_CONN_F_FWD_MASK)
+
+extern __inline__ char ip_vs_fwd_tag(struct ip_vs_conn *cp)
+{
+	char fwd;
+
+	switch (IP_VS_FWD_METHOD(cp)) {
+	case IP_VS_CONN_F_MASQ:
+		fwd = 'M'; break;
+	case IP_VS_CONN_F_LOCALNODE:
+		fwd = 'L'; break;
+	case IP_VS_CONN_F_TUNNEL:
+		fwd = 'T'; break;
+	case IP_VS_CONN_F_DROUTE:
+		fwd = 'R'; break;
+	case IP_VS_CONN_F_BYPASS:
+		fwd = 'B'; break;
+	default:
+		fwd = '?'; break;
+	}
+	return fwd;
+}
+
+
+/*
+ *	transport layer header checking
+ */
+extern inline int ip_vs_header_check(struct sk_buff *skb, int proto, int ihl)
+{
+	int len;
+
+	switch (proto) {
+	case IPPROTO_TCP:
+		len = ihl + sizeof(struct tcphdr);
+		/* we don't care about TCP options */
+		break;
+	case IPPROTO_UDP:
+		len = ihl + sizeof(struct udphdr);
+		break;
+	default:
+		len = 0;
+	}
+
+	/* guarantee protocol header available in skb data area */
+	if (!pskb_may_pull(skb, len))
+		return -1;
+	else
+		return 0;
+}
+
+
+/*
+ *      Destination cache
+ */
+static inline void
+__ip_vs_dst_set(struct ip_vs_dest *dest, u32 rtos, struct dst_entry *dst)
+{
+	struct dst_entry *old_dst;
+
+	old_dst = dest->dst_cache;
+	dest->dst_cache = dst;
+	dest->dst_rtos = rtos;
+	dst_release(old_dst);
+}
+
+static inline void
+__ip_vs_dst_reset(struct ip_vs_dest *dest)
+{
+	struct dst_entry *old_dst;
+
+	old_dst = dest->dst_cache;
+	dest->dst_cache = NULL;
+	dst_release(old_dst);
+}
+
+static inline struct dst_entry *
+__ip_vs_dst_check(struct ip_vs_dest *dest, u32 rtos, u32 cookie)
+{
+	struct dst_entry *dst = dest->dst_cache;
+
+	if (!dst)
+		return NULL;
+	if ((dst->obsolete || rtos != dest->dst_rtos) &&
+	    dst->ops->check(dst, cookie) == NULL) {
+		dest->dst_cache = 0;
+		return NULL;
+	}
+	dst_hold(dst);
+	return dst;
+}
+
+static inline struct rtable *
+__ip_vs_get_out_rt(struct ip_vs_conn *cp, u32 rtos)
+{
+	struct rtable *rt;			/* Route to the other host */
+	struct ip_vs_dest *dest = cp->dest;
+
+	if (dest) {
+		spin_lock(&dest->dst_lock);
+		if (!(rt = (struct rtable *)
+		      __ip_vs_dst_check(dest, rtos, 0))) {
+			if (ip_route_output(&rt, dest->addr, 0, rtos, 0)) {
+				spin_unlock(&dest->dst_lock);
+				IP_VS_DBG_RL("ip_route_output error, "
+					     "dest: %u.%u.%u.%u\n",
+					     NIPQUAD(dest->addr));
+				return NULL;
+			}
+			__ip_vs_dst_set(dest, rtos, dst_clone(&rt->u.dst));
+			IP_VS_DBG(10, "new dst %u.%u.%u.%u, refcnt=%d, rtos=%X\n",
+				  NIPQUAD(dest->addr),
+				  atomic_read(&rt->u.dst.__refcnt), rtos);
+		}
+		spin_unlock(&dest->dst_lock);
+	} else {
+		if (ip_route_output(&rt, cp->daddr, 0, rtos, 0)) {
+			IP_VS_DBG_RL("ip_route_output error, dest: "
+				     "%u.%u.%u.%u\n", NIPQUAD(cp->daddr));
+			return NULL;
+		}
+	}
+
+	return rt;
+}
+
+static inline u16 ip_vs_check_diff(u32 old, u32 new, u16 oldsum)
+{
+	u32 diff[2] = { old, new };
+
+	return csum_fold(csum_partial((char *) diff, sizeof(diff),
+				      oldsum ^ 0xFFFF));
+}
+
+static inline void ip_vs_fast_check_update(union ip_vs_tphdr *h,
+	u32 oldip, u32 newip, u16 oldport, u16 newport, u8 protocol)
+{
+	u16 *checkp;
+
+	if (protocol == IPPROTO_TCP)
+		checkp = &h->th->check;
+	else
+		checkp = &h->uh->check;
+	*checkp = ip_vs_check_diff(~oldip, newip,
+				   ip_vs_check_diff(oldport ^ 0xFFFF,
+						    newport, *checkp));
+	if (!*checkp && protocol == IPPROTO_UDP)
+		*checkp = 0xFFFF;
+}
+
+static inline int
+ip_vs_skb_cow(struct sk_buff *skb, unsigned int headroom,
+	      struct iphdr **iph_p, unsigned char **t_p)
+{
+	int delta = (headroom > 16 ? headroom : 16) - skb_headroom(skb);
+
+	if (delta < 0)
+		delta = 0;
+
+	if (delta || skb_cloned(skb)) {
+		if (pskb_expand_head(skb, (delta+15)&~15, 0, GFP_ATOMIC))
+			return -ENOMEM;
+
+		/* skb data changed, update pointers */
+		*iph_p = skb->nh.iph;
+		*t_p = (char*) (*iph_p) + (*iph_p)->ihl * 4;
+	}
+	return 0;
+}
+
+#endif /* __KERNEL__ */
+
+#endif	/* _IP_VS_H */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/net/neighbour.h linux-2.4.23-pre1/include/net/neighbour.h
--- linux-2.4.22/include/net/neighbour.h	2001-11-22 19:47:11.000000000 +0000
+++ linux-2.4.23-pre1/include/net/neighbour.h	2003-08-27 14:41:50.000000000 +0000
@@ -180,6 +180,7 @@
 extern void			neigh_destroy(struct neighbour *neigh);
 extern int			__neigh_event_send(struct neighbour *neigh, struct sk_buff *skb);
 extern int			neigh_update(struct neighbour *neigh, const u8 *lladdr, u8 new, int override, int arp);
+extern void			neigh_changeaddr(struct neigh_table *tbl, struct net_device *dev);
 extern int			neigh_ifdown(struct neigh_table *tbl, struct net_device *dev);
 extern int			neigh_resolve_output(struct sk_buff *skb);
 extern int			neigh_connected_output(struct sk_buff *skb);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/include/net/pkt_sched.h linux-2.4.23-pre1/include/net/pkt_sched.h
--- linux-2.4.22/include/net/pkt_sched.h	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/include/net/pkt_sched.h	2003-08-27 14:39:41.000000000 +0000
@@ -212,12 +212,16 @@
 
 #if PSCHED_CLOCK_SOURCE == PSCHED_JIFFIES
 
-#if HZ == 100
+#if HZ < 96
+#define PSCHED_JSCALE 14
+#elif HZ >= 96 && HZ < 192
 #define PSCHED_JSCALE 13
-#elif HZ == 1024
+#elif HZ >= 192 && HZ < 384
+#define PSCHED_JSCALE 12
+#elif HZ >= 384 && HZ < 768
+#define PSCHED_JSCALE 11
+#elif HZ >= 768
 #define PSCHED_JSCALE 10
-#else
-#define PSCHED_JSCALE 0
 #endif
 
 #define PSCHED_EXPORTLIST_2
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/init/do_mounts.c linux-2.4.23-pre1/init/do_mounts.c
--- linux-2.4.22/init/do_mounts.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/init/do_mounts.c	2003-08-27 14:41:33.000000000 +0000
@@ -360,6 +360,7 @@
 				flags |= MS_RDONLY;
 				goto retry;
 			case -EINVAL:
+		        case -EBUSY:
 				continue;
 		}
 	        /*
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/kernel/fork.c linux-2.4.23-pre1/kernel/fork.c
--- linux-2.4.22/kernel/fork.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/kernel/fork.c	2003-08-27 14:39:25.000000000 +0000
@@ -266,6 +266,7 @@
 {
 	BUG_ON(mm == &init_mm);
 	pgd_free(mm->pgd);
+	check_pgt_cache();
 	destroy_context(mm);
 	free_mm(mm);
 }
@@ -746,7 +747,8 @@
 		goto bad_fork_cleanup_fs;
 	if (copy_mm(clone_flags, p))
 		goto bad_fork_cleanup_sighand;
-	if (copy_namespace(clone_flags, p))
+	retval = copy_namespace(clone_flags, p);
+	if (retval)
 		goto bad_fork_cleanup_mm;
 	retval = copy_thread(0, clone_flags, stack_start, stack_size, p, regs);
 	if (retval)
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/kernel/panic.c linux-2.4.23-pre1/kernel/panic.c
--- linux-2.4.22/kernel/panic.c	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/kernel/panic.c	2003-08-27 14:41:46.000000000 +0000
@@ -31,6 +31,8 @@
 
 __setup("panic=", panic_setup);
 
+int machine_paniced; 
+
 /**
  *	panic - halt the system
  *	@fmt: The text string to print
@@ -49,6 +51,11 @@
         unsigned long caller = (unsigned long) __builtin_return_address(0);
 #endif
 
+#ifdef CONFIG_VT
+	disable_console_blank();
+#endif
+	machine_paniced = 1;
+	
 	bust_spinlocks(1);
 	va_start(args, fmt);
 	vsprintf(buf, fmt, args);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/kernel/printk.c linux-2.4.23-pre1/kernel/printk.c
--- linux-2.4.22/kernel/printk.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/kernel/printk.c	2003-08-27 14:41:57.000000000 +0000
@@ -29,6 +29,7 @@
 
 #include <asm/uaccess.h>
 
+#if !defined(CONFIG_LOG_BUF_SHIFT) || (CONFIG_LOG_BUF_SHIFT - 0 == 0)
 #if defined(CONFIG_MULTIQUAD) || defined(CONFIG_IA64)
 #define LOG_BUF_LEN	(65536)
 #elif defined(CONFIG_ARCH_S390)
@@ -38,6 +39,9 @@
 #else	
 #define LOG_BUF_LEN	(16384)			/* This must be a power of two */
 #endif
+#else /* CONFIG_LOG_BUF_SHIFT */
+#define LOG_BUF_LEN (1 << CONFIG_LOG_BUF_SHIFT)
+#endif
 
 #define LOG_BUF_MASK	(LOG_BUF_LEN-1)
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/mm/memory.c linux-2.4.23-pre1/mm/memory.c
--- linux-2.4.22/mm/memory.c	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/mm/memory.c	2003-08-27 14:40:26.000000000 +0000
@@ -1414,6 +1414,7 @@
 		 */
 		if (!pgd_none(*pgd)) {
 			pmd_free(new);
+			check_pgt_cache();
 			goto out;
 		}
 	}
@@ -1448,6 +1449,7 @@
 			 */
 			if (!pmd_none(*pmd)) {
 				pte_free(new);
+				check_pgt_cache();
 				goto out;
 			}
 		}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/mm/slab.c linux-2.4.23-pre1/mm/slab.c
--- linux-2.4.22/mm/slab.c	2003-06-13 14:51:39.000000000 +0000
+++ linux-2.4.23-pre1/mm/slab.c	2003-08-27 14:41:22.000000000 +0000
@@ -1784,8 +1784,9 @@
 		full_free = 0;
 		p = searchp->slabs_free.next;
 		while (p != &searchp->slabs_free) {
-			slabp = list_entry(p, slab_t, list);
 #if DEBUG
+			slabp = list_entry(p, slab_t, list);
+
 			if (slabp->inuse)
 				BUG();
 #endif
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/8021q/vlan.c linux-2.4.23-pre1/net/8021q/vlan.c
--- linux-2.4.22/net/8021q/vlan.c	2003-06-13 14:51:39.000000000 +0000
+++ linux-2.4.23-pre1/net/8021q/vlan.c	2003-08-27 14:41:24.000000000 +0000
@@ -533,7 +533,9 @@
 	    
 	grp->vlan_devices[VLAN_ID] = new_dev;
 
-	vlan_proc_add_dev(new_dev); /* create it's proc entry */
+	if (vlan_proc_add_dev(new_dev)<0)/* create it's proc entry */
+            	printk(KERN_WARNING "VLAN: failed to add proc entry for %s\n",
+					                 new_dev->name);
 
 	if (real_dev->features & NETIF_F_HW_VLAN_FILTER)
 		real_dev->vlan_rx_add_vid(real_dev, VLAN_ID);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/8021q/vlan_dev.c linux-2.4.23-pre1/net/8021q/vlan_dev.c
--- linux-2.4.22/net/8021q/vlan_dev.c	2003-06-13 14:51:39.000000000 +0000
+++ linux-2.4.23-pre1/net/8021q/vlan_dev.c	2003-08-27 14:41:39.000000000 +0000
@@ -171,7 +171,7 @@
 
 #ifdef VLAN_DEBUG
 		printk(VLAN_DBG "%s: dropping skb: %p because came in on wrong device, dev: %s  real_dev: %s, skb_dev: %s\n",
-			__FUNCTION__ skb, dev->name, 
+			__FUNCTION__, skb, dev->name, 
 			VLAN_DEV_INFO(skb->dev)->real_dev->name, 
 			skb->dev->name);
 #endif
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/8021q/vlanproc.c linux-2.4.23-pre1/net/8021q/vlanproc.c
--- linux-2.4.22/net/8021q/vlanproc.c	2003-06-13 14:51:39.000000000 +0000
+++ linux-2.4.23-pre1/net/8021q/vlanproc.c	2003-08-27 14:40:04.000000000 +0000
@@ -204,8 +204,10 @@
 #endif
 
 	/** NOTE:  This will consume the memory pointed to by dent, it seems. */
-	remove_proc_entry(VLAN_DEV_INFO(vlandev)->dent->name, proc_vlan_dir);
-	VLAN_DEV_INFO(vlandev)->dent = NULL;
+	if (VLAN_DEV_INFO(vlandev)->dent) {
+		remove_proc_entry(VLAN_DEV_INFO(vlandev)->dent->name, proc_vlan_dir);
+		VLAN_DEV_INFO(vlandev)->dent = NULL;
+	}
 
 	return 0;
 }
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/Makefile linux-2.4.23-pre1/net/Makefile
--- linux-2.4.22/net/Makefile	2002-08-03 00:39:46.000000000 +0000
+++ linux-2.4.23-pre1/net/Makefile	2003-08-27 14:40:23.000000000 +0000
@@ -46,6 +46,10 @@
 subdir-$(CONFIG_ECONET)		+= econet
 subdir-$(CONFIG_VLAN_8021Q)           += 8021q
 
+ifeq ($(CONFIG_NETFILTER),y)
+  mod-subdirs += ipv4/ipvs
+  subdir-$(CONFIG_IP_VS) += ipv4/ipvs
+endif
 
 obj-y	:= socket.o $(join $(subdir-y), $(patsubst %,/%.o,$(notdir $(subdir-y))))
 ifeq ($(CONFIG_NET),y)
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/atm/common.c linux-2.4.23-pre1/net/atm/common.c
--- linux-2.4.22/net/atm/common.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/atm/common.c	2003-08-27 14:42:05.000000000 +0000
@@ -84,7 +84,7 @@
 
 #ifdef CONFIG_ATM_CLIP_MODULE
 EXPORT_SYMBOL(atm_clip_ops);
-EXPORT_SYMBOL(atm_clip_ops_mutex);
+EXPORT_SYMBOL(try_atm_clip_ops);
 EXPORT_SYMBOL(atm_clip_ops_set);
 #endif
 #endif
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/core/Makefile linux-2.4.23-pre1/net/core/Makefile
--- linux-2.4.22/net/core/Makefile	2002-08-03 00:39:46.000000000 +0000
+++ linux-2.4.23-pre1/net/core/Makefile	2003-08-27 14:41:44.000000000 +0000
@@ -21,7 +21,8 @@
 
 obj-$(CONFIG_FILTER) += filter.o
 
-obj-$(CONFIG_NET) += dev.o dev_mcast.o dst.o neighbour.o rtnetlink.o utils.o
+obj-$(CONFIG_NET) +=	dev.o ethtool.o dev_mcast.o dst.o neighbour.o \
+			rtnetlink.o utils.o
 
 obj-$(CONFIG_NETFILTER) += netfilter.o
 obj-$(CONFIG_NET_DIVERT) += dv.o
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/core/dev.c linux-2.4.23-pre1/net/core/dev.c
--- linux-2.4.22/net/core/dev.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/core/dev.c	2003-08-27 14:40:33.000000000 +0000
@@ -1588,6 +1588,7 @@
 	*budget -= work;
 
 	list_del(&blog_dev->poll_list);
+	smp_mb__before_clear_bit();
 	clear_bit(__LINK_STATE_RX_SCHED, &blog_dev->state);
 
 	if (queue->throttle) {
@@ -2198,7 +2199,6 @@
 			    cmd == SIOCBONDSLAVEINFOQUERY ||
 			    cmd == SIOCBONDINFOQUERY ||
 			    cmd == SIOCBONDCHANGEACTIVE ||
-			    cmd == SIOCETHTOOL ||
 			    cmd == SIOCGMIIPHY ||
 			    cmd == SIOCGMIIREG ||
 			    cmd == SIOCSMIIREG ||
@@ -2294,6 +2294,20 @@
 			}
 			return ret;
 
+		case SIOCETHTOOL:
+			dev_load(ifr.ifr_name);
+			rtnl_lock();
+			ret = dev_ethtool(&ifr);
+			rtnl_unlock();
+			if (!ret) {
+				if (colon)
+					*colon = ':';
+				if (copy_to_user(arg, &ifr,
+						 sizeof(struct ifreq)))
+					ret = -EFAULT;
+			}
+			return ret;
+
 		/*
 		 *	These ioctl calls:
 		 *	- require superuser power.
@@ -2301,7 +2315,6 @@
 		 *	- return a value
 		 */
 		 
-		case SIOCETHTOOL:
 		case SIOCGMIIPHY:
 		case SIOCGMIIREG:
 			if (!capable(CAP_NET_ADMIN))
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/core/ethtool.c linux-2.4.23-pre1/net/core/ethtool.c
--- linux-2.4.22/net/core/ethtool.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/core/ethtool.c	2003-08-27 14:39:11.000000000 +0000
@@ -0,0 +1,673 @@
+/*
+ * net/core/ethtool.c - Ethtool ioctl handler
+ * Copyright (c) 2003 Matthew Wilcox <matthew@wil.cx>
+ *
+ * This file is where we call all the ethtool_ops commands to get
+ * the information ethtool needs.  We fall back to calling do_ioctl()
+ * for drivers which haven't been converted to ethtool_ops yet.
+ *
+ * It's GPL, stupid.
+ */
+
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/ethtool.h>
+#include <linux/netdevice.h>
+#include <asm/uaccess.h>
+
+/* 
+ * Some useful ethtool_ops methods that're device independent.
+ * If we find that all drivers want to do the same thing here,
+ * we can turn these into dev_() function calls.
+ */
+
+u32 ethtool_op_get_link(struct net_device *dev)
+{
+	return netif_carrier_ok(dev) ? 1 : 0;
+}
+
+u32 ethtool_op_get_tx_csum(struct net_device *dev)
+{
+	return (dev->features & NETIF_F_IP_CSUM) != 0;
+}
+
+u32 ethtool_op_get_sg(struct net_device *dev)
+{
+	return (dev->features & NETIF_F_SG) != 0;
+}
+
+int ethtool_op_set_sg(struct net_device *dev, u32 data)
+{
+	if (data)
+		dev->features |= NETIF_F_SG;
+	else
+		dev->features &= ~NETIF_F_SG;
+
+	return 0;
+}
+
+/* Handlers for each ethtool command */
+
+static int ethtool_get_settings(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_cmd cmd = { ETHTOOL_GSET };
+	int err;
+
+	if (!dev->ethtool_ops->get_settings)
+		return -EOPNOTSUPP;
+
+	err = dev->ethtool_ops->get_settings(dev, &cmd);
+	if (err < 0)
+		return err;
+
+	if (copy_to_user(useraddr, &cmd, sizeof(cmd)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_set_settings(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_cmd cmd;
+
+	if (!dev->ethtool_ops->set_settings)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&cmd, useraddr, sizeof(cmd)))
+		return -EFAULT;
+
+	return dev->ethtool_ops->set_settings(dev, &cmd);
+}
+
+static int ethtool_get_drvinfo(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_drvinfo info;
+	struct ethtool_ops *ops = dev->ethtool_ops;
+
+	if (!ops->get_drvinfo)
+		return -EOPNOTSUPP;
+
+	memset(&info, 0, sizeof(info));
+	info.cmd = ETHTOOL_GDRVINFO;
+	ops->get_drvinfo(dev, &info);
+
+	if (ops->self_test_count)
+		info.testinfo_len = ops->self_test_count(dev);
+	if (ops->get_stats_count)
+		info.n_stats = ops->get_stats_count(dev);
+	if (ops->get_regs_len)
+		info.regdump_len = ops->get_regs_len(dev);
+	/* XXX: eeprom? */
+
+	if (copy_to_user(useraddr, &info, sizeof(info)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_get_regs(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_regs regs;
+	struct ethtool_ops *ops = dev->ethtool_ops;
+	void *regbuf;
+	int reglen, ret;
+
+	if (!ops->get_regs || !ops->get_regs_len)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&regs, useraddr, sizeof(regs)))
+		return -EFAULT;
+
+	reglen = ops->get_regs_len(dev);
+	if (regs.len > reglen)
+		regs.len = reglen;
+
+	regbuf = kmalloc(reglen, GFP_USER);
+	if (!regbuf)
+		return -ENOMEM;
+
+	ops->get_regs(dev, &regs, regbuf);
+
+	ret = -EFAULT;
+	if (copy_to_user(useraddr, &regs, sizeof(regs)))
+		goto out;
+	useraddr += offsetof(struct ethtool_regs, data);
+	if (copy_to_user(useraddr, regbuf, reglen))
+		goto out;
+	ret = 0;
+
+ out:
+	kfree(regbuf);
+	return ret;
+}
+
+static int ethtool_get_wol(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_wolinfo wol = { ETHTOOL_GWOL };
+
+	if (!dev->ethtool_ops->get_wol)
+		return -EOPNOTSUPP;
+
+	dev->ethtool_ops->get_wol(dev, &wol);
+
+	if (copy_to_user(useraddr, &wol, sizeof(wol)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_set_wol(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_wolinfo wol;
+
+	if (!dev->ethtool_ops->set_wol)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&wol, useraddr, sizeof(wol)))
+		return -EFAULT;
+
+	return dev->ethtool_ops->set_wol(dev, &wol);
+}
+
+static int ethtool_get_msglevel(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_value edata = { ETHTOOL_GMSGLVL };
+
+	if (!dev->ethtool_ops->get_msglevel)
+		return -EOPNOTSUPP;
+
+	edata.data = dev->ethtool_ops->get_msglevel(dev);
+
+	if (copy_to_user(useraddr, &edata, sizeof(edata)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_set_msglevel(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_value edata;
+
+	if (!dev->ethtool_ops->set_msglevel)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&edata, useraddr, sizeof(edata)))
+		return -EFAULT;
+
+	dev->ethtool_ops->set_msglevel(dev, edata.data);
+	return 0;
+}
+
+static int ethtool_nway_reset(struct net_device *dev)
+{
+	if (!dev->ethtool_ops->nway_reset)
+		return -EOPNOTSUPP;
+
+	return dev->ethtool_ops->nway_reset(dev);
+}
+
+static int ethtool_get_link(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_value edata = { ETHTOOL_GLINK };
+
+	if (!dev->ethtool_ops->get_link)
+		return -EOPNOTSUPP;
+
+	edata.data = dev->ethtool_ops->get_link(dev);
+
+	if (copy_to_user(useraddr, &edata, sizeof(edata)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_get_eeprom(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_eeprom eeprom;
+	u8 *data;
+	int len, ret;
+
+	if (!dev->ethtool_ops->get_eeprom)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&eeprom, useraddr, sizeof(eeprom)))
+		return -EFAULT;
+
+	len = eeprom.len;
+	/* Check for wrap and zero */
+	if (eeprom.offset + len <= eeprom.offset)
+		return -EINVAL;
+
+	data = kmalloc(len, GFP_USER);
+	if (!data)
+		return -ENOMEM;
+
+	if (copy_from_user(data, useraddr + sizeof(eeprom), len))
+		return -EFAULT;
+
+	ret = dev->ethtool_ops->get_eeprom(dev, &eeprom, data);
+	if (!ret)
+		goto out;
+
+	ret = -EFAULT;
+	if (copy_to_user(useraddr, &eeprom, sizeof(eeprom)))
+		goto out;
+	if (copy_to_user(useraddr + sizeof(eeprom), data, eeprom.len))
+		goto out;
+	ret = 0;
+
+ out:
+	kfree(data);
+	return ret;
+}
+
+static int ethtool_set_eeprom(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_eeprom eeprom;
+	u8 *data;
+	int len, ret;
+
+	if (!dev->ethtool_ops->set_eeprom)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&eeprom, useraddr, sizeof(eeprom)))
+		return -EFAULT;
+
+	len = eeprom.len;
+	/* Check for wrap and zero */
+	if (eeprom.offset + len <= eeprom.offset)
+		return -EINVAL;
+
+	data = kmalloc(len, GFP_USER);
+	if (!data)
+		return -ENOMEM;
+
+	if (copy_from_user(data, useraddr + sizeof(eeprom), len))
+		return -EFAULT;
+
+	ret = dev->ethtool_ops->set_eeprom(dev, &eeprom, data);
+	if (ret)
+		goto out;
+
+	if (copy_to_user(useraddr + sizeof(eeprom), data, len))
+		ret = -EFAULT;
+
+ out:
+	kfree(data);
+	return ret;
+}
+
+static int ethtool_get_coalesce(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_coalesce coalesce = { ETHTOOL_GCOALESCE };
+
+	if (!dev->ethtool_ops->get_coalesce)
+		return -EOPNOTSUPP;
+
+	dev->ethtool_ops->get_coalesce(dev, &coalesce);
+
+	if (copy_to_user(useraddr, &coalesce, sizeof(coalesce)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_set_coalesce(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_coalesce coalesce;
+
+	if (!dev->ethtool_ops->get_coalesce)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&coalesce, useraddr, sizeof(coalesce)))
+		return -EFAULT;
+
+	return dev->ethtool_ops->set_coalesce(dev, &coalesce);
+}
+
+static int ethtool_get_ringparam(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_ringparam ringparam = { ETHTOOL_GRINGPARAM };
+
+	if (!dev->ethtool_ops->get_ringparam)
+		return -EOPNOTSUPP;
+
+	dev->ethtool_ops->get_ringparam(dev, &ringparam);
+
+	if (copy_to_user(useraddr, &ringparam, sizeof(ringparam)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_set_ringparam(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_ringparam ringparam;
+
+	if (!dev->ethtool_ops->get_ringparam)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&ringparam, useraddr, sizeof(ringparam)))
+		return -EFAULT;
+
+	return dev->ethtool_ops->set_ringparam(dev, &ringparam);
+}
+
+static int ethtool_get_pauseparam(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_pauseparam pauseparam = { ETHTOOL_GPAUSEPARAM };
+
+	if (!dev->ethtool_ops->get_pauseparam)
+		return -EOPNOTSUPP;
+
+	dev->ethtool_ops->get_pauseparam(dev, &pauseparam);
+
+	if (copy_to_user(useraddr, &pauseparam, sizeof(pauseparam)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_set_pauseparam(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_pauseparam pauseparam;
+
+	if (!dev->ethtool_ops->get_pauseparam)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&pauseparam, useraddr, sizeof(pauseparam)))
+		return -EFAULT;
+
+	return dev->ethtool_ops->set_pauseparam(dev, &pauseparam);
+}
+
+static int ethtool_get_rx_csum(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_value edata = { ETHTOOL_GRXCSUM };
+
+	if (!dev->ethtool_ops->get_rx_csum)
+		return -EOPNOTSUPP;
+
+	edata.data = dev->ethtool_ops->get_rx_csum(dev);
+
+	if (copy_to_user(useraddr, &edata, sizeof(edata)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_set_rx_csum(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_value edata;
+
+	if (!dev->ethtool_ops->set_rx_csum)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&edata, useraddr, sizeof(edata)))
+		return -EFAULT;
+
+	dev->ethtool_ops->set_rx_csum(dev, edata.data);
+	return 0;
+}
+
+static int ethtool_get_tx_csum(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_value edata = { ETHTOOL_GTXCSUM };
+
+	if (!dev->ethtool_ops->get_tx_csum)
+		return -EOPNOTSUPP;
+
+	edata.data = dev->ethtool_ops->get_tx_csum(dev);
+
+	if (copy_to_user(useraddr, &edata, sizeof(edata)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_set_tx_csum(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_value edata;
+
+	if (!dev->ethtool_ops->set_tx_csum)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&edata, useraddr, sizeof(edata)))
+		return -EFAULT;
+
+	return dev->ethtool_ops->set_tx_csum(dev, edata.data);
+}
+
+static int ethtool_get_sg(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_value edata = { ETHTOOL_GSG };
+
+	if (!dev->ethtool_ops->get_sg)
+		return -EOPNOTSUPP;
+
+	edata.data = dev->ethtool_ops->get_sg(dev);
+
+	if (copy_to_user(useraddr, &edata, sizeof(edata)))
+		return -EFAULT;
+	return 0;
+}
+
+static int ethtool_set_sg(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_value edata;
+
+	if (!dev->ethtool_ops->set_sg)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&edata, useraddr, sizeof(edata)))
+		return -EFAULT;
+
+	return dev->ethtool_ops->set_sg(dev, edata.data);
+}
+
+static int ethtool_self_test(struct net_device *dev, char *useraddr)
+{
+	struct ethtool_test test;
+	struct ethtool_ops *ops = dev->ethtool_ops;
+	u64 *data;
+	int ret;
+
+	if (!ops->self_test || !ops->self_test_count)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&test, useraddr, sizeof(test)))
+		return -EFAULT;
+
+	test.len = ops->self_test_count(dev);
+	data = kmalloc(test.len * sizeof(u64), GFP_USER);
+	if (!data)
+		return -ENOMEM;
+
+	ops->self_test(dev, &test, data);
+
+	ret = -EFAULT;
+	if (copy_to_user(useraddr, &test, sizeof(test)))
+		goto out;
+	useraddr += sizeof(test);
+	if (copy_to_user(useraddr, data, test.len * sizeof(u64)))
+		goto out;
+	ret = 0;
+
+ out:
+	kfree(data);
+	return ret;
+}
+
+static int ethtool_get_strings(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_gstrings gstrings;
+	struct ethtool_ops *ops = dev->ethtool_ops;
+	u8 *data;
+	int ret;
+
+	if (!ops->get_strings)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&gstrings, useraddr, sizeof(gstrings)))
+		return -EFAULT;
+
+	switch (gstrings.string_set) {
+	case ETH_SS_TEST:
+		if (ops->self_test_count)
+			gstrings.len = ops->self_test_count(dev);
+		else
+			return -EOPNOTSUPP;
+	case ETH_SS_STATS:
+		if (ops->get_stats_count)
+			gstrings.len = ops->get_stats_count(dev);
+		else
+			return -EOPNOTSUPP;
+	default:
+		return -EINVAL;
+	}
+
+	data = kmalloc(gstrings.len * ETH_GSTRING_LEN, GFP_USER);
+	if (!data)
+		return -ENOMEM;
+
+	ops->get_strings(dev, gstrings.string_set, data);
+
+	ret = -EFAULT;
+	if (copy_to_user(useraddr, &gstrings, sizeof(gstrings)))
+		goto out;
+	useraddr += sizeof(gstrings);
+	if (copy_to_user(useraddr, data, gstrings.len * ETH_GSTRING_LEN))
+		goto out;
+	ret = 0;
+
+ out:
+	kfree(data);
+	return ret;
+}
+
+static int ethtool_phys_id(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_value id;
+
+	if (!dev->ethtool_ops->phys_id)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&id, useraddr, sizeof(id)))
+		return -EFAULT;
+
+	return dev->ethtool_ops->phys_id(dev, id.data);
+}
+
+static int ethtool_get_stats(struct net_device *dev, void *useraddr)
+{
+	struct ethtool_stats stats;
+	struct ethtool_ops *ops = dev->ethtool_ops;
+	u64 *data;
+	int ret;
+
+	if (!ops->get_ethtool_stats || !ops->get_stats_count)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&stats, useraddr, sizeof(stats)))
+		return -EFAULT;
+
+	stats.n_stats = ops->get_stats_count(dev);
+	data = kmalloc(stats.n_stats * sizeof(u64), GFP_USER);
+	if (!data)
+		return -ENOMEM;
+
+	ops->get_ethtool_stats(dev, &stats, data);
+
+	ret = -EFAULT;
+	if (copy_to_user(useraddr, &stats, sizeof(stats)))
+		goto out;
+	useraddr += sizeof(stats);
+	if (copy_to_user(useraddr, data, stats.n_stats * sizeof(u64)))
+		goto out;
+	ret = 0;
+
+ out:
+	kfree(data);
+	return ret;
+}
+
+/* The main entry point in this file.  Called from net/core/dev.c */
+
+int dev_ethtool(struct ifreq *ifr)
+{
+	struct net_device *dev = __dev_get_by_name(ifr->ifr_name);
+	void *useraddr = (void *) ifr->ifr_data;
+	u32 ethcmd;
+
+	/*
+	 * XXX: This can be pushed down into the ethtool_* handlers that
+	 * need it.  Keep existing behaviour for the moment.
+	 */
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!dev || !netif_device_present(dev))
+		return -ENODEV;
+
+	if (!dev->ethtool_ops)
+		goto ioctl;
+
+	if (copy_from_user(&ethcmd, useraddr, sizeof (ethcmd)))
+		return -EFAULT;
+
+	switch (ethcmd) {
+	case ETHTOOL_GSET:
+		return ethtool_get_settings(dev, useraddr);
+	case ETHTOOL_SSET:
+		return ethtool_set_settings(dev, useraddr);
+	case ETHTOOL_GDRVINFO:
+		return ethtool_get_drvinfo(dev, useraddr);
+	case ETHTOOL_GREGS:
+		return ethtool_get_regs(dev, useraddr);
+	case ETHTOOL_GWOL:
+		return ethtool_get_wol(dev, useraddr);
+	case ETHTOOL_SWOL:
+		return ethtool_set_wol(dev, useraddr);
+	case ETHTOOL_GMSGLVL:
+		return ethtool_get_msglevel(dev, useraddr);
+	case ETHTOOL_SMSGLVL:
+		return ethtool_set_msglevel(dev, useraddr);
+	case ETHTOOL_NWAY_RST:
+		return ethtool_nway_reset(dev);
+	case ETHTOOL_GLINK:
+		return ethtool_get_link(dev, useraddr);
+	case ETHTOOL_GEEPROM:
+		return ethtool_get_eeprom(dev, useraddr);
+	case ETHTOOL_SEEPROM:
+		return ethtool_set_eeprom(dev, useraddr);
+	case ETHTOOL_GCOALESCE:
+		return ethtool_get_coalesce(dev, useraddr);
+	case ETHTOOL_SCOALESCE:
+		return ethtool_set_coalesce(dev, useraddr);
+	case ETHTOOL_GRINGPARAM:
+		return ethtool_get_ringparam(dev, useraddr);
+	case ETHTOOL_SRINGPARAM:
+		return ethtool_set_ringparam(dev, useraddr);
+	case ETHTOOL_GPAUSEPARAM:
+		return ethtool_get_pauseparam(dev, useraddr);
+	case ETHTOOL_SPAUSEPARAM:
+		return ethtool_set_pauseparam(dev, useraddr);
+	case ETHTOOL_GRXCSUM:
+		return ethtool_get_rx_csum(dev, useraddr);
+	case ETHTOOL_SRXCSUM:
+		return ethtool_set_rx_csum(dev, useraddr);
+	case ETHTOOL_GTXCSUM:
+		return ethtool_get_tx_csum(dev, useraddr);
+	case ETHTOOL_STXCSUM:
+		return ethtool_set_tx_csum(dev, useraddr);
+	case ETHTOOL_GSG:
+		return ethtool_get_sg(dev, useraddr);
+	case ETHTOOL_SSG:
+		return ethtool_set_sg(dev, useraddr);
+	case ETHTOOL_TEST:
+		return ethtool_self_test(dev, useraddr);
+	case ETHTOOL_GSTRINGS:
+		return ethtool_get_strings(dev, useraddr);
+	case ETHTOOL_PHYS_ID:
+		return ethtool_phys_id(dev, useraddr);
+	case ETHTOOL_GSTATS:
+		return ethtool_get_stats(dev, useraddr);
+	default:
+		return -EOPNOTSUPP;
+	}
+
+ ioctl:
+	if (dev->do_ioctl)
+		return dev->do_ioctl(dev, ifr, SIOCETHTOOL);
+	return -EOPNOTSUPP;
+}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/core/neighbour.c linux-2.4.23-pre1/net/core/neighbour.c
--- linux-2.4.22/net/core/neighbour.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/core/neighbour.c	2003-08-27 14:39:19.000000000 +0000
@@ -50,6 +50,7 @@
 static void neigh_app_notify(struct neighbour *n);
 #endif
 static int pneigh_ifdown(struct neigh_table *tbl, struct net_device *dev);
+void neigh_changeaddr(struct neigh_table *tbl, struct net_device *dev);
 
 static int neigh_glbl_allocs;
 static struct neigh_table *neigh_tables;
@@ -169,6 +170,33 @@
 	}
 }
 
+void neigh_changeaddr(struct neigh_table *tbl, struct net_device *dev)
+{
+	int i;
+
+	write_lock_bh(&tbl->lock);
+
+	for (i=0; i <= NEIGH_HASHMASK; i++) {
+		struct neighbour *n, **np;
+
+		np = &tbl->hash_buckets[i];
+		while ((n = *np) != NULL) {
+			if (dev && n->dev != dev) {
+				np = &n->next;
+				continue;
+			}
+			*np = n->next;
+			write_lock_bh(&n->lock);
+			n->dead = 1;
+			neigh_del_timer(n);
+			write_unlock_bh(&n->lock);
+			neigh_release(n);
+		}
+	}
+
+        write_unlock_bh(&tbl->lock);
+}
+
 int neigh_ifdown(struct neigh_table *tbl, struct net_device *dev)
 {
 	int i;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/core/pktgen.c linux-2.4.23-pre1/net/core/pktgen.c
--- linux-2.4.22/net/core/pktgen.c	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/net/core/pktgen.c	2003-08-27 14:39:26.000000000 +0000
@@ -46,6 +46,9 @@
  * Also moved to /proc/net/pktgen/ 
  * --ro 
  *
+ * Fix refcount off by one if first packet fails, potential null deref, 
+ * memleak 030710- KJP
+ *
  * See Documentation/networking/pktgen.txt for how to use this.
  */
 
@@ -84,9 +87,9 @@
 #define cycles()	((u32)get_cycles())
 
 
-#define VERSION "pktgen version 1.2"
+#define VERSION "pktgen version 1.3"
 static char version[] __initdata = 
-  "pktgen.c: v1.2: Packet Generator for packet performance testing.\n";
+  "pktgen.c: v1.3: Packet Generator for packet performance testing.\n";
 
 /* Used to help with determining the pkts on receive */
 
@@ -613,12 +616,11 @@
                                 kfree_skb(skb);
                                 skb = fill_packet(odev, info);
                                 if (skb == NULL) {
-                                        break;
+					goto out_reldev;
                                 }
                                 fp++;
                                 fp_tmp = 0; /* reset counter */
                         }
-                        atomic_inc(&skb->users);
                 }
 
                 nr_frags = skb_shinfo(skb)->nr_frags;
@@ -626,7 +628,11 @@
 		spin_lock_bh(&odev->xmit_lock);
 		if (!netif_queue_stopped(odev)) {
 
+			atomic_inc(&skb->users);
+
 			if (odev->hard_start_xmit(skb, odev)) {
+
+				atomic_dec(&skb->users);
 				if (net_ratelimit()) {
                                    printk(KERN_INFO "Hard xmit error\n");
                                 }
@@ -731,15 +737,15 @@
 			     (unsigned long long) info->errors
 			     );
 	}
-        
+
+	kfree_skb(skb);
+
 out_reldev:
         if (odev) {
                 dev_put(odev);
                 odev = NULL;
         }
 
-        /* TODO:  Is this worth printing out (other than for debug?) */
-        printk("fp = %llu\n", (unsigned long long) fp);
 	return;
 
 }
@@ -955,7 +961,8 @@
 	if (len < 0)
 		return len;
 	memset(name, 0, sizeof(name));
-	copy_from_user(name, &user_buffer[i], len);
+	if (copy_from_user(name, &user_buffer[i], len))
+		return -EFAULT;
 	i += len;
   
 	max = count -i;
@@ -1085,18 +1092,20 @@
 		if (len < 0)
 			return len;
 		memset(info->outdev, 0, sizeof(info->outdev));
-		copy_from_user(info->outdev, &user_buffer[i], len);
+		if (copy_from_user(info->outdev, &user_buffer[i], len))
+			return -EFAULT;
 		i += len;
 		sprintf(result, "OK: odev=%s", info->outdev);
 		return count;
 	}
 	if (!strcmp(name, "flag")) {
                 char f[32];
-                memset(f, 0, 32);
 		len = strn_len(&user_buffer[i], sizeof(f) - 1);
 		if (len < 0)
 			return len;
-		copy_from_user(f, &user_buffer[i], len);
+                memset(f, 0, 32);
+		if (copy_from_user(f, &user_buffer[i], len))
+			return -EFAULT;
 		i += len;
                 if (strcmp(f, "IPSRC_RND") == 0) {
                         info->flags |= F_IPSRC_RND;
@@ -1148,7 +1157,8 @@
 		if (len < 0)
 			return len;
 		memset(info->dst_min, 0, sizeof(info->dst_min));
-		copy_from_user(info->dst_min, &user_buffer[i], len);
+		if (copy_from_user(info->dst_min, &user_buffer[i], len))
+			return -EFAULT;
 		if(debug)
 			printk("pg: dst_min set to: %s\n", info->dst_min);
 		i += len;
@@ -1160,7 +1170,8 @@
 		if (len < 0)
 			return len;
 		memset(info->dst_max, 0, sizeof(info->dst_max));
-		copy_from_user(info->dst_max, &user_buffer[i], len);
+		if (copy_from_user(info->dst_max, &user_buffer[i], len))
+			return -EFAULT;
 		if(debug)
 			printk("pg: dst_max set to: %s\n", info->dst_max);
 		i += len;
@@ -1172,7 +1183,8 @@
 		if (len < 0)
 			return len;
 		memset(info->src_min, 0, sizeof(info->src_min));
-		copy_from_user(info->src_min, &user_buffer[i], len);
+		if (copy_from_user(info->src_min, &user_buffer[i], len))
+			return -EFAULT;
 		if(debug)
 			printk("pg: src_min set to: %s\n", info->src_min);
 		i += len;
@@ -1184,7 +1196,8 @@
 		if (len < 0)
 			return len;
 		memset(info->src_max, 0, sizeof(info->src_max));
-		copy_from_user(info->src_max, &user_buffer[i], len);
+		if (copy_from_user(info->src_max, &user_buffer[i], len))
+			return -EFAULT;
 		if(debug)
 			printk("pg: src_max set to: %s\n", info->src_max);
 		i += len;
@@ -1199,7 +1212,8 @@
 		if (len < 0)
 			return len;
 		memset(valstr, 0, sizeof(valstr));
-		copy_from_user(valstr, &user_buffer[i], len);
+		if (copy_from_user(valstr, &user_buffer[i], len))
+			return -EFAULT;
 		i += len;
 
 		for(*m = 0;*v && m < info->dst_mac + 6; v++) {
@@ -1231,7 +1245,8 @@
 		if (len < 0)
 			return len;
 		memset(valstr, 0, sizeof(valstr));
-		copy_from_user(valstr, &user_buffer[i], len);
+		if (copy_from_user(valstr, &user_buffer[i], len))
+			return -EFAULT;
 		i += len;
 
 		for(*m = 0;*v && m < info->src_mac + 6; v++) {
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/core/sysctl_net_core.c linux-2.4.23-pre1/net/core/sysctl_net_core.c
--- linux-2.4.22/net/core/sysctl_net_core.c	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/net/core/sysctl_net_core.c	2003-08-27 14:40:09.000000000 +0000
@@ -55,7 +55,7 @@
 	 &netdev_max_backlog, sizeof(int), 0644, NULL,
 	 &proc_dointvec},
 	{NET_CORE_NO_CONG_THRESH, "no_cong_thresh",
-	 &no_cong, sizeof(int), 0644, NULL,
+	 &no_cong_thresh, sizeof(int), 0644, NULL,
 	 &proc_dointvec},
 	{NET_CORE_NO_CONG, "no_cong",
 	 &no_cong, sizeof(int), 0644, NULL,
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/Config.in linux-2.4.23-pre1/net/ipv4/Config.in
--- linux-2.4.22/net/ipv4/Config.in	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/Config.in	2003-08-27 14:39:25.000000000 +0000
@@ -43,3 +43,6 @@
 if [ "$CONFIG_NETFILTER" != "n" ]; then
    source net/ipv4/netfilter/Config.in
 fi
+if [ "$CONFIG_NETFILTER" != "n" ]; then
+   source net/ipv4/ipvs/Config.in
+fi
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/arp.c linux-2.4.23-pre1/net/ipv4/arp.c
--- linux-2.4.22/net/ipv4/arp.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/arp.c	2003-08-27 14:41:34.000000000 +0000
@@ -1212,6 +1212,26 @@
 }
 #endif
 
+static int arp_netdev_event(struct notifier_block *this, unsigned long event, void *ptr)
+{
+	struct net_device *dev = ptr;
+
+	switch (event) {
+	case NETDEV_CHANGEADDR:
+		neigh_changeaddr(&arp_tbl, dev);
+		rt_cache_flush(0);
+		break;
+	default:
+		break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+struct notifier_block arp_netdev_notifier = {
+	.notifier_call = arp_netdev_event,
+};
+
 /* Note, that it is not on notifier chain.
    It is necessary, that this routine was called after route cache will be
    flushed.
@@ -1243,6 +1263,7 @@
 #ifdef CONFIG_SYSCTL
 	neigh_sysctl_register(NULL, &arp_tbl.parms, NET_IPV4, NET_IPV4_NEIGH, "ipv4");
 #endif
+	register_netdevice_notifier(&arp_netdev_notifier);
 }
 
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/devinet.c linux-2.4.23-pre1/net/ipv4/devinet.c
--- linux-2.4.22/net/ipv4/devinet.c	2003-06-13 14:51:39.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/devinet.c	2003-08-27 14:39:49.000000000 +0000
@@ -883,6 +883,7 @@
 	unsigned char	 *b = skb->tail;
 
 	nlh = NLMSG_PUT(skb, pid, seq, event, sizeof(*ifm));
+	if (pid) nlh->nlmsg_flags |= NLM_F_MULTI;
 	ifm = NLMSG_DATA(nlh);
 	ifm->ifa_family = AF_INET;
 	ifm->ifa_prefixlen = ifa->ifa_prefixlen;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipconfig.c linux-2.4.23-pre1/net/ipv4/ipconfig.c
--- linux-2.4.22/net/ipv4/ipconfig.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipconfig.c	2003-08-27 14:39:19.000000000 +0000
@@ -124,14 +124,14 @@
 
 int ic_host_name_set __initdata = 0;		/* Host name set by us? */
 
-u32 ic_myaddr __initdata = INADDR_NONE;		/* My IP address */
-u32 ic_netmask __initdata = INADDR_NONE;	/* Netmask for local subnet */
-u32 ic_gateway __initdata = INADDR_NONE;	/* Gateway IP address */
+u32 ic_myaddr = INADDR_NONE;		/* My IP address */
+u32 ic_netmask = INADDR_NONE;	/* Netmask for local subnet */
+u32 ic_gateway = INADDR_NONE;	/* Gateway IP address */
 
-u32 ic_servaddr __initdata = INADDR_NONE;	/* Boot server IP address */
+u32 ic_servaddr = INADDR_NONE;	/* Boot server IP address */
 
-u32 root_server_addr __initdata = INADDR_NONE;	/* Address of NFS server */
-u8 root_server_path[256] __initdata = { 0, };	/* Path to mount as root */
+u32 root_server_addr = INADDR_NONE;	/* Address of NFS server */
+u8 root_server_path[256] = { 0, };	/* Path to mount as root */
 
 /* Persistent data: */
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipmr.c linux-2.4.23-pre1/net/ipv4/ipmr.c
--- linux-2.4.22/net/ipv4/ipmr.c	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipmr.c	2003-08-27 14:40:30.000000000 +0000
@@ -1096,6 +1096,7 @@
 
 	skb->h.ipiph = skb->nh.iph;
 	skb->nh.iph = iph;
+	memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
 #ifdef CONFIG_NETFILTER
 	nf_conntrack_put(skb->nfct);
 	skb->nfct = NULL;
@@ -1104,8 +1105,12 @@
 
 static inline int ipmr_forward_finish(struct sk_buff *skb)
 {
+	struct ip_options *opt = &(IPCB(skb)->opt);
 	struct dst_entry *dst = skb->dst;
 
+	if (unlikely(opt->optlen))
+		ip_forward_options(skb);
+
 	if (skb->len <= dst->pmtu)
 		return dst->output(skb);
 	else
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/Config.in linux-2.4.23-pre1/net/ipv4/ipvs/Config.in
--- linux-2.4.22/net/ipv4/ipvs/Config.in	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/Config.in	2003-08-27 14:39:47.000000000 +0000
@@ -0,0 +1,26 @@
+#
+# IP VS configuration
+#
+mainmenu_option next_comment
+comment '  IP: Virtual Server Configuration'
+
+tristate 'virtual server support (EXPERIMENTAL)' CONFIG_IP_VS
+if [ "$CONFIG_IP_VS" != "n" ]; then
+  bool '  IP virtual server debugging' CONFIG_IP_VS_DEBUG
+  int '  IPVS connection table size (the Nth power of 2)' CONFIG_IP_VS_TAB_BITS 12
+  comment 'IPVS scheduler'
+  dep_tristate '  round-robin scheduling' CONFIG_IP_VS_RR $CONFIG_IP_VS
+  dep_tristate '  weighted round-robin scheduling' CONFIG_IP_VS_WRR $CONFIG_IP_VS
+  dep_tristate '  least-connection scheduling scheduling' CONFIG_IP_VS_LC $CONFIG_IP_VS
+  dep_tristate '  weighted least-connection scheduling' CONFIG_IP_VS_WLC $CONFIG_IP_VS
+  dep_tristate '  locality-based least-connection scheduling' CONFIG_IP_VS_LBLC $CONFIG_IP_VS
+  dep_tristate '  locality-based least-connection with replication scheduling' CONFIG_IP_VS_LBLCR $CONFIG_IP_VS
+  dep_tristate '  destination hashing scheduling' CONFIG_IP_VS_DH $CONFIG_IP_VS
+  dep_tristate '  source hashing scheduling' CONFIG_IP_VS_SH $CONFIG_IP_VS
+  dep_tristate '  shortest expected delay scheduling' CONFIG_IP_VS_SED $CONFIG_IP_VS
+  dep_tristate '  never queue scheduling' CONFIG_IP_VS_NQ $CONFIG_IP_VS
+  comment 'IPVS application helper'
+  dep_tristate '  FTP protocol helper' CONFIG_IP_VS_FTP $CONFIG_IP_VS
+fi
+
+endmenu
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/Makefile linux-2.4.23-pre1/net/ipv4/ipvs/Makefile
--- linux-2.4.22/net/ipv4/ipvs/Makefile	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/Makefile	2003-08-27 14:39:36.000000000 +0000
@@ -0,0 +1,43 @@
+#
+# Makefile for the IPVS modules on top of IPv4.
+#
+# Note! Dependencies are done automagically by 'make dep', which also
+# removes any old dependencies. DON'T put your own dependencies here
+# unless it's something special (ie not a .c file).
+#
+# Note 2! The CFLAGS definition is now in the main makefile...
+
+O_TARGET :=	ipvs.o
+
+export-objs :=	ip_vs_core.o ip_vs_app.o
+
+ip_vs-objs :=	ip_vs_conn.o ip_vs_core.o ip_vs_ctl.o ip_vs_sched.o \
+		ip_vs_app.o ip_vs_sync.o ip_vs_est.o
+
+ifeq ($(CONFIG_IP_VS),y)
+  obj-y := $(ip_vs-objs)
+else
+  ifeq ($(CONFIG_IP_VS),m)
+    obj-m := ip_vs.o
+  endif
+endif
+
+# IPVS schedulers
+obj-$(CONFIG_IP_VS_RR) += ip_vs_rr.o
+obj-$(CONFIG_IP_VS_WRR) += ip_vs_wrr.o
+obj-$(CONFIG_IP_VS_LC) += ip_vs_lc.o
+obj-$(CONFIG_IP_VS_WLC) += ip_vs_wlc.o
+obj-$(CONFIG_IP_VS_LBLC) += ip_vs_lblc.o
+obj-$(CONFIG_IP_VS_LBLCR) += ip_vs_lblcr.o
+obj-$(CONFIG_IP_VS_DH) += ip_vs_dh.o
+obj-$(CONFIG_IP_VS_SH) += ip_vs_sh.o
+obj-$(CONFIG_IP_VS_SED) += ip_vs_sed.o
+obj-$(CONFIG_IP_VS_NQ) += ip_vs_nq.o
+
+# IPVS application helpers
+obj-$(CONFIG_IP_VS_FTP) += ip_vs_ftp.o
+
+include $(TOPDIR)/Rules.make
+
+ip_vs.o: $(ip_vs-objs)
+	$(LD) $(LD_RFLAG) -r -o $@ $(ip_vs-objs)
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_app.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_app.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_app.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_app.c	2003-08-27 14:39:26.000000000 +0000
@@ -0,0 +1,508 @@
+/*
+ * IPVS         Application module
+ *
+ * Version:     $Id: ip_vs_app.c,v 1.14 2001/11/23 14:34:10 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Most code here is taken from ip_masq_app.c in kernel 2.2. The difference
+ * is that ip_vs_app module handles the reverse direction (incoming requests
+ * and outgoing responses). The ip_vs_app modules are only used for VS/NAT.
+ *
+ *		IP_MASQ_APP application masquerading module
+ *
+ * Author:	Juan Jose Ciarlante, <jjciarla@raiz.uncu.edu.ar>
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/skbuff.h>
+#include <linux/in.h>
+#include <linux/ip.h>
+#include <linux/init.h>
+#include <net/protocol.h>
+#include <net/tcp.h>
+#include <net/udp.h>
+#include <asm/system.h>
+#include <linux/stat.h>
+#include <linux/proc_fs.h>
+
+#include <net/ip_vs.h>
+
+#define IP_VS_APP_TAB_SIZE  16          /* must be power of 2 */
+
+#define IP_VS_APP_HASH(proto, port) ((port^proto) & (IP_VS_APP_TAB_SIZE-1))
+#define IP_VS_APP_TYPE(proto, port) (proto<<16 | port)
+#define IP_VS_APP_PORT(type)        (type & 0xffff)
+#define IP_VS_APP_PROTO(type)       ((type>>16) & 0x00ff)
+
+
+EXPORT_SYMBOL(register_ip_vs_app);
+EXPORT_SYMBOL(unregister_ip_vs_app);
+
+
+/*
+ *	will hold ipvs app. hashed list heads
+ */
+static struct list_head ip_vs_app_base[IP_VS_APP_TAB_SIZE];
+
+/* lock for ip_vs_app table */
+static rwlock_t __ip_vs_app_lock = RW_LOCK_UNLOCKED;
+
+
+/*
+ *	ip_vs_app registration routine
+ *	port: host byte order.
+ */
+int register_ip_vs_app(struct ip_vs_app *vapp,
+		       unsigned short proto, __u16 port)
+{
+	unsigned hash;
+
+	if (!vapp) {
+		IP_VS_ERR("register_ip_vs_app(): NULL arg\n");
+		return -EINVAL;
+	}
+
+	MOD_INC_USE_COUNT;
+
+	vapp->type = IP_VS_APP_TYPE(proto, port);
+	hash = IP_VS_APP_HASH(proto, port);
+
+	write_lock_bh(&__ip_vs_app_lock);
+	list_add(&vapp->n_list, &ip_vs_app_base[hash]);
+	write_unlock_bh(&__ip_vs_app_lock);
+
+	return 0;
+}
+
+
+/*
+ *	ip_vs_app unregistration routine.
+ */
+int unregister_ip_vs_app(struct ip_vs_app *vapp)
+{
+	if (!vapp) {
+		IP_VS_ERR("unregister_ip_vs_app(): NULL arg\n");
+		return -EINVAL;
+	}
+
+	write_lock_bh(&__ip_vs_app_lock);
+	list_del(&vapp->n_list);
+	write_unlock_bh(&__ip_vs_app_lock);
+
+	MOD_DEC_USE_COUNT;
+
+	return 0;
+}
+
+
+/*
+ *	get ip_vs_app object by its proto and port (net byte order).
+ */
+static struct ip_vs_app * ip_vs_app_get(unsigned short proto, __u16 port)
+{
+	struct list_head *e;
+	struct ip_vs_app *vapp;
+	unsigned hash;
+	unsigned type;
+
+	port = ntohs(port);
+	type = IP_VS_APP_TYPE(proto, port);
+	hash = IP_VS_APP_HASH(proto, port);
+
+	read_lock_bh(&__ip_vs_app_lock);
+
+	list_for_each(e, &ip_vs_app_base[hash]) {
+		vapp = list_entry(e, struct ip_vs_app, n_list);
+
+		/*
+		 * Test and MOD_INC_USE_COUNT atomically
+		 */
+		if (vapp->module && !try_inc_mod_count(vapp->module)) {
+			/*
+			 * This application module is just deleted
+			 */
+			continue;
+		}
+		if (type == vapp->type) {
+			read_unlock_bh(&__ip_vs_app_lock);
+			return vapp;
+		}
+
+		if (vapp->module)
+			__MOD_DEC_USE_COUNT(vapp->module);
+	}
+
+	read_unlock_bh(&__ip_vs_app_lock);
+	return NULL;
+}
+
+
+/*
+ *	Bind ip_vs_conn to its ip_vs_app based on proto and dport,
+ *	and call the ip_vs_app constructor.
+ */
+struct ip_vs_app * ip_vs_bind_app(struct ip_vs_conn *cp)
+{
+	struct ip_vs_app *vapp;
+
+	/* no need to bind app if its forwarding method is not NAT */
+	if (IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_MASQ)
+		return NULL;
+
+	if (cp->protocol != IPPROTO_TCP && cp->protocol != IPPROTO_UDP)
+		return NULL;
+
+	/*
+	 *	don't allow binding if already bound
+	 */
+	if (cp->app != NULL) {
+		IP_VS_ERR("ip_vs_bind_app(): "
+			  "called for already bound object.\n");
+		return cp->app;
+	}
+
+	vapp = ip_vs_app_get(cp->protocol, cp->vport);
+
+	if (vapp != NULL) {
+		cp->app = vapp;
+
+		if (vapp->init_conn)
+			vapp->init_conn(vapp, cp);
+	}
+	return vapp;
+}
+
+
+/*
+ *	Unbind cp from type object and call cp destructor (does not kfree()).
+ */
+int ip_vs_unbind_app(struct ip_vs_conn *cp)
+{
+	struct ip_vs_app *vapp = cp->app;
+
+	if (cp->protocol != IPPROTO_TCP && cp->protocol != IPPROTO_UDP)
+		return 0;
+
+	if (vapp != NULL) {
+		if (vapp->done_conn)
+			vapp->done_conn(vapp, cp);
+		cp->app = NULL;
+		if (vapp->module)
+			__MOD_DEC_USE_COUNT(vapp->module);
+	}
+	return (vapp != NULL);
+}
+
+
+/*
+ *	Fixes th->seq based on ip_vs_seq info.
+ */
+static inline void vs_fix_seq(const struct ip_vs_seq *vseq, struct tcphdr *th)
+{
+	__u32 seq = ntohl(th->seq);
+
+	/*
+	 *	Adjust seq with delta-offset for all packets after
+	 *	the most recent resized pkt seq and with previous_delta offset
+	 *	for all packets	before most recent resized pkt seq.
+	 */
+	if (vseq->delta || vseq->previous_delta) {
+		if(after(seq, vseq->init_seq)) {
+			th->seq = htonl(seq + vseq->delta);
+			IP_VS_DBG(9, "vs_fix_seq(): added delta (%d) to seq\n",
+				  vseq->delta);
+		} else {
+			th->seq = htonl(seq + vseq->previous_delta);
+			IP_VS_DBG(9, "vs_fix_seq(): added previous_delta "
+				  "(%d) to seq\n", vseq->previous_delta);
+		}
+	}
+}
+
+
+/*
+ *	Fixes th->ack_seq based on ip_vs_seq info.
+ */
+static inline void
+vs_fix_ack_seq(const struct ip_vs_seq *vseq, struct tcphdr *th)
+{
+	__u32 ack_seq = ntohl(th->ack_seq);
+
+	/*
+	 * Adjust ack_seq with delta-offset for
+	 * the packets AFTER most recent resized pkt has caused a shift
+	 * for packets before most recent resized pkt, use previous_delta
+	 */
+	if (vseq->delta || vseq->previous_delta) {
+		/* since ack_seq is the number of octet that is expected
+		   to receive next, so compare it with init_seq+delta */
+		if(after(ack_seq, vseq->init_seq+vseq->delta)) {
+			th->ack_seq = htonl(ack_seq - vseq->delta);
+			IP_VS_DBG(9, "vs_fix_ack_seq(): subtracted delta "
+				  "(%d) from ack_seq\n", vseq->delta);
+
+		} else {
+			th->ack_seq = htonl(ack_seq - vseq->previous_delta);
+			IP_VS_DBG(9, "vs_fix_ack_seq(): subtracted "
+				  "previous_delta (%d) from ack_seq\n",
+				  vseq->previous_delta);
+		}
+	}
+}
+
+
+/*
+ *	Updates ip_vs_seq if pkt has been resized
+ *	Assumes already checked proto==IPPROTO_TCP and diff!=0.
+ */
+static inline void vs_seq_update(struct ip_vs_conn *cp, struct ip_vs_seq *vseq,
+				 unsigned flag, __u32 seq, int diff)
+{
+	/* spinlock is to keep updating cp->flags atomic */
+	spin_lock(&cp->lock);
+	if ( !(cp->flags & flag) || after(seq, vseq->init_seq)) {
+		vseq->previous_delta = vseq->delta;
+		vseq->delta += diff;
+		vseq->init_seq = seq;
+		cp->flags |= flag;
+	}
+	spin_unlock(&cp->lock);
+}
+
+
+/*
+ *	Output pkt hook. Will call bound ip_vs_app specific function
+ *	called by ip_vs_out(), assumes previously checked cp!=NULL
+ *	returns (new - old) skb->len diff.
+ */
+int ip_vs_app_pkt_out(struct ip_vs_conn *cp, struct sk_buff *skb)
+{
+	struct ip_vs_app *vapp;
+	int diff;
+	struct iphdr *iph;
+	struct tcphdr *th;
+	__u32 seq;
+
+	/*
+	 *	check if application module is bound to
+	 *	this ip_vs_conn.
+	 */
+	if ((vapp = cp->app) == NULL)
+		return 0;
+
+	iph = skb->nh.iph;
+	th = (struct tcphdr *)&(((char *)iph)[iph->ihl*4]);
+
+	/*
+	 *	Remember seq number in case this pkt gets resized
+	 */
+	seq = ntohl(th->seq);
+
+	/*
+	 *	Fix seq stuff if flagged as so.
+	 */
+	if (cp->protocol == IPPROTO_TCP) {
+		if (cp->flags & IP_VS_CONN_F_OUT_SEQ)
+			vs_fix_seq(&cp->out_seq, th);
+		if (cp->flags & IP_VS_CONN_F_IN_SEQ)
+			vs_fix_ack_seq(&cp->in_seq, th);
+	}
+
+	/*
+	 *	Call private output hook function
+	 */
+	if (vapp->pkt_out == NULL)
+		return 0;
+
+	diff = vapp->pkt_out(vapp, cp, skb);
+
+	/*
+	 *	Update ip_vs seq stuff if len has changed.
+	 */
+	if (diff != 0 && cp->protocol == IPPROTO_TCP)
+		vs_seq_update(cp, &cp->out_seq,
+			      IP_VS_CONN_F_OUT_SEQ, seq, diff);
+
+	return diff;
+}
+
+
+/*
+ *	Input pkt hook. Will call bound ip_vs_app specific function
+ *	called by ip_fw_demasquerade(), assumes previously checked cp!=NULL.
+ *	returns (new - old) skb->len diff.
+ */
+int ip_vs_app_pkt_in(struct ip_vs_conn *cp, struct sk_buff *skb)
+{
+	struct ip_vs_app *vapp;
+	int diff;
+	struct iphdr *iph;
+	struct tcphdr *th;
+	__u32 seq;
+
+	/*
+	 *	check if application module is bound to
+	 *	this ip_vs_conn.
+	 */
+	if ((vapp = cp->app) == NULL)
+		return 0;
+
+	iph = skb->nh.iph;
+	th = (struct tcphdr *)&(((char *)iph)[iph->ihl*4]);
+
+	/*
+	 *	Remember seq number in case this pkt gets resized
+	 */
+	seq = ntohl(th->seq);
+
+	/*
+	 *	Fix seq stuff if flagged as so.
+	 */
+	if (cp->protocol == IPPROTO_TCP) {
+		if (cp->flags & IP_VS_CONN_F_IN_SEQ)
+			vs_fix_seq(&cp->in_seq, th);
+		if (cp->flags & IP_VS_CONN_F_OUT_SEQ)
+			vs_fix_ack_seq(&cp->out_seq, th);
+	}
+
+	/*
+	 *	Call private input hook function
+	 */
+	if (vapp->pkt_in == NULL)
+		return 0;
+
+	diff = vapp->pkt_in(vapp, cp, skb);
+
+	/*
+	 *	Update ip_vs seq stuff if len has changed.
+	 */
+	if (diff != 0 && cp->protocol == IPPROTO_TCP)
+		vs_seq_update(cp, &cp->in_seq,
+			      IP_VS_CONN_F_IN_SEQ, seq, diff);
+
+	return diff;
+}
+
+
+/*
+ *	/proc/net/ip_vs_app entry function
+ */
+static int ip_vs_app_getinfo(char *buffer, char **start, off_t offset,
+			     int length)
+{
+	off_t pos=0;
+	int len=0;
+	char temp[64];
+	int idx;
+	struct ip_vs_app *vapp;
+	struct list_head *e;
+
+	pos = 64;
+	if (pos > offset) {
+		len += sprintf(buffer+len, "%-63s\n",
+			       "prot port    usecnt name");
+	}
+
+	read_lock_bh(&__ip_vs_app_lock);
+	for (idx=0 ; idx < IP_VS_APP_TAB_SIZE; idx++) {
+		list_for_each (e, &ip_vs_app_base[idx]) {
+			vapp = list_entry(e, struct ip_vs_app, n_list);
+
+			pos += 64;
+			if (pos <= offset)
+				continue;
+			sprintf(temp, "%-3s  %-7u %-6d %-17s",
+				ip_vs_proto_name(IP_VS_APP_PROTO(vapp->type)),
+				IP_VS_APP_PORT(vapp->type),
+				vapp->module?GET_USE_COUNT(vapp->module):0,
+				vapp->name);
+			len += sprintf(buffer+len, "%-63s\n", temp);
+			if (pos >= offset+length)
+				goto done;
+		}
+	}
+  done:
+	read_unlock_bh(&__ip_vs_app_lock);
+
+	*start = buffer+len-(pos-offset);       /* Start of wanted data */
+	len = pos-offset;
+	if (len > length)
+		len = length;
+	if (len < 0)
+		len = 0;
+	return len;
+}
+
+
+/*
+ *	Replace a segment of data with a new segment
+ */
+int ip_vs_skb_replace(struct sk_buff *skb, int pri,
+		      char *o_buf, int o_len, char *n_buf, int n_len)
+{
+	struct iphdr *iph;
+	int diff;
+	int o_offset;
+	int o_left;
+
+	EnterFunction(9);
+
+	diff = n_len - o_len;
+	o_offset = o_buf - (char *)skb->data;
+	/* The length of left data after o_buf+o_len in the skb data */
+	o_left = skb->len - (o_offset + o_len);
+
+	if (diff <= 0) {
+		memmove(o_buf + n_len, o_buf + o_len, o_left);
+		memcpy(o_buf, n_buf, n_len);
+		skb_trim(skb, skb->len + diff);
+	} else if (diff <= skb_tailroom(skb)) {
+		skb_put(skb, diff);
+		memmove(o_buf + n_len, o_buf + o_len, o_left);
+		memcpy(o_buf, n_buf, n_len);
+	} else {
+		if (pskb_expand_head(skb, skb_headroom(skb), diff, pri))
+			return -ENOMEM;
+		skb_put(skb, diff);
+		memmove(skb->data + o_offset + n_len,
+			skb->data + o_offset + o_len, o_left);
+		memcpy(skb->data + o_offset, n_buf, n_len);
+	}
+
+	/* must update the iph total length here */
+	iph = skb->nh.iph;
+	iph->tot_len = htons(skb->len);
+
+	LeaveFunction(9);
+	return 0;
+}
+
+
+int ip_vs_app_init(void)
+{
+	int idx;
+
+	for (idx=0 ; idx < IP_VS_APP_TAB_SIZE; idx++) {
+		INIT_LIST_HEAD(&ip_vs_app_base[idx]);
+	}
+
+	/* we will replace it with proc_net_ipvs_create() soon */
+	proc_net_create("ip_vs_app", 0, ip_vs_app_getinfo);
+	return 0;
+}
+
+void ip_vs_app_cleanup(void)
+{
+	proc_net_remove("ip_vs_app");
+}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_conn.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_conn.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_conn.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_conn.c	2003-08-27 14:40:59.000000000 +0000
@@ -0,0 +1,1563 @@
+/*
+ * IPVS         An implementation of the IP virtual server support for the
+ *              LINUX operating system.  IPVS is now implemented as a module
+ *              over the Netfilter framework. IPVS can be used to build a
+ *              high-performance and highly available server based on a
+ *              cluster of servers.
+ *
+ * Version:     $Id: ip_vs_conn.c,v 1.28.2.5 2003/08/09 13:27:08 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *              Peter Kese <peter.kese@ijs.si>
+ *              Julian Anastasov <ja@ssi.bg>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * The IPVS code for kernel 2.2 was done by Wensong Zhang and Peter Kese,
+ * with changes/fixes from Julian Anastasov, Lars Marowsky-Bree, Horms
+ * and others. Many code here is taken from IP MASQ code of kernel 2.2.
+ *
+ * Changes:
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/compiler.h>
+#include <linux/vmalloc.h>
+#include <linux/ip.h>
+#include <linux/tcp.h>                  /* for tcphdr */
+#include <linux/in.h>
+#include <linux/proc_fs.h>              /* for proc_net_* */
+#include <asm/softirq.h>                /* for local_bh_* */
+#include <net/ip.h>
+#include <net/tcp.h>                    /* for csum_tcpudp_magic */
+#include <net/udp.h>
+#include <net/icmp.h>                   /* for icmp_send */
+#include <net/route.h>                  /* for ip_route_output */
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+#include <linux/jhash.h>
+#include <linux/random.h>
+
+#include <net/ip_vs.h>
+
+
+/*
+ *  Connection hash table: for input and output packets lookups of IPVS
+ */
+static struct list_head *ip_vs_conn_tab;
+
+/* SLAB cache for IPVS connections */
+static kmem_cache_t *ip_vs_conn_cachep;
+
+/* counter for current IPVS connections */
+static atomic_t ip_vs_conn_count = ATOMIC_INIT(0);
+
+/* counter for no-client-port connections */
+static atomic_t ip_vs_conn_no_cport_cnt = ATOMIC_INIT(0);
+
+/* random value for IPVS connection hash */
+static unsigned int ip_vs_conn_rnd;
+
+/*
+ *  Fine locking granularity for big connection hash table
+ */
+#define CT_LOCKARRAY_BITS  4
+#define CT_LOCKARRAY_SIZE  (1<<CT_LOCKARRAY_BITS)
+#define CT_LOCKARRAY_MASK  (CT_LOCKARRAY_SIZE-1)
+
+struct ip_vs_aligned_lock
+{
+	rwlock_t	l;
+} __attribute__((__aligned__(SMP_CACHE_BYTES)));
+
+/* lock array for conn table */
+struct ip_vs_aligned_lock
+__ip_vs_conntbl_lock_array[CT_LOCKARRAY_SIZE] __cacheline_aligned;
+
+static inline void ct_read_lock(unsigned key)
+{
+	read_lock(&__ip_vs_conntbl_lock_array[key&CT_LOCKARRAY_MASK].l);
+}
+
+static inline void ct_read_unlock(unsigned key)
+{
+	read_unlock(&__ip_vs_conntbl_lock_array[key&CT_LOCKARRAY_MASK].l);
+}
+
+static inline void ct_write_lock(unsigned key)
+{
+	write_lock(&__ip_vs_conntbl_lock_array[key&CT_LOCKARRAY_MASK].l);
+}
+
+static inline void ct_write_unlock(unsigned key)
+{
+	write_unlock(&__ip_vs_conntbl_lock_array[key&CT_LOCKARRAY_MASK].l);
+}
+
+static inline void ct_read_lock_bh(unsigned key)
+{
+	read_lock_bh(&__ip_vs_conntbl_lock_array[key&CT_LOCKARRAY_MASK].l);
+}
+
+static inline void ct_read_unlock_bh(unsigned key)
+{
+	read_unlock_bh(&__ip_vs_conntbl_lock_array[key&CT_LOCKARRAY_MASK].l);
+}
+
+static inline void ct_write_lock_bh(unsigned key)
+{
+	write_lock_bh(&__ip_vs_conntbl_lock_array[key&CT_LOCKARRAY_MASK].l);
+}
+
+static inline void ct_write_unlock_bh(unsigned key)
+{
+	write_unlock_bh(&__ip_vs_conntbl_lock_array[key&CT_LOCKARRAY_MASK].l);
+}
+
+
+/*
+ *	Returns hash value for IPVS connection entry
+ */
+static unsigned
+ip_vs_conn_hashkey(unsigned proto, __u32 addr, __u16 port)
+{
+	return jhash_3words(addr, port, proto, ip_vs_conn_rnd)
+		& IP_VS_CONN_TAB_MASK;
+}
+
+
+/*
+ *	Hashes ip_vs_conn in ip_vs_conn_tab by proto,addr,port.
+ *	returns bool success.
+ */
+static int ip_vs_conn_hash(struct ip_vs_conn *cp)
+{
+	unsigned hash;
+
+	if (cp->flags & IP_VS_CONN_F_HASHED) {
+		IP_VS_ERR("ip_vs_conn_hash(): request for already hashed, "
+			  "called from %p\n", __builtin_return_address(0));
+		return 0;
+	}
+
+	/* Hash by protocol, client address and port */
+	hash = ip_vs_conn_hashkey(cp->protocol, cp->caddr, cp->cport);
+
+	ct_write_lock(hash);
+
+	list_add(&cp->c_list, &ip_vs_conn_tab[hash]);
+	cp->flags |= IP_VS_CONN_F_HASHED;
+	atomic_inc(&cp->refcnt);
+
+	ct_write_unlock(hash);
+
+	return 1;
+}
+
+
+/*
+ *	UNhashes ip_vs_conn from ip_vs_conn_tab.
+ *	returns bool success.
+ */
+static int ip_vs_conn_unhash(struct ip_vs_conn *cp)
+{
+	unsigned hash;
+
+	if (!(cp->flags & IP_VS_CONN_F_HASHED)) {
+		IP_VS_ERR("ip_vs_conn_unhash(): request for unhash flagged, "
+			  "called from %p\n", __builtin_return_address(0));
+		return 0;
+	}
+
+	/* unhash it and decrease its reference counter */
+	hash = ip_vs_conn_hashkey(cp->protocol, cp->caddr, cp->cport);
+	ct_write_lock(hash);
+
+	list_del(&cp->c_list);
+	cp->flags &= ~IP_VS_CONN_F_HASHED;
+	atomic_dec(&cp->refcnt);
+
+	ct_write_unlock(hash);
+
+	return 1;
+}
+
+
+/*
+ *  Gets ip_vs_conn associated with supplied parameters in the ip_vs_conn_tab.
+ *  Called for pkts coming from OUTside-to-INside.
+ *	s_addr, s_port: pkt source address (foreign host)
+ *	d_addr, d_port: pkt dest address (load balancer)
+ */
+static inline struct ip_vs_conn *__ip_vs_conn_in_get
+(int protocol, __u32 s_addr, __u16 s_port, __u32 d_addr, __u16 d_port)
+{
+	unsigned hash;
+	struct ip_vs_conn *cp;
+	struct list_head *l,*e;
+
+	hash = ip_vs_conn_hashkey(protocol, s_addr, s_port);
+	l = &ip_vs_conn_tab[hash];
+
+	ct_read_lock(hash);
+
+	for (e=l->next; e!=l; e=e->next) {
+		cp = list_entry(e, struct ip_vs_conn, c_list);
+		if (s_addr==cp->caddr && s_port==cp->cport &&
+		    d_port==cp->vport && d_addr==cp->vaddr &&
+		    protocol==cp->protocol) {
+			/* HIT */
+			atomic_inc(&cp->refcnt);
+			ct_read_unlock(hash);
+			return cp;
+		}
+	}
+
+	ct_read_unlock(hash);
+
+	return NULL;
+}
+
+struct ip_vs_conn *ip_vs_conn_in_get
+(int protocol, __u32 s_addr, __u16 s_port, __u32 d_addr, __u16 d_port)
+{
+	struct ip_vs_conn *cp;
+
+	cp = __ip_vs_conn_in_get(protocol, s_addr, s_port, d_addr, d_port);
+	if (!cp && atomic_read(&ip_vs_conn_no_cport_cnt))
+		cp = __ip_vs_conn_in_get(protocol, s_addr, 0, d_addr, d_port);
+
+	IP_VS_DBG(7, "lookup/in %s %u.%u.%u.%u:%d->%u.%u.%u.%u:%d %s\n",
+		  ip_vs_proto_name(protocol),
+		  NIPQUAD(s_addr), ntohs(s_port),
+		  NIPQUAD(d_addr), ntohs(d_port),
+		  cp?"hit":"not hit");
+
+	return cp;
+}
+
+
+/*
+ *  Gets ip_vs_conn associated with supplied parameters in the ip_vs_conn_tab.
+ *  Called for pkts coming from inside-to-OUTside.
+ *	s_addr, s_port: pkt source address (inside host)
+ *	d_addr, d_port: pkt dest address (foreign host)
+ */
+struct ip_vs_conn *ip_vs_conn_out_get
+(int protocol, __u32 s_addr, __u16 s_port, __u32 d_addr, __u16 d_port)
+{
+	unsigned hash;
+	struct ip_vs_conn *cp, *ret=NULL;
+	struct list_head *l,*e;
+
+	/*
+	 *	Check for "full" addressed entries
+	 */
+	hash = ip_vs_conn_hashkey(protocol, d_addr, d_port);
+	l = &ip_vs_conn_tab[hash];
+
+	ct_read_lock(hash);
+
+	for (e=l->next; e!=l; e=e->next) {
+		cp = list_entry(e, struct ip_vs_conn, c_list);
+		if (d_addr == cp->caddr && d_port == cp->cport &&
+		    s_port == cp->dport && s_addr == cp->daddr &&
+		    protocol == cp->protocol) {
+			/* HIT */
+			atomic_inc(&cp->refcnt);
+			ret = cp;
+			break;
+		}
+	}
+
+	ct_read_unlock(hash);
+
+	IP_VS_DBG(7, "lookup/out %s %u.%u.%u.%u:%d->%u.%u.%u.%u:%d %s\n",
+		  ip_vs_proto_name(protocol),
+		  NIPQUAD(s_addr), ntohs(s_port),
+		  NIPQUAD(d_addr), ntohs(d_port),
+		  ret?"hit":"not hit");
+
+	return ret;
+}
+
+
+/*
+ *      Put back the conn and restart its timer with its timeout
+ */
+void ip_vs_conn_put(struct ip_vs_conn *cp)
+{
+	/* reset it expire in its timeout */
+	mod_timer(&cp->timer, jiffies+cp->timeout);
+
+	__ip_vs_conn_put(cp);
+}
+
+
+/*
+ *	Timeout table[state]
+ */
+struct ip_vs_timeout_table vs_timeout_table = {
+	ATOMIC_INIT(0),	/* refcnt */
+	0,		/* scale  */
+	{
+		[IP_VS_S_NONE]          =	30*60*HZ,
+		[IP_VS_S_ESTABLISHED]	=	15*60*HZ,
+		[IP_VS_S_SYN_SENT]	=	2*60*HZ,
+		[IP_VS_S_SYN_RECV]	=	1*60*HZ,
+		[IP_VS_S_FIN_WAIT]	=	2*60*HZ,
+		[IP_VS_S_TIME_WAIT]	=	2*60*HZ,
+		[IP_VS_S_CLOSE]         =	10*HZ,
+		[IP_VS_S_CLOSE_WAIT]	=	60*HZ,
+		[IP_VS_S_LAST_ACK]	=	30*HZ,
+		[IP_VS_S_LISTEN]	=	2*60*HZ,
+		[IP_VS_S_SYNACK]	=	120*HZ,
+		[IP_VS_S_UDP]		=	5*60*HZ,
+		[IP_VS_S_ICMP]          =	1*60*HZ,
+		[IP_VS_S_LAST]          =	2*HZ,
+	},	/* timeout */
+};
+
+
+struct ip_vs_timeout_table vs_timeout_table_dos = {
+	ATOMIC_INIT(0),	/* refcnt */
+	0,		/* scale  */
+	{
+		[IP_VS_S_NONE]          =	15*60*HZ,
+		[IP_VS_S_ESTABLISHED]	=	8*60*HZ,
+		[IP_VS_S_SYN_SENT]	=	60*HZ,
+		[IP_VS_S_SYN_RECV]	=	10*HZ,
+		[IP_VS_S_FIN_WAIT]	=	60*HZ,
+		[IP_VS_S_TIME_WAIT]	=	60*HZ,
+		[IP_VS_S_CLOSE]         =	10*HZ,
+		[IP_VS_S_CLOSE_WAIT]	=	60*HZ,
+		[IP_VS_S_LAST_ACK]	=	30*HZ,
+		[IP_VS_S_LISTEN]	=	2*60*HZ,
+		[IP_VS_S_SYNACK]	=	100*HZ,
+		[IP_VS_S_UDP]		=	3*60*HZ,
+		[IP_VS_S_ICMP]          =	1*60*HZ,
+		[IP_VS_S_LAST]          =	2*HZ,
+	},	/* timeout */
+};
+
+
+/*
+ *	Timeout table to use for the VS entries
+ *	If NULL we use the default table (vs_timeout_table).
+ *	Under flood attack we switch to vs_timeout_table_dos
+ */
+
+static struct ip_vs_timeout_table *ip_vs_timeout_table = &vs_timeout_table;
+
+static const char * state_name_table[IP_VS_S_LAST+1] = {
+	[IP_VS_S_NONE]          =	"NONE",
+	[IP_VS_S_ESTABLISHED]	=	"ESTABLISHED",
+	[IP_VS_S_SYN_SENT]	=	"SYN_SENT",
+	[IP_VS_S_SYN_RECV]	=	"SYN_RECV",
+	[IP_VS_S_FIN_WAIT]	=	"FIN_WAIT",
+	[IP_VS_S_TIME_WAIT]	=	"TIME_WAIT",
+	[IP_VS_S_CLOSE]         =	"CLOSE",
+	[IP_VS_S_CLOSE_WAIT]	=	"CLOSE_WAIT",
+	[IP_VS_S_LAST_ACK]	=	"LAST_ACK",
+	[IP_VS_S_LISTEN]	=	"LISTEN",
+	[IP_VS_S_SYNACK]	=	"SYNACK",
+	[IP_VS_S_UDP]		=	"UDP",
+	[IP_VS_S_ICMP]          =	"ICMP",
+	[IP_VS_S_LAST]          =	"BUG!",
+};
+
+#define sNO IP_VS_S_NONE
+#define sES IP_VS_S_ESTABLISHED
+#define sSS IP_VS_S_SYN_SENT
+#define sSR IP_VS_S_SYN_RECV
+#define sFW IP_VS_S_FIN_WAIT
+#define sTW IP_VS_S_TIME_WAIT
+#define sCL IP_VS_S_CLOSE
+#define sCW IP_VS_S_CLOSE_WAIT
+#define sLA IP_VS_S_LAST_ACK
+#define sLI IP_VS_S_LISTEN
+#define sSA IP_VS_S_SYNACK
+
+struct vs_tcp_states_t {
+	int next_state[IP_VS_S_LAST];	/* should be _LAST_TCP */
+};
+
+const char * ip_vs_state_name(int state)
+{
+	if (state >= IP_VS_S_LAST)
+		return "ERR!";
+	return state_name_table[state] ? state_name_table[state] : "?";
+}
+
+static struct vs_tcp_states_t vs_tcp_states [] = {
+/*	INPUT */
+/*        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/
+/*syn*/ {{sSR, sES, sES, sSR, sSR, sSR, sSR, sSR, sSR, sSR, sSR }},
+/*fin*/ {{sCL, sCW, sSS, sTW, sTW, sTW, sCL, sCW, sLA, sLI, sTW }},
+/*ack*/ {{sCL, sES, sSS, sES, sFW, sTW, sCL, sCW, sCL, sLI, sES }},
+/*rst*/ {{sCL, sCL, sCL, sSR, sCL, sCL, sCL, sCL, sLA, sLI, sSR }},
+
+/*	OUTPUT */
+/*        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/
+/*syn*/ {{sSS, sES, sSS, sSR, sSS, sSS, sSS, sSS, sSS, sLI, sSR }},
+/*fin*/ {{sTW, sFW, sSS, sTW, sFW, sTW, sCL, sTW, sLA, sLI, sTW }},
+/*ack*/ {{sES, sES, sSS, sES, sFW, sTW, sCL, sCW, sLA, sES, sES }},
+/*rst*/ {{sCL, sCL, sSS, sCL, sCL, sTW, sCL, sCL, sCL, sCL, sCL }},
+
+/*	INPUT-ONLY */
+/*        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/
+/*syn*/ {{sSR, sES, sES, sSR, sSR, sSR, sSR, sSR, sSR, sSR, sSR }},
+/*fin*/ {{sCL, sFW, sSS, sTW, sFW, sTW, sCL, sCW, sLA, sLI, sTW }},
+/*ack*/ {{sCL, sES, sSS, sES, sFW, sTW, sCL, sCW, sCL, sLI, sES }},
+/*rst*/ {{sCL, sCL, sCL, sSR, sCL, sCL, sCL, sCL, sLA, sLI, sCL }},
+};
+
+static struct vs_tcp_states_t vs_tcp_states_dos [] = {
+/*	INPUT */
+/*        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/
+/*syn*/ {{sSR, sES, sES, sSR, sSR, sSR, sSR, sSR, sSR, sSR, sSA }},
+/*fin*/ {{sCL, sCW, sSS, sTW, sTW, sTW, sCL, sCW, sLA, sLI, sSA }},
+/*ack*/ {{sCL, sES, sSS, sSR, sFW, sTW, sCL, sCW, sCL, sLI, sSA }},
+/*rst*/ {{sCL, sCL, sCL, sSR, sCL, sCL, sCL, sCL, sLA, sLI, sCL }},
+
+/*	OUTPUT */
+/*        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/
+/*syn*/ {{sSS, sES, sSS, sSA, sSS, sSS, sSS, sSS, sSS, sLI, sSA }},
+/*fin*/ {{sTW, sFW, sSS, sTW, sFW, sTW, sCL, sTW, sLA, sLI, sTW }},
+/*ack*/ {{sES, sES, sSS, sES, sFW, sTW, sCL, sCW, sLA, sES, sES }},
+/*rst*/ {{sCL, sCL, sSS, sCL, sCL, sTW, sCL, sCL, sCL, sCL, sCL }},
+
+/*	INPUT-ONLY */
+/*        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/
+/*syn*/ {{sSA, sES, sES, sSR, sSA, sSA, sSA, sSA, sSA, sSA, sSA }},
+/*fin*/ {{sCL, sFW, sSS, sTW, sFW, sTW, sCL, sCW, sLA, sLI, sTW }},
+/*ack*/ {{sCL, sES, sSS, sES, sFW, sTW, sCL, sCW, sCL, sLI, sES }},
+/*rst*/ {{sCL, sCL, sCL, sSR, sCL, sCL, sCL, sCL, sLA, sLI, sCL }},
+};
+
+static struct vs_tcp_states_t *ip_vs_state_table = vs_tcp_states;
+
+void ip_vs_secure_tcp_set(int on)
+{
+	if (on) {
+		ip_vs_state_table = vs_tcp_states_dos;
+		ip_vs_timeout_table = &vs_timeout_table_dos;
+	} else {
+		ip_vs_state_table = vs_tcp_states;
+		ip_vs_timeout_table = &vs_timeout_table;
+	}
+}
+
+
+static inline int vs_tcp_state_idx(struct tcphdr *th, int state_off)
+{
+	/*
+	 *	[0-3]: input states, [4-7]: output, [8-11] input only states.
+	 */
+	if (th->rst)
+		return state_off+3;
+	if (th->syn)
+		return state_off+0;
+	if (th->fin)
+		return state_off+1;
+	if (th->ack)
+		return state_off+2;
+	return -1;
+}
+
+
+static inline int vs_set_state_timeout(struct ip_vs_conn *cp, int state)
+{
+	struct ip_vs_timeout_table *vstim = cp->timeout_table;
+
+	/*
+	 *	Use default timeout table if no specific for this entry
+	 */
+	if (!vstim)
+		vstim = &vs_timeout_table;
+
+	cp->timeout = vstim->timeout[cp->state=state];
+
+	if (vstim->scale) {
+		int scale = vstim->scale;
+
+		if (scale<0)
+			cp->timeout >>= -scale;
+		else if (scale > 0)
+			cp->timeout <<= scale;
+	}
+
+	return state;
+}
+
+
+static inline int
+vs_tcp_state(struct ip_vs_conn *cp, int state_off, struct tcphdr *th)
+{
+	int state_idx;
+	int new_state = IP_VS_S_CLOSE;
+
+	/*
+	 *    Update state offset to INPUT_ONLY if necessary
+	 *    or delete NO_OUTPUT flag if output packet detected
+	 */
+	if (cp->flags & IP_VS_CONN_F_NOOUTPUT) {
+		if (state_off == VS_STATE_OUTPUT)
+			cp->flags &= ~IP_VS_CONN_F_NOOUTPUT;
+		else
+			state_off = VS_STATE_INPUT_ONLY;
+	}
+
+	if ((state_idx = vs_tcp_state_idx(th, state_off)) < 0) {
+		IP_VS_DBG(8, "vs_tcp_state_idx(%d)=%d!!!\n",
+			  state_off, state_idx);
+		goto tcp_state_out;
+	}
+
+	new_state = ip_vs_state_table[state_idx].next_state[cp->state];
+
+  tcp_state_out:
+	if (new_state != cp->state) {
+		struct ip_vs_dest *dest = cp->dest;
+
+		IP_VS_DBG(8, "%s %s [%c%c%c%c] %u.%u.%u.%u:%d->"
+			  "%u.%u.%u.%u:%d state: %s->%s cnt:%d\n",
+			  ip_vs_proto_name(cp->protocol),
+			  (state_off==VS_STATE_OUTPUT)?"output ":"input ",
+			  th->syn? 'S' : '.',
+			  th->fin? 'F' : '.',
+			  th->ack? 'A' : '.',
+			  th->rst? 'R' : '.',
+			  NIPQUAD(cp->daddr), ntohs(cp->dport),
+			  NIPQUAD(cp->caddr), ntohs(cp->cport),
+			  ip_vs_state_name(cp->state),
+			  ip_vs_state_name(new_state),
+			  atomic_read(&cp->refcnt));
+		if (dest) {
+			if (!(cp->flags & IP_VS_CONN_F_INACTIVE) &&
+			    (new_state != IP_VS_S_ESTABLISHED)) {
+				atomic_dec(&dest->activeconns);
+				atomic_inc(&dest->inactconns);
+				cp->flags |= IP_VS_CONN_F_INACTIVE;
+			} else if ((cp->flags & IP_VS_CONN_F_INACTIVE) &&
+				   (new_state == IP_VS_S_ESTABLISHED)) {
+				atomic_inc(&dest->activeconns);
+				atomic_dec(&dest->inactconns);
+				cp->flags &= ~IP_VS_CONN_F_INACTIVE;
+			}
+		}
+	}
+
+	return vs_set_state_timeout(cp, new_state);
+}
+
+
+/*
+ *	Handle state transitions
+ */
+int ip_vs_set_state(struct ip_vs_conn *cp,
+		    int state_off, struct iphdr *iph, void *tp)
+{
+	int ret;
+
+	spin_lock(&cp->lock);
+	switch (iph->protocol) {
+	case IPPROTO_TCP:
+		ret = vs_tcp_state(cp, state_off, tp);
+		break;
+	case IPPROTO_UDP:
+		ret = vs_set_state_timeout(cp, IP_VS_S_UDP);
+		break;
+	case IPPROTO_ICMP:
+		ret = vs_set_state_timeout(cp, IP_VS_S_ICMP);
+		break;
+	default:
+		ret = -1;
+	}
+	spin_unlock(&cp->lock);
+
+	return ret;
+}
+
+
+/*
+ *	Set LISTEN timeout. (ip_vs_conn_put will setup timer)
+ */
+int ip_vs_conn_listen(struct ip_vs_conn *cp)
+{
+	vs_set_state_timeout(cp, IP_VS_S_LISTEN);
+	return cp->timeout;
+}
+
+
+/*
+ *      Bypass transmitter
+ *      Let packets bypass the destination when the destination is not
+ *      available, it may be only used in transparent cache cluster.
+ */
+static int ip_vs_bypass_xmit(struct sk_buff *skb, struct ip_vs_conn *cp)
+{
+	struct rtable *rt;			/* Route to the other host */
+	struct iphdr  *iph = skb->nh.iph;
+	u8     tos = iph->tos;
+	int    mtu;
+
+	EnterFunction(10);
+
+	if (ip_route_output(&rt, iph->daddr, 0, RT_TOS(tos), 0)) {
+		IP_VS_DBG_RL("ip_vs_bypass_xmit(): ip_route_output error, "
+			     "dest: %u.%u.%u.%u\n", NIPQUAD(iph->daddr));
+		goto tx_error_icmp;
+	}
+
+	/* MTU checking */
+	mtu = rt->u.dst.pmtu;
+	if ((skb->len > mtu) && (iph->frag_off&__constant_htons(IP_DF))) {
+		ip_rt_put(rt);
+		icmp_send(skb, ICMP_DEST_UNREACH,ICMP_FRAG_NEEDED, htonl(mtu));
+		IP_VS_DBG_RL("ip_vs_bypass_xmit(): frag needed\n");
+		goto tx_error;
+	}
+
+	/* update checksum because skb might be defragmented */
+	ip_send_check(iph);
+
+	if (unlikely(skb_headroom(skb) < rt->u.dst.dev->hard_header_len)) {
+		if (skb_cow(skb, rt->u.dst.dev->hard_header_len)) {
+			ip_rt_put(rt);
+			IP_VS_ERR_RL("ip_vs_bypass_xmit(): no memory\n");
+			goto tx_error;
+		}
+	}
+
+	/* drop old route */
+	dst_release(skb->dst);
+	skb->dst = &rt->u.dst;
+
+#ifdef CONFIG_NETFILTER_DEBUG
+	skb->nf_debug = 1 << NF_IP_LOCAL_OUT;
+#endif /* CONFIG_NETFILTER_DEBUG */
+	skb->nfcache |= NFC_IPVS_PROPERTY;
+	ip_send(skb);
+
+	LeaveFunction(10);
+	return NF_STOLEN;
+
+  tx_error_icmp:
+	dst_link_failure(skb);
+  tx_error:
+	kfree_skb(skb);
+	return NF_STOLEN;
+}
+
+
+/*
+ *      NULL transmitter (do nothing except return NF_ACCEPT)
+ */
+static int ip_vs_null_xmit(struct sk_buff *skb, struct ip_vs_conn *cp)
+{
+	return NF_ACCEPT;
+}
+
+
+/*
+ *      NAT transmitter (only for outside-to-inside nat forwarding)
+ */
+static int ip_vs_nat_xmit(struct sk_buff *skb, struct ip_vs_conn *cp)
+{
+	struct rtable *rt;		/* Route to the other host */
+	struct iphdr  *iph;
+	union ip_vs_tphdr h;
+	int ihl;
+	unsigned short size;
+	int mtu;
+
+	EnterFunction(10);
+
+	/*
+	 * If it has ip_vs_app helper, the helper may change the payload,
+	 * so it needs full checksum checking and checksum calculation.
+	 * If not, only the header (such as IP address and port number)
+	 * will be changed, so it is fast to do incremental checksum update,
+	 * and let the destination host  do final checksum checking.
+	 */
+
+	if (cp->app && skb_is_nonlinear(skb)
+	    && skb_linearize(skb, GFP_ATOMIC) != 0)
+		return NF_DROP;
+
+	iph = skb->nh.iph;
+	ihl = iph->ihl << 2;
+	h.raw = (char*) iph + ihl;
+	size = ntohs(iph->tot_len) - ihl;
+
+	/* do TCP/UDP checksum checking if it has application helper */
+	if (cp->app && (iph->protocol != IPPROTO_UDP || h.uh->check != 0)) {
+		switch (skb->ip_summed) {
+		case CHECKSUM_NONE:
+			skb->csum = csum_partial(h.raw, size, 0);
+
+		case CHECKSUM_HW:
+			if (csum_tcpudp_magic(iph->saddr, iph->daddr, size,
+					      iph->protocol, skb->csum)) {
+				IP_VS_DBG_RL("Incoming failed %s checksum "
+					     "from %d.%d.%d.%d (size=%d)!\n",
+					     ip_vs_proto_name(iph->protocol),
+					     NIPQUAD(iph->saddr),
+					     size);
+				goto tx_error;
+			}
+			break;
+		default:
+			/* CHECKSUM_UNNECESSARY */
+			break;
+		}
+	}
+
+	/*
+	 *  Check if it is no_cport connection ...
+	 */
+	if (cp->flags & IP_VS_CONN_F_NO_CPORT) {
+		atomic_dec(&ip_vs_conn_no_cport_cnt);
+		ip_vs_conn_unhash(cp);
+		cp->flags &= ~IP_VS_CONN_F_NO_CPORT;
+		cp->cport = h.portp[0];
+		/* hash on new dport */
+		ip_vs_conn_hash(cp);
+
+		IP_VS_DBG(10, "filled cport=%d\n", ntohs(cp->dport));
+	}
+
+	if (!(rt = __ip_vs_get_out_rt(cp, RT_TOS(iph->tos))))
+		goto tx_error_icmp;
+
+	/* MTU checking */
+	mtu = rt->u.dst.pmtu;
+	if ((skb->len > mtu) && (iph->frag_off&__constant_htons(IP_DF))) {
+		ip_rt_put(rt);
+		icmp_send(skb, ICMP_DEST_UNREACH,ICMP_FRAG_NEEDED, htonl(mtu));
+		IP_VS_DBG_RL("ip_vs_nat_xmit(): frag needed\n");
+		goto tx_error;
+	}
+
+	/* drop old route */
+	dst_release(skb->dst);
+	skb->dst = &rt->u.dst;
+
+	/* copy-on-write the packet before mangling it */
+	if (ip_vs_skb_cow(skb, rt->u.dst.dev->hard_header_len, &iph, &h.raw))
+		return NF_DROP;
+
+	/* mangle the packet */
+	iph->daddr = cp->daddr;
+	h.portp[1] = cp->dport;
+
+	/*
+	 *	Attempt ip_vs_app call.
+	 *	will fix ip_vs_conn and iph ack_seq stuff
+	 */
+	if (ip_vs_app_pkt_in(cp, skb) != 0) {
+		/* skb data has probably changed, update pointers */
+		iph = skb->nh.iph;
+		h.raw = (char*) iph + ihl;
+		size = skb->len - ihl;
+	}
+
+	/*
+	 *	Adjust TCP/UDP checksums
+	 */
+	if (!cp->app && (iph->protocol != IPPROTO_UDP || h.uh->check != 0)) {
+		/* Only port and addr are changed, do fast csum update */
+		ip_vs_fast_check_update(&h, cp->vaddr, cp->daddr,
+					cp->vport, cp->dport, iph->protocol);
+		if (skb->ip_summed == CHECKSUM_HW)
+			skb->ip_summed = CHECKSUM_NONE;
+	} else {
+		/* full checksum calculation */
+		switch (iph->protocol) {
+		case IPPROTO_TCP:
+			h.th->check = 0;
+			h.th->check = csum_tcpudp_magic(iph->saddr, iph->daddr,
+							size, iph->protocol,
+							csum_partial(h.raw, size, 0));
+			break;
+		case IPPROTO_UDP:
+			h.uh->check = 0;
+			h.uh->check = csum_tcpudp_magic(iph->saddr, iph->daddr,
+							size, iph->protocol,
+							csum_partial(h.raw, size, 0));
+			if (h.uh->check == 0)
+				h.uh->check = 0xFFFF;
+			break;
+		}
+		skb->ip_summed = CHECKSUM_UNNECESSARY;
+	}
+	ip_send_check(iph);
+
+	IP_VS_DBG(10, "NAT to %u.%u.%u.%u:%d\n",
+		  NIPQUAD(iph->daddr), ntohs(h.portp[1]));
+
+	/* FIXME: when application helper enlarges the packet and the length
+	   is larger than the MTU of outgoing device, there will be still
+	   MTU problem. */
+
+#ifdef CONFIG_NETFILTER_DEBUG
+	skb->nf_debug = 1 << NF_IP_LOCAL_OUT;
+#endif /* CONFIG_NETFILTER_DEBUG */
+	skb->nfcache |= NFC_IPVS_PROPERTY;
+	ip_send(skb);
+
+	LeaveFunction(10);
+	return NF_STOLEN;
+
+  tx_error_icmp:
+	dst_link_failure(skb);
+  tx_error:
+	kfree_skb(skb);
+	return NF_STOLEN;
+}
+
+
+/*
+ *   IP Tunneling transmitter
+ *
+ *   This function encapsulates the packet in a new IP packet, its
+ *   destination will be set to cp->daddr. Most code of this function
+ *   is taken from ipip.c.
+ *
+ *   It is used in VS/TUN cluster. The load balancer selects a real
+ *   server from a cluster based on a scheduling algorithm,
+ *   encapsulates the request packet and forwards it to the selected
+ *   server. For example, all real servers are configured with
+ *   "ifconfig tunl0 <Virtual IP Address> up". When the server receives
+ *   the encapsulated packet, it will decapsulate the packet, processe
+ *   the request and return the response packets directly to the client
+ *   without passing the load balancer. This can greatly increase the
+ *   scalability of virtual server.
+ */
+static int ip_vs_tunnel_xmit(struct sk_buff *skb, struct ip_vs_conn *cp)
+{
+	struct rtable *rt;			/* Route to the other host */
+	struct net_device *tdev;		/* Device to other host */
+	struct iphdr  *old_iph = skb->nh.iph;
+	u8     tos = old_iph->tos;
+	u16    df = old_iph->frag_off;
+	struct iphdr  *iph;			/* Our new IP header */
+	int    max_headroom;			/* The extra header space needed */
+	int    mtu;
+
+	EnterFunction(10);
+
+	if (skb->protocol != __constant_htons(ETH_P_IP)) {
+		IP_VS_DBG_RL("ip_vs_tunnel_xmit(): protocol error, "
+			     "ETH_P_IP: %d, skb protocol: %d\n",
+			     __constant_htons(ETH_P_IP), skb->protocol);
+		goto tx_error;
+	}
+
+	if (!(rt = __ip_vs_get_out_rt(cp, RT_TOS(tos))))
+		goto tx_error_icmp;
+
+	tdev = rt->u.dst.dev;
+
+	mtu = rt->u.dst.pmtu - sizeof(struct iphdr);
+	if (mtu < 68) {
+		ip_rt_put(rt);
+		IP_VS_DBG_RL("ip_vs_tunnel_xmit(): mtu less than 68\n");
+		goto tx_error;
+	}
+	if (skb->dst && mtu < skb->dst->pmtu)
+		skb->dst->pmtu = mtu;
+
+	df |= (old_iph->frag_off&__constant_htons(IP_DF));
+
+	if ((old_iph->frag_off&__constant_htons(IP_DF))
+	    && mtu < ntohs(old_iph->tot_len)) {
+		icmp_send(skb, ICMP_DEST_UNREACH,ICMP_FRAG_NEEDED, htonl(mtu));
+		ip_rt_put(rt);
+		IP_VS_DBG_RL("ip_vs_tunnel_xmit(): frag needed\n");
+		goto tx_error;
+	}
+
+	/* update checksum because skb might be defragmented */
+	ip_send_check(old_iph);
+
+	skb->h.raw = skb->nh.raw;
+
+	/*
+	 * Okay, now see if we can stuff it in the buffer as-is.
+	 */
+	max_headroom = (((tdev->hard_header_len+15)&~15)+sizeof(struct iphdr));
+
+	if (skb_headroom(skb) < max_headroom
+	    || skb_cloned(skb) || skb_shared(skb)) {
+		struct sk_buff *new_skb =
+			skb_realloc_headroom(skb, max_headroom);
+		if (!new_skb) {
+			ip_rt_put(rt);
+			kfree_skb(skb);
+			IP_VS_ERR_RL("ip_vs_tunnel_xmit(): no memory\n");
+			return -EINVAL;
+		}
+		kfree_skb(skb);
+		skb = new_skb;
+		old_iph = skb->nh.iph;
+	}
+
+	skb->nh.raw = skb_push(skb, sizeof(struct iphdr));
+	memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
+
+	/* drop old route */
+	dst_release(skb->dst);
+	skb->dst = &rt->u.dst;
+
+	/*
+	 *	Push down and install the IPIP header.
+	 */
+	iph			=	skb->nh.iph;
+	iph->version		=	4;
+	iph->ihl		=	sizeof(struct iphdr)>>2;
+	iph->frag_off		=	df;
+	iph->protocol		=	IPPROTO_IPIP;
+	iph->tos		=	tos;
+	iph->daddr		=	rt->rt_dst;
+	iph->saddr		=	rt->rt_src;
+	iph->ttl		=	old_iph->ttl;
+	iph->tot_len		=	htons(skb->len);
+	ip_select_ident(iph, &rt->u.dst, NULL);
+	ip_send_check(iph);
+
+	skb->ip_summed = CHECKSUM_NONE;
+#ifdef CONFIG_NETFILTER_DEBUG
+	skb->nf_debug = 1 << NF_IP_LOCAL_OUT;
+#endif /* CONFIG_NETFILTER_DEBUG */
+	skb->nfcache |= NFC_IPVS_PROPERTY;
+	ip_send(skb);
+
+	LeaveFunction(10);
+
+	return NF_STOLEN;
+
+  tx_error_icmp:
+	dst_link_failure(skb);
+  tx_error:
+	kfree_skb(skb);
+	return NF_STOLEN;
+}
+
+
+/*
+ *      Direct Routing transmitter
+ */
+static int ip_vs_dr_xmit(struct sk_buff *skb, struct ip_vs_conn *cp)
+{
+	struct rtable *rt;			/* Route to the other host */
+	struct iphdr  *iph = skb->nh.iph;
+	int    mtu;
+
+	EnterFunction(10);
+
+	if (!(rt = __ip_vs_get_out_rt(cp, RT_TOS(iph->tos))))
+		goto tx_error_icmp;
+
+	/* MTU checking */
+	mtu = rt->u.dst.pmtu;
+	if ((iph->frag_off&__constant_htons(IP_DF)) && skb->len > mtu) {
+		icmp_send(skb, ICMP_DEST_UNREACH,ICMP_FRAG_NEEDED, htonl(mtu));
+		ip_rt_put(rt);
+		IP_VS_DBG_RL("ip_vs_dr_xmit(): frag needed\n");
+		goto tx_error;
+	}
+
+	/* update checksum because skb might be defragmented */
+	ip_send_check(iph);
+
+	if (unlikely(skb_headroom(skb) < rt->u.dst.dev->hard_header_len)) {
+		if (skb_cow(skb, rt->u.dst.dev->hard_header_len)) {
+			ip_rt_put(rt);
+			IP_VS_ERR_RL("ip_vs_dr_xmit(): no memory\n");
+			goto tx_error;
+		}
+	}
+
+	/* drop old route */
+	dst_release(skb->dst);
+	skb->dst = &rt->u.dst;
+
+#ifdef CONFIG_NETFILTER_DEBUG
+	skb->nf_debug = 1 << NF_IP_LOCAL_OUT;
+#endif /* CONFIG_NETFILTER_DEBUG */
+	skb->nfcache |= NFC_IPVS_PROPERTY;
+	ip_send(skb);
+
+#if 0000
+	NF_HOOK(PF_INET, NF_IP_LOCAL_OUT, skb, NULL, rt->u.dst.dev,
+		do_ip_send);
+#endif
+	LeaveFunction(10);
+	return NF_STOLEN;
+
+  tx_error_icmp:
+	dst_link_failure(skb);
+  tx_error:
+	kfree_skb(skb);
+	return NF_STOLEN;
+}
+
+
+/*
+ *  Bind a connection entry with the corresponding packet_xmit.
+ *  Called by ip_vs_conn_new.
+ */
+static inline void ip_vs_bind_xmit(struct ip_vs_conn *cp)
+{
+	switch (IP_VS_FWD_METHOD(cp)) {
+	case IP_VS_CONN_F_MASQ:
+		cp->packet_xmit = ip_vs_nat_xmit;
+		break;
+
+	case IP_VS_CONN_F_TUNNEL:
+		cp->packet_xmit = ip_vs_tunnel_xmit;
+		break;
+
+	case IP_VS_CONN_F_DROUTE:
+		cp->packet_xmit = ip_vs_dr_xmit;
+		break;
+
+	case IP_VS_CONN_F_LOCALNODE:
+		cp->packet_xmit = ip_vs_null_xmit;
+		break;
+
+	case IP_VS_CONN_F_BYPASS:
+		cp->packet_xmit = ip_vs_bypass_xmit;
+		break;
+	}
+}
+
+
+/*
+ *  Bind a connection entry with a virtual service destination
+ *  Called just after a new connection entry is created.
+ */
+static inline void
+ip_vs_bind_dest(struct ip_vs_conn *cp, struct ip_vs_dest *dest)
+{
+	/* if dest is NULL, then return directly */
+	if (!dest)
+		return;
+
+	/* Increase the refcnt counter of the dest */
+	atomic_inc(&dest->refcnt);
+
+	/* Bind with the destination and its corresponding transmitter */
+	cp->flags |= atomic_read(&dest->conn_flags);
+	cp->dest = dest;
+
+	IP_VS_DBG(9, "Bind-dest %s c:%u.%u.%u.%u:%d v:%u.%u.%u.%u:%d "
+		  "d:%u.%u.%u.%u:%d fwd:%c s:%s flg:%X cnt:%d destcnt:%d\n",
+		  ip_vs_proto_name(cp->protocol),
+		  NIPQUAD(cp->caddr), ntohs(cp->cport),
+		  NIPQUAD(cp->vaddr), ntohs(cp->vport),
+		  NIPQUAD(cp->daddr), ntohs(cp->dport),
+		  ip_vs_fwd_tag(cp), ip_vs_state_name(cp->state),
+		  cp->flags, atomic_read(&cp->refcnt),
+		  atomic_read(&dest->refcnt));
+}
+
+
+/*
+ *  Unbind a connection entry with its VS destination
+ *  Called by the ip_vs_conn_expire function.
+ */
+static inline void ip_vs_unbind_dest(struct ip_vs_conn *cp)
+{
+	struct ip_vs_dest *dest = cp->dest;
+
+	/* if dest is NULL, then return directly */
+	if (!dest)
+		return;
+
+	IP_VS_DBG(9, "Unbind-dest %s c:%u.%u.%u.%u:%d "
+		  "v:%u.%u.%u.%u:%d d:%u.%u.%u.%u:%d fwd:%c "
+		  "s:%s flg:%X cnt:%d destcnt:%d",
+		  ip_vs_proto_name(cp->protocol),
+		  NIPQUAD(cp->caddr), ntohs(cp->cport),
+		  NIPQUAD(cp->vaddr), ntohs(cp->vport),
+		  NIPQUAD(cp->daddr), ntohs(cp->dport),
+		  ip_vs_fwd_tag(cp), ip_vs_state_name(cp->state),
+		  cp->flags, atomic_read(&cp->refcnt),
+		  atomic_read(&dest->refcnt));
+
+	/*
+	 * Decrease the inactconns or activeconns counter
+	 * if it is not a connection template ((cp->cport!=0)
+	 *   || (cp->flags & IP_VS_CONN_F_NO_CPORT)).
+	 */
+	if (cp->cport || (cp->flags & IP_VS_CONN_F_NO_CPORT)) {
+		if (cp->flags & IP_VS_CONN_F_INACTIVE) {
+			atomic_dec(&dest->inactconns);
+		} else {
+			atomic_dec(&dest->activeconns);
+		}
+	}
+
+	/*
+	 * Simply decrease the refcnt of the dest, because the
+	 * dest will be either in service's destination list
+	 * or in the trash.
+	 */
+	atomic_dec(&dest->refcnt);
+}
+
+
+/*
+ *  Checking if the destination of a connection template is available.
+ *  If available, return 1, otherwise invalidate this connection
+ *  template and return 0.
+ */
+int ip_vs_check_template(struct ip_vs_conn *ct)
+{
+	struct ip_vs_dest *dest = ct->dest;
+
+	/*
+	 * Checking the dest server status.
+	 */
+	if ((dest == NULL) ||
+	    !(dest->flags & IP_VS_DEST_F_AVAILABLE)) {
+		IP_VS_DBG(9, "check_template: dest not available for "
+			  "protocol %s s:%u.%u.%u.%u:%d v:%u.%u.%u.%u:%d "
+			  "-> d:%u.%u.%u.%u:%d\n",
+			  ip_vs_proto_name(ct->protocol),
+			  NIPQUAD(ct->caddr), ntohs(ct->cport),
+			  NIPQUAD(ct->vaddr), ntohs(ct->vport),
+			  NIPQUAD(ct->daddr), ntohs(ct->dport));
+
+		/*
+		 * Invalidate the connection template
+		 */
+		ip_vs_conn_unhash(ct);
+		ct->dport = 65535;
+		ct->vport = 65535;
+		ct->cport = 0;
+		ip_vs_conn_hash(ct);
+
+		/*
+		 * Simply decrease the refcnt of the template,
+		 * don't restart its timer.
+		 */
+		atomic_dec(&ct->refcnt);
+		return 0;
+	}
+	return 1;
+}
+
+
+static inline void
+ip_vs_timeout_attach(struct ip_vs_conn *cp, struct ip_vs_timeout_table *vstim)
+{
+	atomic_inc(&vstim->refcnt);
+	cp->timeout_table = vstim;
+}
+
+static inline void ip_vs_timeout_detach(struct ip_vs_conn *cp)
+{
+	struct ip_vs_timeout_table *vstim = cp->timeout_table;
+
+	if (!vstim)
+		return;
+	cp->timeout_table = NULL;
+	atomic_dec(&vstim->refcnt);
+}
+
+
+static void ip_vs_conn_expire(unsigned long data)
+{
+	struct ip_vs_conn *cp = (struct ip_vs_conn *)data;
+
+	if (cp->timeout_table)
+		cp->timeout = cp->timeout_table->timeout[IP_VS_S_TIME_WAIT];
+	else
+		cp->timeout = vs_timeout_table.timeout[IP_VS_S_TIME_WAIT];
+
+	/*
+	 *	hey, I'm using it
+	 */
+	atomic_inc(&cp->refcnt);
+
+	/*
+	 *	do I control anybody?
+	 */
+	if (atomic_read(&cp->n_control))
+		goto expire_later;
+
+	/*
+	 *	unhash it if it is hashed in the conn table
+	 */
+	ip_vs_conn_unhash(cp);
+
+	/*
+	 *	refcnt==1 implies I'm the only one referrer
+	 */
+	if (likely(atomic_read(&cp->refcnt) == 1)) {
+		/* make sure that there is no timer on it now */
+		if (timer_pending(&cp->timer))
+			del_timer(&cp->timer);
+
+		/* does anybody control me? */
+		if (cp->control)
+			ip_vs_control_del(cp);
+
+		ip_vs_unbind_dest(cp);
+		ip_vs_unbind_app(cp);
+		ip_vs_timeout_detach(cp);
+		if (cp->flags & IP_VS_CONN_F_NO_CPORT)
+			atomic_dec(&ip_vs_conn_no_cport_cnt);
+		atomic_dec(&ip_vs_conn_count);
+
+		kmem_cache_free(ip_vs_conn_cachep, cp);
+		return;
+	}
+
+	/* hash it back to the table */
+	ip_vs_conn_hash(cp);
+
+  expire_later:
+	IP_VS_DBG(7, "delayed: refcnt-1=%d conn.n_control=%d\n",
+		  atomic_read(&cp->refcnt)-1,
+		  atomic_read(&cp->n_control));
+
+	ip_vs_conn_put(cp);
+}
+
+
+void ip_vs_conn_expire_now(struct ip_vs_conn *cp)
+{
+	cp->timeout = 0;
+	mod_timer(&cp->timer, jiffies);
+	__ip_vs_conn_put(cp);
+}
+
+/*
+ *  Create a new connection entry and hash it into the ip_vs_conn_tab.
+ */
+struct ip_vs_conn *
+ip_vs_conn_new(int proto, __u32 caddr, __u16 cport, __u32 vaddr, __u16 vport,
+	       __u32 daddr, __u16 dport, unsigned flags,
+	       struct ip_vs_dest *dest)
+{
+	struct ip_vs_conn *cp;
+
+	cp = kmem_cache_alloc(ip_vs_conn_cachep, GFP_ATOMIC);
+	if (cp == NULL) {
+		IP_VS_ERR_RL("ip_vs_conn_new: no memory available.\n");
+		return NULL;
+	}
+
+	memset(cp, 0, sizeof(*cp));
+	INIT_LIST_HEAD(&cp->c_list);
+	init_timer(&cp->timer);
+	cp->timer.data     = (unsigned long)cp;
+	cp->timer.function = ip_vs_conn_expire;
+	ip_vs_timeout_attach(cp, ip_vs_timeout_table);
+	cp->protocol	   = proto;
+	cp->caddr	   = caddr;
+	cp->cport	   = cport;
+	cp->vaddr	   = vaddr;
+	cp->vport	   = vport;
+	cp->daddr          = daddr;
+	cp->dport          = dport;
+	cp->flags	   = flags;
+	cp->app_data	   = NULL;
+	cp->control	   = NULL;
+	cp->lock           = SPIN_LOCK_UNLOCKED;
+
+	atomic_set(&cp->n_control, 0);
+	atomic_set(&cp->in_pkts, 0);
+
+	atomic_inc(&ip_vs_conn_count);
+	if (flags & IP_VS_CONN_F_NO_CPORT)
+		atomic_inc(&ip_vs_conn_no_cport_cnt);
+
+	/* Bind its application helper (only for VS/NAT) if any */
+	ip_vs_bind_app(cp);
+
+	/* Bind the connection with a destination server */
+	ip_vs_bind_dest(cp, dest);
+
+	/* Set its state and timeout */
+	vs_set_state_timeout(cp, IP_VS_S_NONE);
+
+	/* Bind its packet transmitter */
+	ip_vs_bind_xmit(cp);
+
+	/*
+	 * Set the entry is referenced by the current thread before hashing
+	 * it in the table, so that other thread run ip_vs_random_dropentry
+	 * but cannot drop this entry.
+	 */
+	atomic_set(&cp->refcnt, 1);
+
+	/* Hash it in the ip_vs_conn_tab finally */
+	ip_vs_conn_hash(cp);
+
+	return cp;
+}
+
+
+/*
+ *	/proc/net/ip_vs_conn entries
+ */
+static int
+ip_vs_conn_getinfo(char *buffer, char **start, off_t offset, int length)
+{
+	off_t pos=0;
+	int idx, len=0;
+	char temp[70];
+	struct ip_vs_conn *cp;
+	struct list_head *l, *e;
+
+	pos = 128;
+	if (pos > offset) {
+		len += sprintf(buffer+len, "%-127s\n",
+			       "Pro FromIP   FPrt ToIP     TPrt DestIP   DPrt State       Expires");
+	}
+
+	for(idx = 0; idx < IP_VS_CONN_TAB_SIZE; idx++) {
+		/*
+		 *	Lock is actually only need in next loop
+		 *	we are called from uspace: must stop bh.
+		 */
+		ct_read_lock_bh(idx);
+
+		l = &ip_vs_conn_tab[idx];
+		for (e=l->next; e!=l; e=e->next) {
+			cp = list_entry(e, struct ip_vs_conn, c_list);
+			pos += 128;
+			if (pos <= offset)
+				continue;
+			sprintf(temp,
+				"%-3s %08X %04X %08X %04X %08X %04X %-11s %7lu",
+				ip_vs_proto_name(cp->protocol),
+				ntohl(cp->caddr), ntohs(cp->cport),
+				ntohl(cp->vaddr), ntohs(cp->vport),
+				ntohl(cp->daddr), ntohs(cp->dport),
+				ip_vs_state_name(cp->state),
+				(cp->timer.expires-jiffies)/HZ);
+			len += sprintf(buffer+len, "%-127s\n", temp);
+			if (pos >= offset+length) {
+				ct_read_unlock_bh(idx);
+				goto done;
+			}
+		}
+		ct_read_unlock_bh(idx);
+	}
+
+  done:
+	*start = buffer+len-(pos-offset);       /* Start of wanted data */
+	len = pos-offset;
+	if (len > length)
+		len = length;
+	if (len < 0)
+		len = 0;
+	return len;
+}
+
+
+/*
+ *      Randomly drop connection entries before running out of memory
+ */
+static inline int todrop_entry(struct ip_vs_conn *cp)
+{
+	/*
+	 * The drop rate array needs tuning for real environments.
+	 * Called from timer bh only => no locking
+	 */
+	static char todrop_rate[9] = {0, 1, 2, 3, 4, 5, 6, 7, 8};
+	static char todrop_counter[9] = {0};
+	int i;
+
+	/* if the conn entry hasn't lasted for 60 seconds, don't drop it.
+	   This will leave enough time for normal connection to get
+	   through. */
+	if (cp->timeout+jiffies-cp->timer.expires < 60*HZ)
+		return 0;
+
+	/* Don't drop the entry if its number of incoming packets is not
+	   located in [0, 8] */
+	i = atomic_read(&cp->in_pkts);
+	if (i > 8 || i < 0) return 0;
+
+	if (!todrop_rate[i]) return 0;
+	if (--todrop_counter[i] > 0) return 0;
+
+	todrop_counter[i] = todrop_rate[i];
+	return 1;
+}
+
+
+void ip_vs_random_dropentry(void)
+{
+	int idx;
+	struct ip_vs_conn *cp;
+	struct list_head *l,*e;
+	struct ip_vs_conn *ct;
+
+	/*
+	 * Randomly scan 1/32 of the whole table every second
+	 */
+	for (idx=0; idx<(IP_VS_CONN_TAB_SIZE>>5); idx++) {
+		unsigned hash = net_random()&IP_VS_CONN_TAB_MASK;
+
+		/*
+		 *  Lock is actually needed in this loop.
+		 */
+		ct_write_lock(hash);
+
+		l = &ip_vs_conn_tab[hash];
+		for (e=l->next; e!=l; e=e->next) {
+			cp = list_entry(e, struct ip_vs_conn, c_list);
+			if (!cp->cport && !(cp->flags & IP_VS_CONN_F_NO_CPORT))
+				/* connection template */
+				continue;
+			switch(cp->state) {
+			case IP_VS_S_SYN_RECV:
+			case IP_VS_S_SYNACK:
+				break;
+
+			case IP_VS_S_ESTABLISHED:
+			case IP_VS_S_UDP:
+				if (todrop_entry(cp))
+					break;
+				continue;
+
+			default:
+				continue;
+			}
+
+			/*
+			 * Drop the entry, and drop its ct if not referenced
+			 */
+			atomic_inc(&cp->refcnt);
+			ct_write_unlock(hash);
+
+			if ((ct = cp->control))
+				atomic_inc(&ct->refcnt);
+			IP_VS_DBG(4, "del connection\n");
+			ip_vs_conn_expire_now(cp);
+			if (ct) {
+				IP_VS_DBG(4, "del conn template\n");
+				ip_vs_conn_expire_now(ct);
+			}
+			ct_write_lock(hash);
+		}
+		ct_write_unlock(hash);
+	}
+}
+
+
+/*
+ *      Flush all the connection entries in the ip_vs_conn_tab
+ */
+static void ip_vs_conn_flush(void)
+{
+	int idx;
+	struct ip_vs_conn *cp;
+	struct list_head *l,*e;
+	struct ip_vs_conn *ct;
+
+  flush_again:
+	for (idx=0; idx<IP_VS_CONN_TAB_SIZE; idx++) {
+		/*
+		 *  Lock is actually needed in this loop.
+		 */
+		ct_write_lock_bh(idx);
+
+		l = &ip_vs_conn_tab[idx];
+		for (e=l->next; e!=l; e=e->next) {
+			cp = list_entry(e, struct ip_vs_conn, c_list);
+			atomic_inc(&cp->refcnt);
+			ct_write_unlock(idx);
+
+			if ((ct = cp->control))
+				atomic_inc(&ct->refcnt);
+			IP_VS_DBG(4, "del connection\n");
+			ip_vs_conn_expire_now(cp);
+			if (ct) {
+				IP_VS_DBG(4, "del conn template\n");
+				ip_vs_conn_expire_now(ct);
+			}
+			ct_write_lock(idx);
+		}
+		ct_write_unlock_bh(idx);
+	}
+
+	/* the counter may be not NULL, because maybe some conn entries
+	   are run by slow timer handler or unhashed but still referred */
+	if (atomic_read(&ip_vs_conn_count) != 0) {
+		schedule();
+		goto flush_again;
+	}
+}
+
+
+int ip_vs_conn_init(void)
+{
+	int idx;
+
+	/*
+	 * Allocate the connection hash table and initialize its list heads
+	 */
+	ip_vs_conn_tab = vmalloc(IP_VS_CONN_TAB_SIZE*sizeof(struct list_head));
+	if (!ip_vs_conn_tab)
+		return -ENOMEM;
+
+	IP_VS_INFO("Connection hash table configured "
+		   "(size=%d, memory=%ldKbytes)\n",
+		   IP_VS_CONN_TAB_SIZE,
+		   (long)(IP_VS_CONN_TAB_SIZE*sizeof(struct list_head))/1024);
+	IP_VS_DBG(0, "Each connection entry needs %d bytes at least\n",
+		  sizeof(struct ip_vs_conn));
+
+	for (idx = 0; idx < IP_VS_CONN_TAB_SIZE; idx++) {
+		INIT_LIST_HEAD(&ip_vs_conn_tab[idx]);
+	}
+
+	for (idx = 0; idx < CT_LOCKARRAY_SIZE; idx++)  {
+		__ip_vs_conntbl_lock_array[idx].l = RW_LOCK_UNLOCKED;
+	}
+
+	/* Allocate ip_vs_conn slab cache */
+	ip_vs_conn_cachep = kmem_cache_create("ip_vs_conn",
+					      sizeof(struct ip_vs_conn), 0,
+					      SLAB_HWCACHE_ALIGN, NULL, NULL);
+	if (!ip_vs_conn_cachep) {
+		vfree(ip_vs_conn_tab);
+		return -ENOMEM;
+	}
+
+	proc_net_create("ip_vs_conn", 0, ip_vs_conn_getinfo);
+
+	/* calculate the random value for connection hash */
+	get_random_bytes(&ip_vs_conn_rnd, sizeof(ip_vs_conn_rnd));
+
+	return 0;
+}
+
+void ip_vs_conn_cleanup(void)
+{
+	/* flush all the connection entries first */
+	ip_vs_conn_flush();
+
+	/* Release the empty cache */
+	kmem_cache_destroy(ip_vs_conn_cachep);
+	proc_net_remove("ip_vs_conn");
+	vfree(ip_vs_conn_tab);
+}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_core.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_core.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_core.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_core.c	2003-08-27 14:39:36.000000000 +0000
@@ -0,0 +1,1284 @@
+/*
+ * IPVS         An implementation of the IP virtual server support for the
+ *              LINUX operating system.  IPVS is now implemented as a module
+ *              over the Netfilter framework. IPVS can be used to build a
+ *              high-performance and highly available server based on a
+ *              cluster of servers.
+ *
+ * Version:     $Id: ip_vs_core.c,v 1.31.2.5 2003/07/29 14:37:12 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *              Peter Kese <peter.kese@ijs.si>
+ *              Julian Anastasov <ja@ssi.bg>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * The IPVS code for kernel 2.2 was done by Wensong Zhang and Peter Kese,
+ * with changes/fixes from Julian Anastasov, Lars Marowsky-Bree, Horms
+ * and others.
+ *
+ * Changes:
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/ip.h>
+#include <linux/tcp.h>
+#include <linux/icmp.h>
+
+#include <net/ip.h>
+#include <net/tcp.h>
+#include <net/udp.h>
+#include <net/icmp.h>                   /* for icmp_send */
+#include <net/route.h>
+
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+
+#include <net/ip_vs.h>
+
+
+EXPORT_SYMBOL(register_ip_vs_scheduler);
+EXPORT_SYMBOL(unregister_ip_vs_scheduler);
+EXPORT_SYMBOL(ip_vs_skb_replace);
+EXPORT_SYMBOL(ip_vs_proto_name);
+EXPORT_SYMBOL(ip_vs_conn_new);
+EXPORT_SYMBOL(ip_vs_conn_in_get);
+EXPORT_SYMBOL(ip_vs_conn_out_get);
+EXPORT_SYMBOL(ip_vs_conn_listen);
+EXPORT_SYMBOL(ip_vs_conn_put);
+#ifdef CONFIG_IP_VS_DEBUG
+EXPORT_SYMBOL(ip_vs_get_debug_level);
+#endif
+EXPORT_SYMBOL(check_for_ip_vs_out);
+
+
+/* ID used in ICMP lookups */
+#define icmp_id(icmph)          ((icmph->un).echo.id)
+
+const char *ip_vs_proto_name(unsigned proto)
+{
+	static char buf[20];
+
+	switch (proto) {
+	case IPPROTO_IP:
+		return "IP";
+	case IPPROTO_UDP:
+		return "UDP";
+	case IPPROTO_TCP:
+		return "TCP";
+	case IPPROTO_ICMP:
+		return "ICMP";
+	default:
+		sprintf(buf, "IP_%d", proto);
+		return buf;
+	}
+}
+
+
+static inline void
+ip_vs_in_stats(struct ip_vs_conn *cp, struct sk_buff *skb)
+{
+	struct ip_vs_dest *dest = cp->dest;
+	if (dest && (dest->flags & IP_VS_DEST_F_AVAILABLE)) {
+		spin_lock(&dest->stats.lock);
+		dest->stats.inpkts++;
+		dest->stats.inbytes += skb->len;
+		spin_unlock(&dest->stats.lock);
+
+		spin_lock(&dest->svc->stats.lock);
+		dest->svc->stats.inpkts++;
+		dest->svc->stats.inbytes += skb->len;
+		spin_unlock(&dest->svc->stats.lock);
+
+		spin_lock(&ip_vs_stats.lock);
+		ip_vs_stats.inpkts++;
+		ip_vs_stats.inbytes += skb->len;
+		spin_unlock(&ip_vs_stats.lock);
+	}
+}
+
+
+static inline void
+ip_vs_out_stats(struct ip_vs_conn *cp, struct sk_buff *skb)
+{
+	struct ip_vs_dest *dest = cp->dest;
+	if (dest && (dest->flags & IP_VS_DEST_F_AVAILABLE)) {
+		spin_lock(&dest->stats.lock);
+		dest->stats.outpkts++;
+		dest->stats.outbytes += skb->len;
+		spin_unlock(&dest->stats.lock);
+
+		spin_lock(&dest->svc->stats.lock);
+		dest->svc->stats.outpkts++;
+		dest->svc->stats.outbytes += skb->len;
+		spin_unlock(&dest->svc->stats.lock);
+
+		spin_lock(&ip_vs_stats.lock);
+		ip_vs_stats.outpkts++;
+		ip_vs_stats.outbytes += skb->len;
+		spin_unlock(&ip_vs_stats.lock);
+	}
+}
+
+
+static inline void
+ip_vs_conn_stats(struct ip_vs_conn *cp, struct ip_vs_service *svc)
+{
+	spin_lock(&cp->dest->stats.lock);
+	cp->dest->stats.conns++;
+	spin_unlock(&cp->dest->stats.lock);
+
+	spin_lock(&svc->stats.lock);
+	svc->stats.conns++;
+	spin_unlock(&svc->stats.lock);
+
+	spin_lock(&ip_vs_stats.lock);
+	ip_vs_stats.conns++;
+	spin_unlock(&ip_vs_stats.lock);
+}
+
+/*
+ *  IPVS persistent scheduling function
+ *  It creates a connection entry according to its template if exists,
+ *  or selects a server and creates a connection entry plus a template.
+ *  Locking: we are svc user (svc->refcnt), so we hold all dests too
+ */
+static struct ip_vs_conn *
+ip_vs_sched_persist(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	struct ip_vs_conn *cp = NULL;
+	struct ip_vs_dest *dest;
+	const __u16 *portp;
+	struct ip_vs_conn *ct;
+	__u16  dport;	 /* destination port to forward */
+	__u32  snet;	 /* source network of the client, after masking */
+
+	portp = (__u16 *)&(((char *)iph)[iph->ihl*4]);
+
+	/* Mask saddr with the netmask to adjust template granularity */
+	snet = iph->saddr & svc->netmask;
+
+	IP_VS_DBG(6, "P-schedule: src %u.%u.%u.%u:%u dest %u.%u.%u.%u:%u "
+		  "mnet %u.%u.%u.%u\n",
+		  NIPQUAD(iph->saddr), ntohs(portp[0]),
+		  NIPQUAD(iph->daddr), ntohs(portp[1]),
+		  NIPQUAD(snet));
+
+	/*
+	 * As far as we know, FTP is a very complicated network protocol, and
+	 * it uses control connection and data connections. For active FTP,
+	 * FTP server initialize data connection to the client, its source port
+	 * is often 20. For passive FTP, FTP server tells the clients the port
+	 * that it passively listens to,  and the client issues the data
+	 * connection. In the tunneling or direct routing mode, the load
+	 * balancer is on the client-to-server half of connection, the port
+	 * number is unknown to the load balancer. So, a conn template like
+	 * <caddr, 0, vaddr, 0, daddr, 0> is created for persistent FTP
+	 * service, and a template like <caddr, 0, vaddr, vport, daddr, dport>
+	 * is created for other persistent services.
+	 */
+	if (portp[1] == svc->port) {
+		/* Check if a template already exists */
+		if (svc->port != FTPPORT)
+			ct = ip_vs_conn_in_get(iph->protocol, snet, 0,
+					       iph->daddr, portp[1]);
+		else
+			ct = ip_vs_conn_in_get(iph->protocol, snet, 0,
+					       iph->daddr, 0);
+
+		if (!ct || !ip_vs_check_template(ct)) {
+			/*
+			 * No template found or the dest of the connection
+			 * template is not available.
+			 */
+			dest = svc->scheduler->schedule(svc, iph);
+			if (dest == NULL) {
+				IP_VS_DBG(1, "P-schedule: no dest found.\n");
+				return NULL;
+			}
+
+			/*
+			 * Create a template like <protocol,caddr,0,
+			 * vaddr,vport,daddr,dport> for non-ftp service,
+			 * and <protocol,caddr,0,vaddr,0,daddr,0>
+			 * for ftp service.
+			 */
+			if (svc->port != FTPPORT)
+				ct = ip_vs_conn_new(iph->protocol,
+						    snet, 0,
+						    iph->daddr, portp[1],
+						    dest->addr, dest->port,
+						    0,
+						    dest);
+			else
+				ct = ip_vs_conn_new(iph->protocol,
+						    snet, 0,
+						    iph->daddr, 0,
+						    dest->addr, 0,
+						    0,
+						    dest);
+			if (ct == NULL)
+				return NULL;
+
+			ct->timeout = svc->timeout;
+		} else {
+			/* set destination with the found template */
+			dest = ct->dest;
+		}
+		dport = dest->port;
+	} else {
+		/*
+		 * Note: persistent fwmark-based services and persistent
+		 * port zero service are handled here.
+		 * fwmark template: <IPPROTO_IP,caddr,0,fwmark,0,daddr,0>
+		 * port zero template: <protocol,caddr,0,vaddr,0,daddr,0>
+		 */
+		if (svc->fwmark)
+			ct = ip_vs_conn_in_get(IPPROTO_IP, snet, 0,
+					       htonl(svc->fwmark), 0);
+		else
+			ct = ip_vs_conn_in_get(iph->protocol, snet, 0,
+					       iph->daddr, 0);
+
+		if (!ct || !ip_vs_check_template(ct)) {
+			/*
+			 * If it is not persistent port zero, return NULL,
+			 * otherwise create a connection template.
+			 */
+			if (svc->port)
+				return NULL;
+
+			dest = svc->scheduler->schedule(svc, iph);
+			if (dest == NULL) {
+				IP_VS_DBG(1, "P-schedule: no dest found.\n");
+				return NULL;
+			}
+
+			/*
+			 * Create a template according to the service
+			 */
+			if (svc->fwmark)
+				ct = ip_vs_conn_new(IPPROTO_IP,
+						    snet, 0,
+						    htonl(svc->fwmark), 0,
+						    dest->addr, 0,
+						    0,
+						    dest);
+			else
+				ct = ip_vs_conn_new(iph->protocol,
+						    snet, 0,
+						    iph->daddr, 0,
+						    dest->addr, 0,
+						    0,
+						    dest);
+			if (ct == NULL)
+				return NULL;
+
+			ct->timeout = svc->timeout;
+		} else {
+			/* set destination with the found template */
+			dest = ct->dest;
+		}
+		dport = portp[1];
+	}
+
+	/*
+	 *    Create a new connection according to the template
+	 */
+	cp = ip_vs_conn_new(iph->protocol,
+			    iph->saddr, portp[0],
+			    iph->daddr, portp[1],
+			    dest->addr, dport,
+			    0,
+			    dest);
+	if (cp == NULL) {
+		ip_vs_conn_put(ct);
+		return NULL;
+	}
+
+	/*
+	 *    Increase the inactive connection counter
+	 *    because it is in Syn-Received
+	 *    state (inactive) when the connection is created.
+	 */
+	atomic_inc(&dest->inactconns);
+
+	/*
+	 *    Add its control
+	 */
+	ip_vs_control_add(cp, ct);
+
+	ip_vs_conn_put(ct);
+	return cp;
+}
+
+
+/*
+ *  IPVS main scheduling function
+ *  It selects a server according to the virtual service, and
+ *  creates a connection entry.
+ */
+static struct ip_vs_conn *
+ip_vs_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	struct ip_vs_conn *cp = NULL;
+	struct ip_vs_dest *dest;
+	const __u16 *portp;
+
+	/*
+	 *    Persistent service
+	 */
+	if (svc->flags & IP_VS_SVC_F_PERSISTENT)
+		return ip_vs_sched_persist(svc, iph);
+
+	/*
+	 *    Non-persistent service
+	 */
+	portp = (__u16 *)&(((char *)iph)[iph->ihl*4]);
+	if (!svc->fwmark && portp[1] != svc->port) {
+		if (!svc->port)
+			IP_VS_ERR("Schedule: port zero only supported "
+				  "in persistent services, "
+				  "check your ipvs configuration\n");
+		return NULL;
+	}
+
+	dest = svc->scheduler->schedule(svc, iph);
+	if (dest == NULL) {
+		IP_VS_DBG(1, "Schedule: no dest found.\n");
+		return NULL;
+	}
+
+	/*
+	 *    Create a connection entry.
+	 */
+	cp = ip_vs_conn_new(iph->protocol,
+			    iph->saddr, portp[0],
+			    iph->daddr, portp[1],
+			    dest->addr, dest->port?dest->port:portp[1],
+			    0,
+			    dest);
+	if (cp == NULL)
+		return NULL;
+
+	/*
+	 *    Increase the inactive connection counter because it is in
+	 *    Syn-Received state (inactive) when the connection is created.
+	 */
+	atomic_inc(&dest->inactconns);
+
+	IP_VS_DBG(6, "Schedule fwd:%c s:%s c:%u.%u.%u.%u:%u v:%u.%u.%u.%u:%u "
+		  "d:%u.%u.%u.%u:%u flg:%X cnt:%d\n",
+		  ip_vs_fwd_tag(cp), ip_vs_state_name(cp->state),
+		  NIPQUAD(cp->caddr), ntohs(cp->cport),
+		  NIPQUAD(cp->vaddr), ntohs(cp->vport),
+		  NIPQUAD(cp->daddr), ntohs(cp->dport),
+		  cp->flags, atomic_read(&cp->refcnt));
+
+	return cp;
+}
+
+
+/*
+ *  Pass or drop the packet.
+ *  Called by ip_vs_in, when the virtual service is available but
+ *  no destination is available for a new connection.
+ */
+static int ip_vs_leave(struct ip_vs_service *svc, struct sk_buff *skb)
+{
+	struct iphdr *iph = skb->nh.iph;
+	__u16 *portp = (__u16 *)&(((char *)iph)[iph->ihl*4]);
+
+	/* if it is fwmark-based service, the cache_bypass sysctl is up
+	   and the destination is RTN_UNICAST (and not local), then create
+	   a cache_bypass connection entry */
+	if (sysctl_ip_vs_cache_bypass && svc->fwmark
+	    && (inet_addr_type(iph->daddr) == RTN_UNICAST)) {
+		int ret;
+		struct ip_vs_conn *cp;
+
+		ip_vs_service_put(svc);
+
+		/* create a new connection entry */
+		IP_VS_DBG(6, "ip_vs_leave: create a cache_bypass entry\n");
+		cp = ip_vs_conn_new(iph->protocol,
+				    iph->saddr, portp[0],
+				    iph->daddr, portp[1],
+				    0, 0,
+				    IP_VS_CONN_F_BYPASS,
+				    NULL);
+		if (cp == NULL) {
+			kfree_skb(skb);
+			return NF_STOLEN;
+		}
+
+		/* statistics */
+		ip_vs_in_stats(cp, skb);
+
+		/* set state */
+		ip_vs_set_state(cp, VS_STATE_INPUT, iph, portp);
+
+		/* transmit the first SYN packet */
+		ret = cp->packet_xmit(skb, cp);
+
+		atomic_inc(&cp->in_pkts);
+		ip_vs_conn_put(cp);
+		return ret;
+	}
+
+	/*
+	 * When the virtual ftp service is presented, packets destined
+	 * for other services on the VIP may get here (except services
+	 * listed in the ipvs table), pass the packets, because it is
+	 * not ipvs job to decide to drop the packets.
+	 */
+	if ((svc->port == FTPPORT) && (portp[1] != FTPPORT)) {
+		ip_vs_service_put(svc);
+		return NF_ACCEPT;
+	}
+
+	ip_vs_service_put(svc);
+
+	/*
+	 * Notify the client that the destination is unreachable, and
+	 * release the socket buffer.
+	 * Since it is in IP layer, the TCP socket is not actually
+	 * created, the TCP RST packet cannot be sent, instead that
+	 * ICMP_PORT_UNREACH is sent here no matter it is TCP/UDP. --WZ
+	 */
+	icmp_send(skb, ICMP_DEST_UNREACH, ICMP_PORT_UNREACH, 0);
+	kfree_skb(skb);
+	return NF_STOLEN;
+}
+
+
+/*
+ *      It is hooked before NF_IP_PRI_NAT_SRC at the NF_IP_POST_ROUTING
+ *      chain, and is used for VS/NAT.
+ *      It detects packets for VS/NAT connections and sends the packets
+ *      immediately. This can avoid that iptable_nat mangles the packets
+ *      for VS/NAT.
+ */
+static unsigned int ip_vs_post_routing(unsigned int hooknum,
+				       struct sk_buff **skb_p,
+				       const struct net_device *in,
+				       const struct net_device *out,
+				       int (*okfn)(struct sk_buff *))
+{
+	struct sk_buff  *skb = *skb_p;
+
+	if (!(skb->nfcache & NFC_IPVS_PROPERTY))
+		return NF_ACCEPT;
+
+	/* The packet was sent from IPVS, exit this chain */
+	(*okfn)(skb);
+
+	return NF_STOLEN;
+}
+
+
+/*
+ *	Handle ICMP messages in the inside-to-outside direction (outgoing).
+ *	Find any that might be relevant, check against existing connections,
+ *	forward to the right destination host if relevant.
+ *	Currently handles error types - unreachable, quench, ttl exceeded.
+ *      (Only used in VS/NAT)
+ */
+static int ip_vs_out_icmp(struct sk_buff **skb_p)
+{
+	struct sk_buff	*skb   = *skb_p;
+	struct iphdr	*iph;
+	struct icmphdr	*icmph;
+	struct iphdr	*ciph;	/* The ip header contained within the ICMP */
+	__u16		*pptr;	/* port numbers from TCP/UDP contained header */
+	unsigned short	ihl;
+	unsigned short	len;
+	unsigned short	clen, csize;
+	struct ip_vs_conn *cp;
+
+	/* reassemble IP fragments, but will it happen in ICMP packets?? */
+	if (skb->nh.iph->frag_off & __constant_htons(IP_MF|IP_OFFSET)) {
+		skb = ip_defrag(skb);
+		if (!skb)
+			return NF_STOLEN;
+		*skb_p = skb;
+	}
+
+	if (skb_is_nonlinear(skb)) {
+		if (skb_linearize(skb, GFP_ATOMIC) != 0)
+			return NF_DROP;
+		ip_send_check(skb->nh.iph);
+	}
+
+	iph = skb->nh.iph;
+	ihl = iph->ihl << 2;
+	icmph = (struct icmphdr *)((char *)iph + ihl);
+	len   = ntohs(iph->tot_len) - ihl;
+	if (len < sizeof(struct icmphdr))
+		return NF_DROP;
+
+	IP_VS_DBG(12, "outgoing ICMP (%d,%d) %u.%u.%u.%u->%u.%u.%u.%u\n",
+		  icmph->type, ntohs(icmp_id(icmph)),
+		  NIPQUAD(iph->saddr), NIPQUAD(iph->daddr));
+
+	/*
+	 * Work through seeing if this is for us.
+	 * These checks are supposed to be in an order that means easy
+	 * things are checked first to speed up processing.... however
+	 * this means that some packets will manage to get a long way
+	 * down this stack and then be rejected, but that's life.
+	 */
+	if ((icmph->type != ICMP_DEST_UNREACH) &&
+	    (icmph->type != ICMP_SOURCE_QUENCH) &&
+	    (icmph->type != ICMP_TIME_EXCEEDED))
+		return NF_ACCEPT;
+
+	/* Now find the contained IP header */
+	clen = len - sizeof(struct icmphdr);
+	if (clen < sizeof(struct iphdr))
+		return NF_DROP;
+	ciph = (struct iphdr *) (icmph + 1);
+	csize = ciph->ihl << 2;
+	if (clen < csize)
+		return NF_DROP;
+
+	/* We are only interested ICMPs generated from TCP or UDP packets */
+	if (ciph->protocol != IPPROTO_UDP && ciph->protocol != IPPROTO_TCP)
+		return NF_ACCEPT;
+
+	/* Skip non-first embedded TCP/UDP fragments */
+	if (ciph->frag_off & __constant_htons(IP_OFFSET))
+		return NF_ACCEPT;
+
+	/* We need at least TCP/UDP ports here */
+	if (clen < csize + sizeof(struct udphdr))
+		return NF_DROP;
+
+	/*
+	 * Find the ports involved - this packet was
+	 * incoming so the ports are right way round
+	 * (but reversed relative to outer IP header!)
+	 */
+	pptr = (__u16 *)&(((char *)ciph)[csize]);
+
+	/* Ensure the checksum is correct */
+	if (ip_compute_csum((unsigned char *) icmph, len)) {
+		/* Failed checksum! */
+		IP_VS_DBG(1, "forward ICMP: failed checksum from %d.%d.%d.%d!\n",
+			  NIPQUAD(iph->saddr));
+		return NF_DROP;
+	}
+
+	IP_VS_DBG(11, "Handling outgoing ICMP for "
+		  "%u.%u.%u.%u:%d -> %u.%u.%u.%u:%d\n",
+		  NIPQUAD(ciph->saddr), ntohs(pptr[0]),
+		  NIPQUAD(ciph->daddr), ntohs(pptr[1]));
+
+	/* ciph content is actually <protocol, caddr, cport, daddr, dport> */
+	cp = ip_vs_conn_out_get(ciph->protocol, ciph->daddr, pptr[1],
+				ciph->saddr, pptr[0]);
+	if (!cp)
+		return NF_ACCEPT;
+
+	if (IP_VS_FWD_METHOD(cp) != 0) {
+		IP_VS_ERR("shouldn't reach here, because the box is on the"
+			  "half connection in the tun/dr module.\n");
+	}
+
+	/* Now we do real damage to this packet...! */
+	/* First change the source IP address, and recalc checksum */
+	iph->saddr = cp->vaddr;
+	ip_send_check(iph);
+
+	/* Now change the *dest* address in the contained IP */
+	ciph->daddr = cp->vaddr;
+	ip_send_check(ciph);
+
+	/* the TCP/UDP dest port - cannot redo check */
+	pptr[1] = cp->vport;
+
+	/* And finally the ICMP checksum */
+	icmph->checksum = 0;
+	icmph->checksum = ip_compute_csum((unsigned char *) icmph, len);
+	skb->ip_summed = CHECKSUM_UNNECESSARY;
+
+	/* do the statistics and put it back */
+	ip_vs_out_stats(cp, skb);
+	ip_vs_conn_put(cp);
+
+	IP_VS_DBG(11, "Forwarding correct outgoing ICMP to "
+		  "%u.%u.%u.%u:%d -> %u.%u.%u.%u:%d\n",
+		  NIPQUAD(ciph->saddr), ntohs(pptr[0]),
+		  NIPQUAD(ciph->daddr), ntohs(pptr[1]));
+
+	skb->nfcache |= NFC_IPVS_PROPERTY;
+
+	return NF_ACCEPT;
+}
+
+
+/*
+ *	It is hooked at the NF_IP_FORWARD chain, used only for VS/NAT.
+ *	Check if outgoing packet belongs to the established ip_vs_conn,
+ *      rewrite addresses of the packet and send it on its way...
+ */
+static unsigned int ip_vs_out(unsigned int hooknum,
+			      struct sk_buff **skb_p,
+			      const struct net_device *in,
+			      const struct net_device *out,
+			      int (*okfn)(struct sk_buff *))
+{
+	struct sk_buff  *skb = *skb_p;
+	struct iphdr	*iph;
+	union ip_vs_tphdr h;
+	struct ip_vs_conn *cp;
+	int size;
+	int ihl;
+
+	EnterFunction(11);
+
+	if (skb->nfcache & NFC_IPVS_PROPERTY)
+		return NF_ACCEPT;
+
+	iph = skb->nh.iph;
+	if (iph->protocol == IPPROTO_ICMP)
+		return ip_vs_out_icmp(skb_p);
+
+	/* let it go if other IP protocols */
+	if (iph->protocol != IPPROTO_TCP && iph->protocol != IPPROTO_UDP)
+		return NF_ACCEPT;
+
+	/* reassemble IP fragments */
+	if (iph->frag_off & __constant_htons(IP_MF|IP_OFFSET)) {
+		skb = ip_defrag(skb);
+		if (!skb)
+			return NF_STOLEN;
+		iph = skb->nh.iph;
+		*skb_p = skb;
+	}
+
+	/* make sure that protocol header available in skb data area,
+	   note that skb data area may be reallocated. */
+	ihl = iph->ihl << 2;
+	if (ip_vs_header_check(skb, iph->protocol, ihl) == -1)
+		return NF_DROP;
+
+	iph = skb->nh.iph;
+	h.raw = (char*) iph + ihl;
+
+	/*
+	 *	Check if the packet belongs to an old entry
+	 */
+	cp = ip_vs_conn_out_get(iph->protocol, iph->saddr, h.portp[0],
+				iph->daddr, h.portp[1]);
+	if (!cp) {
+		if (sysctl_ip_vs_nat_icmp_send &&
+		    ip_vs_lookup_real_service(iph->protocol,
+					      iph->saddr, h.portp[0])) {
+			/*
+			 * Notify the real server: there is no existing
+			 * entry if it is not RST packet or not TCP packet.
+			 */
+			if (!h.th->rst || iph->protocol != IPPROTO_TCP) {
+				icmp_send(skb, ICMP_DEST_UNREACH,
+					  ICMP_PORT_UNREACH, 0);
+				kfree_skb(skb);
+				return NF_STOLEN;
+			}
+		}
+		IP_VS_DBG(12, "packet for %s %d.%d.%d.%d:%d "
+			  "continue traversal as normal.\n",
+			  ip_vs_proto_name(iph->protocol),
+			  NIPQUAD(iph->daddr),
+			  ntohs(h.portp[1]));
+		if (skb_is_nonlinear(skb))
+			ip_send_check(iph);
+		return NF_ACCEPT;
+	}
+
+	/*
+	 * If it has ip_vs_app helper, the helper may change the payload,
+	 * so it needs full checksum checking and checksum calculation.
+	 * If not, only the header (addr/port) is changed, so it is fast
+	 * to do incremental checksum update, and let the destination host
+	 * do final checksum checking.
+	 */
+
+	if (cp->app && skb_is_nonlinear(skb)) {
+		if (skb_linearize(skb, GFP_ATOMIC) != 0) {
+			ip_vs_conn_put(cp);
+			return NF_DROP;
+		}
+		iph = skb->nh.iph;
+		h.raw = (char*) iph + ihl;
+	}
+
+	size = skb->len - ihl;
+	IP_VS_DBG(11, "O-pkt: %s size=%d\n",
+		  ip_vs_proto_name(iph->protocol), size);
+
+	/* do TCP/UDP checksum checking if it has application helper */
+	if (cp->app && (iph->protocol != IPPROTO_UDP || h.uh->check != 0)) {
+		switch (skb->ip_summed) {
+		case CHECKSUM_NONE:
+			skb->csum = csum_partial(h.raw, size, 0);
+		case CHECKSUM_HW:
+			if (csum_tcpudp_magic(iph->saddr, iph->daddr, size,
+					      iph->protocol, skb->csum)) {
+				ip_vs_conn_put(cp);
+				IP_VS_DBG_RL("Outgoing failed %s checksum "
+					     "from %d.%d.%d.%d (size=%d)!\n",
+					     ip_vs_proto_name(iph->protocol),
+					     NIPQUAD(iph->saddr),
+					     size);
+				return NF_DROP;
+			}
+			break;
+		default:
+			/* CHECKSUM_UNNECESSARY */
+			break;
+		}
+	}
+
+	IP_VS_DBG(11, "Outgoing %s %u.%u.%u.%u:%d->%u.%u.%u.%u:%d\n",
+		  ip_vs_proto_name(iph->protocol),
+		  NIPQUAD(iph->saddr), ntohs(h.portp[0]),
+		  NIPQUAD(iph->daddr), ntohs(h.portp[1]));
+
+	/* mangle the packet */
+	iph->saddr = cp->vaddr;
+	h.portp[0] = cp->vport;
+
+	/*
+	 *	Call application helper if needed
+	 */
+	if (ip_vs_app_pkt_out(cp, skb) != 0) {
+		/* skb data has probably changed, update pointers */
+		iph = skb->nh.iph;
+		h.raw = (char*)iph + ihl;
+		size = skb->len - ihl;
+	}
+
+	/*
+	 *	Adjust TCP/UDP checksums
+	 */
+	if (!cp->app && (iph->protocol != IPPROTO_UDP || h.uh->check != 0)) {
+		/* Only port and addr are changed, do fast csum update */
+		ip_vs_fast_check_update(&h, cp->daddr, cp->vaddr,
+					cp->dport, cp->vport, iph->protocol);
+		if (skb->ip_summed == CHECKSUM_HW)
+			skb->ip_summed = CHECKSUM_NONE;
+	} else {
+		/* full checksum calculation */
+		switch (iph->protocol) {
+		case IPPROTO_TCP:
+			h.th->check = 0;
+			skb->csum = csum_partial(h.raw, size, 0);
+			h.th->check = csum_tcpudp_magic(iph->saddr, iph->daddr,
+							size, iph->protocol,
+							skb->csum);
+			IP_VS_DBG(11, "O-pkt: %s O-csum=%d (+%d)\n",
+				  ip_vs_proto_name(iph->protocol), h.th->check,
+				  (char*)&(h.th->check) - (char*)h.raw);
+			break;
+		case IPPROTO_UDP:
+			h.uh->check = 0;
+			skb->csum = csum_partial(h.raw, size, 0);
+			h.uh->check = csum_tcpudp_magic(iph->saddr, iph->daddr,
+							size, iph->protocol,
+							skb->csum);
+			if (h.uh->check == 0)
+				h.uh->check = 0xFFFF;
+			IP_VS_DBG(11, "O-pkt: %s O-csum=%d (+%d)\n",
+				  ip_vs_proto_name(iph->protocol), h.uh->check,
+				  (char*)&(h.uh->check) - (char*)h.raw);
+			break;
+		}
+	}
+	ip_send_check(iph);
+
+	ip_vs_out_stats(cp, skb);
+	ip_vs_set_state(cp, VS_STATE_OUTPUT, iph, h.portp);
+	ip_vs_conn_put(cp);
+
+	skb->nfcache |= NFC_IPVS_PROPERTY;
+
+	LeaveFunction(11);
+	return NF_ACCEPT;
+}
+
+
+/*
+ *      Check if the packet is for VS/NAT connections, then send it
+ *      immediately.
+ *      Called by ip_fw_compact to detect packets for VS/NAT before
+ *      they are changed by ipchains masquerading code.
+ */
+unsigned int check_for_ip_vs_out(struct sk_buff **skb_p,
+				 int (*okfn)(struct sk_buff *))
+{
+	unsigned int ret;
+
+	ret = ip_vs_out(NF_IP_FORWARD, skb_p, NULL, NULL, NULL);
+	if (ret != NF_ACCEPT) {
+		return ret;
+	} else {
+		/* send the packet immediately if it is already mangled
+		   by ip_vs_out */
+		if ((*skb_p)->nfcache & NFC_IPVS_PROPERTY) {
+			(*okfn)(*skb_p);
+			return NF_STOLEN;
+		}
+	}
+	return NF_ACCEPT;
+}
+
+
+/*
+ *	Handle ICMP messages in the outside-to-inside direction (incoming)
+ *	and sometimes in outgoing direction from ip_vs_forward_icmp.
+ *	Find any that might be relevant, check against existing connections,
+ *	forward to the right destination host if relevant.
+ *	Currently handles error types - unreachable, quench, ttl exceeded.
+ */
+static int ip_vs_in_icmp(struct sk_buff **skb_p)
+{
+	struct sk_buff	*skb   = *skb_p;
+	struct iphdr    *iph;
+	struct icmphdr  *icmph;
+	struct iphdr    *ciph;	/* The ip header contained within the ICMP */
+	__u16	        *pptr;	/* port numbers from TCP/UDP contained header */
+	unsigned short   len;
+	unsigned short	clen, csize;
+	struct ip_vs_conn *cp;
+	struct rtable *rt;			/* Route to the other host */
+	int    mtu;
+
+	if (skb_is_nonlinear(skb)) {
+		if (skb_linearize(skb, GFP_ATOMIC) != 0)
+			return NF_DROP;
+	}
+
+	iph = skb->nh.iph;
+	ip_send_check(iph);
+	icmph = (struct icmphdr *)((char *)iph + (iph->ihl << 2));
+	len = ntohs(iph->tot_len) - (iph->ihl<<2);
+	if (len < sizeof(struct icmphdr))
+		return NF_DROP;
+
+	IP_VS_DBG(12, "icmp in (%d,%d) %u.%u.%u.%u -> %u.%u.%u.%u\n",
+		  icmph->type, ntohs(icmp_id(icmph)),
+		  NIPQUAD(iph->saddr), NIPQUAD(iph->daddr));
+
+	if ((icmph->type != ICMP_DEST_UNREACH) &&
+	    (icmph->type != ICMP_SOURCE_QUENCH) &&
+	    (icmph->type != ICMP_TIME_EXCEEDED))
+		return NF_ACCEPT;
+
+	/*
+	 * If we get here we have an ICMP error of one of the above 3 types
+	 * Now find the contained IP header
+	 */
+	clen = len - sizeof(struct icmphdr);
+	if (clen < sizeof(struct iphdr))
+		return NF_DROP;
+	ciph = (struct iphdr *) (icmph + 1);
+	csize = ciph->ihl << 2;
+	if (clen < csize)
+		return NF_DROP;
+
+	/* We are only interested ICMPs generated from TCP or UDP packets */
+	if (ciph->protocol != IPPROTO_UDP && ciph->protocol != IPPROTO_TCP)
+		return NF_ACCEPT;
+
+	/* Skip non-first embedded TCP/UDP fragments */
+	if (ciph->frag_off & __constant_htons(IP_OFFSET))
+		return NF_ACCEPT;
+
+	/* We need at least TCP/UDP ports here */
+	if (clen < csize + sizeof(struct udphdr))
+		return NF_DROP;
+
+	/* Ensure the checksum is correct */
+	if (ip_compute_csum((unsigned char *) icmph, len)) {
+		/* Failed checksum! */
+		IP_VS_ERR_RL("incoming ICMP: failed checksum from "
+			     "%d.%d.%d.%d!\n", NIPQUAD(iph->saddr));
+		return NF_DROP;
+	}
+
+	pptr = (__u16 *)&(((char *)ciph)[csize]);
+
+	IP_VS_DBG(11, "Handling incoming ICMP for "
+		  "%u.%u.%u.%u:%d -> %u.%u.%u.%u:%d\n",
+		  NIPQUAD(ciph->saddr), ntohs(pptr[0]),
+		  NIPQUAD(ciph->daddr), ntohs(pptr[1]));
+
+	/* This is pretty much what ip_vs_conn_in_get() does,
+	   except parameters are in the reverse order */
+	cp = ip_vs_conn_in_get(ciph->protocol,
+			       ciph->daddr, pptr[1],
+			       ciph->saddr, pptr[0]);
+	if (cp == NULL)
+		return NF_ACCEPT;
+
+	ip_vs_in_stats(cp, skb);
+
+	/* The ICMP packet for VS/TUN, VS/DR and LOCALNODE will be
+	   forwarded directly here, because there is no need to
+	   translate address/port back */
+	if (IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_MASQ) {
+		int ret;
+		if (cp->packet_xmit)
+			ret = cp->packet_xmit(skb, cp);
+		else
+			ret = NF_ACCEPT;
+		atomic_inc(&cp->in_pkts);
+		ip_vs_conn_put(cp);
+		return ret;
+	}
+
+	/*
+	 * mangle and send the packet here
+	 */
+	if (!(rt = __ip_vs_get_out_rt(cp, RT_TOS(iph->tos))))
+		goto tx_error_icmp;
+
+	/* MTU checking */
+	mtu = rt->u.dst.pmtu;
+	if ((skb->len > mtu) && (iph->frag_off&__constant_htons(IP_DF))) {
+		ip_rt_put(rt);
+		icmp_send(skb, ICMP_DEST_UNREACH,ICMP_FRAG_NEEDED, htonl(mtu));
+		IP_VS_DBG_RL("ip_vs_in_icmp(): frag needed\n");
+		goto tx_error;
+	}
+
+	/* drop old route */
+	dst_release(skb->dst);
+	skb->dst = &rt->u.dst;
+
+	/* copy-on-write the packet before mangling it */
+	if (ip_vs_skb_cow(skb, rt->u.dst.dev->hard_header_len,
+			  &iph, (unsigned char**)&icmph)) {
+		ip_vs_conn_put(cp);
+		return NF_DROP;
+	}
+	ciph = (struct iphdr *) (icmph + 1);
+	pptr = (__u16 *)&(((char *)ciph)[csize]);
+
+	/* The ICMP packet for VS/NAT must be written to correct addresses
+	   before being forwarded to the right server */
+
+	/* First change the dest IP address, and recalc checksum */
+	iph->daddr = cp->daddr;
+	ip_send_check(iph);
+
+	/* Now change the *source* address in the contained IP */
+	ciph->saddr = cp->daddr;
+	ip_send_check(ciph);
+
+	/* the TCP/UDP source port - cannot redo check */
+	pptr[0] = cp->dport;
+
+	/* And finally the ICMP checksum */
+	icmph->checksum = 0;
+	icmph->checksum = ip_compute_csum((unsigned char *) icmph, len);
+	skb->ip_summed = CHECKSUM_UNNECESSARY;
+
+	IP_VS_DBG(11, "Forwarding incoming ICMP to "
+		  "%u.%u.%u.%u:%d -> %u.%u.%u.%u:%d\n",
+		  NIPQUAD(ciph->saddr), ntohs(pptr[0]),
+		  NIPQUAD(ciph->daddr), ntohs(pptr[1]));
+
+#ifdef CONFIG_NETFILTER_DEBUG
+	skb->nf_debug = 1 << NF_IP_LOCAL_OUT;
+#endif /* CONFIG_NETFILTER_DEBUG */
+	ip_send(skb);
+	ip_vs_conn_put(cp);
+	return NF_STOLEN;
+
+  tx_error_icmp:
+	dst_link_failure(skb);
+  tx_error:
+	dev_kfree_skb(skb);
+	ip_vs_conn_put(cp);
+	return NF_STOLEN;
+}
+
+
+/*
+ *	Check if it's for virtual services, look it up,
+ *	and send it on its way...
+ */
+static unsigned int ip_vs_in(unsigned int hooknum,
+			     struct sk_buff **skb_p,
+			     const struct net_device *in,
+			     const struct net_device *out,
+			     int (*okfn)(struct sk_buff *))
+{
+	struct sk_buff	*skb = *skb_p;
+	struct iphdr	*iph = skb->nh.iph;
+	union ip_vs_tphdr h;
+	struct ip_vs_conn *cp;
+	struct ip_vs_service *svc;
+	int ihl;
+	int ret;
+
+	/*
+	 *	Big tappo: only PACKET_HOST (nor loopback neither mcasts)
+	 *	... don't know why 1st test DOES NOT include 2nd (?)
+	 */
+	if (skb->pkt_type != PACKET_HOST || skb->dev == &loopback_dev) {
+		IP_VS_DBG(12, "packet type=%d proto=%d daddr=%d.%d.%d.%d ignored\n",
+			  skb->pkt_type,
+			  iph->protocol,
+			  NIPQUAD(iph->daddr));
+		return NF_ACCEPT;
+	}
+
+	if (iph->protocol == IPPROTO_ICMP)
+		return ip_vs_in_icmp(skb_p);
+
+	/* let it go if other IP protocols */
+	if (iph->protocol != IPPROTO_TCP && iph->protocol != IPPROTO_UDP)
+		return NF_ACCEPT;
+
+	/* make sure that protocol header available in skb data area,
+	   note that skb data area may be reallocated. */
+	ihl = iph->ihl << 2;
+	if (ip_vs_header_check(skb, iph->protocol, ihl) == -1)
+		return NF_DROP;
+	iph = skb->nh.iph;
+	h.raw = (char*) iph + ihl;
+
+	/*
+	 * Check if the packet belongs to an existing connection entry
+	 */
+	cp = ip_vs_conn_in_get(iph->protocol, iph->saddr, h.portp[0],
+			       iph->daddr, h.portp[1]);
+
+	if (!cp &&
+	    (h.th->syn || (iph->protocol!=IPPROTO_TCP)) &&
+	    (svc = ip_vs_service_get(skb->nfmark, iph->protocol,
+				     iph->daddr, h.portp[1]))) {
+		if (ip_vs_todrop()) {
+			/*
+			 * It seems that we are very loaded.
+			 * We have to drop this packet :(
+			 */
+			ip_vs_service_put(svc);
+			return NF_DROP;
+		}
+
+		/*
+		 * Let the virtual server select a real server for the
+		 * incoming connection, and create a connection entry.
+		 */
+		cp = ip_vs_schedule(svc, iph);
+		if (!cp)
+			return ip_vs_leave(svc, skb);
+		ip_vs_conn_stats(cp, svc);
+		ip_vs_service_put(svc);
+	}
+
+	if (!cp) {
+		/* sorry, all this trouble for a no-hit :) */
+		IP_VS_DBG(12, "packet for %s %d.%d.%d.%d:%d continue "
+			  "traversal as normal.\n",
+			  ip_vs_proto_name(iph->protocol),
+			  NIPQUAD(iph->daddr),
+			  ntohs(h.portp[1]));
+		return NF_ACCEPT;
+	}
+
+	IP_VS_DBG(11, "Incoming %s %u.%u.%u.%u:%d->%u.%u.%u.%u:%d\n",
+		  ip_vs_proto_name(iph->protocol),
+		  NIPQUAD(iph->saddr), ntohs(h.portp[0]),
+		  NIPQUAD(iph->daddr), ntohs(h.portp[1]));
+
+	/* Check the server status */
+	if (cp->dest && !(cp->dest->flags & IP_VS_DEST_F_AVAILABLE)) {
+		/* the destination server is not availabe */
+
+		if (sysctl_ip_vs_expire_nodest_conn) {
+			/* try to expire the connection immediately */
+			ip_vs_conn_expire_now(cp);
+		} else {
+			/* don't restart its timer, and silently
+			   drop the packet. */
+			__ip_vs_conn_put(cp);
+		}
+		return NF_DROP;
+	}
+
+	ip_vs_in_stats(cp, skb);
+	ip_vs_set_state(cp, VS_STATE_INPUT, iph, h.portp);
+	if (cp->packet_xmit)
+		ret = cp->packet_xmit(skb, cp);
+	else {
+		IP_VS_DBG_RL("warning: packet_xmit is null");
+		ret = NF_ACCEPT;
+	}
+
+	/* increase its packet counter and check if it is needed
+	   to be synchronized */
+	atomic_inc(&cp->in_pkts);
+	if (ip_vs_sync_state == IP_VS_STATE_MASTER &&
+	    (cp->protocol != IPPROTO_TCP ||
+	     cp->state == IP_VS_S_ESTABLISHED) &&
+	    (atomic_read(&cp->in_pkts) % 50 == sysctl_ip_vs_sync_threshold))
+		ip_vs_sync_conn(cp);
+
+	ip_vs_conn_put(cp);
+	return ret;
+}
+
+
+/*
+ *	It is hooked at the NF_IP_FORWARD chain, in order to catch ICMP
+ *      packets destined for 0.0.0.0/0.
+ *      When fwmark-based virtual service is used, such as transparent
+ *      cache cluster, TCP packets can be marked and routed to ip_vs_in,
+ *      but ICMP destined for 0.0.0.0/0 cannot not be easily marked and
+ *      sent to ip_vs_in_icmp. So, catch them at the NF_IP_FORWARD chain
+ *      and send them to ip_vs_in_icmp.
+ */
+static unsigned int ip_vs_forward_icmp(unsigned int hooknum,
+				       struct sk_buff **skb_p,
+				       const struct net_device *in,
+				       const struct net_device *out,
+				       int (*okfn)(struct sk_buff *))
+{
+	struct sk_buff	*skb = *skb_p;
+	struct iphdr	*iph = skb->nh.iph;
+
+	if (iph->protocol != IPPROTO_ICMP)
+		return NF_ACCEPT;
+
+	if (iph->frag_off & __constant_htons(IP_MF|IP_OFFSET)) {
+		skb = ip_defrag(skb);
+		if (!skb)
+			return NF_STOLEN;
+		*skb_p = skb;
+	}
+
+	return ip_vs_in_icmp(skb_p);
+}
+
+
+/* After packet filtering, forward packet through VS/DR, VS/TUN,
+   or VS/NAT(change destination), so that filtering rules can be
+   applied to IPVS. */
+static struct nf_hook_ops ip_vs_in_ops = {
+	{ NULL, NULL },
+	ip_vs_in, PF_INET, NF_IP_LOCAL_IN, 100
+};
+
+/* After packet filtering, change source only for VS/NAT */
+static struct nf_hook_ops ip_vs_out_ops = {
+	{ NULL, NULL },
+	ip_vs_out, PF_INET, NF_IP_FORWARD, 100
+};
+
+/* After packet filtering (but before ip_vs_out_icmp), catch icmp
+   destined for 0.0.0.0/0, which is for incoming IPVS connections */
+static struct nf_hook_ops ip_vs_forward_icmp_ops = {
+	{ NULL, NULL },
+	ip_vs_forward_icmp, PF_INET, NF_IP_FORWARD, 99
+};
+
+/* Before the netfilter connection tracking, exit from POST_ROUTING */
+static struct nf_hook_ops ip_vs_post_routing_ops = {
+	{ NULL, NULL },
+	ip_vs_post_routing, PF_INET, NF_IP_POST_ROUTING, NF_IP_PRI_NAT_SRC-1
+};
+
+
+/*
+ *	Initialize IP Virtual Server
+ */
+static int __init ip_vs_init(void)
+{
+	int ret;
+
+	ret = ip_vs_control_init();
+	if (ret < 0) {
+		IP_VS_ERR("can't setup control.\n");
+		goto cleanup_nothing;
+	}
+
+	ret = ip_vs_conn_init();
+	if (ret < 0) {
+		IP_VS_ERR("can't setup connection table.\n");
+		goto cleanup_control;
+	}
+
+	ret = ip_vs_app_init();
+	if (ret < 0) {
+		IP_VS_ERR("can't setup application helper.\n");
+		goto cleanup_conn;
+	}
+
+	ret = nf_register_hook(&ip_vs_in_ops);
+	if (ret < 0) {
+		IP_VS_ERR("can't register in hook.\n");
+		goto cleanup_app;
+	}
+	ret = nf_register_hook(&ip_vs_out_ops);
+	if (ret < 0) {
+		IP_VS_ERR("can't register out hook.\n");
+		goto cleanup_inops;
+	}
+	ret = nf_register_hook(&ip_vs_post_routing_ops);
+	if (ret < 0) {
+		IP_VS_ERR("can't register post_routing hook.\n");
+		goto cleanup_outops;
+	}
+	ret = nf_register_hook(&ip_vs_forward_icmp_ops);
+	if (ret < 0) {
+		IP_VS_ERR("can't register forward_icmp hook.\n");
+		goto cleanup_postroutingops;
+	}
+
+	IP_VS_INFO("ipvs loaded.\n");
+	return ret;
+
+  cleanup_postroutingops:
+	nf_unregister_hook(&ip_vs_post_routing_ops);
+  cleanup_outops:
+	nf_unregister_hook(&ip_vs_out_ops);
+  cleanup_inops:
+	nf_unregister_hook(&ip_vs_in_ops);
+  cleanup_app:
+	ip_vs_app_cleanup();
+  cleanup_conn:
+	ip_vs_conn_cleanup();
+  cleanup_control:
+	ip_vs_control_cleanup();
+  cleanup_nothing:
+	return ret;
+}
+
+static void __exit ip_vs_cleanup(void)
+{
+	nf_unregister_hook(&ip_vs_forward_icmp_ops);
+	nf_unregister_hook(&ip_vs_post_routing_ops);
+	nf_unregister_hook(&ip_vs_out_ops);
+	nf_unregister_hook(&ip_vs_in_ops);
+	ip_vs_app_cleanup();
+	ip_vs_conn_cleanup();
+	ip_vs_control_cleanup();
+	IP_VS_INFO("ipvs unloaded.\n");
+}
+
+module_init(ip_vs_init);
+module_exit(ip_vs_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_ctl.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_ctl.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_ctl.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_ctl.c	2003-08-27 14:40:08.000000000 +0000
@@ -0,0 +1,2154 @@
+/*
+ * IPVS         An implementation of the IP virtual server support for the
+ *              LINUX operating system.  IPVS is now implemented as a module
+ *              over the NetFilter framework. IPVS can be used to build a
+ *              high-performance and highly available server based on a
+ *              cluster of servers.
+ *
+ * Version:     $Id: ip_vs_ctl.c,v 1.30.2.3 2003/07/29 14:37:12 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *              Peter Kese <peter.kese@ijs.si>
+ *              Julian Anastasov <ja@ssi.bg>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/fs.h>
+#include <linux/sysctl.h>
+#include <linux/proc_fs.h>
+#include <linux/timer.h>
+#include <linux/swap.h>
+#include <linux/proc_fs.h>
+
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+
+#include <net/ip.h>
+#include <net/sock.h>
+
+#include <asm/uaccess.h>
+
+#include <net/ip_vs.h>
+
+/* semaphore for IPVS sockopts. And, [gs]etsockopt may sleep. */
+static DECLARE_MUTEX(__ip_vs_mutex);
+
+/* lock for service table */
+rwlock_t __ip_vs_svc_lock = RW_LOCK_UNLOCKED;
+
+/* lock for table with the real services */
+static rwlock_t __ip_vs_rs_lock = RW_LOCK_UNLOCKED;
+
+/* lock for state and timeout tables */
+static rwlock_t __ip_vs_securetcp_lock = RW_LOCK_UNLOCKED;
+
+/* lock for drop entry handling */
+static spinlock_t __ip_vs_dropentry_lock = SPIN_LOCK_UNLOCKED;
+
+/* lock for drop packet handling */
+static spinlock_t __ip_vs_droppacket_lock = SPIN_LOCK_UNLOCKED;
+
+/* 1/rate drop and drop-entry variables */
+int ip_vs_drop_rate = 0;
+int ip_vs_drop_counter = 0;
+atomic_t ip_vs_dropentry = ATOMIC_INIT(0);
+
+/* number of virtual services */
+static int ip_vs_num_services = 0;
+
+/* sysctl variables */
+static int sysctl_ip_vs_drop_entry = 0;
+static int sysctl_ip_vs_drop_packet = 0;
+static int sysctl_ip_vs_secure_tcp = 0;
+static int sysctl_ip_vs_amemthresh = 2048;
+static int sysctl_ip_vs_am_droprate = 10;
+int sysctl_ip_vs_cache_bypass = 0;
+int sysctl_ip_vs_expire_nodest_conn = 0;
+int sysctl_ip_vs_sync_threshold = 3;
+int sysctl_ip_vs_nat_icmp_send = 0;
+
+#ifdef CONFIG_IP_VS_DEBUG
+static int sysctl_ip_vs_debug_level = 0;
+
+int ip_vs_get_debug_level(void)
+{
+	return sysctl_ip_vs_debug_level;
+}
+#endif
+
+/*
+ *	update_defense_level is called from timer bh and from sysctl.
+ */
+static void update_defense_level(void)
+{
+	struct sysinfo i;
+	int availmem;
+	int nomem;
+
+	/* we only count free and buffered memory (in pages) */
+	si_meminfo(&i);
+	availmem = i.freeram + i.bufferram;
+
+	nomem = (availmem < sysctl_ip_vs_amemthresh);
+
+	/* drop_entry */
+	spin_lock(&__ip_vs_dropentry_lock);
+	switch (sysctl_ip_vs_drop_entry) {
+	case 0:
+		atomic_set(&ip_vs_dropentry, 0);
+		break;
+	case 1:
+		if (nomem) {
+			atomic_set(&ip_vs_dropentry, 1);
+			sysctl_ip_vs_drop_entry = 2;
+		} else {
+			atomic_set(&ip_vs_dropentry, 0);
+		}
+		break;
+	case 2:
+		if (nomem) {
+			atomic_set(&ip_vs_dropentry, 1);
+		} else {
+			atomic_set(&ip_vs_dropentry, 0);
+			sysctl_ip_vs_drop_entry = 1;
+		};
+		break;
+	case 3:
+		atomic_set(&ip_vs_dropentry, 1);
+		break;
+	}
+	spin_unlock(&__ip_vs_dropentry_lock);
+
+	/* drop_packet */
+	spin_lock(&__ip_vs_droppacket_lock);
+	switch (sysctl_ip_vs_drop_packet) {
+	case 0:
+		ip_vs_drop_rate = 0;
+		break;
+	case 1:
+		if (nomem) {
+			ip_vs_drop_rate = ip_vs_drop_counter
+				= sysctl_ip_vs_amemthresh /
+				(sysctl_ip_vs_amemthresh - availmem);
+			sysctl_ip_vs_drop_packet = 2;
+		} else {
+			ip_vs_drop_rate = 0;
+		}
+		break;
+	case 2:
+		if (nomem) {
+			ip_vs_drop_rate = ip_vs_drop_counter
+				= sysctl_ip_vs_amemthresh /
+				(sysctl_ip_vs_amemthresh - availmem);
+		} else {
+			ip_vs_drop_rate = 0;
+			sysctl_ip_vs_drop_packet = 1;
+		}
+		break;
+	case 3:
+		ip_vs_drop_rate = sysctl_ip_vs_am_droprate;
+		break;
+	}
+	spin_unlock(&__ip_vs_droppacket_lock);
+
+	/* secure_tcp */
+	write_lock(&__ip_vs_securetcp_lock);
+	switch (sysctl_ip_vs_secure_tcp) {
+	case 0:
+		ip_vs_secure_tcp_set(0);
+		break;
+	case 1:
+		if (nomem) {
+			ip_vs_secure_tcp_set(1);
+			sysctl_ip_vs_secure_tcp = 2;
+		} else {
+			ip_vs_secure_tcp_set(0);
+		}
+		break;
+	case 2:
+		if (nomem) {
+			ip_vs_secure_tcp_set(1);
+		} else {
+			ip_vs_secure_tcp_set(0);
+			sysctl_ip_vs_secure_tcp = 1;
+		}
+		break;
+	case 3:
+		ip_vs_secure_tcp_set(1);
+		break;
+	}
+	write_unlock(&__ip_vs_securetcp_lock);
+}
+
+
+/*
+ *	Timer for checking the defense
+ */
+static struct timer_list defense_timer;
+#define DEFENSE_TIMER_PERIOD	1*HZ
+
+static void defense_timer_handler(unsigned long data)
+{
+	update_defense_level();
+	if (atomic_read(&ip_vs_dropentry))
+		ip_vs_random_dropentry();
+
+	mod_timer(&defense_timer, jiffies + DEFENSE_TIMER_PERIOD);
+}
+
+
+/*
+ *  Hash table: for virtual service lookups
+ */
+#define IP_VS_SVC_TAB_BITS 8
+#define IP_VS_SVC_TAB_SIZE (1 << IP_VS_SVC_TAB_BITS)
+#define IP_VS_SVC_TAB_MASK (IP_VS_SVC_TAB_SIZE - 1)
+
+/* the service table hashed by <protocol, addr, port> */
+static struct list_head ip_vs_svc_table[IP_VS_SVC_TAB_SIZE];
+/* the service table hashed by fwmark */
+static struct list_head ip_vs_svc_fwm_table[IP_VS_SVC_TAB_SIZE];
+
+/*
+ *  Hash table: for real service lookups
+ */
+#define IP_VS_RTAB_BITS 4
+#define IP_VS_RTAB_SIZE (1 << IP_VS_RTAB_BITS)
+#define IP_VS_RTAB_MASK (IP_VS_RTAB_SIZE - 1)
+
+static struct list_head ip_vs_rtable[IP_VS_RTAB_SIZE];
+
+/*
+ * Trash for destinations
+ */
+static LIST_HEAD(ip_vs_dest_trash);
+
+/*
+ * FTP & NULL virtual service counters
+ */
+static atomic_t ip_vs_ftpsvc_counter = ATOMIC_INIT(0);
+static atomic_t ip_vs_nullsvc_counter = ATOMIC_INIT(0);
+
+
+/*
+ *  Returns hash value for virtual service
+ */
+static __inline__ unsigned
+ip_vs_svc_hashkey(unsigned proto, __u32 addr, __u16 port)
+{
+	register unsigned porth = ntohs(port);
+
+	return (proto^ntohl(addr)^(porth>>IP_VS_SVC_TAB_BITS)^porth)
+		& IP_VS_SVC_TAB_MASK;
+}
+
+/*
+ *  Returns hash value of fwmark for virtual service lookup
+ */
+static __inline__ unsigned ip_vs_svc_fwm_hashkey(__u32 fwmark)
+{
+	return fwmark & IP_VS_SVC_TAB_MASK;
+}
+
+/*
+ *  Hashes ip_vs_service in the ip_vs_svc_table by <proto,addr,port>
+ *  or in the ip_vs_svc_fwm_table by fwmark.
+ *  Should be called with locked tables.
+ *  Returns bool success.
+ */
+static int ip_vs_svc_hash(struct ip_vs_service *svc)
+{
+	unsigned hash;
+
+	if (svc->flags & IP_VS_SVC_F_HASHED) {
+		IP_VS_ERR("ip_vs_svc_hash(): request for already hashed, "
+			  "called from %p\n", __builtin_return_address(0));
+		return 0;
+	}
+
+	if (svc->fwmark == 0) {
+		/*
+		 *  Hash it by <protocol,addr,port> in ip_vs_svc_table
+		 */
+		hash = ip_vs_svc_hashkey(svc->protocol, svc->addr, svc->port);
+		list_add(&svc->s_list, &ip_vs_svc_table[hash]);
+	} else {
+		/*
+		 *  Hash it by fwmark in ip_vs_svc_fwm_table
+		 */
+		hash = ip_vs_svc_fwm_hashkey(svc->fwmark);
+		list_add(&svc->f_list, &ip_vs_svc_fwm_table[hash]);
+	}
+
+	svc->flags |= IP_VS_SVC_F_HASHED;
+	/* increase its refcnt because it is referenced by the svc table */
+	atomic_inc(&svc->refcnt);
+	return 1;
+}
+
+
+/*
+ *  Unhashes ip_vs_service from ip_vs_svc_table/ip_vs_svc_fwm_table.
+ *  Should be called with locked tables.
+ *  Returns bool success.
+ */
+static int ip_vs_svc_unhash(struct ip_vs_service *svc)
+{
+	if (!(svc->flags & IP_VS_SVC_F_HASHED)) {
+		IP_VS_ERR("ip_vs_svc_unhash(): request for unhash flagged, "
+			  "called from %p\n", __builtin_return_address(0));
+		return 0;
+	}
+
+	if (svc->fwmark == 0) {
+		/*
+		 * Remove it from the ip_vs_svc_table table.
+		 */
+		list_del(&svc->s_list);
+	} else {
+		/*
+		 * Remove it from the ip_vs_svc_fwm_table table.
+		 */
+		list_del(&svc->f_list);
+	}
+
+	svc->flags &= ~IP_VS_SVC_F_HASHED;
+	atomic_dec(&svc->refcnt);
+	return 1;
+}
+
+
+/*
+ *  Get service by {proto,addr,port} in the service table.
+ */
+static __inline__ struct ip_vs_service *
+__ip_vs_service_get(__u16 protocol, __u32 vaddr, __u16 vport)
+{
+	unsigned hash;
+	struct ip_vs_service *svc;
+	struct list_head *l,*e;
+
+	/*
+	 *	Check for "full" addressed entries
+	 */
+	hash = ip_vs_svc_hashkey(protocol, vaddr, vport);
+
+	l = &ip_vs_svc_table[hash];
+	for (e=l->next; e!=l; e=e->next) {
+		svc = list_entry(e, struct ip_vs_service, s_list);
+		if ((svc->addr == vaddr)
+		    && (svc->port == vport)
+		    && (svc->protocol == protocol)) {
+			/* HIT */
+			atomic_inc(&svc->usecnt);
+			return svc;
+		}
+	}
+
+	return NULL;
+}
+
+
+/*
+ *  Get service by {fwmark} in the service table.
+ */
+static __inline__ struct ip_vs_service *__ip_vs_svc_fwm_get(__u32 fwmark)
+{
+	unsigned hash;
+	struct ip_vs_service *svc;
+	struct list_head *l,*e;
+
+	/*
+	 *	Check for "full" addressed entries
+	 */
+	hash = ip_vs_svc_fwm_hashkey(fwmark);
+
+	l = &ip_vs_svc_fwm_table[hash];
+	for (e=l->next; e!=l; e=e->next) {
+		svc = list_entry(e, struct ip_vs_service, f_list);
+		if (svc->fwmark == fwmark) {
+			/* HIT */
+			atomic_inc(&svc->usecnt);
+			return svc;
+		}
+	}
+
+	return NULL;
+}
+
+struct ip_vs_service *
+ip_vs_service_get(__u32 fwmark, __u16 protocol, __u32 vaddr, __u16 vport)
+{
+	struct ip_vs_service *svc;
+
+	read_lock(&__ip_vs_svc_lock);
+
+	/*
+	 *	Check the table hashed by fwmark first
+	 */
+	if (fwmark && (svc = __ip_vs_svc_fwm_get(fwmark)))
+		goto out;
+
+	/*
+	 *	Check the table hashed by <protocol,addr,port>
+	 *	for "full" addressed entries
+	 */
+	svc = __ip_vs_service_get(protocol, vaddr, vport);
+
+	if (svc == NULL
+	    && protocol == IPPROTO_TCP
+	    && atomic_read(&ip_vs_ftpsvc_counter)
+	    && (vport == FTPDATA || ntohs(vport) >= PROT_SOCK)) {
+		/*
+		 * Check if ftp service entry exists, the packet
+		 * might belong to FTP data connections.
+		 */
+		svc = __ip_vs_service_get(protocol, vaddr, FTPPORT);
+	}
+
+	if (svc == NULL
+	    && atomic_read(&ip_vs_nullsvc_counter)) {
+		/*
+		 * Check if the catch-all port (port zero) exists
+		 */
+		svc = __ip_vs_service_get(protocol, vaddr, 0);
+	}
+
+  out:
+	read_unlock(&__ip_vs_svc_lock);
+
+	IP_VS_DBG(6, "lookup service: fwm %u %s %u.%u.%u.%u:%u %s\n",
+		  fwmark, ip_vs_proto_name(protocol),
+		  NIPQUAD(vaddr), ntohs(vport),
+		  svc?"hit":"not hit");
+
+	return svc;
+}
+
+
+static inline void
+__ip_vs_bind_svc(struct ip_vs_dest *dest, struct ip_vs_service *svc)
+{
+	atomic_inc(&svc->refcnt);
+	dest->svc = svc;
+}
+
+static inline void
+__ip_vs_unbind_svc(struct ip_vs_dest *dest)
+{
+	struct ip_vs_service *svc = dest->svc;
+
+	dest->svc = NULL;
+	if (atomic_dec_and_test(&svc->refcnt))
+		kfree(svc);
+}
+
+/*
+ *  Returns hash value for real service
+ */
+static __inline__ unsigned ip_vs_rs_hashkey(__u32 addr, __u16 port)
+{
+	register unsigned porth = ntohs(port);
+
+	return (ntohl(addr)^(porth>>IP_VS_RTAB_BITS)^porth)
+		& IP_VS_RTAB_MASK;
+}
+
+/*
+ *  Hashes ip_vs_dest in ip_vs_rtable by proto,addr,port.
+ *  should be called with locked tables.
+ *  returns bool success.
+ */
+static int ip_vs_rs_hash(struct ip_vs_dest *dest)
+{
+	unsigned hash;
+
+	if (!list_empty(&dest->d_list)) {
+		return 0;
+	}
+
+	/*
+	 *	Hash by proto,addr,port,
+	 *	which are the parameters of the real service.
+	 */
+	hash = ip_vs_rs_hashkey(dest->addr, dest->port);
+	list_add(&dest->d_list, &ip_vs_rtable[hash]);
+
+	return 1;
+}
+
+/*
+ *  UNhashes ip_vs_dest from ip_vs_rtable.
+ *  should be called with locked tables.
+ *  returns bool success.
+ */
+static int ip_vs_rs_unhash(struct ip_vs_dest *dest)
+{
+	/*
+	 * Remove it from the ip_vs_rtable table.
+	 */
+	if (!list_empty(&dest->d_list)) {
+		list_del(&dest->d_list);
+		INIT_LIST_HEAD(&dest->d_list);
+	}
+
+	return 1;
+}
+
+/*
+ *  Lookup real service by {proto,addr,port} in the real service table.
+ */
+struct ip_vs_dest *
+ip_vs_lookup_real_service(__u16 protocol, __u32 daddr, __u16 dport)
+{
+	unsigned hash;
+	struct ip_vs_dest *dest;
+	struct list_head *l,*e;
+
+	/*
+	 *	Check for "full" addressed entries
+	 *	Return the first found entry
+	 */
+	hash = ip_vs_rs_hashkey(daddr, dport);
+
+	l = &ip_vs_rtable[hash];
+
+	read_lock(&__ip_vs_rs_lock);
+	for (e=l->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, d_list);
+		if ((dest->addr == daddr)
+		    && (dest->port == dport)
+		    && ((dest->protocol == protocol) ||
+			dest->vfwmark)) {
+			/* HIT */
+			read_unlock(&__ip_vs_rs_lock);
+			return dest;
+		}
+	}
+	read_unlock(&__ip_vs_rs_lock);
+
+	return NULL;
+}
+
+/*
+ *  Lookup destination by {addr,port} in the given service
+ */
+static struct ip_vs_dest *
+ip_vs_lookup_dest(struct ip_vs_service *svc, __u32 daddr, __u16 dport)
+{
+	struct ip_vs_dest *dest;
+	struct list_head *l, *e;
+
+	/*
+	 * Find the destination for the given service
+	 */
+	l = &svc->destinations;
+	for (e=l->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+		if ((dest->addr == daddr) && (dest->port == dport)) {
+			/* HIT */
+			return dest;
+		}
+	}
+
+	return NULL;
+}
+
+
+/*
+ *  Lookup dest by {svc,addr,port} in the destination trash.
+ *  The destination trash is used to hold the destinations that are removed
+ *  from the service table but are still referenced by some conn entries.
+ *  The reason to add the destination trash is when the dest is temporary
+ *  down (either by administrator or by monitor program), the dest can be
+ *  picked back from the trash, the remaining connections to the dest can
+ *  continue, and the counting information of the dest is also useful for
+ *  scheduling.
+ */
+static struct ip_vs_dest *
+ip_vs_trash_get_dest(struct ip_vs_service *svc, __u32 daddr, __u16 dport)
+{
+	struct ip_vs_dest *dest;
+	struct list_head *l, *e;
+
+	/*
+	 * Find the destination in trash
+	 */
+	l = &ip_vs_dest_trash;
+
+	for (e=l->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+		IP_VS_DBG(3, "Destination %u/%u.%u.%u.%u:%u still in trash, "
+			  "refcnt=%d\n",
+			  dest->vfwmark,
+			  NIPQUAD(dest->addr), ntohs(dest->port),
+			  atomic_read(&dest->refcnt));
+		if (dest->addr == daddr &&
+		    dest->port == dport &&
+		    dest->vfwmark == svc->fwmark &&
+		    dest->protocol == svc->protocol &&
+		    (svc->fwmark ||
+		     (dest->vaddr == svc->addr &&
+		      dest->vport == svc->port))) {
+			/* HIT */
+			return dest;
+		}
+
+		/*
+		 * Try to purge the destination from trash if not referenced
+		 */
+		if (atomic_read(&dest->refcnt) == 1) {
+			IP_VS_DBG(3, "Removing destination %u/%u.%u.%u.%u:%u "
+				  "from trash\n",
+				  dest->vfwmark,
+				  NIPQUAD(dest->addr), ntohs(dest->port));
+			e = e->prev;
+			list_del(&dest->n_list);
+			__ip_vs_dst_reset(dest);
+			__ip_vs_unbind_svc(dest);
+			kfree(dest);
+		}
+	}
+
+	return NULL;
+}
+
+
+/*
+ *  Clean up all the destinations in the trash
+ *  Called by the ip_vs_control_cleanup()
+ *
+ *  When the ip_vs_control_clearup is activated by ipvs module exit,
+ *  the service tables must have been flushed and all the connections
+ *  are expired, and the refcnt of each destination in the trash must
+ *  be 1, so we simply release them here.
+ */
+static void ip_vs_trash_cleanup(void)
+{
+	struct ip_vs_dest *dest;
+	struct list_head *l;
+
+	l = &ip_vs_dest_trash;
+
+	while (l->next != l) {
+		dest = list_entry(l->next, struct ip_vs_dest, n_list);
+		list_del(&dest->n_list);
+		__ip_vs_dst_reset(dest);
+		__ip_vs_unbind_svc(dest);
+		kfree(dest);
+	}
+}
+
+
+/*
+ *  Update a destination in the given service
+ */
+static void __ip_vs_update_dest(struct ip_vs_service *svc,
+				struct ip_vs_dest *dest,
+				struct ip_vs_rule_user *ur)
+{
+	int conn_flags;
+
+	/*
+	 *    Set the weight and the flags
+	 */
+	atomic_set(&dest->weight, ur->weight);
+
+	conn_flags = ur->conn_flags | IP_VS_CONN_F_INACTIVE;
+
+	/*
+	 *    Check if local node and update the flags
+	 */
+	if (inet_addr_type(ur->daddr) == RTN_LOCAL) {
+		conn_flags = (conn_flags & ~IP_VS_CONN_F_FWD_MASK)
+			| IP_VS_CONN_F_LOCALNODE;
+	}
+
+	/*
+	 *    Set the IP_VS_CONN_F_NOOUTPUT flag if not masquerading
+	 */
+	if ((conn_flags & IP_VS_CONN_F_FWD_MASK) != 0) {
+		conn_flags |= IP_VS_CONN_F_NOOUTPUT;
+	} else {
+		/*
+		 *    Put the real service in ip_vs_rtable if not present.
+		 *    For now only for NAT!
+		 */
+		write_lock_bh(&__ip_vs_rs_lock);
+		ip_vs_rs_hash(dest);
+		write_unlock_bh(&__ip_vs_rs_lock);
+	}
+	atomic_set(&dest->conn_flags, conn_flags);
+
+	/* bind the service */
+	if (!dest->svc) {
+		__ip_vs_bind_svc(dest, svc);
+	} else {
+		if (dest->svc != svc) {
+			__ip_vs_unbind_svc(dest);
+			__ip_vs_bind_svc(dest, svc);
+		}
+	}
+
+	/* set the dest status flags */
+	dest->flags |= IP_VS_DEST_F_AVAILABLE;
+}
+
+
+/*
+ *  Create a destination for the given service
+ */
+static int
+ip_vs_new_dest(struct ip_vs_service *svc, struct ip_vs_rule_user *ur,
+	       struct ip_vs_dest **destp)
+{
+	struct ip_vs_dest *dest;
+	unsigned atype;
+
+	EnterFunction(2);
+
+	atype = inet_addr_type(ur->daddr);
+	if (atype != RTN_LOCAL && atype != RTN_UNICAST)
+		return -EINVAL;
+
+	*destp = dest = (struct ip_vs_dest*)
+		kmalloc(sizeof(struct ip_vs_dest), GFP_ATOMIC);
+	if (dest == NULL) {
+		IP_VS_ERR("ip_vs_new_dest: kmalloc failed.\n");
+		return -ENOMEM;
+	}
+	memset(dest, 0, sizeof(struct ip_vs_dest));
+
+	dest->protocol = svc->protocol;
+	dest->vaddr = svc->addr;
+	dest->vport = svc->port;
+	dest->vfwmark = svc->fwmark;
+	dest->addr = ur->daddr;
+	dest->port = ur->dport;
+
+	atomic_set(&dest->activeconns, 0);
+	atomic_set(&dest->inactconns, 0);
+	atomic_set(&dest->refcnt, 0);
+
+	INIT_LIST_HEAD(&dest->d_list);
+	dest->dst_lock = SPIN_LOCK_UNLOCKED;
+	dest->stats.lock = SPIN_LOCK_UNLOCKED;
+	__ip_vs_update_dest(svc, dest, ur);
+	ip_vs_new_estimator(&dest->stats);
+
+	LeaveFunction(2);
+	return 0;
+}
+
+
+/*
+ *  Add a destination into an existing service
+ */
+static int ip_vs_add_dest(struct ip_vs_service *svc,
+			  struct ip_vs_rule_user *ur)
+{
+	struct ip_vs_dest *dest;
+	__u32 daddr = ur->daddr;
+	__u16 dport = ur->dport;
+	int ret;
+
+	EnterFunction(2);
+
+	if (ur->weight < 0) {
+		IP_VS_ERR("ip_vs_add_dest(): server weight less than zero\n");
+		return -ERANGE;
+	}
+
+	/*
+	 * Check if the dest already exists in the list
+	 */
+	dest = ip_vs_lookup_dest(svc, daddr, dport);
+	if (dest != NULL) {
+		IP_VS_DBG(1, "ip_vs_add_dest(): dest already exists\n");
+		return -EEXIST;
+	}
+
+	/*
+	 * Check if the dest already exists in the trash and
+	 * is from the same service
+	 */
+	dest = ip_vs_trash_get_dest(svc, daddr, dport);
+	if (dest != NULL) {
+		IP_VS_DBG(3, "Get destination %u.%u.%u.%u:%u from trash, "
+			  "refcnt=%d, service %u/%u.%u.%u.%u:%u\n",
+			  NIPQUAD(daddr), ntohs(dport),
+			  atomic_read(&dest->refcnt),
+			  dest->vfwmark,
+			  NIPQUAD(dest->vaddr),
+			  ntohs(dest->vport));
+		__ip_vs_update_dest(svc, dest, ur);
+
+		/*
+		 * Get the destination from the trash
+		 */
+		list_del(&dest->n_list);
+
+		ip_vs_new_estimator(&dest->stats);
+
+		write_lock_bh(&__ip_vs_svc_lock);
+
+		/*
+		 * Wait until all other svc users go away.
+		 */
+		while (atomic_read(&svc->usecnt) > 1) {};
+
+		list_add(&dest->n_list, &svc->destinations);
+		svc->num_dests++;
+
+		/* call the update_service function of its scheduler */
+		svc->scheduler->update_service(svc);
+
+		write_unlock_bh(&__ip_vs_svc_lock);
+		return 0;
+	}
+
+	/*
+	 * Allocate and initialize the dest structure
+	 */
+	ret = ip_vs_new_dest(svc, ur, &dest);
+	if (ret) {
+		return ret;
+	}
+
+	/*
+	 * Add the dest entry into the list
+	 */
+	atomic_inc(&dest->refcnt);
+
+	write_lock_bh(&__ip_vs_svc_lock);
+
+	/*
+	 * Wait until all other svc users go away.
+	 */
+	while (atomic_read(&svc->usecnt) > 1) {};
+
+	list_add(&dest->n_list, &svc->destinations);
+	svc->num_dests++;
+
+	/* call the update_service function of its scheduler */
+	svc->scheduler->update_service(svc);
+
+	write_unlock_bh(&__ip_vs_svc_lock);
+
+	LeaveFunction(2);
+
+	return 0;
+}
+
+
+/*
+ *  Edit a destination in the given service
+ */
+static int ip_vs_edit_dest(struct ip_vs_service *svc,
+			   struct ip_vs_rule_user *ur)
+{
+	struct ip_vs_dest *dest;
+	__u32 daddr = ur->daddr;
+	__u16 dport = ur->dport;
+
+	EnterFunction(2);
+
+	if (ur->weight < 0) {
+		IP_VS_ERR("ip_vs_edit_dest(): server weight less than zero\n");
+		return -ERANGE;
+	}
+
+	/*
+	 *  Lookup the destination list
+	 */
+	dest = ip_vs_lookup_dest(svc, daddr, dport);
+	if (dest == NULL) {
+		IP_VS_DBG(1, "ip_vs_edit_dest(): dest doesn't exist\n");
+		return -ENOENT;
+	}
+
+	__ip_vs_update_dest(svc, dest, ur);
+
+	/* call the update_service, because server weight may be changed */
+	svc->scheduler->update_service(svc);
+
+	LeaveFunction(2);
+
+	return 0;
+}
+
+
+/*
+ *  Delete a destination (must be already unlinked from the service)
+ */
+static void __ip_vs_del_dest(struct ip_vs_dest *dest)
+{
+	ip_vs_kill_estimator(&dest->stats);
+
+	/*
+	 *  Remove it from the d-linked list with the real services.
+	 */
+	write_lock_bh(&__ip_vs_rs_lock);
+	ip_vs_rs_unhash(dest);
+	write_unlock_bh(&__ip_vs_rs_lock);
+
+	/*
+	 *  Decrease the refcnt of the dest, and free the dest
+	 *  if nobody refers to it (refcnt=0). Otherwise, throw
+	 *  the destination into the trash.
+	 */
+	if (atomic_dec_and_test(&dest->refcnt)) {
+		__ip_vs_dst_reset(dest);
+		/* simply decrease svc->refcnt here, let the caller check
+		   and release the service if nobody refers to it.
+		   Only user context can release destination and service,
+		   and only one user context can update virtual service at a
+		   time, so the operation here is OK */
+		atomic_dec(&dest->svc->refcnt);
+		kfree(dest);
+	} else {
+		IP_VS_DBG(3, "Moving dest %u.%u.%u.%u:%u into trash, refcnt=%d\n",
+			  NIPQUAD(dest->addr), ntohs(dest->port),
+			  atomic_read(&dest->refcnt));
+		list_add(&dest->n_list, &ip_vs_dest_trash);
+		atomic_inc(&dest->refcnt);
+	}
+}
+
+
+/*
+ *  Unlink a destination from the given service
+ */
+static void __ip_vs_unlink_dest(struct ip_vs_service *svc,
+				struct ip_vs_dest *dest,
+				int svcupd)
+{
+	dest->flags &= ~IP_VS_DEST_F_AVAILABLE;
+
+	/*
+	 *  Remove it from the d-linked destination list.
+	 */
+	list_del(&dest->n_list);
+	svc->num_dests--;
+	if (svcupd) {
+		/*
+		 *  Call the update_service function of its scheduler
+		 */
+		svc->scheduler->update_service(svc);
+	}
+}
+
+
+/*
+ *  Delete a destination server in the given service
+ */
+static int ip_vs_del_dest(struct ip_vs_service *svc,struct ip_vs_rule_user *ur)
+{
+	struct ip_vs_dest *dest;
+	__u32 daddr = ur->daddr;
+	__u16 dport = ur->dport;
+
+	EnterFunction(2);
+
+	dest = ip_vs_lookup_dest(svc, daddr, dport);
+	if (dest == NULL) {
+		IP_VS_DBG(1, "ip_vs_del_dest(): destination not found!\n");
+		return -ENOENT;
+	}
+
+	write_lock_bh(&__ip_vs_svc_lock);
+
+	/*
+	 *	Wait until all other svc users go away.
+	 */
+	while (atomic_read(&svc->usecnt) > 1) {};
+
+	/*
+	 *	Unlink dest from the service
+	 */
+	__ip_vs_unlink_dest(svc, dest, 1);
+
+	write_unlock_bh(&__ip_vs_svc_lock);
+
+	/*
+	 *	Delete the destination
+	 */
+	__ip_vs_del_dest(dest);
+
+	LeaveFunction(2);
+
+	return 0;
+}
+
+
+/*
+ *  Add a service into the service hash table
+ */
+static int
+ip_vs_add_service(struct ip_vs_rule_user *ur, struct ip_vs_service **svc_p)
+{
+	int ret = 0;
+	struct ip_vs_scheduler *sched;
+	struct ip_vs_service *svc = NULL;
+
+	MOD_INC_USE_COUNT;
+
+	/*
+	 * Lookup the scheduler, by 'ur->sched_name'
+	 */
+	sched = ip_vs_scheduler_get(ur->sched_name);
+	if (sched == NULL) {
+		IP_VS_INFO("Scheduler module ip_vs_%s.o not found\n",
+			   ur->sched_name);
+		ret = -ENOENT;
+		goto out_mod_dec;
+	}
+
+	svc = (struct ip_vs_service*)
+		kmalloc(sizeof(struct ip_vs_service), GFP_ATOMIC);
+	if (svc == NULL) {
+		IP_VS_DBG(1, "ip_vs_add_service: kmalloc failed.\n");
+		ret = -ENOMEM;
+		goto out_err;
+	}
+	memset(svc, 0, sizeof(struct ip_vs_service));
+
+	svc->protocol = ur->protocol;
+	svc->addr = ur->vaddr;
+	svc->port = ur->vport;
+	svc->fwmark = ur->vfwmark;
+	svc->flags = ur->vs_flags;
+	svc->timeout = ur->timeout * HZ;
+	svc->netmask = ur->netmask;
+
+	INIT_LIST_HEAD(&svc->destinations);
+	svc->sched_lock = RW_LOCK_UNLOCKED;
+	svc->stats.lock = SPIN_LOCK_UNLOCKED;
+
+	/*
+	 *    Bind the scheduler
+	 */
+	ret = ip_vs_bind_scheduler(svc, sched);
+	if (ret) {
+		goto out_err;
+	}
+
+	/*
+	 *    Update the virtual service counters
+	 */
+	if (svc->port == FTPPORT)
+		atomic_inc(&ip_vs_ftpsvc_counter);
+	else if (svc->port == 0)
+		atomic_inc(&ip_vs_nullsvc_counter);
+
+	/*
+	 *    I'm the first user of the service
+	 */
+	atomic_set(&svc->usecnt, 1);
+	atomic_set(&svc->refcnt, 0);
+
+	ip_vs_new_estimator(&svc->stats);
+	ip_vs_num_services++;
+
+	/*
+	 *    Hash the service into the service table
+	 */
+	write_lock_bh(&__ip_vs_svc_lock);
+	ip_vs_svc_hash(svc);
+	write_unlock_bh(&__ip_vs_svc_lock);
+
+	*svc_p = svc;
+	return 0;
+
+  out_err:
+	if (svc)
+		kfree(svc);
+	ip_vs_scheduler_put(sched);
+  out_mod_dec:
+	MOD_DEC_USE_COUNT;
+	return ret;
+}
+
+
+/*
+ *	Edit a service and bind it with a new scheduler
+ */
+static int ip_vs_edit_service(struct ip_vs_service *svc,
+			      struct ip_vs_rule_user *ur)
+{
+	struct ip_vs_scheduler *sched, *old_sched;
+	int ret = 0;
+
+	/*
+	 * Lookup the scheduler, by 'ur->sched_name'
+	 */
+	sched = ip_vs_scheduler_get(ur->sched_name);
+	if (sched == NULL) {
+		IP_VS_INFO("Scheduler module ip_vs_%s.o not found\n",
+			   ur->sched_name);
+		return -ENOENT;
+	}
+
+	write_lock_bh(&__ip_vs_svc_lock);
+
+	/*
+	 * Wait until all other svc users go away.
+	 */
+	while (atomic_read(&svc->usecnt) > 1) {};
+
+	/*
+	 * Set the flags and timeout value
+	 */
+	svc->flags = ur->vs_flags | IP_VS_SVC_F_HASHED;
+	svc->timeout = ur->timeout * HZ;
+	svc->netmask = ur->netmask;
+
+	old_sched = svc->scheduler;
+	if (sched != old_sched) {
+		/*
+		 * Unbind the old scheduler
+		 */
+		if ((ret = ip_vs_unbind_scheduler(svc))) {
+			old_sched = sched;
+			goto out;
+		}
+
+		/*
+		 * Bind the new scheduler
+		 */
+		if ((ret = ip_vs_bind_scheduler(svc, sched))) {
+			/*
+			 * If ip_vs_bind_scheduler fails, restore the old
+			 * scheduler.
+			 * The main reason of failure is out of memory.
+			 *
+			 * The question is if the old scheduler can be
+			 * restored all the time. TODO: if it cannot be
+			 * restored some time, we must delete the service,
+			 * otherwise the system may crash.
+			 */
+			ip_vs_bind_scheduler(svc, old_sched);
+			old_sched = sched;
+		}
+	}
+
+  out:
+	write_unlock_bh(&__ip_vs_svc_lock);
+
+	if (old_sched)
+		ip_vs_scheduler_put(old_sched);
+
+	return ret;
+}
+
+
+/*
+ *  Delete a service from the service list
+ *  The service must be unlinked, unlocked and not referenced!
+ */
+static void __ip_vs_del_service(struct ip_vs_service *svc)
+{
+	struct list_head *l;
+	struct ip_vs_dest *dest;
+	struct ip_vs_scheduler *old_sched;
+
+	ip_vs_num_services--;
+	ip_vs_kill_estimator(&svc->stats);
+
+	/*
+	 *    Unbind scheduler
+	 */
+	old_sched = svc->scheduler;
+	ip_vs_unbind_scheduler(svc);
+	if (old_sched && old_sched->module)
+		__MOD_DEC_USE_COUNT(old_sched->module);
+
+	/*
+	 *    Unlink the whole destination list
+	 */
+	l = &svc->destinations;
+	while (l->next != l) {
+		dest = list_entry(l->next, struct ip_vs_dest, n_list);
+		__ip_vs_unlink_dest(svc, dest, 0);
+		__ip_vs_del_dest(dest);
+	}
+
+	/*
+	 *    Update the virtual service counters
+	 */
+	if (svc->port == FTPPORT)
+		atomic_dec(&ip_vs_ftpsvc_counter);
+	else if (svc->port == 0)
+		atomic_dec(&ip_vs_nullsvc_counter);
+
+	/*
+	 *    Free the service if nobody refers to it
+	 */
+	if (atomic_read(&svc->refcnt) == 0)
+		kfree(svc);
+	MOD_DEC_USE_COUNT;
+}
+
+/*
+ *  Delete a service from the service list
+ */
+static int ip_vs_del_service(struct ip_vs_service *svc)
+{
+	if (svc == NULL)
+		return -EEXIST;
+
+	/*
+	 * Unhash it from the service table
+	 */
+	write_lock_bh(&__ip_vs_svc_lock);
+
+	ip_vs_svc_unhash(svc);
+
+	/*
+	 * Wait until all the svc users go away.
+	 */
+	while (atomic_read(&svc->usecnt) > 1) {};
+
+	__ip_vs_del_service(svc);
+
+	write_unlock_bh(&__ip_vs_svc_lock);
+
+	return 0;
+}
+
+
+/*
+ *  Flush all the virtual services
+ */
+static int ip_vs_flush(void)
+{
+	int idx;
+	struct ip_vs_service *svc;
+	struct list_head *l;
+
+	/*
+	 * Flush the service table hashed by <protocol,addr,port>
+	 */
+	for(idx = 0; idx < IP_VS_SVC_TAB_SIZE; idx++) {
+		l = &ip_vs_svc_table[idx];
+		while (l->next != l) {
+			svc = list_entry(l->next,struct ip_vs_service,s_list);
+			write_lock_bh(&__ip_vs_svc_lock);
+			ip_vs_svc_unhash(svc);
+			/*
+			 * Wait until all the svc users go away.
+			 */
+			while (atomic_read(&svc->usecnt) > 0) {};
+			__ip_vs_del_service(svc);
+			write_unlock_bh(&__ip_vs_svc_lock);
+		}
+	}
+
+	/*
+	 * Flush the service table hashed by fwmark
+	 */
+	for(idx = 0; idx < IP_VS_SVC_TAB_SIZE; idx++) {
+		l = &ip_vs_svc_fwm_table[idx];
+		while (l->next != l) {
+			svc = list_entry(l->next,struct ip_vs_service,f_list);
+			write_lock_bh(&__ip_vs_svc_lock);
+			ip_vs_svc_unhash(svc);
+			/*
+			 * Wait until all the svc users go away.
+			 */
+			while (atomic_read(&svc->usecnt) > 0) {};
+			__ip_vs_del_service(svc);
+			write_unlock_bh(&__ip_vs_svc_lock);
+		}
+	}
+
+	return 0;
+}
+
+
+/*
+ *  Zero counters in a service or all services
+ */
+static inline void
+__ip_vs_zero_stats(struct ip_vs_stats *stats)
+{
+	spin_lock_bh(&stats->lock);
+	memset(stats, 0, (char *)&stats->lock - (char *)stats);
+	spin_unlock_bh(&stats->lock);
+	ip_vs_zero_estimator(stats);
+}
+
+static int ip_vs_zero_service(struct ip_vs_service *svc)
+{
+	struct list_head *l;
+	struct ip_vs_dest *dest;
+
+	write_lock_bh(&__ip_vs_svc_lock);
+	list_for_each (l, &svc->destinations) {
+		dest = list_entry(l, struct ip_vs_dest, n_list);
+		__ip_vs_zero_stats(&dest->stats);
+	}
+	__ip_vs_zero_stats(&svc->stats);
+	write_unlock_bh(&__ip_vs_svc_lock);
+	return 0;
+}
+
+static int ip_vs_zero_all(void)
+{
+	int idx;
+	struct list_head *l;
+	struct ip_vs_service *svc;
+
+	for(idx = 0; idx < IP_VS_SVC_TAB_SIZE; idx++) {
+		list_for_each (l, &ip_vs_svc_table[idx]) {
+			svc = list_entry(l, struct ip_vs_service, s_list);
+			ip_vs_zero_service(svc);
+		}
+	}
+
+	for(idx = 0; idx < IP_VS_SVC_TAB_SIZE; idx++) {
+		list_for_each (l, &ip_vs_svc_fwm_table[idx]) {
+			svc = list_entry(l, struct ip_vs_service, f_list);
+			ip_vs_zero_service(svc);
+		}
+	}
+
+	__ip_vs_zero_stats(&ip_vs_stats);
+	return 0;
+}
+
+
+static int ip_vs_sysctl_defense_mode(ctl_table *ctl, int write,
+	struct file * filp, void *buffer, size_t *lenp)
+{
+	int *valp = ctl->data;
+	int val = *valp;
+	int ret;
+
+	ret = proc_dointvec(ctl, write, filp, buffer, lenp);
+	if (write && (*valp != val)) {
+		if ((*valp < 0) || (*valp > 3)) {
+			/* Restore the correct value */
+			*valp = val;
+		} else {
+			local_bh_disable();
+			update_defense_level();
+			local_bh_enable();
+		}
+	}
+	return ret;
+}
+
+
+/*
+ *      IPVS sysctl table
+ */
+struct ip_vs_sysctl_table {
+	struct ctl_table_header *sysctl_header;
+	ctl_table vs_vars[NET_IPV4_VS_LAST];
+	ctl_table vs_dir[2];
+	ctl_table ipv4_dir[2];
+	ctl_table root_dir[2];
+};
+
+
+static struct ip_vs_sysctl_table ipv4_vs_table = {
+	NULL,
+	{{NET_IPV4_VS_AMEMTHRESH, "amemthresh",
+	  &sysctl_ip_vs_amemthresh, sizeof(int), 0644, NULL,
+	  &proc_dointvec},
+#ifdef CONFIG_IP_VS_DEBUG
+	 {NET_IPV4_VS_DEBUG_LEVEL, "debug_level",
+	  &sysctl_ip_vs_debug_level, sizeof(int), 0644, NULL,
+	  &proc_dointvec},
+#endif
+	 {NET_IPV4_VS_AMDROPRATE, "am_droprate",
+	  &sysctl_ip_vs_am_droprate, sizeof(int), 0644, NULL,
+	  &proc_dointvec},
+	 {NET_IPV4_VS_DROP_ENTRY, "drop_entry",
+	  &sysctl_ip_vs_drop_entry, sizeof(int), 0644, NULL,
+	  &ip_vs_sysctl_defense_mode},
+	 {NET_IPV4_VS_DROP_PACKET, "drop_packet",
+	  &sysctl_ip_vs_drop_packet, sizeof(int), 0644, NULL,
+	  &ip_vs_sysctl_defense_mode},
+	 {NET_IPV4_VS_SECURE_TCP, "secure_tcp",
+	  &sysctl_ip_vs_secure_tcp, sizeof(int), 0644, NULL,
+	  &ip_vs_sysctl_defense_mode},
+	 {NET_IPV4_VS_TO_ES, "timeout_established",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_ESTABLISHED],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_SS, "timeout_synsent",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_SYN_SENT],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_SR, "timeout_synrecv",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_SYN_RECV],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_FW, "timeout_finwait",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_FIN_WAIT],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_TW, "timeout_timewait",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_TIME_WAIT],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_CL, "timeout_close",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_CLOSE],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_CW, "timeout_closewait",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_CLOSE_WAIT],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_LA, "timeout_lastack",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_LAST_ACK],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_LI, "timeout_listen",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_LISTEN],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_SA, "timeout_synack",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_SYNACK],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_UDP, "timeout_udp",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_UDP],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_TO_ICMP, "timeout_icmp",
+	  &vs_timeout_table_dos.timeout[IP_VS_S_ICMP],
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {NET_IPV4_VS_CACHE_BYPASS, "cache_bypass",
+	  &sysctl_ip_vs_cache_bypass, sizeof(int), 0644, NULL,
+	  &proc_dointvec},
+	 {NET_IPV4_VS_EXPIRE_NODEST_CONN, "expire_nodest_conn",
+	  &sysctl_ip_vs_expire_nodest_conn, sizeof(int), 0644, NULL,
+	  &proc_dointvec},
+	 {NET_IPV4_VS_SYNC_THRESHOLD, "sync_threshold",
+	  &sysctl_ip_vs_sync_threshold, sizeof(int), 0644, NULL,
+	  &proc_dointvec},
+	 {NET_IPV4_VS_NAT_ICMP_SEND, "nat_icmp_send",
+	  &sysctl_ip_vs_nat_icmp_send, sizeof(int), 0644, NULL,
+	  &proc_dointvec},
+	 {0}},
+	{{NET_IPV4_VS, "vs", NULL, 0, 0555, ipv4_vs_table.vs_vars},
+	 {0}},
+	{{NET_IPV4, "ipv4", NULL, 0, 0555, ipv4_vs_table.vs_dir},
+	 {0}},
+	{{CTL_NET, "net", NULL, 0, 0555, ipv4_vs_table.ipv4_dir},
+	 {0}}
+};
+
+
+/*
+ *	Write the contents of the VS rule table to a PROCfs file.
+ *	(It is kept just for backward compatibility)
+ */
+static inline char *ip_vs_fwd_name(unsigned flags)
+{
+	char *fwd;
+
+	switch (flags & IP_VS_CONN_F_FWD_MASK) {
+	case IP_VS_CONN_F_LOCALNODE:
+		fwd = "Local";
+		break;
+	case IP_VS_CONN_F_TUNNEL:
+		fwd = "Tunnel";
+		break;
+	case IP_VS_CONN_F_DROUTE:
+		fwd = "Route";
+		break;
+	default:
+		fwd = "Masq";
+	}
+	return fwd;
+}
+
+static int ip_vs_get_info(char *buf, char **start, off_t offset, int length)
+{
+	int len=0;
+	off_t pos=0;
+	char temp[64], temp2[32];
+	int idx;
+	struct ip_vs_service *svc;
+	struct ip_vs_dest *dest;
+	struct list_head *l, *e, *p, *q;
+
+	/*
+	 * Note: since the length of the buffer is usually the multiple
+	 * of 512, it is good to use fixed record of the divisor of 512,
+	 * so that records won't be truncated at buffer boundary.
+	 */
+	pos = 192;
+	if (pos > offset) {
+		sprintf(temp,
+			"IP Virtual Server version %d.%d.%d (size=%d)",
+			NVERSION(IP_VS_VERSION_CODE), IP_VS_CONN_TAB_SIZE);
+		len += sprintf(buf+len, "%-63s\n", temp);
+		len += sprintf(buf+len, "%-63s\n",
+			       "Prot LocalAddress:Port Scheduler Flags");
+		len += sprintf(buf+len, "%-63s\n",
+			       "  -> RemoteAddress:Port Forward Weight ActiveConn InActConn");
+	}
+
+	read_lock_bh(&__ip_vs_svc_lock);
+
+	/* print the service table hashed by <protocol,addr,port> */
+	for (idx = 0; idx < IP_VS_SVC_TAB_SIZE; idx++) {
+		l = &ip_vs_svc_table[idx];
+		for (e=l->next; e!=l; e=e->next) {
+			svc = list_entry(e, struct ip_vs_service, s_list);
+			pos += 64;
+			if (pos > offset) {
+				if (svc->flags & IP_VS_SVC_F_PERSISTENT)
+					sprintf(temp2, "persistent %d %08X",
+						svc->timeout,
+						ntohl(svc->netmask));
+				else
+					temp2[0] = '\0';
+
+				sprintf(temp, "%s  %08X:%04X %s %s",
+					ip_vs_proto_name(svc->protocol),
+					ntohl(svc->addr),
+					ntohs(svc->port),
+					svc->scheduler->name, temp2);
+				len += sprintf(buf+len, "%-63s\n", temp);
+				if (len >= length)
+					goto done;
+			}
+
+			p = &svc->destinations;
+			for (q=p->next; q!=p; q=q->next) {
+				dest = list_entry(q, struct ip_vs_dest, n_list);
+				pos += 64;
+				if (pos <= offset)
+					continue;
+				sprintf(temp,
+					"  -> %08X:%04X      %-7s %-6d %-10d %-10d",
+					ntohl(dest->addr),
+					ntohs(dest->port),
+					ip_vs_fwd_name(atomic_read(&dest->conn_flags)),
+					atomic_read(&dest->weight),
+					atomic_read(&dest->activeconns),
+					atomic_read(&dest->inactconns));
+				len += sprintf(buf+len, "%-63s\n", temp);
+				if (len >= length)
+					goto done;
+			}
+		}
+	}
+
+	/* print the service table hashed by fwmark */
+	for (idx = 0; idx < IP_VS_SVC_TAB_SIZE; idx++) {
+		l = &ip_vs_svc_fwm_table[idx];
+		for (e=l->next; e!=l; e=e->next) {
+			svc = list_entry(e, struct ip_vs_service, f_list);
+			pos += 64;
+			if (pos > offset) {
+				if (svc->flags & IP_VS_SVC_F_PERSISTENT)
+					sprintf(temp2, "persistent %d %08X",
+						svc->timeout,
+						ntohl(svc->netmask));
+				else
+					temp2[0] = '\0';
+
+				sprintf(temp, "FWM  %08X %s %s",
+					svc->fwmark,
+					svc->scheduler->name, temp2);
+				len += sprintf(buf+len, "%-63s\n", temp);
+				if (len >= length)
+					goto done;
+			}
+
+			p = &svc->destinations;
+			for (q=p->next; q!=p; q=q->next) {
+				dest = list_entry(q, struct ip_vs_dest, n_list);
+				pos += 64;
+				if (pos <= offset)
+					continue;
+				sprintf(temp,
+					"  -> %08X:%04X      %-7s %-6d %-10d %-10d",
+					ntohl(dest->addr),
+					ntohs(dest->port),
+					ip_vs_fwd_name(atomic_read(&dest->conn_flags)),
+					atomic_read(&dest->weight),
+					atomic_read(&dest->activeconns),
+					atomic_read(&dest->inactconns));
+				len += sprintf(buf+len, "%-63s\n", temp);
+				if (len >= length)
+					goto done;
+			}
+		}
+	}
+
+  done:
+	read_unlock_bh(&__ip_vs_svc_lock);
+
+	*start = buf+len-(pos-offset);          /* Start of wanted data */
+	len = pos-offset;
+	if (len > length)
+		len = length;
+	if (len < 0)
+		len = 0;
+	return len;
+}
+
+
+struct ip_vs_stats ip_vs_stats;
+
+static int
+ip_vs_stats_get_info(char *buf, char **start, off_t offset, int length)
+{
+	int len=0;
+	off_t pos=0;
+	char temp[64];
+
+	pos += 320;
+	if (pos > offset) {
+		len += sprintf(buf+len, "%-63s\n%-63s\n",
+/*                              01234567 01234567 01234567 0123456701234567 0123456701234567 */
+			       "   Total Incoming Outgoing         Incoming         Outgoing",
+			       "   Conns  Packets  Packets            Bytes            Bytes");
+
+		spin_lock_bh(&ip_vs_stats.lock);
+		sprintf(temp, "%8X %8X %8X %8X%08X %8X%08X",
+			ip_vs_stats.conns,
+			ip_vs_stats.inpkts,
+			ip_vs_stats.outpkts,
+			(__u32)(ip_vs_stats.inbytes>>32),
+			(__u32)ip_vs_stats.inbytes,
+			(__u32)(ip_vs_stats.outbytes>>32),
+			(__u32)ip_vs_stats.outbytes);
+		len += sprintf(buf+len, "%-62s\n\n", temp);
+
+		len += sprintf(buf+len, "%-63s\n",
+/*                              01234567 01234567 01234567 0123456701234567 0123456701234567 */
+			       " Conns/s   Pkts/s   Pkts/s          Bytes/s          Bytes/s");
+		sprintf(temp, "%8X %8X %8X %16X %16X",
+			ip_vs_stats.cps,
+			ip_vs_stats.inpps,
+			ip_vs_stats.outpps,
+			ip_vs_stats.inbps,
+			ip_vs_stats.outbps);
+		len += sprintf(buf+len, "%-63s\n", temp);
+
+		spin_unlock_bh(&ip_vs_stats.lock);
+	}
+
+	*start = buf+len-(pos-offset);          /* Start of wanted data */
+	len = pos-offset;
+	if (len > length)
+		len = length;
+	if (len < 0)
+		len = 0;
+	return len;
+}
+
+
+/*
+ * Set timeout values for tcp tcpfin udp in the vs_timeout_table.
+ */
+static int ip_vs_set_timeouts(struct ip_vs_rule_user *u)
+{
+	IP_VS_DBG(2, "Setting timeout tcp:%d tcpfin:%d udp:%d\n",
+		  u->tcp_timeout,
+		  u->tcp_fin_timeout,
+		  u->udp_timeout);
+
+	if (u->tcp_timeout) {
+		vs_timeout_table.timeout[IP_VS_S_ESTABLISHED]
+			= u->tcp_timeout * HZ;
+	}
+
+	if (u->tcp_fin_timeout) {
+		vs_timeout_table.timeout[IP_VS_S_FIN_WAIT]
+			= u->tcp_fin_timeout * HZ;
+	}
+
+	if (u->udp_timeout) {
+		vs_timeout_table.timeout[IP_VS_S_UDP]
+			= u->udp_timeout * HZ;
+	}
+	return 0;
+}
+
+
+static int
+do_ip_vs_set_ctl(struct sock *sk, int cmd, void *user, unsigned int len)
+{
+	int ret;
+	struct ip_vs_rule_user *urule;
+	struct ip_vs_service *svc = NULL;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/*
+	 * Check the size of mm, no overflow...
+	 * len > 128000 is a sanity check.
+	 */
+	if (len < sizeof(struct ip_vs_rule_user)) {
+		IP_VS_ERR("set_ctl: len %u < %u\n",
+			  len, sizeof(struct ip_vs_rule_user));
+		return -EINVAL;
+	} else if (len > 128000) {
+		IP_VS_ERR("set_ctl: len %u > 128000\n", len);
+		return -EINVAL;
+	} else if ((urule = kmalloc(len, GFP_KERNEL)) == NULL) {
+		IP_VS_ERR("set_ctl: no mem for len %u\n", len);
+		return -ENOMEM;
+	} else if (copy_from_user(urule, user, len) != 0) {
+		ret = -EFAULT;
+		goto out_free;
+	}
+
+	MOD_INC_USE_COUNT;
+	if (down_interruptible(&__ip_vs_mutex)) {
+		ret = -ERESTARTSYS;
+		goto out_dec;
+	}
+
+	if (cmd == IP_VS_SO_SET_FLUSH) {
+		/* Flush the virtual service */
+		ret = ip_vs_flush();
+		goto out_unlock;
+	} else if (cmd == IP_VS_SO_SET_TIMEOUTS) {
+		/* Set timeout values for (tcp tcpfin udp) */
+		ret = ip_vs_set_timeouts(urule);
+		goto out_unlock;
+	} else if (cmd == IP_VS_SO_SET_STARTDAEMON) {
+		ret = start_sync_thread(urule->state, urule->mcast_ifn);
+		goto out_unlock;
+	} else if (cmd == IP_VS_SO_SET_STOPDAEMON) {
+		ret = stop_sync_thread();
+		goto out_unlock;
+	} else if (cmd == IP_VS_SO_SET_ZERO) {
+		/* if no service address is set, zero counters in all */
+		if (!urule->vfwmark && !urule->vaddr && !urule->vport) {
+			ret = ip_vs_zero_all();
+			goto out_unlock;
+		}
+	}
+
+	/*
+	 * Check for valid protocol: TCP or UDP. Even for fwmark!=0
+	 */
+	if (urule->protocol!=IPPROTO_TCP && urule->protocol!=IPPROTO_UDP) {
+		IP_VS_INFO("vs_ctl: invalid protocol: %d %d.%d.%d.%d:%d %s",
+			   ntohs(urule->protocol), NIPQUAD(urule->vaddr),
+			   ntohs(urule->vport), urule->sched_name);
+		ret = -EFAULT;
+		goto out_unlock;
+	}
+
+	/*
+	 * Lookup the exact service by <protocol, vaddr, vport> or fwmark
+	 */
+	if (urule->vfwmark == 0)
+		svc = __ip_vs_service_get(urule->protocol,
+					  urule->vaddr, urule->vport);
+	else
+		svc = __ip_vs_svc_fwm_get(urule->vfwmark);
+
+	if (cmd != IP_VS_SO_SET_ADD
+	    && (svc == NULL || svc->protocol != urule->protocol)) {
+		ret = -ESRCH;
+		goto out_unlock;
+	}
+
+	switch (cmd) {
+	case IP_VS_SO_SET_ADD:
+		if (svc != NULL)
+			ret = -EEXIST;
+		else
+			ret = ip_vs_add_service(urule, &svc);
+		break;
+	case IP_VS_SO_SET_EDIT:
+		ret = ip_vs_edit_service(svc, urule);
+		break;
+	case IP_VS_SO_SET_DEL:
+		ret = ip_vs_del_service(svc);
+		if (!ret)
+			goto out_unlock;
+		break;
+	case IP_VS_SO_SET_ADDDEST:
+		ret = ip_vs_add_dest(svc, urule);
+		break;
+	case IP_VS_SO_SET_EDITDEST:
+		ret = ip_vs_edit_dest(svc, urule);
+		break;
+	case IP_VS_SO_SET_DELDEST:
+		ret = ip_vs_del_dest(svc, urule);
+		break;
+	case IP_VS_SO_SET_ZERO:
+		ret = ip_vs_zero_service(svc);
+		break;
+	default:
+		ret = -EINVAL;
+	}
+
+	if (svc)
+		ip_vs_service_put(svc);
+
+  out_unlock:
+	up(&__ip_vs_mutex);
+  out_dec:
+	MOD_DEC_USE_COUNT;
+  out_free:
+	kfree(urule);
+	return ret;
+}
+
+
+static inline void
+__ip_vs_copy_stats(struct ip_vs_stats_user *dst, struct ip_vs_stats *src)
+{
+	spin_lock_bh(&src->lock);
+	memcpy(dst, src, (char*)&src->lock - (char*)src);
+	spin_unlock_bh(&src->lock);
+}
+
+static inline int
+__ip_vs_get_service_entries(const struct ip_vs_get_services *get,
+			    struct ip_vs_get_services *uptr)
+{
+	int idx, count=0;
+	struct ip_vs_service *svc;
+	struct list_head *l;
+	struct ip_vs_service_user entry;
+	int ret = 0;
+
+	for (idx = 0; idx < IP_VS_SVC_TAB_SIZE; idx++) {
+		list_for_each (l, &ip_vs_svc_table[idx]) {
+			if (count >= get->num_services)
+				goto out;
+			svc = list_entry(l, struct ip_vs_service, s_list);
+			entry.protocol = svc->protocol;
+			entry.addr = svc->addr;
+			entry.port = svc->port;
+			entry.fwmark = svc->fwmark;
+			strcpy(entry.sched_name, svc->scheduler->name);
+			entry.flags = svc->flags;
+			entry.timeout = svc->timeout / HZ;
+			entry.netmask = svc->netmask;
+			entry.num_dests = svc->num_dests;
+			__ip_vs_copy_stats(&entry.stats, &svc->stats);
+			if (copy_to_user(&uptr->entrytable[count],
+					 &entry, sizeof(entry))) {
+				ret = -EFAULT;
+				goto out;
+			}
+			count++;
+		}
+	}
+
+	for (idx = 0; idx < IP_VS_SVC_TAB_SIZE; idx++) {
+		list_for_each (l, &ip_vs_svc_fwm_table[idx]) {
+			if (count >= get->num_services)
+				goto out;
+			svc = list_entry(l, struct ip_vs_service, f_list);
+			entry.protocol = svc->protocol;
+			entry.addr = svc->addr;
+			entry.port = svc->port;
+			entry.fwmark = svc->fwmark;
+			strcpy(entry.sched_name, svc->scheduler->name);
+			entry.flags = svc->flags;
+			entry.timeout = svc->timeout / HZ;
+			entry.netmask = svc->netmask;
+			entry.num_dests = svc->num_dests;
+			__ip_vs_copy_stats(&entry.stats, &svc->stats);
+			if (copy_to_user(&uptr->entrytable[count],
+					 &entry, sizeof(entry))) {
+				ret = -EFAULT;
+				goto out;
+			}
+			count++;
+		}
+	}
+ out:
+	return ret;
+}
+
+static inline int
+__ip_vs_get_dest_entries(const struct ip_vs_get_dests *get,
+			 struct ip_vs_get_dests *uptr)
+{
+	struct ip_vs_service *svc;
+	int ret = 0;
+
+	if (get->fwmark)
+		svc = __ip_vs_svc_fwm_get(get->fwmark);
+	else
+		svc = __ip_vs_service_get(get->protocol,
+					  get->addr, get->port);
+	if (svc) {
+		int count = 0;
+		struct ip_vs_dest *dest;
+		struct list_head *l, *e;
+		struct ip_vs_dest_user entry;
+
+		l = &svc->destinations;
+		for (e=l->next; e!=l; e=e->next) {
+			if (count >= get->num_dests)
+				break;
+			dest = list_entry(e, struct ip_vs_dest, n_list);
+			entry.addr = dest->addr;
+			entry.port = dest->port;
+			entry.flags = atomic_read(&dest->conn_flags);
+			entry.weight = atomic_read(&dest->weight);
+			entry.activeconns = atomic_read(&dest->activeconns);
+			entry.inactconns = atomic_read(&dest->inactconns);
+			__ip_vs_copy_stats(&entry.stats, &dest->stats);
+			if (copy_to_user(&uptr->entrytable[count],
+					 &entry, sizeof(entry))) {
+				ret = -EFAULT;
+				break;
+			}
+			count++;
+		}
+		ip_vs_service_put(svc);
+	} else
+		ret = -ESRCH;
+	return ret;
+}
+
+static inline void
+__ip_vs_get_timeouts(struct ip_vs_timeout_user *u)
+{
+	u->tcp_timeout = vs_timeout_table.timeout[IP_VS_S_ESTABLISHED] / HZ;
+	u->tcp_fin_timeout = vs_timeout_table.timeout[IP_VS_S_FIN_WAIT] / HZ;
+	u->udp_timeout = vs_timeout_table.timeout[IP_VS_S_UDP] / HZ;
+}
+
+static int
+do_ip_vs_get_ctl(struct sock *sk, int cmd, void *user, int *len)
+{
+	int ret = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (down_interruptible(&__ip_vs_mutex))
+		return -ERESTARTSYS;
+
+	switch (cmd) {
+	case IP_VS_SO_GET_VERSION:
+	{
+		char buf[64];
+
+		sprintf(buf, "IP Virtual Server version %d.%d.%d (size=%d)",
+			NVERSION(IP_VS_VERSION_CODE), IP_VS_CONN_TAB_SIZE);
+		if (*len < strlen(buf)+1) {
+			ret = -EINVAL;
+			goto out;
+		}
+		if (copy_to_user(user, buf, strlen(buf)+1) != 0) {
+			ret = -EFAULT;
+			goto out;
+		}
+		*len = strlen(buf)+1;
+	}
+	break;
+
+	case IP_VS_SO_GET_INFO:
+	{
+		struct ip_vs_getinfo info;
+		info.version = IP_VS_VERSION_CODE;
+		info.size = IP_VS_CONN_TAB_SIZE;
+		info.num_services = ip_vs_num_services;
+		if (copy_to_user(user, &info, sizeof(info)) != 0)
+			ret = -EFAULT;
+	}
+	break;
+
+	case IP_VS_SO_GET_SERVICES:
+	{
+		struct ip_vs_get_services get;
+
+		if (*len < sizeof(get)) {
+			IP_VS_ERR("length: %u < %u\n", *len, sizeof(get));
+			ret = -EINVAL;
+			goto out;
+		}
+		if (copy_from_user(&get, user, sizeof(get))) {
+			ret = -EFAULT;
+			goto out;
+		}
+		if (*len != (sizeof(get)+sizeof(struct ip_vs_service_user)*get.num_services)) {
+			IP_VS_ERR("length: %u != %u\n", *len,
+				  sizeof(get)+sizeof(struct ip_vs_service_user)*get.num_services);
+			ret = -EINVAL;
+			goto out;
+		}
+		ret = __ip_vs_get_service_entries(&get, user);
+	}
+	break;
+
+	case IP_VS_SO_GET_SERVICE:
+	{
+		struct ip_vs_service_user get;
+		struct ip_vs_service *svc;
+
+		if (*len != sizeof(get)) {
+			IP_VS_ERR("length: %u != %u\n", *len, sizeof(get));
+			ret = -EINVAL;
+			goto out;
+		}
+		if (copy_from_user(&get, user, sizeof(get))) {
+			ret = -EFAULT;
+			goto out;
+		}
+
+		if (get.fwmark)
+			svc = __ip_vs_svc_fwm_get(get.fwmark);
+		else
+			svc = __ip_vs_service_get(get.protocol,
+						  get.addr, get.port);
+		if (svc) {
+			strcpy(get.sched_name, svc->scheduler->name);
+			get.flags = svc->flags;
+			get.timeout = svc->timeout / HZ;
+			get.netmask = svc->netmask;
+			get.num_dests = svc->num_dests;
+			__ip_vs_copy_stats(&get.stats, &svc->stats);
+			if (copy_to_user(user, &get, *len) != 0)
+				ret = -EFAULT;
+			ip_vs_service_put(svc);
+		} else
+			ret = -ESRCH;
+	}
+	break;
+
+	case IP_VS_SO_GET_DESTS:
+	{
+		struct ip_vs_get_dests get;
+
+		if (*len < sizeof(get)) {
+			IP_VS_ERR("length: %u < %u\n", *len, sizeof(get));
+			ret = -EINVAL;
+			goto out;
+		}
+		if (copy_from_user(&get, user, sizeof(get))) {
+			ret = -EFAULT;
+			goto out;
+		}
+		if (*len != (sizeof(get) +
+			     sizeof(struct ip_vs_dest_user)*get.num_dests)) {
+			IP_VS_ERR("length: %u != %u\n", *len,
+				  sizeof(get)+sizeof(struct ip_vs_dest_user)*get.num_dests);
+			ret = -EINVAL;
+			goto out;
+		}
+		ret = __ip_vs_get_dest_entries(&get, user);
+	}
+	break;
+
+	case IP_VS_SO_GET_TIMEOUTS:
+	{
+		struct ip_vs_timeout_user u;
+
+		if (*len < sizeof(u)) {
+			IP_VS_ERR("length: %u < %u\n", *len, sizeof(u));
+			ret = -EINVAL;
+			goto out;
+		}
+		__ip_vs_get_timeouts(&u);
+		if (copy_to_user(user, &u, sizeof(u)) != 0)
+			ret = -EFAULT;
+	}
+	break;
+
+	case IP_VS_SO_GET_DAEMON:
+	{
+		struct ip_vs_daemon_user u;
+
+		if (*len < sizeof(u)) {
+			IP_VS_ERR("length: %u < %u\n", *len, sizeof(u));
+			ret = -EINVAL;
+			goto out;
+		}
+		u.state = ip_vs_sync_state;
+		strcpy(u.mcast_ifn, ip_vs_mcast_ifn);
+		if (copy_to_user(user, &u, sizeof(u)) != 0)
+			ret = -EFAULT;
+	}
+	break;
+
+	default:
+		ret = -EINVAL;
+	}
+
+  out:
+	up(&__ip_vs_mutex);
+	return ret;
+}
+
+
+static struct nf_sockopt_ops ip_vs_sockopts = {
+	{ NULL, NULL }, PF_INET,
+	IP_VS_BASE_CTL, IP_VS_SO_SET_MAX+1, do_ip_vs_set_ctl,
+	IP_VS_BASE_CTL, IP_VS_SO_GET_MAX+1, do_ip_vs_get_ctl
+};
+
+
+int ip_vs_control_init(void)
+{
+	int ret;
+	int idx;
+
+	EnterFunction(2);
+
+	ret = nf_register_sockopt(&ip_vs_sockopts);
+	if (ret) {
+		IP_VS_ERR("cannot register sockopt.\n");
+		return ret;
+	}
+
+	proc_net_create("ip_vs", 0, ip_vs_get_info);
+	proc_net_create("ip_vs_stats", 0, ip_vs_stats_get_info);
+
+	ipv4_vs_table.sysctl_header =
+		register_sysctl_table(ipv4_vs_table.root_dir, 0);
+	/*
+	 * Initilize ip_vs_svc_table, ip_vs_svc_fwm_table, ip_vs_rtable,
+	 * ip_vs_schedulers.
+	 */
+	for(idx = 0; idx < IP_VS_SVC_TAB_SIZE; idx++)  {
+		INIT_LIST_HEAD(&ip_vs_svc_table[idx]);
+		INIT_LIST_HEAD(&ip_vs_svc_fwm_table[idx]);
+	}
+	for(idx = 0; idx < IP_VS_RTAB_SIZE; idx++)  {
+		INIT_LIST_HEAD(&ip_vs_rtable[idx]);
+	}
+
+	memset(&ip_vs_stats, 0, sizeof(ip_vs_stats));
+	ip_vs_stats.lock = SPIN_LOCK_UNLOCKED;
+	ip_vs_new_estimator(&ip_vs_stats);
+
+	/* Hook the defense timer */
+	init_timer(&defense_timer);
+	defense_timer.function = defense_timer_handler;
+	defense_timer.expires = jiffies + DEFENSE_TIMER_PERIOD;
+	add_timer(&defense_timer);
+
+	LeaveFunction(2);
+	return 0;
+}
+
+void ip_vs_control_cleanup(void)
+{
+	EnterFunction(2);
+	ip_vs_trash_cleanup();
+	del_timer_sync(&defense_timer);
+	ip_vs_kill_estimator(&ip_vs_stats);
+	unregister_sysctl_table(ipv4_vs_table.sysctl_header);
+	proc_net_remove("ip_vs_stats");
+	proc_net_remove("ip_vs");
+	nf_unregister_sockopt(&ip_vs_sockopts);
+	LeaveFunction(2);
+}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_dh.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_dh.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_dh.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_dh.c	2003-08-27 14:40:30.000000000 +0000
@@ -0,0 +1,265 @@
+/*
+ * IPVS:        Destination Hashing scheduling module
+ *
+ * Version:     $Id: ip_vs_dh.c,v 1.4 2001/10/19 15:05:17 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@gnuchina.org>
+ *
+ *              Inspired by the consistent hashing scheduler patch from
+ *              Thomas Proell <proellt@gmx.de>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *
+ */
+
+/*
+ * The dh algorithm is to select server by the hash key of destination IP
+ * address. The pseudo code is as follows:
+ *
+ *       n <- servernode[dest_ip];
+ *       if (n is dead) OR
+ *          (n is overloaded, such as n.conns>2*n.weight) then
+ *                 return NULL;
+ *
+ *       return n;
+ *
+ * Notes that servernode is a 256-bucket hash table that maps the hash
+ * index derived from packet destination IP address to the current server
+ * array. If the dh scheduler is used in cache cluster, it is good to
+ * combine it with cache_bypass feature. When the statically assigned
+ * server is dead or overloaded, the load balancer can bypass the cache
+ * server and send requests to the original server directly.
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+
+#include <net/ip_vs.h>
+
+
+/*
+ *      IPVS DH bucket
+ */
+struct ip_vs_dh_bucket {
+	struct ip_vs_dest       *dest;          /* real server (cache) */
+};
+
+/*
+ *     for IPVS DH entry hash table
+ */
+#ifndef CONFIG_IP_VS_DH_TAB_BITS
+#define CONFIG_IP_VS_DH_TAB_BITS        8
+#endif
+#define IP_VS_DH_TAB_BITS               CONFIG_IP_VS_DH_TAB_BITS
+#define IP_VS_DH_TAB_SIZE               (1 << IP_VS_DH_TAB_BITS)
+#define IP_VS_DH_TAB_MASK               (IP_VS_DH_TAB_SIZE - 1)
+
+
+/*
+ *	Returns hash value for IPVS DH entry
+ */
+static inline unsigned ip_vs_dh_hashkey(__u32 addr)
+{
+	return (ntohl(addr)*2654435761UL) & IP_VS_DH_TAB_MASK;
+}
+
+
+/*
+ *      Get ip_vs_dest associated with supplied parameters.
+ */
+static inline struct ip_vs_dest *
+ip_vs_dh_get(struct ip_vs_dh_bucket *tbl, __u32 addr)
+{
+	return (tbl[ip_vs_dh_hashkey(addr)]).dest;
+}
+
+
+/*
+ *      Assign all the hash buckets of the specified table with the service.
+ */
+static int
+ip_vs_dh_assign(struct ip_vs_dh_bucket *tbl, struct ip_vs_service *svc)
+{
+	int i;
+	struct ip_vs_dh_bucket *b;
+	struct list_head *p;
+	struct ip_vs_dest *dest;
+
+	b = tbl;
+	p = &svc->destinations;
+	for (i=0; i<IP_VS_DH_TAB_SIZE; i++) {
+		if (list_empty(p)) {
+			b->dest = NULL;
+		} else {
+			if (p == &svc->destinations)
+				p = p->next;
+
+			dest = list_entry(p, struct ip_vs_dest, n_list);
+			atomic_inc(&dest->refcnt);
+			b->dest = dest;
+
+			p = p->next;
+		}
+		b++;
+	}
+	return 0;
+}
+
+
+/*
+ *      Flush all the hash buckets of the specified table.
+ */
+static void ip_vs_dh_flush(struct ip_vs_dh_bucket *tbl)
+{
+	int i;
+	struct ip_vs_dh_bucket *b;
+
+	b = tbl;
+	for (i=0; i<IP_VS_DH_TAB_SIZE; i++) {
+		if (b->dest) {
+			atomic_dec(&b->dest->refcnt);
+			b->dest = NULL;
+		}
+		b++;
+	}
+}
+
+
+static int ip_vs_dh_init_svc(struct ip_vs_service *svc)
+{
+	struct ip_vs_dh_bucket *tbl;
+
+	/* allocate the DH table for this service */
+	tbl = kmalloc(sizeof(struct ip_vs_dh_bucket)*IP_VS_DH_TAB_SIZE,
+		      GFP_ATOMIC);
+	if (tbl == NULL) {
+		IP_VS_ERR("ip_vs_dh_init_svc(): no memory\n");
+		return -ENOMEM;
+	}
+	svc->sched_data = tbl;
+	IP_VS_DBG(6, "DH hash table (memory=%dbytes) allocated for "
+		  "current service\n",
+		  sizeof(struct ip_vs_dh_bucket)*IP_VS_DH_TAB_SIZE);
+
+	/* assign the hash buckets with the updated service */
+	ip_vs_dh_assign(tbl, svc);
+
+	return 0;
+}
+
+
+static int ip_vs_dh_done_svc(struct ip_vs_service *svc)
+{
+	struct ip_vs_dh_bucket *tbl = svc->sched_data;
+
+	/* got to clean up hash buckets here */
+	ip_vs_dh_flush(tbl);
+
+	/* release the table itself */
+	kfree(svc->sched_data);
+	IP_VS_DBG(6, "DH hash table (memory=%dbytes) released\n",
+		  sizeof(struct ip_vs_dh_bucket)*IP_VS_DH_TAB_SIZE);
+
+	return 0;
+}
+
+
+static int ip_vs_dh_update_svc(struct ip_vs_service *svc)
+{
+	struct ip_vs_dh_bucket *tbl = svc->sched_data;
+
+	/* got to clean up hash buckets here */
+	ip_vs_dh_flush(tbl);
+
+	/* assign the hash buckets with the updated service */
+	ip_vs_dh_assign(tbl, svc);
+
+	return 0;
+}
+
+
+/*
+ *      If the number of active connections is twice larger than its weight,
+ *      consider that the server is overloaded here.
+ */
+static inline int is_overloaded(struct ip_vs_dest *dest)
+{
+	if (atomic_read(&dest->activeconns) > atomic_read(&dest->weight)*2) {
+		return 1;
+	}
+	return 0;
+}
+
+
+/*
+ *      Destination hashing scheduling
+ */
+static struct ip_vs_dest *
+ip_vs_dh_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	struct ip_vs_dest *dest;
+	struct ip_vs_dh_bucket *tbl;
+
+	IP_VS_DBG(6, "ip_vs_dh_schedule(): Scheduling...\n");
+
+	tbl = (struct ip_vs_dh_bucket *)svc->sched_data;
+	dest = ip_vs_dh_get(tbl, iph->daddr);
+	if (!dest
+	    || !(dest->flags & IP_VS_DEST_F_AVAILABLE)
+	    || atomic_read(&dest->weight) <= 0
+	    || is_overloaded(dest)) {
+		return NULL;
+	}
+
+	IP_VS_DBG(6, "DH: destination IP address %u.%u.%u.%u "
+		  "--> server %u.%u.%u.%u:%d\n",
+		  NIPQUAD(iph->daddr),
+		  NIPQUAD(dest->addr),
+		  ntohs(dest->port));
+
+	return dest;
+}
+
+
+/*
+ *      IPVS DH Scheduler structure
+ */
+static struct ip_vs_scheduler ip_vs_dh_scheduler =
+{
+	{0},                    /* n_list */
+	"dh",                   /* name */
+	ATOMIC_INIT(0),         /* refcnt */
+	THIS_MODULE,            /* this module */
+	ip_vs_dh_init_svc,      /* service initializer */
+	ip_vs_dh_done_svc,      /* service done */
+	ip_vs_dh_update_svc,    /* service updater */
+	ip_vs_dh_schedule,      /* select a server from the destination list */
+};
+
+
+static int __init ip_vs_dh_init(void)
+{
+	INIT_LIST_HEAD(&ip_vs_dh_scheduler.n_list);
+	return register_ip_vs_scheduler(&ip_vs_dh_scheduler);
+}
+
+
+static void __exit ip_vs_dh_cleanup(void)
+{
+	unregister_ip_vs_scheduler(&ip_vs_dh_scheduler);
+}
+
+
+module_init(ip_vs_dh_init);
+module_exit(ip_vs_dh_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_est.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_est.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_est.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_est.c	2003-08-27 14:39:36.000000000 +0000
@@ -0,0 +1,200 @@
+/*
+ * ip_vs_est.c  Simple rate estimator for IPVS
+ *
+ * Version:     $Id: ip_vs_est.c,v 1.3.2.1 2003/07/29 14:37:13 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *
+ */
+#include <linux/kernel.h>
+#include <linux/types.h>
+
+#include <net/ip_vs.h>
+
+/*
+  This code is to estimate rate in a shorter interval (such as 8
+  seconds) for virtual services and real servers. For measure rate in a
+  long interval, it is easy to implement a user level daemon which
+  periodically reads those statistical counters and measure rate.
+
+  Currently, the measurement is activated by slow timer handler. Hope
+  this measurement will not introduce too much load.
+
+  We measure rate during the last 8 seconds every 2 seconds:
+
+    avgrate = avgrate*(1-W) + rate*W
+
+    where W = 2^(-2)
+
+  NOTES.
+
+  * The stored value for average bps is scaled by 2^5, so that maximal
+    rate is ~2.15Gbits/s, average pps and cps are scaled by 2^10.
+
+  * A lot code is taken from net/sched/estimator.c
+ */
+
+
+struct ip_vs_estimator
+{
+	struct ip_vs_estimator	*next;
+	struct ip_vs_stats	*stats;
+
+	u32			last_conns;
+	u32			last_inpkts;
+	u32			last_outpkts;
+	u64			last_inbytes;
+	u64			last_outbytes;
+
+	u32			cps;
+	u32			inpps;
+	u32			outpps;
+	u32			inbps;
+	u32			outbps;
+};
+
+
+static struct ip_vs_estimator *est_list = NULL;
+static rwlock_t est_lock = RW_LOCK_UNLOCKED;
+static struct timer_list est_timer;
+
+static void estimation_timer(unsigned long arg)
+{
+	struct ip_vs_estimator *e;
+	struct ip_vs_stats *s;
+	u32 n_conns;
+	u32 n_inpkts, n_outpkts;
+	u64 n_inbytes, n_outbytes;
+	u32 rate;
+
+	read_lock(&est_lock);
+	for (e = est_list; e; e = e->next) {
+		s = e->stats;
+
+		spin_lock(&s->lock);
+		n_conns = s->conns;
+		n_inpkts = s->inpkts;
+		n_outpkts = s->outpkts;
+		n_inbytes = s->inbytes;
+		n_outbytes = s->outbytes;
+
+		/* scaled by 2^10, but divided 2 seconds */
+		rate = (n_conns - e->last_conns)<<9;
+		e->last_conns = n_conns;
+		e->cps += ((long)rate - (long)e->cps)>>2;
+		s->cps = (e->cps+0x1FF)>>10;
+
+		rate = (n_inpkts - e->last_inpkts)<<9;
+		e->last_inpkts = n_inpkts;
+		e->inpps += ((long)rate - (long)e->inpps)>>2;
+		s->inpps = (e->inpps+0x1FF)>>10;
+
+		rate = (n_outpkts - e->last_outpkts)<<9;
+		e->last_outpkts = n_outpkts;
+		e->outpps += ((long)rate - (long)e->outpps)>>2;
+		s->outpps = (e->outpps+0x1FF)>>10;
+
+		rate = (n_inbytes - e->last_inbytes)<<4;
+		e->last_inbytes = n_inbytes;
+		e->inbps += ((long)rate - (long)e->inbps)>>2;
+		s->inbps = (e->inbps+0xF)>>5;
+
+		rate = (n_outbytes - e->last_outbytes)<<4;
+		e->last_outbytes = n_outbytes;
+		e->outbps += ((long)rate - (long)e->outbps)>>2;
+		s->outbps = (e->outbps+0xF)>>5;
+		spin_unlock(&s->lock);
+	}
+	read_unlock(&est_lock);
+	mod_timer(&est_timer, jiffies + 2*HZ);
+}
+
+int ip_vs_new_estimator(struct ip_vs_stats *stats)
+{
+	struct ip_vs_estimator *est;
+
+	est = kmalloc(sizeof(*est), GFP_KERNEL);
+	if (est == NULL)
+		return -ENOMEM;
+
+	memset(est, 0, sizeof(*est));
+	est->stats = stats;
+	est->last_conns = stats->conns;
+	est->cps = stats->cps<<10;
+
+	est->last_inpkts = stats->inpkts;
+	est->inpps = stats->inpps<<10;
+
+	est->last_outpkts = stats->outpkts;
+	est->outpps = stats->outpps<<10;
+
+	est->last_inbytes = stats->inbytes;
+	est->inbps = stats->inbps<<5;
+
+	est->last_outbytes = stats->outbytes;
+	est->outbps = stats->outbps<<5;
+
+	est->next = est_list;
+	if (est->next == NULL) {
+		init_timer(&est_timer);
+		est_timer.expires = jiffies + 2*HZ;
+		est_timer.function = estimation_timer;
+		add_timer(&est_timer);
+	}
+	write_lock_bh(&est_lock);
+	est_list = est;
+	write_unlock_bh(&est_lock);
+	return 0;
+}
+
+void ip_vs_kill_estimator(struct ip_vs_stats *stats)
+{
+	struct ip_vs_estimator *est, **pest;
+	int killed = 0;
+
+	write_lock_bh(&est_lock);
+	pest = &est_list;
+	while ((est=*pest) != NULL) {
+		if (est->stats != stats) {
+			pest = &est->next;
+			continue;
+		}
+		*pest = est->next;
+		kfree(est);
+		killed++;
+	}
+	if (killed && est_list == NULL)
+		del_timer_sync(&est_timer);
+	write_unlock_bh(&est_lock);
+}
+
+void ip_vs_zero_estimator(struct ip_vs_stats *stats)
+{
+	struct ip_vs_estimator *e;
+
+	write_lock_bh(&est_lock);
+	for (e = est_list; e; e = e->next) {
+		if (e->stats != stats)
+			continue;
+
+		/* set counters zero */
+		e->last_conns = 0;
+		e->last_inpkts = 0;
+		e->last_outpkts = 0;
+		e->last_inbytes = 0;
+		e->last_outbytes = 0;
+		e->cps = 0;
+		e->inpps = 0;
+		e->outpps = 0;
+		e->inbps = 0;
+		e->outbps = 0;
+	}
+	write_unlock_bh(&est_lock);
+}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_ftp.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_ftp.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_ftp.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_ftp.c	2003-08-27 14:40:57.000000000 +0000
@@ -0,0 +1,407 @@
+/*
+ * IP_VS        ftp application module
+ *
+ * Version:	$Id: ip_vs_ftp.c,v 1.12 2002/08/10 04:32:35 wensong Exp $
+ *
+ * Authors:	Wensong Zhang <wensong@linuxvirtualserver.org>
+ *
+ * Changes:
+ *
+ *
+ *	This program is free software; you can redistribute it and/or
+ *	modify it under the terms of the GNU General Public License
+ *	as published by the Free Software Foundation; either version
+ *	2 of the License, or (at your option) any later version.
+ *
+ * Most code here is taken from ip_masq_ftp.c in kernel 2.2. The difference
+ * is that ip_vs_ftp module handles the reverse direction to ip_masq_ftp.
+ *
+ *		IP_MASQ_FTP ftp masquerading module
+ *
+ * Version:	@(#)ip_masq_ftp.c 0.04   02/05/96
+ *
+ * Author:	Wouter Gadeyne
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <asm/system.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/skbuff.h>
+#include <linux/in.h>
+#include <linux/ip.h>
+#include <linux/init.h>
+#include <net/protocol.h>
+#include <net/tcp.h>
+
+#include <net/ip_vs.h>
+
+
+#define SERVER_STRING "227 Entering Passive Mode ("
+#define CLIENT_STRING "PORT "
+
+
+/*
+ * List of ports (up to IP_VS_APP_MAX_PORTS) to be handled by helper
+ * First port is set to the default port.
+ */
+static int ports[IP_VS_APP_MAX_PORTS] = {21, 0};
+struct ip_vs_app *incarnations[IP_VS_APP_MAX_PORTS];
+
+/*
+ *	Debug level
+ */
+#ifdef CONFIG_IP_VS_DEBUG
+static int debug=0;
+MODULE_PARM(debug, "i");
+#endif
+
+MODULE_PARM(ports, "1-" __MODULE_STRING(IP_VS_APP_MAX_PORTS) "i");
+
+/*	Dummy variable */
+static int ip_vs_ftp_pasv;
+
+
+static int
+ip_vs_ftp_init_conn(struct ip_vs_app *vapp, struct ip_vs_conn *cp)
+{
+	return 0;
+}
+
+
+static int
+ip_vs_ftp_done_conn(struct ip_vs_app *vapp, struct ip_vs_conn *cp)
+{
+	return 0;
+}
+
+
+/*
+ * Get <addr,port> from the string "xxx.xxx.xxx.xxx,ppp,ppp", started
+ * with the "pattern" and terminated with the "term" character.
+ * <addr,port> is in network order.
+ */
+static int ip_vs_ftp_get_addrport(char *data, char *data_limit,
+				  const char *pattern, size_t plen, char term,
+				  __u32 *addr, __u16 *port,
+				  char **start, char **end)
+{
+	unsigned char p1,p2,p3,p4,p5,p6;
+
+	while (data < data_limit) {
+		if (strnicmp(data, pattern, plen) != 0) {
+			data++;
+			continue;
+		}
+		*start = data+plen;
+		p1 = simple_strtoul(data+plen, &data, 10);
+		if (*data != ',')
+			continue;
+		p2 = simple_strtoul(data+1, &data, 10);
+		if (*data != ',')
+			continue;
+		p3 = simple_strtoul(data+1, &data, 10);
+		if (*data != ',')
+			continue;
+		p4 = simple_strtoul(data+1, &data, 10);
+		if (*data != ',')
+			continue;
+		p5 = simple_strtoul(data+1, &data, 10);
+		if (*data != ',')
+			continue;
+		p6 = simple_strtoul(data+1, &data, 10);
+		if (*data != term)
+			continue;
+
+		*end = data;
+		*addr = (p4<<24) | (p3<<16) | (p2<<8) | p1;
+		*port = (p6<<8) | p5;
+		return 1;
+	}
+	return 0;
+}
+
+
+/*
+ * Look at outgoing ftp packets to catch the response to a PASV command
+ * from the server (inside-to-outside).
+ * When we see one, we build a connection entry with the client address,
+ * client port 0 (unknown at the moment), the server address and the
+ * server port.  Mark the current connection entry as a control channel
+ * of the new entry. All this work is just to make the data connection
+ * can be scheduled to the right server later.
+ *
+ * The outgoing packet should be something like
+ *   "227 Entering Passive Mode (xxx,xxx,xxx,xxx,ppp,ppp)".
+ * xxx,xxx,xxx,xxx is the server address, ppp,ppp is the server port number.
+ */
+static int ip_vs_ftp_out(struct ip_vs_app *vapp,
+			 struct ip_vs_conn *cp, struct sk_buff *skb)
+{
+	struct iphdr *iph;
+	struct tcphdr *th;
+	char *data, *data_limit;
+	char *start, *end;
+	__u32 from;
+	__u16 port;
+	struct ip_vs_conn *n_cp;
+	char buf[24];		/* xxx.xxx.xxx.xxx,ppp,ppp\000 */
+	unsigned buf_len;
+	int diff;
+
+	/* Only useful for established sessions */
+	if (cp->state != IP_VS_S_ESTABLISHED)
+		return 0;
+
+	if (cp->app_data == &ip_vs_ftp_pasv) {
+		iph = skb->nh.iph;
+		th = (struct tcphdr *)&(((char *)iph)[iph->ihl*4]);
+		data = (char *)th + (th->doff << 2);
+		data_limit = skb->tail;
+
+		if (ip_vs_ftp_get_addrport(data, data_limit,
+					   SERVER_STRING,
+					   sizeof(SERVER_STRING)-1, ')',
+					   &from, &port,
+					   &start, &end) == 0)
+			return 0;
+
+		IP_VS_DBG(1-debug, "PASV response (%u.%u.%u.%u:%d) -> "
+			  "%u.%u.%u.%u:%d detected\n",
+			  NIPQUAD(from), ntohs(port), NIPQUAD(cp->caddr), 0);
+
+		/*
+		 * Now update or create an connection entry for it
+		 */
+		n_cp = ip_vs_conn_out_get(iph->protocol, from, port,
+					  cp->caddr, 0);
+		if (!n_cp) {
+			n_cp = ip_vs_conn_new(IPPROTO_TCP,
+					      cp->caddr, 0,
+					      cp->vaddr, port,
+					      from, port,
+					      IP_VS_CONN_F_NO_CPORT,
+					      cp->dest);
+			if (!n_cp)
+				return 0;
+
+			/* add its controller */
+			ip_vs_control_add(n_cp, cp);
+
+			/* increase dest's inactive connection counter */
+			if (cp->dest)
+				atomic_inc(&cp->dest->inactconns);
+		}
+
+		/*
+		 * Replace the old passive address with the new one
+		 */
+		from = n_cp->vaddr;
+		port = n_cp->vport;
+		sprintf(buf,"%d,%d,%d,%d,%d,%d", NIPQUAD(from),
+			port&255, port>>8&255);
+		buf_len = strlen(buf);
+
+		/*
+		 * Calculate required delta-offset to keep TCP happy
+		 */
+		diff = buf_len - (end-start);
+
+		if (diff == 0) {
+			/* simply replace it with new passive address */
+			memcpy(start, buf, buf_len);
+		} else {
+			/* fixme: return value isn't checked here */
+			ip_vs_skb_replace(skb, GFP_ATOMIC, start,
+					  end-start, buf, buf_len);
+		}
+
+		cp->app_data = NULL;
+		ip_vs_conn_listen(n_cp);
+		ip_vs_conn_put(n_cp);
+		return diff;
+	}
+	return 0;
+}
+
+
+/*
+ * Look at incoming ftp packets to catch the PASV/PORT command
+ * (outside-to-inside).
+ *
+ * The incoming packet having the PORT command should be something like
+ *      "PORT xxx,xxx,xxx,xxx,ppp,ppp\n".
+ * xxx,xxx,xxx,xxx is the client address, ppp,ppp is the client port number.
+ * In this case, we create a connection entry using the client address and
+ * port, so that the active ftp data connection from the server can reach
+ * the client.
+ */
+static int ip_vs_ftp_in(struct ip_vs_app *vapp,
+			struct ip_vs_conn *cp, struct sk_buff *skb)
+{
+	struct iphdr *iph;
+	struct tcphdr *th;
+	char *data, *data_start, *data_limit;
+	char *start, *end;
+	__u32 to;
+	__u16 port;
+	struct ip_vs_conn *n_cp;
+
+	/* Only useful for established sessions */
+	if (cp->state != IP_VS_S_ESTABLISHED)
+		return 0;
+
+	/*
+	 * Detecting whether it is passive
+	 */
+	iph = skb->nh.iph;
+	th = (struct tcphdr *)&(((char *)iph)[iph->ihl*4]);
+
+	/* Since there may be OPTIONS in the TCP packet and the HLEN is
+	   the length of the header in 32-bit multiples, it is accurate
+	   to calculate data address by th+HLEN*4 */
+	data = data_start = (char *)th + (th->doff << 2);
+	data_limit = skb->tail;
+
+	while (data < data_limit) {
+		if (strnicmp(data, "PASV\r\n", 6) == 0) {
+			IP_VS_DBG(1-debug, "got PASV at %d of %d\n",
+				  data - data_start,
+				  data_limit - data_start);
+			cp->app_data = &ip_vs_ftp_pasv;
+			return 0;
+		}
+		data++;
+	}
+
+	/*
+	 * To support virtual FTP server, the scenerio is as follows:
+	 *       FTP client ----> Load Balancer ----> FTP server
+	 * First detect the port number in the application data,
+	 * then create a new connection entry for the coming data
+	 * connection.
+	 */
+	data = data_start;
+	data_limit = skb->h.raw + skb->len - 18;
+
+	if (ip_vs_ftp_get_addrport(data, data_limit,
+				   CLIENT_STRING, sizeof(CLIENT_STRING)-1,
+				   '\r', &to, &port,
+				   &start, &end) == 0)
+		return 0;
+
+	IP_VS_DBG(1-debug, "PORT %u.%u.%u.%u:%d detected\n",
+		  NIPQUAD(to), ntohs(port));
+
+	/*
+	 * Now update or create a connection entry for it
+	 */
+	IP_VS_DBG(1-debug, "protocol %s %u.%u.%u.%u:%d %u.%u.%u.%u:%d\n",
+		  ip_vs_proto_name(iph->protocol),
+		  NIPQUAD(to), ntohs(port), NIPQUAD(iph->daddr), 0);
+
+	n_cp = ip_vs_conn_in_get(iph->protocol,
+				 to, port,
+				 iph->daddr, htons(ntohs(cp->vport)-1));
+	if (!n_cp) {
+		n_cp = ip_vs_conn_new(IPPROTO_TCP,
+				      to, port,
+				      cp->vaddr, htons(ntohs(cp->vport)-1),
+				      cp->daddr, htons(ntohs(cp->dport)-1),
+				      0,
+				      cp->dest);
+		if (!n_cp)
+			return 0;
+
+		/* add its controller */
+		ip_vs_control_add(n_cp, cp);
+
+		/* increase dest's inactive connection counter */
+		if (cp->dest)
+			atomic_inc(&cp->dest->inactconns);
+	}
+
+	/*
+	 *	Move tunnel to listen state
+	 */
+	ip_vs_conn_listen(n_cp);
+	ip_vs_conn_put(n_cp);
+
+	/* no diff required for incoming packets */
+	return 0;
+}
+
+
+static struct ip_vs_app ip_vs_ftp = {
+	{0},			/* n_list */
+	"ftp",			/* name */
+	0,                      /* type */
+	THIS_MODULE,            /* this module */
+	ip_vs_ftp_init_conn,    /* ip_vs_init_conn */
+	ip_vs_ftp_done_conn,    /* ip_vs_done_conn */
+	ip_vs_ftp_out,          /* pkt_out */
+	ip_vs_ftp_in,           /* pkt_in */
+};
+
+
+/*
+ *	ip_vs_ftp initialization
+ */
+static int __init ip_vs_ftp_init(void)
+{
+	int i, j;
+
+	for (i=0; i<IP_VS_APP_MAX_PORTS; i++) {
+		if (ports[i]) {
+			if (!(incarnations[i] =
+			     kmalloc(sizeof(struct ip_vs_app), GFP_KERNEL)))
+				return -ENOMEM;
+
+			memcpy(incarnations[i], &ip_vs_ftp,
+			       sizeof(struct ip_vs_app));
+			if ((j = register_ip_vs_app(incarnations[i],
+						    IPPROTO_TCP,
+						    ports[i]))) {
+				return j;
+			}
+			IP_VS_DBG(1-debug,
+				  "Ftp: loaded support on port[%d] = %d\n",
+				  i, ports[i]);
+		} else {
+			/* To be safe, force the incarnation table entry
+			   to be NULL */
+			incarnations[i] = NULL;
+		}
+	}
+	return 0;
+}
+
+
+/*
+ *	ip_vs_ftp finish.
+ */
+static void __exit ip_vs_ftp_exit(void)
+{
+	int i, j, k;
+
+	k=0;
+	for (i=0; i<IP_VS_APP_MAX_PORTS; i++) {
+		if (incarnations[i]) {
+			if ((j = unregister_ip_vs_app(incarnations[i]))) {
+				k = j;
+			} else {
+				kfree(incarnations[i]);
+				incarnations[i] = NULL;
+				IP_VS_DBG(1-debug, "Ftp: unloaded support on port[%d] = %d\n",
+					  i, ports[i]);
+			}
+		}
+	}
+}
+
+
+module_init(ip_vs_ftp_init);
+module_exit(ip_vs_ftp_exit);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_lblc.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_lblc.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_lblc.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_lblc.c	2003-08-27 14:40:33.000000000 +0000
@@ -0,0 +1,624 @@
+/*
+ * IPVS:        Locality-Based Least-Connection scheduling module
+ *
+ * Version:     $Id: ip_vs_lblc.c,v 1.9 2002/03/25 12:44:35 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@gnuchina.org>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *     Martin Hamilton         :    fixed the terrible locking bugs
+ *                                   *lock(tbl->lock) ==> *lock(&tbl->lock)
+ *     Wensong Zhang           :    fixed the uninitilized tbl->lock bug
+ *     Wensong Zhang           :    added doing full expiration check to
+ *                                   collect stale entries of 24+ hours when
+ *                                   no partial expire check in a half hour
+ *     Julian Anastasov        :    replaced del_timer call with del_timer_sync
+ *                                   to avoid the possible race between timer
+ *                                   handler and del_timer thread in SMP
+ *
+ */
+
+/*
+ * The lblc algorithm is as follows (pseudo code):
+ *
+ *       if cachenode[dest_ip] is null then
+ *               n, cachenode[dest_ip] <- {weighted least-conn node};
+ *       else
+ *               n <- cachenode[dest_ip];
+ *               if (n is dead) OR
+ *                  (n.conns>n.weight AND
+ *                   there is a node m with m.conns<m.weight/2) then
+ *                 n, cachenode[dest_ip] <- {weighted least-conn node};
+ *
+ *       return n;
+ *
+ * Thanks must go to Wenzhuo Zhang for talking WCCP to me and pushing
+ * me to write this module.
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+
+/* for systcl */
+#include <linux/fs.h>
+#include <linux/sysctl.h>
+
+#include <net/ip_vs.h>
+
+
+/*
+ *    It is for garbage collection of stale IPVS lblc entries,
+ *    when the table is full.
+ */
+#define CHECK_EXPIRE_INTERVAL   (60*HZ)
+#define ENTRY_TIMEOUT           (6*60*HZ)
+
+/*
+ *    It is for full expiration check.
+ *    When there is no partial expiration check (garbage collection)
+ *    in a half hour, do a full expiration check to collect stale
+ *    entries that haven't been touched for a day.
+ */
+#define COUNT_FOR_FULL_EXPIRATION   30
+int sysctl_ip_vs_lblc_expiration = 24*60*60*HZ;
+
+
+/*
+ *     for IPVS lblc entry hash table
+ */
+#ifndef CONFIG_IP_VS_LBLC_TAB_BITS
+#define CONFIG_IP_VS_LBLC_TAB_BITS      10
+#endif
+#define IP_VS_LBLC_TAB_BITS     CONFIG_IP_VS_LBLC_TAB_BITS
+#define IP_VS_LBLC_TAB_SIZE     (1 << IP_VS_LBLC_TAB_BITS)
+#define IP_VS_LBLC_TAB_MASK     (IP_VS_LBLC_TAB_SIZE - 1)
+
+
+/*
+ *      IPVS lblc entry represents an association between destination
+ *      IP address and its destination server
+ */
+struct ip_vs_lblc_entry {
+	struct list_head        list;
+	__u32                   addr;           /* destination IP address */
+	struct ip_vs_dest       *dest;          /* real server (cache) */
+	unsigned long           lastuse;        /* last used time */
+};
+
+
+/*
+ *      IPVS lblc hash table
+ */
+struct ip_vs_lblc_table {
+	rwlock_t	        lock;           /* lock for this table */
+	struct list_head        bucket[IP_VS_LBLC_TAB_SIZE];  /* hash bucket */
+	atomic_t                entries;        /* number of entries */
+	int                     max_size;       /* maximum size of entries */
+	struct timer_list       periodic_timer; /* collect stale entries */
+	int                     rover;          /* rover for expire check */
+	int                     counter;        /* counter for no expire */
+};
+
+
+/*
+ *      IPVS LBLC sysctl table
+ */
+struct ip_vs_lblc_sysctl_table {
+	struct ctl_table_header *sysctl_header;
+	ctl_table vs_vars[2];
+	ctl_table vs_dir[2];
+	ctl_table ipv4_dir[2];
+	ctl_table root_dir[2];
+};
+
+
+static struct ip_vs_lblc_sysctl_table lblc_sysctl_table = {
+	NULL,
+	{{NET_IPV4_VS_LBLC_EXPIRE, "lblc_expiration",
+	  &sysctl_ip_vs_lblc_expiration,
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {0}},
+	{{NET_IPV4_VS, "vs", NULL, 0, 0555, lblc_sysctl_table.vs_vars},
+	 {0}},
+	{{NET_IPV4, "ipv4", NULL, 0, 0555, lblc_sysctl_table.vs_dir},
+	 {0}},
+	{{CTL_NET, "net", NULL, 0, 0555, lblc_sysctl_table.ipv4_dir},
+	 {0}}
+};
+
+
+/*
+ *      new/free a ip_vs_lblc_entry, which is a mapping of a destionation
+ *      IP address to a server.
+ */
+static inline struct ip_vs_lblc_entry *
+ip_vs_lblc_new(__u32 daddr, struct ip_vs_dest *dest)
+{
+	struct ip_vs_lblc_entry *en;
+
+	en = kmalloc(sizeof(struct ip_vs_lblc_entry), GFP_ATOMIC);
+	if (en == NULL) {
+		IP_VS_ERR("ip_vs_lblc_new(): no memory\n");
+		return NULL;
+	}
+
+	INIT_LIST_HEAD(&en->list);
+	en->addr = daddr;
+
+	atomic_inc(&dest->refcnt);
+	en->dest = dest;
+
+	return en;
+}
+
+
+static inline void ip_vs_lblc_free(struct ip_vs_lblc_entry *en)
+{
+	list_del(&en->list);
+	/*
+	 * We don't kfree dest because it is refered either by its service
+	 * or the trash dest list.
+	 */
+	atomic_dec(&en->dest->refcnt);
+	kfree(en);
+}
+
+
+/*
+ *	Returns hash value for IPVS LBLC entry
+ */
+static inline unsigned ip_vs_lblc_hashkey(__u32 addr)
+{
+	return (ntohl(addr)*2654435761UL) & IP_VS_LBLC_TAB_MASK;
+}
+
+
+/*
+ *	Hash an entry in the ip_vs_lblc_table.
+ *	returns bool success.
+ */
+static int
+ip_vs_lblc_hash(struct ip_vs_lblc_table *tbl, struct ip_vs_lblc_entry *en)
+{
+	unsigned hash;
+
+	if (!list_empty(&en->list)) {
+		IP_VS_ERR("ip_vs_lblc_hash(): request for already hashed, "
+			  "called from %p\n", __builtin_return_address(0));
+		return 0;
+	}
+
+	/*
+	 *	Hash by destination IP address
+	 */
+	hash = ip_vs_lblc_hashkey(en->addr);
+
+	write_lock(&tbl->lock);
+	list_add(&en->list, &tbl->bucket[hash]);
+	atomic_inc(&tbl->entries);
+	write_unlock(&tbl->lock);
+
+	return 1;
+}
+
+
+#if 0000
+/*
+ *	Unhash ip_vs_lblc_entry from ip_vs_lblc_table.
+ *	returns bool success.
+ */
+static int ip_vs_lblc_unhash(struct ip_vs_lblc_table *tbl,
+			     struct ip_vs_lblc_entry *en)
+{
+	if (list_empty(&en->list)) {
+		IP_VS_ERR("ip_vs_lblc_unhash(): request for not hashed entry, "
+			  "called from %p\n", __builtin_return_address(0));
+		return 0;
+	}
+
+	/*
+	 * Remove it from the table
+	 */
+	write_lock(&tbl->lock);
+	list_del(&en->list);
+	INIT_LIST_HEAD(&en->list);
+	write_unlock(&tbl->lock);
+
+	return 1;
+}
+#endif
+
+
+/*
+ *  Get ip_vs_lblc_entry associated with supplied parameters.
+ */
+static inline struct ip_vs_lblc_entry *
+ip_vs_lblc_get(struct ip_vs_lblc_table *tbl, __u32 addr)
+{
+	unsigned hash;
+	struct ip_vs_lblc_entry *en;
+	struct list_head *l,*e;
+
+	hash = ip_vs_lblc_hashkey(addr);
+	l = &tbl->bucket[hash];
+
+	read_lock(&tbl->lock);
+
+	for (e=l->next; e!=l; e=e->next) {
+		en = list_entry(e, struct ip_vs_lblc_entry, list);
+		if (en->addr == addr) {
+			/* HIT */
+			read_unlock(&tbl->lock);
+			return en;
+		}
+	}
+
+	read_unlock(&tbl->lock);
+
+	return NULL;
+}
+
+
+/*
+ *      Flush all the entries of the specified table.
+ */
+static void ip_vs_lblc_flush(struct ip_vs_lblc_table *tbl)
+{
+	int i;
+	struct list_head *l;
+	struct ip_vs_lblc_entry *en;
+
+	for (i=0; i<IP_VS_LBLC_TAB_SIZE; i++) {
+		write_lock(&tbl->lock);
+		for (l=&tbl->bucket[i]; l->next!=l; ) {
+			en = list_entry(l->next,
+					struct ip_vs_lblc_entry, list);
+			ip_vs_lblc_free(en);
+			atomic_dec(&tbl->entries);
+		}
+		write_unlock(&tbl->lock);
+	}
+}
+
+
+static inline void ip_vs_lblc_full_check(struct ip_vs_lblc_table *tbl)
+{
+	unsigned long now = jiffies;
+	int i, j;
+	struct list_head *l, *e;
+	struct ip_vs_lblc_entry *en;
+
+	for (i=0, j=tbl->rover; i<IP_VS_LBLC_TAB_SIZE; i++) {
+		j = (j + 1) & IP_VS_LBLC_TAB_MASK;
+		e = l = &tbl->bucket[j];
+		write_lock(&tbl->lock);
+		while (e->next != l) {
+			en = list_entry(e->next,
+					struct ip_vs_lblc_entry, list);
+			if ((now - en->lastuse) <
+			    sysctl_ip_vs_lblc_expiration) {
+				e = e->next;
+				continue;
+			}
+			ip_vs_lblc_free(en);
+			atomic_dec(&tbl->entries);
+		}
+		write_unlock(&tbl->lock);
+	}
+	tbl->rover = j;
+}
+
+
+/*
+ *      Periodical timer handler for IPVS lblc table
+ *      It is used to collect stale entries when the number of entries
+ *      exceeds the maximum size of the table.
+ *
+ *      Fixme: we probably need more complicated algorithm to collect
+ *             entries that have not been used for a long time even
+ *             if the number of entries doesn't exceed the maximum size
+ *             of the table.
+ *      The full expiration check is for this purpose now.
+ */
+static void ip_vs_lblc_check_expire(unsigned long data)
+{
+	struct ip_vs_lblc_table *tbl;
+	unsigned long now = jiffies;
+	int goal;
+	int i, j;
+	struct list_head *l, *e;
+	struct ip_vs_lblc_entry *en;
+
+	tbl = (struct ip_vs_lblc_table *)data;
+
+	if ((tbl->counter % COUNT_FOR_FULL_EXPIRATION) == 0) {
+		/* do full expiration check */
+		ip_vs_lblc_full_check(tbl);
+		tbl->counter = 1;
+		goto out;
+	}
+
+	if (atomic_read(&tbl->entries) <= tbl->max_size) {
+		tbl->counter++;
+		goto out;
+	}
+
+	goal = (atomic_read(&tbl->entries) - tbl->max_size)*4/3;
+	if (goal > tbl->max_size/2)
+		goal = tbl->max_size/2;
+
+	for (i=0, j=tbl->rover; i<IP_VS_LBLC_TAB_SIZE; i++) {
+		j = (j + 1) & IP_VS_LBLC_TAB_MASK;
+		e = l = &tbl->bucket[j];
+		write_lock(&tbl->lock);
+		while (e->next != l) {
+			en = list_entry(e->next,
+					struct ip_vs_lblc_entry, list);
+			if ((now - en->lastuse) < ENTRY_TIMEOUT) {
+				e = e->next;
+				continue;
+			}
+			ip_vs_lblc_free(en);
+			atomic_dec(&tbl->entries);
+			goal--;
+		}
+		write_unlock(&tbl->lock);
+		if (goal <= 0)
+			break;
+	}
+	tbl->rover = j;
+
+  out:
+	mod_timer(&tbl->periodic_timer, jiffies+CHECK_EXPIRE_INTERVAL);
+}
+
+
+static int ip_vs_lblc_init_svc(struct ip_vs_service *svc)
+{
+	int i;
+	struct ip_vs_lblc_table *tbl;
+
+	/*
+	 *    Allocate the ip_vs_lblc_table for this service
+	 */
+	tbl = kmalloc(sizeof(struct ip_vs_lblc_table), GFP_ATOMIC);
+	if (tbl == NULL) {
+		IP_VS_ERR("ip_vs_lblc_init_svc(): no memory\n");
+		return -ENOMEM;
+	}
+	svc->sched_data = tbl;
+	IP_VS_DBG(6, "LBLC hash table (memory=%dbytes) allocated for "
+		  "current service\n",
+		  sizeof(struct ip_vs_lblc_table));
+
+	/*
+	 *    Initialize the hash buckets
+	 */
+	for (i=0; i<IP_VS_LBLC_TAB_SIZE; i++) {
+		INIT_LIST_HEAD(&tbl->bucket[i]);
+	}
+	tbl->lock = RW_LOCK_UNLOCKED;
+	tbl->max_size = IP_VS_LBLC_TAB_SIZE*16;
+	tbl->rover = 0;
+	tbl->counter = 1;
+
+	/*
+	 *    Hook periodic timer for garbage collection
+	 */
+	init_timer(&tbl->periodic_timer);
+	tbl->periodic_timer.data = (unsigned long)tbl;
+	tbl->periodic_timer.function = ip_vs_lblc_check_expire;
+	tbl->periodic_timer.expires = jiffies+CHECK_EXPIRE_INTERVAL;
+	add_timer(&tbl->periodic_timer);
+
+	return 0;
+}
+
+
+static int ip_vs_lblc_done_svc(struct ip_vs_service *svc)
+{
+	struct ip_vs_lblc_table *tbl = svc->sched_data;
+
+	/* remove periodic timer */
+	del_timer_sync(&tbl->periodic_timer);
+
+	/* got to clean up table entries here */
+	ip_vs_lblc_flush(tbl);
+
+	/* release the table itself */
+	kfree(svc->sched_data);
+	IP_VS_DBG(6, "LBLC hash table (memory=%dbytes) released\n",
+		  sizeof(struct ip_vs_lblc_table));
+
+	return 0;
+}
+
+
+static int ip_vs_lblc_update_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static inline struct ip_vs_dest *
+__ip_vs_wlc_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	register struct list_head *l, *e;
+	struct ip_vs_dest *dest, *least;
+	int loh, doh;
+
+	/*
+	 * We think the overhead of processing active connections is fifty
+	 * times higher than that of inactive connections in average. (This
+	 * fifty times might not be accurate, we will change it later.) We
+	 * use the following formula to estimate the overhead:
+	 *                dest->activeconns*50 + dest->inactconns
+	 * and the load:
+	 *                (dest overhead) / dest->weight
+	 *
+	 * Remember -- no floats in kernel mode!!!
+	 * The comparison of h1*w2 > h2*w1 is equivalent to that of
+	 *                h1/w1 > h2/w2
+	 * if every weight is larger than zero.
+	 *
+	 * The server with weight=0 is quiesced and will not receive any
+	 * new connection.
+	 */
+
+	l = &svc->destinations;
+	for (e=l->next; e!=l; e=e->next) {
+		least = list_entry(e, struct ip_vs_dest, n_list);
+		if (atomic_read(&least->weight) > 0) {
+			loh = atomic_read(&least->activeconns) * 50
+				+ atomic_read(&least->inactconns);
+			goto nextstage;
+		}
+	}
+	return NULL;
+
+	/*
+	 *    Find the destination with the least load.
+	 */
+  nextstage:
+	for (e=e->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+		doh = atomic_read(&dest->activeconns) * 50
+			+ atomic_read(&dest->inactconns);
+		if (loh * atomic_read(&dest->weight) >
+		    doh * atomic_read(&least->weight)) {
+			least = dest;
+			loh = doh;
+		}
+	}
+
+	IP_VS_DBG(6, "LBLC: server %d.%d.%d.%d:%d "
+		  "activeconns %d refcnt %d weight %d overhead %d\n",
+		  NIPQUAD(least->addr), ntohs(least->port),
+		  atomic_read(&least->activeconns),
+		  atomic_read(&least->refcnt),
+		  atomic_read(&least->weight), loh);
+
+	return least;
+}
+
+
+/*
+ *   If this destination server is overloaded and there is a less loaded
+ *   server, then return true.
+ */
+static inline int
+is_overloaded(struct ip_vs_dest *dest, struct ip_vs_service *svc)
+{
+	if (atomic_read(&dest->activeconns) > atomic_read(&dest->weight)) {
+		register struct list_head *l, *e;
+		struct ip_vs_dest *d;
+
+		l = &svc->destinations;
+		for (e=l->next; e!=l; e=e->next) {
+			d = list_entry(e, struct ip_vs_dest, n_list);
+			if (atomic_read(&d->activeconns)*2
+			    < atomic_read(&d->weight)) {
+				return 1;
+			}
+		}
+	}
+	return 0;
+}
+
+
+/*
+ *    Locality-Based (weighted) Least-Connection scheduling
+ */
+static struct ip_vs_dest *
+ip_vs_lblc_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	struct ip_vs_dest *dest;
+	struct ip_vs_lblc_table *tbl;
+	struct ip_vs_lblc_entry *en;
+
+	IP_VS_DBG(6, "ip_vs_lblc_schedule(): Scheduling...\n");
+
+	tbl = (struct ip_vs_lblc_table *)svc->sched_data;
+	en = ip_vs_lblc_get(tbl, iph->daddr);
+	if (en == NULL) {
+		dest = __ip_vs_wlc_schedule(svc, iph);
+		if (dest == NULL) {
+			IP_VS_DBG(1, "no destination available\n");
+			return NULL;
+		}
+		en = ip_vs_lblc_new(iph->daddr, dest);
+		if (en == NULL) {
+			return NULL;
+		}
+		ip_vs_lblc_hash(tbl, en);
+	} else {
+		dest = en->dest;
+		if (!(dest->flags & IP_VS_DEST_F_AVAILABLE)
+		    || atomic_read(&dest->weight) <= 0
+		    || is_overloaded(dest, svc)) {
+			dest = __ip_vs_wlc_schedule(svc, iph);
+			if (dest == NULL) {
+				IP_VS_DBG(1, "no destination available\n");
+				return NULL;
+			}
+			atomic_dec(&en->dest->refcnt);
+			atomic_inc(&dest->refcnt);
+			en->dest = dest;
+		}
+	}
+	en->lastuse = jiffies;
+
+	IP_VS_DBG(6, "LBLC: destination IP address %u.%u.%u.%u "
+		  "--> server %u.%u.%u.%u:%d\n",
+		  NIPQUAD(en->addr),
+		  NIPQUAD(dest->addr),
+		  ntohs(dest->port));
+
+	return dest;
+}
+
+
+/*
+ *      IPVS LBLC Scheduler structure
+ */
+static struct ip_vs_scheduler ip_vs_lblc_scheduler =
+{
+	{0},                    /* n_list */
+	"lblc",                 /* name */
+	ATOMIC_INIT(0),         /* refcnt */
+	THIS_MODULE,		/* this module */
+	ip_vs_lblc_init_svc,    /* service initializer */
+	ip_vs_lblc_done_svc,    /* service done */
+	ip_vs_lblc_update_svc,  /* service updater */
+	ip_vs_lblc_schedule,    /* select a server from the destination list */
+};
+
+
+static int __init ip_vs_lblc_init(void)
+{
+	INIT_LIST_HEAD(&ip_vs_lblc_scheduler.n_list);
+	lblc_sysctl_table.sysctl_header =
+		register_sysctl_table(lblc_sysctl_table.root_dir, 0);
+	return register_ip_vs_scheduler(&ip_vs_lblc_scheduler);
+}
+
+
+static void __exit ip_vs_lblc_cleanup(void)
+{
+	unregister_sysctl_table(lblc_sysctl_table.sysctl_header);
+	unregister_ip_vs_scheduler(&ip_vs_lblc_scheduler);
+}
+
+
+module_init(ip_vs_lblc_init);
+module_exit(ip_vs_lblc_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_lblcr.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_lblcr.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_lblcr.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_lblcr.c	2003-08-27 14:40:45.000000000 +0000
@@ -0,0 +1,884 @@
+/*
+ * IPVS:        Locality-Based Least-Connection with Replication scheduler
+ *
+ * Version:     $Id: ip_vs_lblcr.c,v 1.10 2002/03/25 12:44:35 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@gnuchina.org>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *     Julian Anastasov        :    Added the missing (dest->weight>0)
+ *                                  condition in the ip_vs_dest_set_max.
+ *
+ */
+
+/*
+ * The lblc/r algorithm is as follows (pseudo code):
+ *
+ *       if serverSet[dest_ip] is null then
+ *               n, serverSet[dest_ip] <- {weighted least-conn node};
+ *       else
+ *               n <- {least-conn (alive) node in serverSet[dest_ip]};
+ *               if (n is null) OR
+ *                  (n.conns>n.weight AND
+ *                   there is a node m with m.conns<m.weight/2) then
+ *                   n <- {weighted least-conn node};
+ *                   add n to serverSet[dest_ip];
+ *               if |serverSet[dest_ip]| > 1 AND
+ *                   now - serverSet[dest_ip].lastMod > T then
+ *                   m <- {most conn node in serverSet[dest_ip]};
+ *                   remove m from serverSet[dest_ip];
+ *       if serverSet[dest_ip] changed then
+ *               serverSet[dest_ip].lastMod <- now;
+ *
+ *       return n;
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+
+/* for systcl */
+#include <linux/fs.h>
+#include <linux/sysctl.h>
+/* for proc_net_create/proc_net_remove */
+#include <linux/proc_fs.h>
+
+#include <net/ip_vs.h>
+
+
+/*
+ *    It is for garbage collection of stale IPVS lblcr entries,
+ *    when the table is full.
+ */
+#define CHECK_EXPIRE_INTERVAL   (60*HZ)
+#define ENTRY_TIMEOUT           (6*60*HZ)
+
+/*
+ *    It is for full expiration check.
+ *    When there is no partial expiration check (garbage collection)
+ *    in a half hour, do a full expiration check to collect stale
+ *    entries that haven't been touched for a day.
+ */
+#define COUNT_FOR_FULL_EXPIRATION   30
+int sysctl_ip_vs_lblcr_expiration = 24*60*60*HZ;
+
+
+/*
+ *     for IPVS lblcr entry hash table
+ */
+#ifndef CONFIG_IP_VS_LBLCR_TAB_BITS
+#define CONFIG_IP_VS_LBLCR_TAB_BITS      10
+#endif
+#define IP_VS_LBLCR_TAB_BITS     CONFIG_IP_VS_LBLCR_TAB_BITS
+#define IP_VS_LBLCR_TAB_SIZE     (1 << IP_VS_LBLCR_TAB_BITS)
+#define IP_VS_LBLCR_TAB_MASK     (IP_VS_LBLCR_TAB_SIZE - 1)
+
+
+/*
+ *      IPVS destination set structure and operations
+ */
+struct ip_vs_dest_list {
+	struct ip_vs_dest_list  *next;          /* list link */
+	struct ip_vs_dest       *dest;          /* destination server */
+};
+
+struct ip_vs_dest_set {
+	atomic_t                size;           /* set size */
+	unsigned long           lastmod;        /* last modified time */
+	struct ip_vs_dest_list  *list;          /* destination list */
+	rwlock_t	        lock;           /* lock for this list */
+};
+
+
+static struct ip_vs_dest_list *
+ip_vs_dest_set_insert(struct ip_vs_dest_set *set, struct ip_vs_dest *dest)
+{
+	struct ip_vs_dest_list *e;
+
+	for (e=set->list; e!=NULL; e=e->next) {
+		if (e->dest == dest)
+			/* already existed */
+			return NULL;
+	}
+
+	e = kmalloc(sizeof(struct ip_vs_dest_list), GFP_ATOMIC);
+	if (e == NULL) {
+		IP_VS_ERR("ip_vs_dest_set_insert(): no memory\n");
+		return NULL;
+	}
+
+	atomic_inc(&dest->refcnt);
+	e->dest = dest;
+
+	/* link it to the list */
+	write_lock(&set->lock);
+	e->next = set->list;
+	set->list = e;
+	atomic_inc(&set->size);
+	write_unlock(&set->lock);
+
+	set->lastmod = jiffies;
+	return e;
+}
+
+static void
+ip_vs_dest_set_erase(struct ip_vs_dest_set *set, struct ip_vs_dest *dest)
+{
+	struct ip_vs_dest_list *e, **ep;
+
+	write_lock(&set->lock);
+	for (ep=&set->list, e=*ep; e!=NULL; e=*ep) {
+		if (e->dest == dest) {
+			/* HIT */
+			*ep = e->next;
+			atomic_dec(&set->size);
+			set->lastmod = jiffies;
+			atomic_dec(&e->dest->refcnt);
+			kfree(e);
+			break;
+		}
+		ep = &e->next;
+	}
+	write_unlock(&set->lock);
+}
+
+static void ip_vs_dest_set_eraseall(struct ip_vs_dest_set *set)
+{
+	struct ip_vs_dest_list *e, **ep;
+
+	write_lock(&set->lock);
+	for (ep=&set->list, e=*ep; e!=NULL; e=*ep) {
+		*ep = e->next;
+		/*
+		 * We don't kfree dest because it is refered either
+		 * by its service or by the trash dest list.
+		 */
+		atomic_dec(&e->dest->refcnt);
+		kfree(e);
+	}
+	write_unlock(&set->lock);
+}
+
+/* get weighted least-connection node in the destination set */
+static inline struct ip_vs_dest *ip_vs_dest_set_min(struct ip_vs_dest_set *set)
+{
+	register struct ip_vs_dest_list *e;
+	struct ip_vs_dest *dest, *least;
+	int loh, doh;
+
+	if (set == NULL)
+		return NULL;
+
+	read_lock(&set->lock);
+	/* select the first destination server, whose weight > 0 */
+	for (e=set->list; e!=NULL; e=e->next) {
+		least = e->dest;
+		if ((atomic_read(&least->weight) > 0)
+		    && (least->flags & IP_VS_DEST_F_AVAILABLE)) {
+			loh = atomic_read(&least->activeconns) * 50
+				+ atomic_read(&least->inactconns);
+			goto nextstage;
+		}
+	}
+	read_unlock(&set->lock);
+	return NULL;
+
+	/* find the destination with the weighted least load */
+  nextstage:
+	for (e=e->next; e!=NULL; e=e->next) {
+		dest = e->dest;
+		doh = atomic_read(&dest->activeconns) * 50
+			+ atomic_read(&dest->inactconns);
+		if ((loh * atomic_read(&dest->weight) >
+		     doh * atomic_read(&least->weight))
+		    && (dest->flags & IP_VS_DEST_F_AVAILABLE)) {
+			least = dest;
+			loh = doh;
+		}
+	}
+	read_unlock(&set->lock);
+
+	IP_VS_DBG(6, "ip_vs_dest_set_min: server %d.%d.%d.%d:%d "
+		  "activeconns %d refcnt %d weight %d overhead %d\n",
+		  NIPQUAD(least->addr), ntohs(least->port),
+		  atomic_read(&least->activeconns),
+		  atomic_read(&least->refcnt),
+		  atomic_read(&least->weight), loh);
+	return least;
+}
+
+
+/* get weighted most-connection node in the destination set */
+static inline struct ip_vs_dest *ip_vs_dest_set_max(struct ip_vs_dest_set *set)
+{
+	register struct ip_vs_dest_list *e;
+	struct ip_vs_dest *dest, *most;
+	int moh, doh;
+
+	if (set == NULL)
+		return NULL;
+
+	read_lock(&set->lock);
+	/* select the first destination server, whose weight > 0 */
+	for (e=set->list; e!=NULL; e=e->next) {
+		most = e->dest;
+		if (atomic_read(&most->weight) > 0) {
+			moh = atomic_read(&most->activeconns) * 50
+				+ atomic_read(&most->inactconns);
+			goto nextstage;
+		}
+	}
+	read_unlock(&set->lock);
+	return NULL;
+
+	/* find the destination with the weighted most load */
+  nextstage:
+	for (e=e->next; e!=NULL; e=e->next) {
+		dest = e->dest;
+		doh = atomic_read(&dest->activeconns) * 50
+			+ atomic_read(&dest->inactconns);
+		/* moh/mw < doh/dw ==> moh*dw < doh*mw, where mw,dw>0 */
+		if ((moh * atomic_read(&dest->weight) <
+		     doh * atomic_read(&most->weight))
+		    && (atomic_read(&dest->weight) > 0)) {
+			most = dest;
+			moh = doh;
+		}
+	}
+	read_unlock(&set->lock);
+
+	IP_VS_DBG(6, "ip_vs_dest_set_max: server %d.%d.%d.%d:%d "
+		  "activeconns %d refcnt %d weight %d overhead %d\n",
+		  NIPQUAD(most->addr), ntohs(most->port),
+		  atomic_read(&most->activeconns),
+		  atomic_read(&most->refcnt),
+		  atomic_read(&most->weight), moh);
+	return most;
+}
+
+
+/*
+ *      IPVS lblcr entry represents an association between destination
+ *      IP address and its destination server set
+ */
+struct ip_vs_lblcr_entry {
+	struct list_head        list;
+	__u32                   addr;           /* destination IP address */
+	struct ip_vs_dest_set   set;            /* destination server set */
+	unsigned long           lastuse;        /* last used time */
+};
+
+
+/*
+ *      IPVS lblcr hash table
+ */
+struct ip_vs_lblcr_table {
+	rwlock_t	        lock;           /* lock for this table */
+	struct list_head        bucket[IP_VS_LBLCR_TAB_SIZE];  /* hash bucket */
+	atomic_t                entries;        /* number of entries */
+	int                     max_size;       /* maximum size of entries */
+	struct timer_list       periodic_timer; /* collect stale entries */
+	int                     rover;          /* rover for expire check */
+	int                     counter;        /* counter for no expire */
+};
+
+
+/*
+ *      IPVS LBLCR sysctl table
+ */
+struct ip_vs_lblcr_sysctl_table {
+	struct ctl_table_header *sysctl_header;
+	ctl_table vs_vars[2];
+	ctl_table vs_dir[2];
+	ctl_table ipv4_dir[2];
+	ctl_table root_dir[2];
+};
+
+
+static struct ip_vs_lblcr_sysctl_table lblcr_sysctl_table = {
+	NULL,
+	{{NET_IPV4_VS_LBLCR_EXPIRE, "lblcr_expiration",
+	  &sysctl_ip_vs_lblcr_expiration,
+	  sizeof(int), 0644, NULL, &proc_dointvec_jiffies},
+	 {0}},
+	{{NET_IPV4_VS, "vs", NULL, 0, 0555, lblcr_sysctl_table.vs_vars},
+	 {0}},
+	{{NET_IPV4, "ipv4", NULL, 0, 0555, lblcr_sysctl_table.vs_dir},
+	 {0}},
+	{{CTL_NET, "net", NULL, 0, 0555, lblcr_sysctl_table.ipv4_dir},
+	 {0}}
+};
+
+
+/*
+ *      new/free a ip_vs_lblcr_entry, which is a mapping of a destination
+ *      IP address to a server.
+ */
+static inline struct ip_vs_lblcr_entry *ip_vs_lblcr_new(__u32 daddr)
+{
+	struct ip_vs_lblcr_entry *en;
+
+	en = kmalloc(sizeof(struct ip_vs_lblcr_entry), GFP_ATOMIC);
+	if (en == NULL) {
+		IP_VS_ERR("ip_vs_lblcr_new(): no memory\n");
+		return NULL;
+	}
+
+	INIT_LIST_HEAD(&en->list);
+	en->addr = daddr;
+
+	/* initilize its dest set */
+	atomic_set(&(en->set.size), 0);
+	en->set.list = NULL;
+	en->set.lock = RW_LOCK_UNLOCKED;
+
+	return en;
+}
+
+
+static inline void ip_vs_lblcr_free(struct ip_vs_lblcr_entry *en)
+{
+	list_del(&en->list);
+	ip_vs_dest_set_eraseall(&en->set);
+	kfree(en);
+}
+
+
+/*
+ *	Returns hash value for IPVS LBLCR entry
+ */
+static inline unsigned ip_vs_lblcr_hashkey(__u32 addr)
+{
+	return (ntohl(addr)*2654435761UL) & IP_VS_LBLCR_TAB_MASK;
+}
+
+
+/*
+ *	Hash an entry in the ip_vs_lblcr_table.
+ *	returns bool success.
+ */
+static int
+ip_vs_lblcr_hash(struct ip_vs_lblcr_table *tbl, struct ip_vs_lblcr_entry *en)
+{
+	unsigned hash;
+
+	if (!list_empty(&en->list)) {
+		IP_VS_ERR("ip_vs_lblcr_hash(): request for already hashed, "
+			  "called from %p\n", __builtin_return_address(0));
+		return 0;
+	}
+
+	/*
+	 *	Hash by destination IP address
+	 */
+	hash = ip_vs_lblcr_hashkey(en->addr);
+
+	write_lock(&tbl->lock);
+	list_add(&en->list, &tbl->bucket[hash]);
+	atomic_inc(&tbl->entries);
+	write_unlock(&tbl->lock);
+
+	return 1;
+}
+
+
+#if 0000
+/*
+ *	Unhash ip_vs_lblcr_entry from ip_vs_lblcr_table.
+ *	returns bool success.
+ */
+static int ip_vs_lblcr_unhash(struct ip_vs_lblcr_table *tbl,
+			     struct ip_vs_lblcr_entry *en)
+{
+	if (list_empty(&en->list)) {
+		IP_VS_ERR("ip_vs_lblcr_unhash(): request for not hashed entry, "
+			  "called from %p\n", __builtin_return_address(0));
+		return 0;
+	}
+
+	/*
+	 * Remove it from the table
+	 */
+	write_lock(&tbl->lock);
+	list_del(&en->list);
+	INIT_LIST_HEAD(&en->list);
+	write_unlock(&tbl->lock);
+
+	return 1;
+}
+#endif
+
+
+/*
+ *  Get ip_vs_lblcr_entry associated with supplied parameters.
+ */
+static inline struct ip_vs_lblcr_entry *
+ip_vs_lblcr_get(struct ip_vs_lblcr_table *tbl, __u32 addr)
+{
+	unsigned hash;
+	struct ip_vs_lblcr_entry *en;
+	struct list_head *l,*e;
+
+	hash = ip_vs_lblcr_hashkey(addr);
+	l = &tbl->bucket[hash];
+
+	read_lock(&tbl->lock);
+
+	for (e=l->next; e!=l; e=e->next) {
+		en = list_entry(e, struct ip_vs_lblcr_entry, list);
+		if (en->addr == addr) {
+			/* HIT */
+			read_unlock(&tbl->lock);
+			return en;
+		}
+	}
+
+	read_unlock(&tbl->lock);
+
+	return NULL;
+}
+
+
+/*
+ *      Flush all the entries of the specified table.
+ */
+static void ip_vs_lblcr_flush(struct ip_vs_lblcr_table *tbl)
+{
+	int i;
+	struct list_head *l;
+	struct ip_vs_lblcr_entry *en;
+
+	for (i=0; i<IP_VS_LBLCR_TAB_SIZE; i++) {
+		write_lock(&tbl->lock);
+		for (l=&tbl->bucket[i]; l->next!=l; ) {
+			en = list_entry(l->next,
+					struct ip_vs_lblcr_entry, list);
+			ip_vs_lblcr_free(en);
+			atomic_dec(&tbl->entries);
+		}
+		write_unlock(&tbl->lock);
+	}
+}
+
+
+static inline void ip_vs_lblcr_full_check(struct ip_vs_lblcr_table *tbl)
+{
+	unsigned long now = jiffies;
+	int i, j;
+	struct list_head *l, *e;
+	struct ip_vs_lblcr_entry *en;
+
+	for (i=0, j=tbl->rover; i<IP_VS_LBLCR_TAB_SIZE; i++) {
+		j = (j + 1) & IP_VS_LBLCR_TAB_MASK;
+		e = l = &tbl->bucket[j];
+		write_lock(&tbl->lock);
+		while (e->next != l) {
+			en = list_entry(e->next,
+					struct ip_vs_lblcr_entry, list);
+			if ((now - en->lastuse) <
+			    sysctl_ip_vs_lblcr_expiration) {
+				e = e->next;
+				continue;
+			}
+			ip_vs_lblcr_free(en);
+			atomic_dec(&tbl->entries);
+		}
+		write_unlock(&tbl->lock);
+	}
+	tbl->rover = j;
+}
+
+
+/*
+ *      Periodical timer handler for IPVS lblcr table
+ *      It is used to collect stale entries when the number of entries
+ *      exceeds the maximum size of the table.
+ *
+ *      Fixme: we probably need more complicated algorithm to collect
+ *             entries that have not been used for a long time even
+ *             if the number of entries doesn't exceed the maximum size
+ *             of the table.
+ *      The full expiration check is for this purpose now.
+ */
+static void ip_vs_lblcr_check_expire(unsigned long data)
+{
+	struct ip_vs_lblcr_table *tbl;
+	unsigned long now = jiffies;
+	int goal;
+	int i, j;
+	struct list_head *l, *e;
+	struct ip_vs_lblcr_entry *en;
+
+	tbl = (struct ip_vs_lblcr_table *)data;
+
+	if ((tbl->counter % COUNT_FOR_FULL_EXPIRATION) == 0) {
+		/* do full expiration check */
+		ip_vs_lblcr_full_check(tbl);
+		tbl->counter = 1;
+		goto out;
+	}
+
+	if (atomic_read(&tbl->entries) <= tbl->max_size) {
+		tbl->counter++;
+		goto out;
+	}
+
+	goal = (atomic_read(&tbl->entries) - tbl->max_size)*4/3;
+	if (goal > tbl->max_size/2)
+		goal = tbl->max_size/2;
+
+	for (i=0, j=tbl->rover; i<IP_VS_LBLCR_TAB_SIZE; i++) {
+		j = (j + 1) & IP_VS_LBLCR_TAB_MASK;
+		e = l = &tbl->bucket[j];
+		write_lock(&tbl->lock);
+		while (e->next != l) {
+			en = list_entry(e->next,
+					struct ip_vs_lblcr_entry, list);
+			if ((now - en->lastuse) < ENTRY_TIMEOUT) {
+				e = e->next;
+				continue;
+			}
+			ip_vs_lblcr_free(en);
+			atomic_dec(&tbl->entries);
+			goal--;
+		}
+		write_unlock(&tbl->lock);
+		if (goal <= 0)
+			break;
+	}
+	tbl->rover = j;
+
+  out:
+	mod_timer(&tbl->periodic_timer, jiffies+CHECK_EXPIRE_INTERVAL);
+}
+
+
+#ifdef CONFIG_IP_VS_LBLCR_DEBUG
+static struct ip_vs_lblcr_table *lblcr_table_list;
+
+/*
+ *	/proc/net/ip_vs_lblcr to display the mappings of
+ *                  destination IP address <==> its serverSet
+ */
+static int
+ip_vs_lblcr_getinfo(char *buffer, char **start, off_t offset, int length)
+{
+	off_t pos=0, begin;
+	int len=0, size;
+	struct ip_vs_lblcr_table *tbl;
+	unsigned long now = jiffies;
+	int i;
+	struct list_head *l, *e;
+	struct ip_vs_lblcr_entry *en;
+
+	tbl = lblcr_table_list;
+
+	size = sprintf(buffer, "LastTime Dest IP address  Server set\n");
+	pos += size;
+	len += size;
+
+	for (i=0; i<IP_VS_LBLCR_TAB_SIZE; i++) {
+		l = &tbl->bucket[i];
+		read_lock_bh(&tbl->lock);
+		for (e=l->next; e!=l; e=e->next) {
+			char tbuf[16];
+			struct ip_vs_dest_list *d;
+
+			en = list_entry(e, struct ip_vs_lblcr_entry, list);
+			sprintf(tbuf, "%u.%u.%u.%u", NIPQUAD(en->addr));
+			size = sprintf(buffer+len, "%8lu %-16s ",
+				       now-en->lastuse, tbuf);
+
+			read_lock(&en->set.lock);
+			for (d=en->set.list; d!=NULL; d=d->next) {
+				size += sprintf(buffer+len+size,
+						"%u.%u.%u.%u ",
+						NIPQUAD(d->dest->addr));
+			}
+			read_unlock(&en->set.lock);
+			size += sprintf(buffer+len+size, "\n");
+			len += size;
+			pos += size;
+			if (pos <= offset)
+				len=0;
+			if (pos >= offset+length) {
+				read_unlock_bh(&tbl->lock);
+				goto done;
+			}
+		}
+		read_unlock_bh(&tbl->lock);
+	}
+
+  done:
+	begin = len - (pos - offset);
+	*start = buffer + begin;
+	len -= begin;
+	if(len>length)
+		len = length;
+	return len;
+}
+#endif
+
+
+static int ip_vs_lblcr_init_svc(struct ip_vs_service *svc)
+{
+	int i;
+	struct ip_vs_lblcr_table *tbl;
+
+	/*
+	 *    Allocate the ip_vs_lblcr_table for this service
+	 */
+	tbl = kmalloc(sizeof(struct ip_vs_lblcr_table), GFP_ATOMIC);
+	if (tbl == NULL) {
+		IP_VS_ERR("ip_vs_lblcr_init_svc(): no memory\n");
+		return -ENOMEM;
+	}
+	svc->sched_data = tbl;
+	IP_VS_DBG(6, "LBLCR hash table (memory=%dbytes) allocated for "
+		  "current service\n",
+		  sizeof(struct ip_vs_lblcr_table));
+
+	/*
+	 *    Initialize the hash buckets
+	 */
+	for (i=0; i<IP_VS_LBLCR_TAB_SIZE; i++) {
+		INIT_LIST_HEAD(&tbl->bucket[i]);
+	}
+	tbl->lock = RW_LOCK_UNLOCKED;
+	tbl->max_size = IP_VS_LBLCR_TAB_SIZE*16;
+	tbl->rover = 0;
+	tbl->counter = 1;
+
+	/*
+	 *    Hook periodic timer for garbage collection
+	 */
+	init_timer(&tbl->periodic_timer);
+	tbl->periodic_timer.data = (unsigned long)tbl;
+	tbl->periodic_timer.function = ip_vs_lblcr_check_expire;
+	tbl->periodic_timer.expires = jiffies+CHECK_EXPIRE_INTERVAL;
+	add_timer(&tbl->periodic_timer);
+
+#ifdef CONFIG_IP_VS_LBLCR_DEBUG
+	lblcr_table_list = tbl;
+#endif
+	return 0;
+}
+
+
+static int ip_vs_lblcr_done_svc(struct ip_vs_service *svc)
+{
+	struct ip_vs_lblcr_table *tbl = svc->sched_data;
+
+	/* remove periodic timer */
+	del_timer_sync(&tbl->periodic_timer);
+
+	/* got to clean up table entries here */
+	ip_vs_lblcr_flush(tbl);
+
+	/* release the table itself */
+	kfree(svc->sched_data);
+	IP_VS_DBG(6, "LBLCR hash table (memory=%dbytes) released\n",
+		  sizeof(struct ip_vs_lblcr_table));
+
+	return 0;
+}
+
+
+static int ip_vs_lblcr_update_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static inline struct ip_vs_dest *
+__ip_vs_wlc_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	register struct list_head *l, *e;
+	struct ip_vs_dest *dest, *least;
+	int loh, doh;
+
+	/*
+	 * We think the overhead of processing active connections is fifty
+	 * times higher than that of inactive connections in average. (This
+	 * fifty times might not be accurate, we will change it later.) We
+	 * use the following formula to estimate the overhead:
+	 *                dest->activeconns*50 + dest->inactconns
+	 * and the load:
+	 *                (dest overhead) / dest->weight
+	 *
+	 * Remember -- no floats in kernel mode!!!
+	 * The comparison of h1*w2 > h2*w1 is equivalent to that of
+	 *                h1/w1 > h2/w2
+	 * if every weight is larger than zero.
+	 *
+	 * The server with weight=0 is quiesced and will not receive any
+	 * new connection.
+	 */
+
+	l = &svc->destinations;
+	for (e=l->next; e!=l; e=e->next) {
+		least = list_entry(e, struct ip_vs_dest, n_list);
+		if (atomic_read(&least->weight) > 0) {
+			loh = atomic_read(&least->activeconns) * 50
+				+ atomic_read(&least->inactconns);
+			goto nextstage;
+		}
+	}
+	return NULL;
+
+	/*
+	 *    Find the destination with the least load.
+	 */
+  nextstage:
+	for (e=e->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+		doh = atomic_read(&dest->activeconns) * 50
+			+ atomic_read(&dest->inactconns);
+		if (loh * atomic_read(&dest->weight) >
+		    doh * atomic_read(&least->weight)) {
+			least = dest;
+			loh = doh;
+		}
+	}
+
+	IP_VS_DBG(6, "LBLCR: server %d.%d.%d.%d:%d "
+		  "activeconns %d refcnt %d weight %d overhead %d\n",
+		  NIPQUAD(least->addr), ntohs(least->port),
+		  atomic_read(&least->activeconns),
+		  atomic_read(&least->refcnt),
+		  atomic_read(&least->weight), loh);
+
+	return least;
+}
+
+
+/*
+ *   If this destination server is overloaded and there is a less loaded
+ *   server, then return true.
+ */
+static inline int
+is_overloaded(struct ip_vs_dest *dest, struct ip_vs_service *svc)
+{
+	if (atomic_read(&dest->activeconns) > atomic_read(&dest->weight)) {
+		register struct list_head *l, *e;
+		struct ip_vs_dest *d;
+
+		l = &svc->destinations;
+		for (e=l->next; e!=l; e=e->next) {
+			d = list_entry(e, struct ip_vs_dest, n_list);
+			if (atomic_read(&d->activeconns)*2
+			    < atomic_read(&d->weight)) {
+				return 1;
+			}
+		}
+	}
+	return 0;
+}
+
+
+/*
+ *    Locality-Based (weighted) Least-Connection scheduling
+ */
+static struct ip_vs_dest *
+ip_vs_lblcr_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	struct ip_vs_dest *dest;
+	struct ip_vs_lblcr_table *tbl;
+	struct ip_vs_lblcr_entry *en;
+
+	IP_VS_DBG(6, "ip_vs_lblcr_schedule(): Scheduling...\n");
+
+	tbl = (struct ip_vs_lblcr_table *)svc->sched_data;
+	en = ip_vs_lblcr_get(tbl, iph->daddr);
+	if (en == NULL) {
+		dest = __ip_vs_wlc_schedule(svc, iph);
+		if (dest == NULL) {
+			IP_VS_DBG(1, "no destination available\n");
+			return NULL;
+		}
+		en = ip_vs_lblcr_new(iph->daddr);
+		if (en == NULL) {
+			return NULL;
+		}
+		ip_vs_dest_set_insert(&en->set, dest);
+		ip_vs_lblcr_hash(tbl, en);
+	} else {
+		dest = ip_vs_dest_set_min(&en->set);
+		if (!dest || is_overloaded(dest, svc)) {
+			dest = __ip_vs_wlc_schedule(svc, iph);
+			if (dest == NULL) {
+				IP_VS_DBG(1, "no destination available\n");
+				return NULL;
+			}
+			ip_vs_dest_set_insert(&en->set, dest);
+		}
+		if (atomic_read(&en->set.size) > 1 &&
+		    jiffies-en->set.lastmod > sysctl_ip_vs_lblcr_expiration) {
+			struct ip_vs_dest *m;
+			m = ip_vs_dest_set_max(&en->set);
+			if (m)
+				ip_vs_dest_set_erase(&en->set, m);
+		}
+	}
+	en->lastuse = jiffies;
+
+	IP_VS_DBG(6, "LBLCR: destination IP address %u.%u.%u.%u "
+		  "--> server %u.%u.%u.%u:%d\n",
+		  NIPQUAD(en->addr),
+		  NIPQUAD(dest->addr),
+		  ntohs(dest->port));
+
+	return dest;
+}
+
+
+/*
+ *      IPVS LBLCR Scheduler structure
+ */
+static struct ip_vs_scheduler ip_vs_lblcr_scheduler =
+{
+	{0},                     /* n_list */
+	"lblcr",                 /* name */
+	ATOMIC_INIT(0),          /* refcnt */
+	THIS_MODULE,             /* this module */
+	ip_vs_lblcr_init_svc,    /* service initializer */
+	ip_vs_lblcr_done_svc,    /* service done */
+	ip_vs_lblcr_update_svc,  /* service updater */
+	ip_vs_lblcr_schedule,    /* select a server from the destination list */
+};
+
+
+static int __init ip_vs_lblcr_init(void)
+{
+	INIT_LIST_HEAD(&ip_vs_lblcr_scheduler.n_list);
+	lblcr_sysctl_table.sysctl_header =
+		register_sysctl_table(lblcr_sysctl_table.root_dir, 0);
+#ifdef CONFIG_IP_VS_LBLCR_DEBUG
+	proc_net_create("ip_vs_lblcr", 0, ip_vs_lblcr_getinfo);
+#endif
+	return register_ip_vs_scheduler(&ip_vs_lblcr_scheduler);
+}
+
+
+static void __exit ip_vs_lblcr_cleanup(void)
+{
+#ifdef CONFIG_IP_VS_LBLCR_DEBUG
+	proc_net_remove("ip_vs_lblcr");
+#endif
+	unregister_sysctl_table(lblcr_sysctl_table.sysctl_header);
+	unregister_ip_vs_scheduler(&ip_vs_lblcr_scheduler);
+}
+
+
+module_init(ip_vs_lblcr_init);
+module_exit(ip_vs_lblcr_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_lc.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_lc.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_lc.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_lc.c	2003-08-27 14:40:25.000000000 +0000
@@ -0,0 +1,142 @@
+/*
+ * IPVS:        Least-Connection Scheduling module
+ *
+ * Version:     $Id: ip_vs_lc.c,v 1.8.2.1 2003/04/11 14:02:35 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *     Wensong Zhang            :     added the ip_vs_lc_update_svc
+ *     Wensong Zhang            :     added any dest with weight=0 is quiesced
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+
+#include <net/ip_vs.h>
+
+
+static int ip_vs_lc_init_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static int ip_vs_lc_done_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static int ip_vs_lc_update_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static inline unsigned int
+ip_vs_lc_dest_overhead(struct ip_vs_dest *dest)
+{
+	/*
+	 * We think the overhead of processing active connections is 256
+	 * times higher than that of inactive connections in average. (This
+	 * 256 times might not be accurate, we will change it later) We
+	 * use the following formula to estimate the overhead now:
+	 *		  dest->activeconns*256 + dest->inactconns
+	 */
+	return (atomic_read(&dest->activeconns) << 8) +
+		atomic_read(&dest->inactconns);
+}
+
+
+/*
+ *	Least Connection scheduling
+ */
+static struct ip_vs_dest *
+ip_vs_lc_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	struct list_head *l, *e;
+	struct ip_vs_dest *dest, *least;
+	unsigned int loh, doh;
+
+	IP_VS_DBG(6, "ip_vs_lc_schedule(): Scheduling...\n");
+
+	/*
+	 * Simply select the server with the least number of
+	 *        (activeconns<<5) + inactconns
+	 * Except whose weight is equal to zero.
+	 * If the weight is equal to zero, it means that the server is
+	 * quiesced, the existing connections to the server still get
+	 * served, but no new connection is assigned to the server.
+	 */
+
+	l = &svc->destinations;
+	for (e=l->next; e!=l; e=e->next) {
+		least = list_entry (e, struct ip_vs_dest, n_list);
+		if (atomic_read(&least->weight) > 0) {
+			loh = ip_vs_lc_dest_overhead(least);
+			goto nextstage;
+		}
+	}
+	return NULL;
+
+	/*
+	 *    Find the destination with the least load.
+	 */
+  nextstage:
+	for (e=e->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+		if (atomic_read(&dest->weight) == 0)
+			continue;
+		doh = ip_vs_lc_dest_overhead(dest);
+		if (doh < loh) {
+			least = dest;
+			loh = doh;
+		}
+	}
+
+	IP_VS_DBG(6, "LC: server %u.%u.%u.%u:%u activeconns %d inactconns %d\n",
+		  NIPQUAD(least->addr), ntohs(least->port),
+		  atomic_read(&least->activeconns),
+		  atomic_read(&least->inactconns));
+
+	return least;
+}
+
+
+static struct ip_vs_scheduler ip_vs_lc_scheduler = {
+	{0},			/* n_list */
+	"lc",			/* name */
+	ATOMIC_INIT(0),		/* refcnt */
+	THIS_MODULE,		/* this module */
+	ip_vs_lc_init_svc,	/* service initializer */
+	ip_vs_lc_done_svc,	/* service done */
+	ip_vs_lc_update_svc,	/* service updater */
+	ip_vs_lc_schedule,	/* select a server from the destination list */
+};
+
+
+static int __init ip_vs_lc_init(void)
+{
+	INIT_LIST_HEAD(&ip_vs_lc_scheduler.n_list);
+	return register_ip_vs_scheduler(&ip_vs_lc_scheduler) ;
+}
+
+static void __exit ip_vs_lc_cleanup(void)
+{
+	unregister_ip_vs_scheduler(&ip_vs_lc_scheduler);
+}
+
+module_init(ip_vs_lc_init);
+module_exit(ip_vs_lc_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_nq.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_nq.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_nq.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_nq.c	2003-08-27 14:39:49.000000000 +0000
@@ -0,0 +1,177 @@
+/*
+ * IPVS:        Never Queue scheduling module
+ *
+ * Version:     $Id: ip_vs_nq.c,v 1.1.2.1 2003/05/20 17:05:02 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *
+ */
+
+/*
+ * The NQ algorithm adopts a two-speed model. When there is an idle server
+ * available, the job will be sent to the idle server, instead of waiting
+ * for a fast one. When there is no idle server available, the job will be
+ * sent to the server that minimize its expected delay (The Shortest
+ * Expected Delay scheduling algorithm).
+ *
+ * See the following paper for more information:
+ * A. Weinrib and S. Shenker, Greed is not enough: Adaptive load sharing
+ * in large heterogeneous systems. In Proceedings IEEE INFOCOM'88,
+ * pages 986-994, 1988.
+ *
+ * Thanks must go to Marko Buuri <marko@buuri.name> for talking NQ to me.
+ *
+ * The difference between NQ and SED is that NQ can improve overall
+ * system utilization.
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+
+#include <net/ip_vs.h>
+
+
+static int
+ip_vs_nq_init_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static int
+ip_vs_nq_done_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static int
+ip_vs_nq_update_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static inline unsigned int
+ip_vs_nq_dest_overhead(struct ip_vs_dest *dest)
+{
+	/*
+	 * We only use the active connection number in the cost
+	 * calculation here.
+	 */
+	return atomic_read(&dest->activeconns) + 1;
+}
+
+
+/*
+ *	Weighted Least Connection scheduling
+ */
+static struct ip_vs_dest *
+ip_vs_nq_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	register struct list_head *l, *e;
+	struct ip_vs_dest *dest, *least;
+	unsigned int loh, doh;
+
+	IP_VS_DBG(6, "ip_vs_nq_schedule(): Scheduling...\n");
+
+	/*
+	 * We calculate the load of each dest server as follows:
+	 *	(server expected overhead) / dest->weight
+	 *
+	 * Remember -- no floats in kernel mode!!!
+	 * The comparison of h1*w2 > h2*w1 is equivalent to that of
+	 *		  h1/w1 > h2/w2
+	 * if every weight is larger than zero.
+	 *
+	 * The server with weight=0 is quiesced and will not receive any
+	 * new connections.
+	 */
+
+	l = &svc->destinations;
+	for (e=l->next; e!=l; e=e->next) {
+		least = list_entry(e, struct ip_vs_dest, n_list);
+		if (atomic_read(&least->weight) > 0) {
+			loh = ip_vs_nq_dest_overhead(least);
+
+			/* return the server directly if it is idle */
+			if (atomic_read(&least->activeconns) == 0)
+				goto out;
+
+			goto nextstage;
+		}
+	}
+	return NULL;
+
+	/*
+	 *    Find the destination with the least load.
+	 */
+  nextstage:
+	for (e=e->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+		doh = ip_vs_nq_dest_overhead(dest);
+
+		/* return the server directly if it is idle */
+		if (atomic_read(&dest->activeconns) == 0) {
+			least = dest;
+			loh = doh;
+			goto out;
+		}
+
+		if (loh * atomic_read(&dest->weight) >
+		    doh * atomic_read(&least->weight)) {
+			least = dest;
+			loh = doh;
+		}
+	}
+
+  out:
+	IP_VS_DBG(6, "NQ: server %u.%u.%u.%u:%u "
+		  "activeconns %d refcnt %d weight %d overhead %d\n",
+		  NIPQUAD(least->addr), ntohs(least->port),
+		  atomic_read(&least->activeconns),
+		  atomic_read(&least->refcnt),
+		  atomic_read(&least->weight), loh);
+
+	return least;
+}
+
+
+static struct ip_vs_scheduler ip_vs_nq_scheduler =
+{
+	.name =			"nq",
+	.refcnt =		ATOMIC_INIT(0),
+	.module =		THIS_MODULE,
+	.init_service =		ip_vs_nq_init_svc,
+	.done_service =		ip_vs_nq_done_svc,
+	.update_service =	ip_vs_nq_update_svc,
+	.schedule =		ip_vs_nq_schedule,
+};
+
+
+static int __init ip_vs_nq_init(void)
+{
+	INIT_LIST_HEAD(&ip_vs_nq_scheduler.n_list);
+	return register_ip_vs_scheduler(&ip_vs_nq_scheduler);
+}
+
+static void __exit ip_vs_nq_cleanup(void)
+{
+	unregister_ip_vs_scheduler(&ip_vs_nq_scheduler);
+}
+
+module_init(ip_vs_nq_init);
+module_exit(ip_vs_nq_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_rr.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_rr.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_rr.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_rr.c	2003-08-27 14:40:50.000000000 +0000
@@ -0,0 +1,120 @@
+/*
+ * IPVS:        Round-Robin Scheduling module
+ *
+ * Version:     $Id: ip_vs_rr.c,v 1.8 2001/10/19 15:05:17 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *              Peter Kese <peter.kese@ijs.si>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Fixes/Changes:
+ *     Wensong Zhang            :     changed the ip_vs_rr_schedule to return dest
+ *     Julian Anastasov         :     fixed the NULL pointer access bug in debugging
+ *     Wensong Zhang            :     changed some comestics things for debugging
+ *     Wensong Zhang            :     changed for the d-linked destination list
+ *     Wensong Zhang            :     added the ip_vs_rr_update_svc
+ *     Wensong Zhang            :     added any dest with weight=0 is quiesced
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+
+#include <net/ip_vs.h>
+
+
+static int ip_vs_rr_init_svc(struct ip_vs_service *svc)
+{
+	svc->sched_data = &svc->destinations;
+	return 0;
+}
+
+
+static int ip_vs_rr_done_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static int ip_vs_rr_update_svc(struct ip_vs_service *svc)
+{
+	svc->sched_data = &svc->destinations;
+	return 0;
+}
+
+
+/*
+ * Round-Robin Scheduling
+ */
+static struct ip_vs_dest *
+ip_vs_rr_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	register struct list_head *p, *q;
+	struct ip_vs_dest *dest;
+
+	IP_VS_DBG(6, "ip_vs_rr_schedule(): Scheduling...\n");
+
+	write_lock(&svc->sched_lock);
+	p = (struct list_head *)svc->sched_data;
+	p = p->next;
+	q = p;
+	do {
+		if (q == &svc->destinations) {
+			q = q->next;
+			continue;
+		}
+		dest = list_entry(q, struct ip_vs_dest, n_list);
+		if (atomic_read(&dest->weight) > 0)
+			/* HIT */
+			goto out;
+		q = q->next;
+	} while (q != p);
+	write_unlock(&svc->sched_lock);
+	return NULL;
+
+  out:
+	svc->sched_data = q;
+	write_unlock(&svc->sched_lock);
+	IP_VS_DBG(6, "RR: server %u.%u.%u.%u:%u "
+		  "activeconns %d refcnt %d weight %d\n",
+		  NIPQUAD(dest->addr), ntohs(dest->port),
+		  atomic_read(&dest->activeconns),
+		  atomic_read(&dest->refcnt), atomic_read(&dest->weight));
+
+	return dest;
+}
+
+
+static struct ip_vs_scheduler ip_vs_rr_scheduler = {
+	{0},			/* n_list */
+	"rr",			/* name */
+	ATOMIC_INIT(0),		/* refcnt */
+	THIS_MODULE,		/* this module */
+	ip_vs_rr_init_svc,	/* service initializer */
+	ip_vs_rr_done_svc,	/* service done */
+	ip_vs_rr_update_svc,	/* service updater */
+	ip_vs_rr_schedule,	/* select a server from the destination list */
+};
+
+static int __init ip_vs_rr_init(void)
+{
+	INIT_LIST_HEAD(&ip_vs_rr_scheduler.n_list);
+	return register_ip_vs_scheduler(&ip_vs_rr_scheduler);
+}
+
+static void __exit ip_vs_rr_cleanup(void)
+{
+	unregister_ip_vs_scheduler(&ip_vs_rr_scheduler);
+}
+
+module_init(ip_vs_rr_init);
+module_exit(ip_vs_rr_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_sched.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_sched.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_sched.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_sched.c	2003-08-27 14:39:54.000000000 +0000
@@ -0,0 +1,260 @@
+/*
+ * IPVS         An implementation of the IP virtual server support for the
+ *              LINUX operating system.  IPVS is now implemented as a module
+ *              over the Netfilter framework. IPVS can be used to build a
+ *              high-performance and highly available server based on a
+ *              cluster of servers.
+ *
+ * Version:     $Id: ip_vs_sched.c,v 1.11 2001/11/04 08:58:43 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *              Peter Kese <peter.kese@ijs.si>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/sched.h>
+#include <linux/spinlock.h>
+#include <asm/softirq.h>                /* for local_bh_* */
+#include <asm/string.h>
+#include <linux/kmod.h>
+
+#include <net/ip_vs.h>
+
+/*
+ *  IPVS scheduler list
+ */
+static LIST_HEAD(ip_vs_schedulers);
+
+/* lock for service table */
+static rwlock_t __ip_vs_sched_lock = RW_LOCK_UNLOCKED;
+
+
+/*
+ *  Bind a service with a scheduler
+ */
+int ip_vs_bind_scheduler(struct ip_vs_service *svc,
+			 struct ip_vs_scheduler *scheduler)
+{
+	int ret;
+
+	if (svc == NULL) {
+		IP_VS_ERR("ip_vs_bind_scheduler(): svc arg NULL\n");
+		return -EINVAL;
+	}
+	if (scheduler == NULL) {
+		IP_VS_ERR("ip_vs_bind_scheduler(): scheduler arg NULL\n");
+		return -EINVAL;
+	}
+
+	svc->scheduler = scheduler;
+
+	if (scheduler->init_service) {
+		ret = scheduler->init_service(svc);
+		if (ret) {
+			IP_VS_ERR("ip_vs_bind_scheduler(): init error\n");
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+
+/*
+ *  Unbind a service with its scheduler
+ */
+int ip_vs_unbind_scheduler(struct ip_vs_service *svc)
+{
+	struct ip_vs_scheduler *sched;
+
+	if (svc == NULL) {
+		IP_VS_ERR("ip_vs_unbind_scheduler(): svc arg NULL\n");
+		return -EINVAL;
+	}
+
+	sched = svc->scheduler;
+	if (sched == NULL) {
+		IP_VS_ERR("ip_vs_unbind_scheduler(): svc isn't bound\n");
+		return -EINVAL;
+	}
+
+	if (sched->done_service) {
+		if (sched->done_service(svc) != 0) {
+			IP_VS_ERR("ip_vs_unbind_scheduler(): done error\n");
+			return -EINVAL;
+		}
+	}
+
+	svc->scheduler = NULL;
+	return 0;
+}
+
+
+/*
+ *  Get scheduler in the scheduler list by name
+ */
+static struct ip_vs_scheduler *ip_vs_sched_getbyname(const char *sched_name)
+{
+	struct ip_vs_scheduler *sched;
+	struct list_head *l, *e;
+
+	IP_VS_DBG(2, "ip_vs_sched_getbyname(): sched_name \"%s\"\n",
+		  sched_name);
+
+	l = &ip_vs_schedulers;
+
+	read_lock_bh(&__ip_vs_sched_lock);
+
+	for (e=l->next; e!=l; e=e->next) {
+		sched = list_entry(e, struct ip_vs_scheduler, n_list);
+
+		/*
+		 * Test and MOD_INC_USE_COUNT atomically
+		 */
+		if (sched->module && !try_inc_mod_count(sched->module)) {
+			/*
+			 * This scheduler is just deleted
+			 */
+			continue;
+		}
+		if (strcmp(sched_name, sched->name)==0) {
+			/* HIT */
+			read_unlock_bh(&__ip_vs_sched_lock);
+			return sched;
+		}
+		if (sched->module)
+			__MOD_DEC_USE_COUNT(sched->module);
+	}
+
+	read_unlock_bh(&__ip_vs_sched_lock);
+	return NULL;
+}
+
+
+/*
+ *  Lookup scheduler and try to load it if it doesn't exist
+ */
+struct ip_vs_scheduler *ip_vs_scheduler_get(const char *sched_name)
+{
+	struct ip_vs_scheduler *sched;
+
+	/*
+	 *  Search for the scheduler by sched_name
+	 */
+	sched = ip_vs_sched_getbyname(sched_name);
+
+	/*
+	 *  If scheduler not found, load the module and search again
+	 */
+	if (sched == NULL) {
+		char module_name[IP_VS_SCHEDNAME_MAXLEN+8];
+		sprintf(module_name,"ip_vs_%s", sched_name);
+		request_module(module_name);
+		sched = ip_vs_sched_getbyname(sched_name);
+	}
+
+	return sched;
+}
+
+void ip_vs_scheduler_put(struct ip_vs_scheduler *scheduler)
+{
+	if (scheduler->module)
+		__MOD_DEC_USE_COUNT(scheduler->module);
+}
+
+
+/*
+ *  Register a scheduler in the scheduler list
+ */
+int register_ip_vs_scheduler(struct ip_vs_scheduler *scheduler)
+{
+	struct ip_vs_scheduler *sched;
+
+	if (!scheduler) {
+		IP_VS_ERR("register_ip_vs_scheduler(): NULL arg\n");
+		return -EINVAL;
+	}
+
+	if (!scheduler->name) {
+		IP_VS_ERR("register_ip_vs_scheduler(): NULL scheduler_name\n");
+		return -EINVAL;
+	}
+
+	MOD_INC_USE_COUNT;
+
+	/*
+	 *  Make sure that the scheduler with this name doesn't exist
+	 *  in the scheduler list.
+	 */
+	sched = ip_vs_sched_getbyname(scheduler->name);
+	if (sched) {
+		ip_vs_scheduler_put(sched);
+		MOD_DEC_USE_COUNT;
+		IP_VS_ERR("register_ip_vs_scheduler(): [%s] scheduler "
+			  "already existed in the system\n", scheduler->name);
+		return -EINVAL;
+	}
+
+	write_lock_bh(&__ip_vs_sched_lock);
+
+	if (scheduler->n_list.next != &scheduler->n_list) {
+		write_unlock_bh(&__ip_vs_sched_lock);
+		MOD_DEC_USE_COUNT;
+		IP_VS_ERR("register_ip_vs_scheduler(): [%s] scheduler "
+			  "already linked\n", scheduler->name);
+		return -EINVAL;
+	}
+
+	/*
+	 *	Add it into the d-linked scheduler list
+	 */
+	list_add(&scheduler->n_list, &ip_vs_schedulers);
+	write_unlock_bh(&__ip_vs_sched_lock);
+
+	IP_VS_INFO("[%s] scheduler registered.\n", scheduler->name);
+
+	return 0;
+}
+
+
+/*
+ *  Unregister a scheduler from the scheduler list
+ */
+int unregister_ip_vs_scheduler(struct ip_vs_scheduler *scheduler)
+{
+	if (!scheduler) {
+		IP_VS_ERR( "unregister_ip_vs_scheduler(): NULL arg\n");
+		return -EINVAL;
+	}
+
+	write_lock_bh(&__ip_vs_sched_lock);
+	if (scheduler->n_list.next == &scheduler->n_list) {
+		write_unlock_bh(&__ip_vs_sched_lock);
+		IP_VS_ERR("unregister_ip_vs_scheduler(): [%s] scheduler "
+			  "is not in the list. failed\n", scheduler->name);
+		return -EINVAL;
+	}
+
+	/*
+	 *	Remove it from the d-linked scheduler list
+	 */
+	list_del(&scheduler->n_list);
+	write_unlock_bh(&__ip_vs_sched_lock);
+
+	MOD_DEC_USE_COUNT;
+
+	IP_VS_INFO("[%s] scheduler unregistered.\n", scheduler->name);
+
+	return 0;
+}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_sed.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_sed.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_sed.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_sed.c	2003-08-27 14:39:46.000000000 +0000
@@ -0,0 +1,167 @@
+/*
+ * IPVS:        Shortest Expected Delay scheduling module
+ *
+ * Version:     $Id: ip_vs_sed.c,v 1.1.2.1 2003/05/20 17:05:02 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *
+ */
+
+/*
+ * The SED algorithm attempts to minimize each job's expected delay until
+ * completion. The expected delay that the job will experience is
+ * (Ci + 1) / Ui if sent to the ith server, in which Ci is the number of
+ * jobs on the the ith server and Ui is the fixed service rate (weight) of
+ * the ith server. The SED algorithm adopts a greedy policy that each does
+ * what is in its own best interest, i.e. to join the queue which would
+ * minimize its expected delay of completion.
+ *
+ * See the following paper for more information:
+ * A. Weinrib and S. Shenker, Greed is not enough: Adaptive load sharing
+ * in large heterogeneous systems. In Proceedings IEEE INFOCOM'88,
+ * pages 986-994, 1988.
+ *
+ * Thanks must go to Marko Buuri <marko@buuri.name> for talking SED to me.
+ *
+ * The difference between SED and WLC is that SED includes the incoming
+ * job in the cost function (the increment of 1). SED may outperform
+ * WLC, while scheduling big jobs under larger heterogeneous systems
+ * (the server weight varies a lot).
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+
+#include <net/ip_vs.h>
+
+
+static int
+ip_vs_sed_init_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static int
+ip_vs_sed_done_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static int
+ip_vs_sed_update_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static inline unsigned int
+ip_vs_sed_dest_overhead(struct ip_vs_dest *dest)
+{
+	/*
+	 * We only use the active connection number in the cost
+	 * calculation here.
+	 */
+	return atomic_read(&dest->activeconns) + 1;
+}
+
+
+/*
+ *	Weighted Least Connection scheduling
+ */
+static struct ip_vs_dest *
+ip_vs_sed_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	register struct list_head *l, *e;
+	struct ip_vs_dest *dest, *least;
+	unsigned int loh, doh;
+
+	IP_VS_DBG(6, "ip_vs_sed_schedule(): Scheduling...\n");
+
+	/*
+	 * We calculate the load of each dest server as follows:
+	 *	(server expected overhead) / dest->weight
+	 *
+	 * Remember -- no floats in kernel mode!!!
+	 * The comparison of h1*w2 > h2*w1 is equivalent to that of
+	 *		  h1/w1 > h2/w2
+	 * if every weight is larger than zero.
+	 *
+	 * The server with weight=0 is quiesced and will not receive any
+	 * new connections.
+	 */
+
+	l = &svc->destinations;
+	for (e=l->next; e!=l; e=e->next) {
+		least = list_entry(e, struct ip_vs_dest, n_list);
+		if (atomic_read(&least->weight) > 0) {
+			loh = ip_vs_sed_dest_overhead(least);
+			goto nextstage;
+		}
+	}
+	return NULL;
+
+	/*
+	 *    Find the destination with the least load.
+	 */
+  nextstage:
+	for (e=e->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+		doh = ip_vs_sed_dest_overhead(dest);
+		if (loh * atomic_read(&dest->weight) >
+		    doh * atomic_read(&least->weight)) {
+			least = dest;
+			loh = doh;
+		}
+	}
+
+	IP_VS_DBG(6, "SED: server %u.%u.%u.%u:%u "
+		  "activeconns %d refcnt %d weight %d overhead %d\n",
+		  NIPQUAD(least->addr), ntohs(least->port),
+		  atomic_read(&least->activeconns),
+		  atomic_read(&least->refcnt),
+		  atomic_read(&least->weight), loh);
+
+	return least;
+}
+
+
+static struct ip_vs_scheduler ip_vs_sed_scheduler =
+{
+	.name =			"sed",
+	.refcnt =		ATOMIC_INIT(0),
+	.module =		THIS_MODULE,
+	.init_service =		ip_vs_sed_init_svc,
+	.done_service =		ip_vs_sed_done_svc,
+	.update_service =	ip_vs_sed_update_svc,
+	.schedule =		ip_vs_sed_schedule,
+};
+
+
+static int __init ip_vs_sed_init(void)
+{
+	INIT_LIST_HEAD(&ip_vs_sed_scheduler.n_list);
+	return register_ip_vs_scheduler(&ip_vs_sed_scheduler);
+}
+
+static void __exit ip_vs_sed_cleanup(void)
+{
+	unregister_ip_vs_scheduler(&ip_vs_sed_scheduler);
+}
+
+module_init(ip_vs_sed_init);
+module_exit(ip_vs_sed_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_sh.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_sh.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_sh.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_sh.c	2003-08-27 14:40:39.000000000 +0000
@@ -0,0 +1,262 @@
+/*
+ * IPVS:        Source Hashing scheduling module
+ *
+ * Version:     $Id: ip_vs_sh.c,v 1.4 2001/10/19 15:05:17 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@gnuchina.org>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *
+ */
+
+/*
+ * The sh algorithm is to select server by the hash key of source IP
+ * address. The pseudo code is as follows:
+ *
+ *       n <- servernode[src_ip];
+ *       if (n is dead) OR
+ *          (n is overloaded, such as n.conns>2*n.weight) then
+ *                 return NULL;
+ *
+ *       return n;
+ *
+ * Notes that servernode is a 256-bucket hash table that maps the hash
+ * index derived from packet source IP address to the current server
+ * array. If the sh scheduler is used in cache cluster, it is good to
+ * combine it with cache_bypass feature. When the statically assigned
+ * server is dead or overloaded, the load balancer can bypass the cache
+ * server and send requests to the original server directly.
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+
+#include <net/ip_vs.h>
+
+
+/*
+ *      IPVS SH bucket
+ */
+struct ip_vs_sh_bucket {
+	struct ip_vs_dest       *dest;          /* real server (cache) */
+};
+
+/*
+ *     for IPVS SH entry hash table
+ */
+#ifndef CONFIG_IP_VS_SH_TAB_BITS
+#define CONFIG_IP_VS_SH_TAB_BITS        8
+#endif
+#define IP_VS_SH_TAB_BITS               CONFIG_IP_VS_SH_TAB_BITS
+#define IP_VS_SH_TAB_SIZE               (1 << IP_VS_SH_TAB_BITS)
+#define IP_VS_SH_TAB_MASK               (IP_VS_SH_TAB_SIZE - 1)
+
+
+/*
+ *	Returns hash value for IPVS SH entry
+ */
+static inline unsigned ip_vs_sh_hashkey(__u32 addr)
+{
+	return (ntohl(addr)*2654435761UL) & IP_VS_SH_TAB_MASK;
+}
+
+
+/*
+ *      Get ip_vs_dest associated with supplied parameters.
+ */
+static inline struct ip_vs_dest *
+ip_vs_sh_get(struct ip_vs_sh_bucket *tbl, __u32 addr)
+{
+	return (tbl[ip_vs_sh_hashkey(addr)]).dest;
+}
+
+
+/*
+ *      Assign all the hash buckets of the specified table with the service.
+ */
+static int
+ip_vs_sh_assign(struct ip_vs_sh_bucket *tbl, struct ip_vs_service *svc)
+{
+	int i;
+	struct ip_vs_sh_bucket *b;
+	struct list_head *p;
+	struct ip_vs_dest *dest;
+
+	b = tbl;
+	p = &svc->destinations;
+	for (i=0; i<IP_VS_SH_TAB_SIZE; i++) {
+		if (list_empty(p)) {
+			b->dest = NULL;
+		} else {
+			if (p == &svc->destinations)
+				p = p->next;
+
+			dest = list_entry(p, struct ip_vs_dest, n_list);
+			atomic_inc(&dest->refcnt);
+			b->dest = dest;
+
+			p = p->next;
+		}
+		b++;
+	}
+	return 0;
+}
+
+
+/*
+ *      Flush all the hash buckets of the specified table.
+ */
+static void ip_vs_sh_flush(struct ip_vs_sh_bucket *tbl)
+{
+	int i;
+	struct ip_vs_sh_bucket *b;
+
+	b = tbl;
+	for (i=0; i<IP_VS_SH_TAB_SIZE; i++) {
+		if (b->dest) {
+			atomic_dec(&b->dest->refcnt);
+			b->dest = NULL;
+		}
+		b++;
+	}
+}
+
+
+static int ip_vs_sh_init_svc(struct ip_vs_service *svc)
+{
+	struct ip_vs_sh_bucket *tbl;
+
+	/* allocate the SH table for this service */
+	tbl = kmalloc(sizeof(struct ip_vs_sh_bucket)*IP_VS_SH_TAB_SIZE,
+		      GFP_ATOMIC);
+	if (tbl == NULL) {
+		IP_VS_ERR("ip_vs_sh_init_svc(): no memory\n");
+		return -ENOMEM;
+	}
+	svc->sched_data = tbl;
+	IP_VS_DBG(6, "SH hash table (memory=%dbytes) allocated for "
+		  "current service\n",
+		  sizeof(struct ip_vs_sh_bucket)*IP_VS_SH_TAB_SIZE);
+
+	/* assign the hash buckets with the updated service */
+	ip_vs_sh_assign(tbl, svc);
+
+	return 0;
+}
+
+
+static int ip_vs_sh_done_svc(struct ip_vs_service *svc)
+{
+	struct ip_vs_sh_bucket *tbl = svc->sched_data;
+
+	/* got to clean up hash buckets here */
+	ip_vs_sh_flush(tbl);
+
+	/* release the table itself */
+	kfree(svc->sched_data);
+	IP_VS_DBG(6, "SH hash table (memory=%dbytes) released\n",
+		  sizeof(struct ip_vs_sh_bucket)*IP_VS_SH_TAB_SIZE);
+
+	return 0;
+}
+
+
+static int ip_vs_sh_update_svc(struct ip_vs_service *svc)
+{
+	struct ip_vs_sh_bucket *tbl = svc->sched_data;
+
+	/* got to clean up hash buckets here */
+	ip_vs_sh_flush(tbl);
+
+	/* assign the hash buckets with the updated service */
+	ip_vs_sh_assign(tbl, svc);
+
+	return 0;
+}
+
+
+/*
+ *      If the number of active connections is twice larger than its weight,
+ *      consider that the server is overloaded here.
+ */
+static inline int is_overloaded(struct ip_vs_dest *dest)
+{
+	if (atomic_read(&dest->activeconns) > atomic_read(&dest->weight)*2) {
+		return 1;
+	}
+	return 0;
+}
+
+
+/*
+ *      Source Hashing scheduling
+ */
+static struct ip_vs_dest *
+ip_vs_sh_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	struct ip_vs_dest *dest;
+	struct ip_vs_sh_bucket *tbl;
+
+	IP_VS_DBG(6, "ip_vs_sh_schedule(): Scheduling...\n");
+
+	tbl = (struct ip_vs_sh_bucket *)svc->sched_data;
+	dest = ip_vs_sh_get(tbl, iph->saddr);
+	if (!dest
+	    || !(dest->flags & IP_VS_DEST_F_AVAILABLE)
+	    || atomic_read(&dest->weight) <= 0
+	    || is_overloaded(dest)) {
+		return NULL;
+	}
+
+	IP_VS_DBG(6, "SH: source IP address %u.%u.%u.%u "
+		  "--> server %u.%u.%u.%u:%d\n",
+		  NIPQUAD(iph->saddr),
+		  NIPQUAD(dest->addr),
+		  ntohs(dest->port));
+
+	return dest;
+}
+
+
+/*
+ *      IPVS SH Scheduler structure
+ */
+static struct ip_vs_scheduler ip_vs_sh_scheduler =
+{
+	{0},                    /* n_list */
+	"sh",                   /* name */
+	ATOMIC_INIT(0),         /* refcnt */
+	THIS_MODULE,            /* this module */
+	ip_vs_sh_init_svc,      /* service initializer */
+	ip_vs_sh_done_svc,      /* service done */
+	ip_vs_sh_update_svc,    /* service updater */
+	ip_vs_sh_schedule,      /* select a server from the destination list */
+};
+
+
+static int __init ip_vs_sh_init(void)
+{
+	INIT_LIST_HEAD(&ip_vs_sh_scheduler.n_list);
+	return register_ip_vs_scheduler(&ip_vs_sh_scheduler);
+}
+
+
+static void __exit ip_vs_sh_cleanup(void)
+{
+	unregister_ip_vs_scheduler(&ip_vs_sh_scheduler);
+}
+
+
+module_init(ip_vs_sh_init);
+module_exit(ip_vs_sh_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_sync.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_sync.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_sync.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_sync.c	2003-08-27 14:40:45.000000000 +0000
@@ -0,0 +1,793 @@
+/*
+ * IPVS         An implementation of the IP virtual server support for the
+ *              LINUX operating system.  IPVS is now implemented as a module
+ *              over the NetFilter framework. IPVS can be used to build a
+ *              high-performance and highly available server based on a
+ *              cluster of servers.
+ *
+ * Version:     $Id: ip_vs_sync.c,v 1.8 2002/08/17 14:06:02 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *
+ * ip_vs_sync:  sync connection info from master load balancer to backups
+ *              through multicast
+ */
+
+#define __KERNEL_SYSCALLS__             /*  for waitpid */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/slab.h>
+#include <linux/net.h>
+#include <linux/sched.h>
+#include <linux/wait.h>
+#include <linux/unistd.h>
+
+#include <linux/skbuff.h>
+#include <linux/in.h>
+#include <linux/igmp.h>                 /* for ip_mc_join_group */
+
+#include <net/ip.h>
+#include <net/sock.h>
+#include <asm/uaccess.h>                /* for get_fs and set_fs */
+
+#include <net/ip_vs.h>
+
+#define IP_VS_SYNC_GROUP 0xe0000051    /* multicast addr - 224.0.0.81 */
+#define IP_VS_SYNC_PORT  8848          /* multicast port */
+
+
+/*
+ *	IPVS sync connection entry
+ */
+struct ip_vs_sync_conn {
+	__u8			reserved;
+
+	/* Protocol, addresses and port numbers */
+	__u8			protocol;       /* Which protocol (TCP/UDP) */
+	__u16			cport;
+	__u16                   vport;
+	__u16                   dport;
+	__u32                   caddr;          /* client address */
+	__u32                   vaddr;          /* virtual address */
+	__u32                   daddr;          /* destination address */
+
+	/* Flags and state transition */
+	__u16                   flags;          /* status flags */
+	__u16                   state;          /* state info */
+
+	/* The sequence options start here */
+};
+
+struct ip_vs_sync_conn_options {
+	struct ip_vs_seq        in_seq;         /* incoming seq. struct */
+	struct ip_vs_seq        out_seq;        /* outgoing seq. struct */
+};
+
+#define IP_VS_SYNC_CONN_TIMEOUT (3*60*HZ)
+#define SIMPLE_CONN_SIZE  (sizeof(struct ip_vs_sync_conn))
+#define FULL_CONN_SIZE  \
+(sizeof(struct ip_vs_sync_conn) + sizeof(struct ip_vs_sync_conn_options))
+
+
+/*
+  The master mulitcasts messages to the backup load balancers in the
+  following format.
+
+       0                   1                   2                   3
+       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+      |  Count Conns  |   Reserved    |            Size               |
+      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+      |                                                               |
+      |                    IPVS Sync Connection (1)                   |
+      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+      |                            .                                  |
+      |                            .                                  |
+      |                            .                                  |
+      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+      |                                                               |
+      |                    IPVS Sync Connection (n)                   |
+      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+*/
+#define SYNC_MESG_MAX_SIZE      (24*50+4)
+struct ip_vs_sync_mesg {
+	__u8                    nr_conns;
+	__u8                    reserved;
+	__u16                   size;
+
+	/* ip_vs_sync_conn entries start here */
+};
+
+
+struct ip_vs_sync_buff {
+	struct list_head        list;
+	unsigned long           firstuse;
+
+	/* pointers for the message data */
+	struct ip_vs_sync_mesg  *mesg;
+	unsigned char           *head;
+	unsigned char           *end;
+};
+
+
+/* the sync_buff list head and the lock */
+static LIST_HEAD(ip_vs_sync_queue);
+static spinlock_t ip_vs_sync_lock = SPIN_LOCK_UNLOCKED;
+
+/* current sync_buff for accepting new conn entries */
+static struct ip_vs_sync_buff   *curr_sb = NULL;
+static spinlock_t curr_sb_lock = SPIN_LOCK_UNLOCKED;
+
+static inline void sb_queue_tail(struct ip_vs_sync_buff *sb)
+{
+	spin_lock(&ip_vs_sync_lock);
+	list_add_tail(&sb->list, &ip_vs_sync_queue);
+	spin_unlock(&ip_vs_sync_lock);
+}
+
+static inline struct ip_vs_sync_buff * sb_dequeue(void)
+{
+	struct ip_vs_sync_buff *sb;
+
+	spin_lock_bh(&ip_vs_sync_lock);
+	if (list_empty(&ip_vs_sync_queue)) {
+		sb = NULL;
+	} else {
+		sb = list_entry(ip_vs_sync_queue.next,
+				struct ip_vs_sync_buff,
+				list);
+		list_del(&sb->list);
+	}
+	spin_unlock_bh(&ip_vs_sync_lock);
+
+	return sb;
+}
+
+static inline struct ip_vs_sync_buff * ip_vs_sync_buff_create(void)
+{
+	struct ip_vs_sync_buff *sb;
+
+	if (!(sb=kmalloc(sizeof(struct ip_vs_sync_buff), GFP_ATOMIC)))
+		return NULL;
+
+	if (!(sb->mesg=kmalloc(SYNC_MESG_MAX_SIZE, GFP_ATOMIC))) {
+		kfree(sb);
+		return NULL;
+	}
+	sb->mesg->nr_conns = 0;
+	sb->mesg->size = 4;
+	sb->head = (unsigned char *)sb->mesg + 4;
+	sb->end = (unsigned char *)sb->mesg + SYNC_MESG_MAX_SIZE;
+	sb->firstuse = jiffies;
+	return sb;
+}
+
+static inline void ip_vs_sync_buff_release(struct ip_vs_sync_buff *sb)
+{
+	kfree(sb->mesg);
+	kfree(sb);
+}
+
+/*
+ *	Get the current sync buffer if it has been created for more
+ *	than the specified time or the specified time is zero.
+ */
+static inline struct ip_vs_sync_buff *
+get_curr_sync_buff(unsigned long time)
+{
+	struct ip_vs_sync_buff *sb;
+
+	spin_lock_bh(&curr_sb_lock);
+	if (curr_sb &&
+	    (jiffies - curr_sb->firstuse > time || time == 0)) {
+		sb = curr_sb;
+		curr_sb = NULL;
+	} else
+		sb = NULL;
+	spin_unlock_bh(&curr_sb_lock);
+	return sb;
+}
+
+
+/*
+ *      Add an ip_vs_conn information into the current sync_buff.
+ *      Called by ip_vs_in.
+ */
+void ip_vs_sync_conn(struct ip_vs_conn *cp)
+{
+	struct ip_vs_sync_mesg *m;
+	struct ip_vs_sync_conn *s;
+	int len;
+
+	spin_lock(&curr_sb_lock);
+	if (!curr_sb) {
+		if (!(curr_sb=ip_vs_sync_buff_create())) {
+			spin_unlock(&curr_sb_lock);
+			IP_VS_ERR("ip_vs_sync_buff_create failed.\n");
+			return;
+		}
+	}
+
+	len = (cp->flags & IP_VS_CONN_F_SEQ_MASK) ? FULL_CONN_SIZE :
+		SIMPLE_CONN_SIZE;
+	m = curr_sb->mesg;
+	s = (struct ip_vs_sync_conn *)curr_sb->head;
+
+	/* copy members */
+	s->protocol = cp->protocol;
+	s->cport = cp->cport;
+	s->vport = cp->vport;
+	s->dport = cp->dport;
+	s->caddr = cp->caddr;
+	s->vaddr = cp->vaddr;
+	s->daddr = cp->daddr;
+	s->flags = htons(cp->flags & ~IP_VS_CONN_F_HASHED);
+	s->state = htons(cp->state);
+	if (cp->flags & IP_VS_CONN_F_SEQ_MASK) {
+		struct ip_vs_sync_conn_options *opt =
+			(struct ip_vs_sync_conn_options *)&s[1];
+		memcpy(opt, &cp->in_seq, sizeof(*opt));
+	}
+
+	m->nr_conns++;
+	m->size += len;
+	curr_sb->head += len;
+
+	/* check if there is a space for next one */
+	if (curr_sb->head+FULL_CONN_SIZE > curr_sb->end) {
+		sb_queue_tail(curr_sb);
+		curr_sb = NULL;
+	}
+	spin_unlock(&curr_sb_lock);
+
+	/* synchronize its controller if it has */
+	if (cp->control)
+		ip_vs_sync_conn(cp->control);
+}
+
+
+/*
+ *      Process received multicast message and create the corresponding
+ *      ip_vs_conn entries.
+ */
+static void ip_vs_process_message(const char *buffer, const size_t buflen)
+{
+	struct ip_vs_sync_mesg *m = (struct ip_vs_sync_mesg *)buffer;
+	struct ip_vs_sync_conn *s;
+	struct ip_vs_sync_conn_options *opt;
+	struct ip_vs_conn *cp;
+	char *p;
+	int i;
+
+	if (buflen != m->size) {
+		IP_VS_ERR("bogus message\n");
+		return;
+	}
+
+	p = (char *)buffer + sizeof(struct ip_vs_sync_mesg);
+	for (i=0; i<m->nr_conns; i++) {
+		s = (struct ip_vs_sync_conn *)p;
+		cp = ip_vs_conn_in_get(s->protocol,
+				       s->caddr, s->cport,
+				       s->vaddr, s->vport);
+		if (!cp) {
+			cp = ip_vs_conn_new(s->protocol,
+					    s->caddr, s->cport,
+					    s->vaddr, s->vport,
+					    s->daddr, s->dport,
+					    ntohs(s->flags), NULL);
+			if (!cp) {
+				IP_VS_ERR("ip_vs_conn_new failed\n");
+				return;
+			}
+			cp->state = ntohs(s->state);
+		} else if (!cp->dest) {
+			/* it is an entry created by the synchronization */
+			cp->state = ntohs(s->state);
+			cp->flags = ntohs(s->flags) | IP_VS_CONN_F_HASHED;
+		}	/* Note that we don't touch its state and flags
+			   if it is a normal entry. */
+
+		if (ntohs(s->flags) & IP_VS_CONN_F_SEQ_MASK) {
+			opt = (struct ip_vs_sync_conn_options *)&s[1];
+			memcpy(&cp->in_seq, opt, sizeof(*opt));
+			p += FULL_CONN_SIZE;
+		} else
+			p += SIMPLE_CONN_SIZE;
+
+		atomic_set(&cp->in_pkts, sysctl_ip_vs_sync_threshold);
+		cp->timeout = IP_VS_SYNC_CONN_TIMEOUT;
+		ip_vs_conn_put(cp);
+
+		if (p > buffer+buflen) {
+			IP_VS_ERR("bogus message\n");
+			return;
+		}
+	}
+}
+
+
+/* ipvs sync daemon state */
+volatile int ip_vs_sync_state = IP_VS_STATE_NONE;
+
+/* multicast interface name */
+char ip_vs_mcast_ifn[IP_VS_IFNAME_MAXLEN];
+
+/* multicast addr */
+static struct sockaddr_in mcast_addr;
+
+
+/*
+ *      Setup loopback of outgoing multicasts on a sending socket
+ */
+static void set_mcast_loop(struct sock *sk, u_char loop)
+{
+	/* setsockopt(sock, SOL_IP, IP_MULTICAST_LOOP, &loop, sizeof(loop)); */
+	lock_sock(sk);
+	sk->protinfo.af_inet.mc_loop = loop ? 1 : 0;
+	release_sock(sk);
+}
+
+/*
+ *      Specify TTL for outgoing multicasts on a sending socket
+ */
+static void set_mcast_ttl(struct sock *sk, u_char ttl)
+{
+	/* setsockopt(sock, SOL_IP, IP_MULTICAST_TTL, &ttl, sizeof(ttl)); */
+	lock_sock(sk);
+	sk->protinfo.af_inet.mc_ttl = ttl;
+	release_sock(sk);
+}
+
+/*
+ *      Specifiy default interface for outgoing multicasts
+ */
+static int set_mcast_if(struct sock *sk, char *ifname)
+{
+	struct net_device *dev;
+
+	if ((dev = __dev_get_by_name(ifname)) == NULL)
+		return -ENODEV;
+
+	if (sk->bound_dev_if && dev->ifindex != sk->bound_dev_if)
+		return -EINVAL;
+
+	lock_sock(sk);
+	sk->protinfo.af_inet.mc_index = dev->ifindex;
+	/*  sk->protinfo.af_inet.mc_addr  = 0; */
+	release_sock(sk);
+
+	return 0;
+}
+
+/*
+ *      Join a multicast group.
+ *      the group is specified by a class D multicast address 224.0.0.0/8
+ *      in the in_addr structure passed in as a parameter.
+ */
+static int
+join_mcast_group(struct sock *sk, struct in_addr *addr, char *ifname)
+{
+	struct ip_mreqn mreq;
+	struct net_device *dev;
+	int ret;
+
+	memset(&mreq, 0, sizeof(mreq));
+	memcpy(&mreq.imr_multiaddr, addr, sizeof(struct in_addr));
+
+	if ((dev = __dev_get_by_name(ifname)) == NULL)
+		return -ENODEV;
+	if (sk->bound_dev_if && dev->ifindex != sk->bound_dev_if)
+		return -EINVAL;
+
+	mreq.imr_ifindex = dev->ifindex;
+
+	lock_sock(sk);
+	ret = ip_mc_join_group(sk, &mreq);
+	release_sock(sk);
+
+	return ret;
+}
+
+
+static int bind_mcastif_addr(struct socket *sock, char *ifname)
+{
+	struct net_device *dev;
+	u32 addr;
+	struct sockaddr_in sin;
+
+	if ((dev = __dev_get_by_name(ifname)) == NULL)
+		return -ENODEV;
+
+	addr = inet_select_addr(dev, 0, RT_SCOPE_UNIVERSE);
+	if (!addr)
+		IP_VS_ERR("You probably need to specify IP address on "
+			  "multicast interface.\n");
+
+	IP_VS_DBG(7, "binding socket with (%s) %u.%u.%u.%u\n",
+		  ifname, NIPQUAD(addr));
+
+	/* Now bind the socket with the address of multicast interface */
+	sin.sin_family	     = AF_INET;
+	sin.sin_addr.s_addr  = addr;
+	sin.sin_port         = 0;
+
+	return sock->ops->bind(sock, (struct sockaddr*)&sin, sizeof(sin));
+}
+
+/*
+ *      Set up sending multicast socket over UDP
+ */
+static struct socket * make_send_sock(void)
+{
+	struct socket *sock;
+
+	/* First create a socket */
+	if (sock_create(PF_INET, SOCK_DGRAM, IPPROTO_UDP, &sock) < 0) {
+		IP_VS_ERR("Error during creation of socket; terminating\n");
+		return NULL;
+	}
+
+	if (set_mcast_if(sock->sk, ip_vs_mcast_ifn) < 0) {
+		IP_VS_ERR("Error setting outbound mcast interface\n");
+		goto error;
+	}
+
+	set_mcast_loop(sock->sk, 0);
+	set_mcast_ttl(sock->sk, 1);
+
+	if (bind_mcastif_addr(sock, ip_vs_mcast_ifn) < 0) {
+		IP_VS_ERR("Error binding address of the mcast interface\n");
+		goto error;
+	}
+
+	if (sock->ops->connect(sock,
+			       (struct sockaddr*)&mcast_addr,
+			       sizeof(struct sockaddr), 0) < 0) {
+		IP_VS_ERR("Error connecting to the multicast addr\n");
+		goto error;
+	}
+
+	return sock;
+
+  error:
+	sock_release(sock);
+	return NULL;
+}
+
+
+/*
+ *      Set up receiving multicast socket over UDP
+ */
+static struct socket * make_receive_sock(void)
+{
+	struct socket *sock;
+
+	/* First create a socket */
+	if (sock_create(PF_INET, SOCK_DGRAM, IPPROTO_UDP, &sock) < 0) {
+		IP_VS_ERR("Error during creation of socket; terminating\n");
+		return NULL;
+	}
+
+	/* it is equivalent to the REUSEADDR option in user-space */
+	sock->sk->reuse = 1;
+
+	if (sock->ops->bind(sock,
+			    (struct sockaddr*)&mcast_addr,
+			    sizeof(struct sockaddr)) < 0) {
+		IP_VS_ERR("Error binding to the multicast addr\n");
+		goto error;
+	}
+
+	/* join the multicast group */
+	if (join_mcast_group(sock->sk,
+			     (struct in_addr*)&mcast_addr.sin_addr,
+			     ip_vs_mcast_ifn) < 0) {
+		IP_VS_ERR("Error joining to the multicast group\n");
+		goto error;
+	}
+
+	return sock;
+
+  error:
+	sock_release(sock);
+	return NULL;
+}
+
+
+static int
+ip_vs_send_async(struct socket *sock, const char *buffer, const size_t length)
+{
+	struct msghdr	msg;
+	mm_segment_t	oldfs;
+	struct iovec	iov;
+	int		len;
+
+	EnterFunction(7);
+	iov.iov_base     = (void *)buffer;
+	iov.iov_len      = length;
+	msg.msg_name     = 0;
+	msg.msg_namelen  = 0;
+	msg.msg_iov	 = &iov;
+	msg.msg_iovlen   = 1;
+	msg.msg_control  = NULL;
+	msg.msg_controllen = 0;
+	msg.msg_flags    = MSG_DONTWAIT|MSG_NOSIGNAL;
+
+	oldfs = get_fs(); set_fs(KERNEL_DS);
+	len = sock_sendmsg(sock, &msg, (size_t)(length));
+	set_fs(oldfs);
+
+	LeaveFunction(7);
+	return len;
+}
+
+
+static int
+ip_vs_receive(struct socket *sock, char *buffer, const size_t buflen)
+{
+	struct msghdr		msg;
+	struct iovec		iov;
+	int			len;
+	mm_segment_t		oldfs;
+
+	EnterFunction(7);
+
+	/* Receive a packet */
+	iov.iov_base     = buffer;
+	iov.iov_len      = (size_t)buflen;
+	msg.msg_name     = 0;
+	msg.msg_namelen  = 0;
+	msg.msg_iov	 = &iov;
+	msg.msg_iovlen   = 1;
+	msg.msg_control  = NULL;
+	msg.msg_controllen = 0;
+	msg.msg_flags    = 0;
+
+	oldfs = get_fs(); set_fs(KERNEL_DS);
+	len = sock_recvmsg(sock, &msg, buflen, 0);
+	set_fs(oldfs);
+
+	if (len < 0)
+		return -1;
+
+	LeaveFunction(7);
+	return len;
+}
+
+
+static int errno;
+
+static DECLARE_WAIT_QUEUE_HEAD(sync_wait);
+static pid_t sync_pid = 0;
+
+static DECLARE_WAIT_QUEUE_HEAD(stop_sync_wait);
+static int stop_sync = 0;
+
+static void sync_master_loop(void)
+{
+	struct socket *sock;
+	struct ip_vs_sync_buff *sb;
+	struct ip_vs_sync_mesg *m;
+
+	/* create the sending multicast socket */
+	sock = make_send_sock();
+	if (!sock)
+		return;
+
+	for (;;) {
+		while ((sb=sb_dequeue())) {
+			m = sb->mesg;
+			if (ip_vs_send_async(sock, (char *)m,
+					     m->size) != m->size)
+				IP_VS_ERR("ip_vs_send_async error\n");
+			ip_vs_sync_buff_release(sb);
+		}
+
+		/* check if entries stay in curr_sb for 2 seconds */
+		if ((sb = get_curr_sync_buff(2*HZ))) {
+			m = sb->mesg;
+			if (ip_vs_send_async(sock, (char *)m,
+					     m->size) != m->size)
+				IP_VS_ERR("ip_vs_send_async error\n");
+			ip_vs_sync_buff_release(sb);
+		}
+
+		if (stop_sync)
+			break;
+
+		__set_current_state(TASK_INTERRUPTIBLE);
+		schedule_timeout(HZ);
+		__set_current_state(TASK_RUNNING);
+	}
+
+	/* clean up the sync_buff queue */
+	while ((sb=sb_dequeue())) {
+		ip_vs_sync_buff_release(sb);
+	}
+
+	/* clean up the current sync_buff */
+	if ((sb = get_curr_sync_buff(0))) {
+		ip_vs_sync_buff_release(sb);
+	}
+
+	/* release the sending multicast socket */
+	sock_release(sock);
+}
+
+
+static void sync_backup_loop(void)
+{
+	struct socket *sock;
+	char *buf;
+	int len;
+
+	if (!(buf=kmalloc(SYNC_MESG_MAX_SIZE, GFP_ATOMIC))) {
+		IP_VS_ERR("sync_backup_loop: kmalloc error\n");
+		return;
+	}
+
+	/* create the receiving multicast socket */
+	sock = make_receive_sock();
+	if (!sock)
+		goto out;
+
+	for (;;) {
+		/* do you have data now? */
+		while (!skb_queue_empty(&(sock->sk->receive_queue))) {
+			if ((len=ip_vs_receive(sock, buf,
+					       SYNC_MESG_MAX_SIZE))<=0) {
+				IP_VS_ERR("receiving message error\n");
+				break;
+			}
+			/* disable bottom half, because it accessed the data
+			   shared by softirq while getting/creating conns */
+			local_bh_disable();
+			ip_vs_process_message(buf, len);
+			local_bh_enable();
+		}
+
+		if (stop_sync)
+			break;
+
+		__set_current_state(TASK_INTERRUPTIBLE);
+		schedule_timeout(HZ);
+		__set_current_state(TASK_RUNNING);
+	}
+
+	/* release the sending multicast socket */
+	sock_release(sock);
+
+  out:
+	kfree(buf);
+}
+
+
+static int sync_thread(void *startup)
+{
+	DECLARE_WAITQUEUE(wait, current);
+	mm_segment_t oldmm;
+	int state;
+
+	MOD_INC_USE_COUNT;
+	daemonize();
+
+	oldmm = get_fs();
+	set_fs(KERNEL_DS);
+
+	if (ip_vs_sync_state == IP_VS_STATE_MASTER)
+		sprintf(current->comm, "ipvs syncmaster");
+	else if (ip_vs_sync_state == IP_VS_STATE_BACKUP)
+		sprintf(current->comm, "ipvs syncbackup");
+	else IP_VS_BUG();
+
+	spin_lock_irq(&current->sigmask_lock);
+	siginitsetinv(&current->blocked, 0);
+	recalc_sigpending(current);
+	spin_unlock_irq(&current->sigmask_lock);
+
+	/* set up multicast address */
+	mcast_addr.sin_family = AF_INET;
+	mcast_addr.sin_port = htons(IP_VS_SYNC_PORT);
+	mcast_addr.sin_addr.s_addr = htonl(IP_VS_SYNC_GROUP);
+
+	add_wait_queue(&sync_wait, &wait);
+
+	state = ip_vs_sync_state;
+	sync_pid = current->pid;
+	IP_VS_INFO("sync thread started.\n");
+	complete((struct completion *)startup);
+
+	/* processing master/backup loop here */
+	if (state == IP_VS_STATE_MASTER)
+		sync_master_loop();
+	else if (state == IP_VS_STATE_BACKUP)
+		sync_backup_loop();
+	else IP_VS_BUG();
+
+	remove_wait_queue(&sync_wait, &wait);
+
+	/* thread exits */
+	sync_pid = 0;
+	IP_VS_INFO("sync thread stopped!\n");
+
+	set_fs(oldmm);
+	MOD_DEC_USE_COUNT;
+
+	stop_sync = 0;
+	wake_up(&stop_sync_wait);
+
+	return 0;
+}
+
+
+static int fork_sync_thread(void *startup)
+{
+	/* fork the sync thread here, then the parent process of the
+	   sync thread is the init process after this thread exits. */
+	if (kernel_thread(sync_thread, startup, 0) < 0)
+		IP_VS_BUG();
+	return 0;
+}
+
+
+int start_sync_thread(int state, char *mcast_ifn)
+{
+	DECLARE_COMPLETION(startup);
+	pid_t pid;
+	int waitpid_result;
+
+	if (sync_pid)
+		return -EEXIST;
+
+	IP_VS_DBG(7, "%s: pid %d\n", __FUNCTION__, current->pid);
+	IP_VS_DBG(7, "Each ip_vs_sync_conn entry need %d bytes\n",
+		  sizeof(struct ip_vs_sync_conn));
+
+	ip_vs_sync_state = state;
+	strcpy(ip_vs_mcast_ifn, mcast_ifn);
+
+	if ((pid = kernel_thread(fork_sync_thread, &startup, 0)) < 0)
+		IP_VS_BUG();
+
+	if ((waitpid_result = waitpid(pid, NULL, __WCLONE)) != pid) {
+		IP_VS_ERR("%s: waitpid(%d,...) failed, errno %d\n",
+			  __FUNCTION__, pid, -waitpid_result);
+	}
+
+	wait_for_completion(&startup);
+
+	return 0;
+}
+
+
+int stop_sync_thread(void)
+{
+	DECLARE_WAITQUEUE(wait, current);
+
+	if (!sync_pid)
+		return -ESRCH;
+
+	IP_VS_DBG(7, "%s: pid %d\n", __FUNCTION__, current->pid);
+	IP_VS_INFO("stopping sync thread %d ...\n", sync_pid);
+
+	__set_current_state(TASK_UNINTERRUPTIBLE);
+	add_wait_queue(&stop_sync_wait, &wait);
+	ip_vs_sync_state = IP_VS_STATE_NONE;
+	stop_sync = 1;
+	wake_up(&sync_wait);
+	schedule();
+	__set_current_state(TASK_RUNNING);
+	remove_wait_queue(&stop_sync_wait, &wait);
+
+	/* Note: no need to reap the sync thread, because its parent
+	   process is the init process */
+
+	if (stop_sync)
+		IP_VS_BUG();
+
+	return 0;
+}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_wlc.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_wlc.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_wlc.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_wlc.c	2003-08-27 14:41:52.000000000 +0000
@@ -0,0 +1,157 @@
+/*
+ * IPVS:        Weighted Least-Connection Scheduling module
+ *
+ * Version:     $Id: ip_vs_wlc.c,v 1.10.2.1 2003/04/11 14:02:35 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *              Peter Kese <peter.kese@ijs.si>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *     Wensong Zhang            :     changed the ip_vs_wlc_schedule to return dest
+ *     Wensong Zhang            :     changed to use the inactconns in scheduling
+ *     Wensong Zhang            :     changed some comestics things for debugging
+ *     Wensong Zhang            :     changed for the d-linked destination list
+ *     Wensong Zhang            :     added the ip_vs_wlc_update_svc
+ *     Wensong Zhang            :     added any dest with weight=0 is quiesced
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+
+#include <net/ip_vs.h>
+
+
+static int
+ip_vs_wlc_init_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static int
+ip_vs_wlc_done_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static int
+ip_vs_wlc_update_svc(struct ip_vs_service *svc)
+{
+	return 0;
+}
+
+
+static inline unsigned int
+ip_vs_wlc_dest_overhead(struct ip_vs_dest *dest)
+{
+	/*
+	 * We think the overhead of processing active connections is 256
+	 * times higher than that of inactive connections in average. (This
+	 * 256 times might not be accurate, we will change it later) We
+	 * use the following formula to estimate the overhead now:
+	 *		  dest->activeconns*256 + dest->inactconns
+	 */
+	return (atomic_read(&dest->activeconns) << 8) +
+		atomic_read(&dest->inactconns);
+}
+
+
+/*
+ *    Weighted Least Connection scheduling
+ */
+static struct ip_vs_dest *
+ip_vs_wlc_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	register struct list_head *l, *e;
+	struct ip_vs_dest *dest, *least;
+	unsigned int loh, doh;
+
+	IP_VS_DBG(6, "ip_vs_wlc_schedule(): Scheduling...\n");
+
+	/*
+	 * We calculate the load of each dest server as follows:
+	 *		  (dest overhead) / dest->weight
+	 *
+	 * Remember -- no floats in kernel mode!!!
+	 * The comparison of h1*w2 > h2*w1 is equivalent to that of
+	 *		  h1/w1 > h2/w2
+	 * if every weight is larger than zero.
+	 *
+	 * The server with weight=0 is quiesced and will not receive any
+	 * new connections.
+	 */
+
+	l = &svc->destinations;
+	for (e=l->next; e!=l; e=e->next) {
+		least = list_entry(e, struct ip_vs_dest, n_list);
+		if (atomic_read(&least->weight) > 0) {
+			loh = ip_vs_wlc_dest_overhead(least);
+			goto nextstage;
+		}
+	}
+	return NULL;
+
+	/*
+	 *    Find the destination with the least load.
+	 */
+  nextstage:
+	for (e=e->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+
+		doh = ip_vs_wlc_dest_overhead(dest);
+		if (loh * atomic_read(&dest->weight) >
+		    doh * atomic_read(&least->weight)) {
+			least = dest;
+			loh = doh;
+		}
+	}
+
+	IP_VS_DBG(6, "WLC: server %u.%u.%u.%u:%u "
+		  "activeconns %d refcnt %d weight %d overhead %d\n",
+		  NIPQUAD(least->addr), ntohs(least->port),
+		  atomic_read(&least->activeconns),
+		  atomic_read(&least->refcnt),
+		  atomic_read(&least->weight), loh);
+
+	return least;
+}
+
+
+static struct ip_vs_scheduler ip_vs_wlc_scheduler =
+{
+	{0},			/* n_list */
+	"wlc",			/* name */
+	ATOMIC_INIT(0),         /* refcnt */
+	THIS_MODULE,		/* this module */
+	ip_vs_wlc_init_svc,	/* service initializer */
+	ip_vs_wlc_done_svc,	/* service done */
+	ip_vs_wlc_update_svc,	/* service updater */
+	ip_vs_wlc_schedule,	/* select a server from the destination list */
+};
+
+
+static int __init ip_vs_wlc_init(void)
+{
+	INIT_LIST_HEAD(&ip_vs_wlc_scheduler.n_list);
+	return register_ip_vs_scheduler(&ip_vs_wlc_scheduler);
+}
+
+static void __exit ip_vs_wlc_cleanup(void)
+{
+	unregister_ip_vs_scheduler(&ip_vs_wlc_scheduler);
+}
+
+module_init(ip_vs_wlc_init);
+module_exit(ip_vs_wlc_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/ipvs/ip_vs_wrr.c linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_wrr.c
--- linux-2.4.22/net/ipv4/ipvs/ip_vs_wrr.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/ipvs/ip_vs_wrr.c	2003-08-27 14:41:24.000000000 +0000
@@ -0,0 +1,240 @@
+/*
+ * IPVS:        Weighted Round-Robin Scheduling module
+ *
+ * Version:     $Id: ip_vs_wrr.c,v 1.11 2002/03/25 12:44:35 wensong Exp $
+ *
+ * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *     Wensong Zhang            :     changed the ip_vs_wrr_schedule to return dest
+ *     Wensong Zhang            :     changed some comestics things for debugging
+ *     Wensong Zhang            :     changed for the d-linked destination list
+ *     Wensong Zhang            :     added the ip_vs_wrr_update_svc
+ *     Julian Anastasov         :     fixed the bug of returning destination
+ *                                    with weight 0 when all weights are zero
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+
+#include <net/ip_vs.h>
+
+/*
+ * current destination pointer for weighted round-robin scheduling
+ */
+struct ip_vs_wrr_mark {
+	struct list_head *cl;	/* current list head */
+	int cw;			/* current weight */
+	int mw;			/* maximum weight */
+	int di;			/* decreasing interval */
+};
+
+
+/*
+ *    Get the gcd of server weights
+ */
+static int gcd(int a, int b)
+{
+	int c;
+
+	while ((c = a % b)) {
+		a = b;
+		b = c;
+	}
+	return b;
+}
+
+static int ip_vs_wrr_gcd_weight(struct ip_vs_service *svc)
+{
+	register struct list_head *l, *e;
+	struct ip_vs_dest *dest;
+	int weight;
+	int g = 1;
+
+	l = &svc->destinations;
+	for (e=l->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+		weight = atomic_read(&dest->weight);
+		if (weight > 0) {
+			g = weight;
+			break;
+		}
+	}
+	if (e == l)
+		return g;
+
+	for (e=e->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+		weight = atomic_read(&dest->weight);
+		if (weight > 0)
+			g = gcd(weight, g);
+	}
+
+	return g;
+}
+
+
+/*
+ *    Get the maximum weight of the service destinations.
+ */
+static int ip_vs_wrr_max_weight(struct ip_vs_service *svc)
+{
+	register struct list_head *l, *e;
+	struct ip_vs_dest *dest;
+	int weight = 0;
+
+	l = &svc->destinations;
+	for (e=l->next; e!=l; e=e->next) {
+		dest = list_entry(e, struct ip_vs_dest, n_list);
+		if (atomic_read(&dest->weight) > weight)
+			weight = atomic_read(&dest->weight);
+	}
+
+	return weight;
+}
+
+
+static int ip_vs_wrr_init_svc(struct ip_vs_service *svc)
+{
+	struct ip_vs_wrr_mark *mark;
+
+	/*
+	 *    Allocate the mark variable for WRR scheduling
+	 */
+	mark = kmalloc(sizeof(struct ip_vs_wrr_mark), GFP_ATOMIC);
+	if (mark == NULL) {
+		IP_VS_ERR("ip_vs_wrr_init_svc(): no memory\n");
+		return -ENOMEM;
+	}
+	mark->cl = &svc->destinations;
+	mark->cw = 0;
+	mark->mw = ip_vs_wrr_max_weight(svc);
+	mark->di = ip_vs_wrr_gcd_weight(svc);
+	svc->sched_data = mark;
+
+	return 0;
+}
+
+
+static int ip_vs_wrr_done_svc(struct ip_vs_service *svc)
+{
+	/*
+	 *    Release the mark variable
+	 */
+	kfree(svc->sched_data);
+
+	return 0;
+}
+
+
+static int ip_vs_wrr_update_svc(struct ip_vs_service *svc)
+{
+	struct ip_vs_wrr_mark *mark = svc->sched_data;
+
+	mark->cl = &svc->destinations;
+	mark->mw = ip_vs_wrr_max_weight(svc);
+	mark->di = ip_vs_wrr_gcd_weight(svc);
+	return 0;
+}
+
+
+/*
+ *    Weighted Round-Robin Scheduling
+ */
+static struct ip_vs_dest *
+ip_vs_wrr_schedule(struct ip_vs_service *svc, struct iphdr *iph)
+{
+	struct ip_vs_dest *dest;
+	struct ip_vs_wrr_mark *mark = svc->sched_data;
+
+	IP_VS_DBG(6, "ip_vs_wrr_schedule(): Scheduling...\n");
+
+	/*
+	 * This loop will always terminate, because 0<mark->cw<max_weight,
+	 * and at least one server has its weight equal to max_weight.
+	 */
+	write_lock(&svc->sched_lock);
+	while (1) {
+		if (mark->cl == &svc->destinations) {
+			/* it is at the head of the destination list */
+
+			if (mark->cl == mark->cl->next) {
+				/* no dest entry */
+				write_unlock(&svc->sched_lock);
+				return NULL;
+			}
+
+			mark->cl = svc->destinations.next;
+			mark->cw -= mark->di;
+			if (mark->cw <= 0) {
+				mark->cw = mark->mw;
+				/*
+				 * Still zero, which means no availabe servers.
+				 */
+				if (mark->cw == 0) {
+					mark->cl = &svc->destinations;
+					write_unlock(&svc->sched_lock);
+					IP_VS_INFO("ip_vs_wrr_schedule(): "
+						   "no available servers\n");
+					return NULL;
+				}
+			}
+		}
+		else mark->cl = mark->cl->next;
+
+		if (mark->cl != &svc->destinations) {
+			/* not at the head of the list */
+			dest = list_entry(mark->cl, struct ip_vs_dest, n_list);
+			if (atomic_read(&dest->weight) >= mark->cw) {
+				write_unlock(&svc->sched_lock);
+				break;
+			}
+		}
+	}
+
+	IP_VS_DBG(6, "WRR: server %u.%u.%u.%u:%u "
+		  "activeconns %d refcnt %d weight %d\n",
+		  NIPQUAD(dest->addr), ntohs(dest->port),
+		  atomic_read(&dest->activeconns),
+		  atomic_read(&dest->refcnt),
+		  atomic_read(&dest->weight));
+
+	return	dest;
+}
+
+
+static struct ip_vs_scheduler ip_vs_wrr_scheduler = {
+	{0},			/* n_list */
+	"wrr",			/* name */
+	ATOMIC_INIT(0),		/* refcnt */
+	THIS_MODULE,		/* this module */
+	ip_vs_wrr_init_svc,	/* service initializer */
+	ip_vs_wrr_done_svc,	/* service done */
+	ip_vs_wrr_update_svc,	/* service updater */
+	ip_vs_wrr_schedule,	/* select a server from the destination list */
+};
+
+static int __init ip_vs_wrr_init(void)
+{
+	INIT_LIST_HEAD(&ip_vs_wrr_scheduler.n_list);
+	return register_ip_vs_scheduler(&ip_vs_wrr_scheduler) ;
+}
+
+static void __exit ip_vs_wrr_cleanup(void)
+{
+	unregister_ip_vs_scheduler(&ip_vs_wrr_scheduler);
+}
+
+module_init(ip_vs_wrr_init);
+module_exit(ip_vs_wrr_cleanup);
+MODULE_LICENSE("GPL");
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/netfilter/ip_conntrack_core.c linux-2.4.23-pre1/net/ipv4/netfilter/ip_conntrack_core.c
--- linux-2.4.22/net/ipv4/netfilter/ip_conntrack_core.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/netfilter/ip_conntrack_core.c	2003-08-27 14:39:12.000000000 +0000
@@ -291,14 +291,15 @@
 static void
 clean_from_lists(struct ip_conntrack *ct)
 {
+	unsigned int ho, hr;
+	
 	DEBUGP("clean_from_lists(%p)\n", ct);
 	MUST_BE_WRITE_LOCKED(&ip_conntrack_lock);
-	LIST_DELETE(&ip_conntrack_hash
-		    [hash_conntrack(&ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple)],
-		    &ct->tuplehash[IP_CT_DIR_ORIGINAL]);
-	LIST_DELETE(&ip_conntrack_hash
-		    [hash_conntrack(&ct->tuplehash[IP_CT_DIR_REPLY].tuple)],
-		    &ct->tuplehash[IP_CT_DIR_REPLY]);
+
+	ho = hash_conntrack(&ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple);
+	hr = hash_conntrack(&ct->tuplehash[IP_CT_DIR_REPLY].tuple);
+	LIST_DELETE(&ip_conntrack_hash[ho], &ct->tuplehash[IP_CT_DIR_ORIGINAL]);
+	LIST_DELETE(&ip_conntrack_hash[hr], &ct->tuplehash[IP_CT_DIR_REPLY]);
 
 	/* Destroy all un-established, pending expectations */
 	remove_expectations(ct, 1);
@@ -370,9 +371,10 @@
 		    const struct ip_conntrack *ignored_conntrack)
 {
 	struct ip_conntrack_tuple_hash *h;
+	unsigned int hash = hash_conntrack(tuple);
 
 	MUST_BE_READ_LOCKED(&ip_conntrack_lock);
-	h = LIST_FIND(&ip_conntrack_hash[hash_conntrack(tuple)],
+	h = LIST_FIND(&ip_conntrack_hash[hash],
 		      conntrack_tuple_cmp,
 		      struct ip_conntrack_tuple_hash *,
 		      tuple, ignored_conntrack);
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/netfilter/ip_fw_compat.c linux-2.4.23-pre1/net/ipv4/netfilter/ip_fw_compat.c
--- linux-2.4.22/net/ipv4/netfilter/ip_fw_compat.c	2001-12-21 17:42:05.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/netfilter/ip_fw_compat.c	2003-08-27 14:40:18.000000000 +0000
@@ -47,6 +47,12 @@
 extern int __init masq_init(void);
 extern void masq_cleanup(void);
 
+#ifdef CONFIG_IP_VS
+/* From ip_vs_core.c */
+extern unsigned int
+check_for_ip_vs_out(struct sk_buff **skb_p, int (*okfn)(struct sk_buff *));
+#endif
+
 /* They call these; we do what they want. */
 int register_firewall(int pf, struct firewall_ops *fw)
 {
@@ -172,8 +178,14 @@
 		return NF_ACCEPT;
 
 	case FW_MASQUERADE:
-		if (hooknum == NF_IP_FORWARD)
+		if (hooknum == NF_IP_FORWARD) {
+#ifdef CONFIG_IP_VS
+                        /* check if it is for ip_vs */
+                        if (check_for_ip_vs_out(pskb, okfn) == NF_STOLEN)
+                                return NF_STOLEN;
+#endif
 			return do_masquerade(pskb, out);
+                }
 		else return NF_ACCEPT;
 
 	case FW_REDIRECT:
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/netfilter/ip_nat_core.c linux-2.4.23-pre1/net/ipv4/netfilter/ip_nat_core.c
--- linux-2.4.22/net/ipv4/netfilter/ip_nat_core.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/netfilter/ip_nat_core.c	2003-08-27 14:39:36.000000000 +0000
@@ -67,6 +67,7 @@
 static void ip_nat_cleanup_conntrack(struct ip_conntrack *conn)
 {
 	struct ip_nat_info *info = &conn->nat.info;
+	unsigned int hs, hp;
 
 	if (!info->initialized)
 		return;
@@ -74,21 +75,18 @@
 	IP_NF_ASSERT(info->bysource.conntrack);
 	IP_NF_ASSERT(info->byipsproto.conntrack);
 
+	hs = hash_by_src(&conn->tuplehash[IP_CT_DIR_ORIGINAL].tuple.src,
+	                 conn->tuplehash[IP_CT_DIR_ORIGINAL]
+	                 .tuple.dst.protonum);
+
+	hp = hash_by_ipsproto(conn->tuplehash[IP_CT_DIR_REPLY].tuple.src.ip,
+	                      conn->tuplehash[IP_CT_DIR_REPLY].tuple.dst.ip,
+	                      conn->tuplehash[IP_CT_DIR_REPLY]
+	                      .tuple.dst.protonum);
+
 	WRITE_LOCK(&ip_nat_lock);
-	LIST_DELETE(&bysource[hash_by_src(&conn->tuplehash[IP_CT_DIR_ORIGINAL]
-					  .tuple.src,
-					  conn->tuplehash[IP_CT_DIR_ORIGINAL]
-					  .tuple.dst.protonum)],
-		    &info->bysource);
-
-	LIST_DELETE(&byipsproto
-		    [hash_by_ipsproto(conn->tuplehash[IP_CT_DIR_REPLY]
-				      .tuple.src.ip,
-				      conn->tuplehash[IP_CT_DIR_REPLY]
-				      .tuple.dst.ip,
-				      conn->tuplehash[IP_CT_DIR_REPLY]
-				      .tuple.dst.protonum)],
-		    &info->byipsproto);
+	LIST_DELETE(&bysource[hs], &info->bysource);
+	LIST_DELETE(&byipsproto[hp], &info->byipsproto);
 	WRITE_UNLOCK(&ip_nat_lock);
 }
 
@@ -244,11 +242,12 @@
 	   const struct ip_conntrack *conntrack)
 {
 	unsigned int score = 0;
+	unsigned int h;
 
 	MUST_BE_READ_LOCKED(&ip_nat_lock);
-	LIST_FIND(&byipsproto[hash_by_ipsproto(src, dst, protonum)],
-		  fake_cmp, struct ip_nat_hash *, src, dst, protonum, &score,
-		  conntrack);
+	h = hash_by_ipsproto(src, dst, protonum);
+	LIST_FIND(&byipsproto[h], fake_cmp, struct ip_nat_hash *,
+	          src, dst, protonum, &score, conntrack);
 
 	return score;
 }
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/netfilter/ip_nat_tftp.c linux-2.4.23-pre1/net/ipv4/netfilter/ip_nat_tftp.c
--- linux-2.4.22/net/ipv4/netfilter/ip_nat_tftp.c	2003-06-13 14:51:39.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/netfilter/ip_nat_tftp.c	2003-08-27 14:39:25.000000000 +0000
@@ -153,7 +153,7 @@
 
 static int __init init(void)
 {
-	int i, ret;
+	int i, ret = 0;
 	char *tmpname;
 
 	if (!ports[0])
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/netfilter/ipt_LOG.c linux-2.4.23-pre1/net/ipv4/netfilter/ipt_LOG.c
--- linux-2.4.22/net/ipv4/netfilter/ipt_LOG.c	2002-02-25 19:38:14.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/netfilter/ipt_LOG.c	2003-08-27 14:40:01.000000000 +0000
@@ -3,15 +3,14 @@
  */
 #include <linux/module.h>
 #include <linux/skbuff.h>
-#include <linux/ip.h>
 #include <linux/spinlock.h>
+#include <linux/ip.h>
 #include <net/icmp.h>
 #include <net/udp.h>
 #include <net/tcp.h>
-#include <linux/netfilter_ipv4/ip_tables.h>
-
-struct in_device;
 #include <net/route.h>
+
+#include <linux/netfilter_ipv4/ip_tables.h>
 #include <linux/netfilter_ipv4/ipt_LOG.h>
 
 #if 0
@@ -20,10 +19,20 @@
 #define DEBUGP(format, args...)
 #endif
 
+/* FIXME: move to ip.h like in 2.5 */
+struct ahhdr {
+	__u8    nexthdr;
+	__u8    hdrlen;
+	__u16   reserved;
+	__u32   spi;
+	__u32   seq_no;
+};
+
 struct esphdr {
 	__u32   spi;
-}; /* FIXME evil kludge */
-        
+	__u32   seq_no;
+};
+
 /* Use lock to serialize, so printks don't overlap */
 static spinlock_t log_lock = SPIN_LOCK_UNLOCKED;
 
@@ -58,7 +67,8 @@
 		printk("FRAG:%u ", ntohs(iph->frag_off) & IP_OFFSET);
 
 	if ((info->logflags & IPT_LOG_IPOPT)
-	    && iph->ihl * 4 != sizeof(struct iphdr)) {
+	    && iph->ihl * 4 != sizeof(struct iphdr)
+	    && iph->ihl * 4 >= datalen) {
 		unsigned int i;
 
 		/* Max length: 127 "OPT (" 15*4*2chars ") " */
@@ -230,13 +240,30 @@
 		break;
 	}
 	/* Max Length */
-	case IPPROTO_AH:
+	case IPPROTO_AH: {
+		struct ahhdr *ah = protoh;
+
+		/* Max length: 9 "PROTO=AH " */
+		printk("PROTO=AH ");
+
+		if (ntohs(iph->frag_off) & IP_OFFSET)
+			break;
+
+		/* Max length: 25 "INCOMPLETE [65535 bytes] " */
+		if (datalen < sizeof (*ah)) {
+			printk("INCOMPLETE [%u bytes] ", datalen);
+			break;
+		}
+
+		/* Length: 15 "SPI=0xF1234567 " */
+		printk("SPI=0x%x ", ntohl(ah->spi) );
+		break;
+	}
 	case IPPROTO_ESP: {
 		struct esphdr *esph = protoh;
-		int esp= (iph->protocol==IPPROTO_ESP);
 
 		/* Max length: 10 "PROTO=ESP " */
-		printk("PROTO=%s ",esp? "ESP" : "AH");
+		printk("PROTO=ESP ");
 
 		if (ntohs(iph->frag_off) & IP_OFFSET)
 			break;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/netfilter/ipt_MASQUERADE.c linux-2.4.23-pre1/net/ipv4/netfilter/ipt_MASQUERADE.c
--- linux-2.4.22/net/ipv4/netfilter/ipt_MASQUERADE.c	2001-09-30 19:26:08.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/netfilter/ipt_MASQUERADE.c	2003-08-27 14:39:21.000000000 +0000
@@ -87,13 +87,20 @@
 	key.dst = (*pskb)->nh.iph->daddr;
 	key.src = 0; /* Unknown: that's what we're trying to establish */
 	key.tos = RT_TOS((*pskb)->nh.iph->tos)|RTO_CONN;
-	key.oif = out->ifindex;
 #ifdef CONFIG_IP_ROUTE_FWMARK
 	key.fwmark = (*pskb)->nfmark;
 #endif
 	if (ip_route_output_key(&rt, &key) != 0) {
-		/* Shouldn't happen */
-		printk("MASQUERADE: No route: Rusty's brain broke!\n");
+                /* Funky routing can do this. */
+                if (net_ratelimit())
+                        printk("MASQUERADE:"
+                               " No route: Rusty's brain broke!\n");
+                return NF_DROP;
+        }
+        if (rt->u.dst.dev != out) {
+                if (net_ratelimit())
+                        printk("MASQUERADE:"
+                               " Route sent us somewhere else.\n");
 		return NF_DROP;
 	}
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/netfilter/ipt_ah.c linux-2.4.23-pre1/net/ipv4/netfilter/ipt_ah.c
--- linux-2.4.22/net/ipv4/netfilter/ipt_ah.c	2002-11-28 23:53:15.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/netfilter/ipt_ah.c	2003-08-27 14:41:12.000000000 +0000
@@ -15,7 +15,11 @@
 #endif
 
 struct ahhdr {
+	__u8    nexthdr;
+	__u8    hdrlen;
+	__u16   reserved;
 	__u32   spi;
+	__u32   seq_no;
 };
 
 /* Returns 1 if the spi is matched by the range, 0 otherwise */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/netfilter/ipt_esp.c linux-2.4.23-pre1/net/ipv4/netfilter/ipt_esp.c
--- linux-2.4.22/net/ipv4/netfilter/ipt_esp.c	2002-02-25 19:38:14.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/netfilter/ipt_esp.c	2003-08-27 14:39:20.000000000 +0000
@@ -16,6 +16,7 @@
 
 struct esphdr {
 	__u32   spi;
+	__u32   seq_no;
 };
 
 /* Returns 1 if the spi is matched by the range, 0 otherwise */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv4/route.c linux-2.4.23-pre1/net/ipv4/route.c
--- linux-2.4.22/net/ipv4/route.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv4/route.c	2003-08-27 14:41:54.000000000 +0000
@@ -375,7 +375,9 @@
  */
 static inline u32 rt_score(struct rtable *rt)
 {
-	u32 score = rt->u.dst.__use;
+	u32 score = jiffies - rt->u.dst.lastuse;
+
+	score = ~score & ~(3<<30);
 
 	if (rt_valuable(rt))
 		score |= (1<<31);
@@ -703,8 +705,7 @@
 		 * The second limit is less certain. At the moment it allows
 		 * only 2 entries per bucket. We will see.
 		 */
-		if (chain_length > ip_rt_gc_elasticity ||
-		    (chain_length > 1 && !(min_score & (1<<31)))) {
+		if (chain_length > ip_rt_gc_elasticity) {
 			*candp = cand->u.rt_next;
 			rt_free(cand);
 		}
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv6/addrconf.c linux-2.4.23-pre1/net/ipv6/addrconf.c
--- linux-2.4.22/net/ipv6/addrconf.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv6/addrconf.c	2003-08-27 14:41:43.000000000 +0000
@@ -103,7 +103,7 @@
 
 static int addrconf_ifdown(struct net_device *dev, int how);
 
-static void addrconf_dad_start(struct inet6_ifaddr *ifp);
+static void addrconf_dad_start(struct inet6_ifaddr *ifp, int flags);
 static void addrconf_dad_timer(unsigned long data);
 static void addrconf_dad_completed(struct inet6_ifaddr *ifp);
 static void addrconf_rs_timer(unsigned long data);
@@ -898,7 +898,7 @@
 	rtmsg.rtmsg_dst_len = 8;
 	rtmsg.rtmsg_metric = IP6_RT_PRIO_ADDRCONF;
 	rtmsg.rtmsg_ifindex = dev->ifindex;
-	rtmsg.rtmsg_flags = RTF_UP|RTF_ADDRCONF;
+	rtmsg.rtmsg_flags = RTF_UP;
 	rtmsg.rtmsg_type = RTMSG_NEWROUTE;
 	ip6_route_add(&rtmsg, NULL);
 }
@@ -925,7 +925,7 @@
 	struct in6_addr addr;
 
 	ipv6_addr_set(&addr,  htonl(0xFE800000), 0, 0, 0);
-	addrconf_prefix_route(&addr, 64, dev, 0, RTF_ADDRCONF);
+	addrconf_prefix_route(&addr, 64, dev, 0, 0);
 }
 
 static struct inet6_dev *addrconf_add_dev(struct net_device *dev)
@@ -1017,7 +1017,7 @@
 		}
 	} else if (pinfo->onlink && valid_lft) {
 		addrconf_prefix_route(&pinfo->prefix, pinfo->prefix_len,
-				      dev, rt_expires, RTF_ADDRCONF|RTF_EXPIRES);
+				      dev, rt_expires, RTF_ADDRCONF|RTF_EXPIRES|RTF_PREFIX_RT);
 	}
 	if (rt)
 		dst_release(&rt->u.dst);
@@ -1063,7 +1063,7 @@
 				return;
 			}
 
-			addrconf_dad_start(ifp);
+			addrconf_dad_start(ifp, RTF_ADDRCONF|RTF_PREFIX_RT);
 		}
 
 		if (ifp && valid_lft == 0) {
@@ -1175,7 +1175,7 @@
 
 	ifp = ipv6_add_addr(idev, pfx, plen, scope, IFA_F_PERMANENT);
 	if (!IS_ERR(ifp)) {
-		addrconf_dad_start(ifp);
+		addrconf_dad_start(ifp, 0);
 		in6_ifa_put(ifp);
 		return 0;
 	}
@@ -1350,7 +1350,7 @@
 
 	ifp = ipv6_add_addr(idev, addr, 64, IFA_LINK, IFA_F_PERMANENT);
 	if (!IS_ERR(ifp)) {
-		addrconf_dad_start(ifp);
+		addrconf_dad_start(ifp, 0);
 		in6_ifa_put(ifp);
 	}
 }
@@ -1588,8 +1588,7 @@
 		memset(&rtmsg, 0, sizeof(struct in6_rtmsg));
 		rtmsg.rtmsg_type = RTMSG_NEWROUTE;
 		rtmsg.rtmsg_metric = IP6_RT_PRIO_ADDRCONF;
-		rtmsg.rtmsg_flags = (RTF_ALLONLINK | RTF_ADDRCONF | 
-				     RTF_DEFAULT | RTF_UP);
+		rtmsg.rtmsg_flags = (RTF_ALLONLINK | RTF_DEFAULT | RTF_UP);
 
 		rtmsg.rtmsg_ifindex = ifp->idev->dev->ifindex;
 
@@ -1603,7 +1602,7 @@
 /*
  *	Duplicate Address Detection
  */
-static void addrconf_dad_start(struct inet6_ifaddr *ifp)
+static void addrconf_dad_start(struct inet6_ifaddr *ifp, int flags)
 {
 	struct net_device *dev;
 	unsigned long rand_num;
@@ -1613,7 +1612,7 @@
 	addrconf_join_solict(dev, &ifp->addr);
 
 	if (ifp->prefix_len != 128 && (ifp->flags&IFA_F_PERMANENT))
-		addrconf_prefix_route(&ifp->addr, ifp->prefix_len, dev, 0, RTF_ADDRCONF);
+		addrconf_prefix_route(&ifp->addr, ifp->prefix_len, dev, 0, flags);
 
 	net_srandom(ifp->addr.s6_addr32[3]);
 	rand_num = net_random() % (ifp->idev->cnf.rtr_solicit_delay ? : 1);
@@ -1895,6 +1894,7 @@
 	unsigned char	 *b = skb->tail;
 
 	nlh = NLMSG_PUT(skb, pid, seq, event, sizeof(*ifm));
+	if (pid) nlh->nlmsg_flags |= NLM_F_MULTI;
 	ifm = NLMSG_DATA(nlh);
 	ifm->ifa_family = AF_INET6;
 	ifm->ifa_prefixlen = ifa->prefix_len;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv6/ndisc.c linux-2.4.23-pre1/net/ipv6/ndisc.c
--- linux-2.4.22/net/ipv6/ndisc.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv6/ndisc.c	2003-08-27 14:39:16.000000000 +0000
@@ -1336,6 +1336,26 @@
 	return 0;
 }
 
+static int ndisc_netdev_event(struct notifier_block *this, unsigned long event, void *ptr)
+{
+	struct net_device *dev = ptr;
+
+	switch (event) {
+	case NETDEV_CHANGEADDR:
+		neigh_changeaddr(&nd_tbl, dev);
+		fib6_run_gc(0);
+		break;
+	default:
+		break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+struct notifier_block ndisc_netdev_notifier = {
+	.notifier_call = ndisc_netdev_event,
+};
+
 int __init ndisc_init(struct net_proto_family *ops)
 {
 	struct sock *sk;
@@ -1377,6 +1397,7 @@
 	neigh_sysctl_register(NULL, &nd_tbl.parms, NET_IPV6, NET_IPV6_NEIGH, "ipv6");
 #endif
 
+	register_netdevice_notifier(&ndisc_netdev_notifier);
 	return 0;
 }
 
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv6/raw.c linux-2.4.23-pre1/net/ipv6/raw.c
--- linux-2.4.22/net/ipv6/raw.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv6/raw.c	2003-08-27 14:40:19.000000000 +0000
@@ -771,6 +771,7 @@
 			val = -1;
 		else
 			val = opt->offset;
+		break;
 
 	default:
 		return -ENOPROTOOPT;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/ipv6/route.c linux-2.4.23-pre1/net/ipv6/route.c
--- linux-2.4.22/net/ipv6/route.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/ipv6/route.c	2003-08-27 14:39:45.000000000 +0000
@@ -1580,13 +1580,19 @@
 			 struct in6_addr *src,
 			 int iif,
 			 int type, u32 pid, u32 seq,
-			 struct nlmsghdr *in_nlh)
+			 struct nlmsghdr *in_nlh, int prefix)
 {
 	struct rtmsg *rtm;
 	struct nlmsghdr  *nlh;
 	unsigned char	 *b = skb->tail;
 	struct rta_cacheinfo ci;
 
+	if (prefix) {	/* user wants prefix routes only */
+		if (!(rt->rt6i_flags & RTF_PREFIX_RT)) {
+			/* success since this is not a prefix route */
+			return 1;
+		}
+	}
 	if (!pid && in_nlh) {
 		pid = in_nlh->nlmsg_pid;
 	}
@@ -1667,10 +1673,17 @@
 static int rt6_dump_route(struct rt6_info *rt, void *p_arg)
 {
 	struct rt6_rtnl_dump_arg *arg = (struct rt6_rtnl_dump_arg *) p_arg;
+	struct rtmsg *rtm;
+	int prefix;
+
+	rtm = NLMSG_DATA(arg->cb->nlh);
+	if (rtm)
+		prefix = (rtm->rtm_flags & RTM_F_PREFIX) != 0;
+	else prefix = 0;
 
 	return rt6_fill_node(arg->skb, rt, NULL, NULL, 0, RTM_NEWROUTE,
 		     NETLINK_CB(arg->cb->skb).pid, arg->cb->nlh->nlmsg_seq,
-		     NULL);
+		     NULL, prefix);
 }
 
 static int fib6_dump_node(struct fib6_walker_t *w)
@@ -1821,7 +1834,7 @@
 			    fl.nl_u.ip6_u.saddr,
 			    iif,
 			    RTM_NEWROUTE, NETLINK_CB(in_skb).pid,
-			    nlh->nlmsg_seq, nlh);
+			    nlh->nlmsg_seq, nlh, 0);
 	if (err < 0) {
 		err = -EMSGSIZE;
 		goto out_free;
@@ -1847,7 +1860,7 @@
 		netlink_set_err(rtnl, 0, RTMGRP_IPV6_ROUTE, ENOBUFS);
 		return;
 	}
-	if (rt6_fill_node(skb, rt, NULL, NULL, 0, event, 0, 0, nlh) < 0) {
+	if (rt6_fill_node(skb, rt, NULL, NULL, 0, event, 0, 0, nlh, 0) < 0) {
 		kfree_skb(skb);
 		netlink_set_err(rtnl, 0, RTMGRP_IPV6_ROUTE, EINVAL);
 		return;
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/netsyms.c linux-2.4.23-pre1/net/netsyms.c
--- linux-2.4.22/net/netsyms.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/netsyms.c	2003-08-27 14:40:20.000000000 +0000
@@ -18,6 +18,7 @@
 #include <linux/fcdevice.h>
 #include <linux/ioport.h>
 #include <linux/tty.h>
+#include <linux/ethtool.h>
 #include <net/neighbour.h>
 #include <net/snmp.h>
 #include <net/dst.h>
@@ -193,6 +194,7 @@
 EXPORT_SYMBOL(neigh_parms_release);
 EXPORT_SYMBOL(neigh_rand_reach_time);
 EXPORT_SYMBOL(neigh_compat_output); 
+EXPORT_SYMBOL(neigh_changeaddr);
 
 /*	dst_entry	*/
 EXPORT_SYMBOL(dst_alloc);
@@ -265,6 +267,7 @@
 EXPORT_SYMBOL(in_aton);
 EXPORT_SYMBOL(ip_mc_inc_group);
 EXPORT_SYMBOL(ip_mc_dec_group);
+EXPORT_SYMBOL(ip_mc_join_group);
 EXPORT_SYMBOL(ip_finish_output);
 EXPORT_SYMBOL(inet_stream_ops);
 EXPORT_SYMBOL(inet_dgram_ops);
@@ -611,4 +614,10 @@
 EXPORT_SYMBOL(wireless_send_event);
 #endif /* CONFIG_NET_RADIO || CONFIG_NET_PCMCIA_RADIO */
 
+/* ethtool.c */
+EXPORT_SYMBOL(ethtool_op_get_link);
+EXPORT_SYMBOL(ethtool_op_get_tx_csum);
+EXPORT_SYMBOL(ethtool_op_get_sg);
+EXPORT_SYMBOL(ethtool_op_set_sg);
+
 #endif  /* CONFIG_NET */
diff -Naur -X /home/marcelo/lib/dontdiff linux-2.4.22/net/sched/sch_htb.c linux-2.4.23-pre1/net/sched/sch_htb.c
--- linux-2.4.22/net/sched/sch_htb.c	2003-08-25 11:44:44.000000000 +0000
+++ linux-2.4.23-pre1/net/sched/sch_htb.c	2003-08-27 14:39:14.000000000 +0000
@@ -19,9 +19,11 @@
  *			code review and helpful comments on shaping
  *		Tomasz Wrona, <tw@eter.tym.pl>
  *			created test case so that I was able to fix nasty bug
+ *		Wilfried Weissmann
+ *			spotted bug in dequeue code and helped with fix
  *		and many others. thanks.
  *
- * $Id: sch_htb.c,v 1.20 2003/06/18 19:55:49 devik Exp devik $
+ * $Id: sch_htb.c,v 1.24 2003/07/28 15:25:23 devik Exp devik $
  */
 #include <linux/config.h>
 #include <linux/module.h>
@@ -73,7 +75,7 @@
 #define HTB_HYSTERESIS 1/* whether to use mode hysteresis for speedup */
 #define HTB_QLOCK(S) spin_lock_bh(&(S)->dev->queue_lock)
 #define HTB_QUNLOCK(S) spin_unlock_bh(&(S)->dev->queue_lock)
-#define HTB_VER 0x3000c	/* major must be matched with number suplied by TC as version */
+#define HTB_VER 0x3000d	/* major must be matched with number suplied by TC as version */
 
 #if HTB_VER >> 16 != TC_HTB_PROTOVER
 #error "Mismatched sch_htb.c and pkt_sch.h"
@@ -98,7 +100,8 @@
  from LSB
  */
 #ifdef HTB_DEBUG
-#define HTB_DBG(S,L,FMT,ARG...) if (((q->debug>>(2*S))&3) >= L) \
+#define HTB_DBG_COND(S,L) (((q->debug>>(2*S))&3) >= L)
+#define HTB_DBG(S,L,FMT,ARG...) if (HTB_DBG_COND(S,L)) \
 	printk(KERN_DEBUG FMT,##ARG)
 #define HTB_CHCL(cl) BUG_TRAP((cl)->magic == HTB_CMAGIC)
 #define HTB_PASSQ q,
@@ -114,6 +117,7 @@
 		rb_erase(N,R); \
 		(N)->rb_color = -1; } while (0)
 #else
+#define HTB_DBG_COND(S,L) (0)
 #define HTB_DBG(S,L,FMT,ARG...)
 #define HTB_PASSQ
 #define HTB_ARGQ
@@ -454,12 +458,14 @@
 {
 	rb_node_t *p;
 	if ((*n)->rb_right) {
+		/* child at right. use it or its leftmost ancestor */
 		*n = (*n)->rb_right;
 		while ((*n)->rb_left) 
 			*n = (*n)->rb_left;
 		return;
 	}
 	while ((p = (*n)->rb_parent) != NULL) {
+		/* if we've arrived from left child then we have next node */
 		if (p->rb_left == *n) break;
 		*n = p;
 	}
@@ -912,6 +918,7 @@
 		rb_node_t **pptr;
 	} stk[TC_HTB_MAXDEPTH],*sp = stk;
 	
+	BUG_TRAP(tree->rb_node);
 	sp->root = tree->rb_node;
 	sp->pptr = pptr;
 
@@ -945,15 +952,36 @@
 htb_dequeue_tree(struct htb_sched *q,int prio,int level)
 {
 	struct sk_buff *skb = NULL;
-	//struct htb_sched *q = (struct htb_sched *)sch->data;
 	struct htb_class *cl,*start;
 	/* look initial class up in the row */
 	start = cl = htb_lookup_leaf (q->row[level]+prio,prio,q->ptr[level]+prio);
 	
 	do {
-		BUG_TRAP(cl && cl->un.leaf.q->q.qlen); if (!cl) return NULL;
+next:
+		BUG_TRAP(cl); 
+		if (!cl) return NULL;
 		HTB_DBG(4,1,"htb_deq_tr prio=%d lev=%d cl=%X defic=%d\n",
 				prio,level,cl->classid,cl->un.leaf.deficit[level]);
+
+		/* class can be empty - it is unlikely but can be true if leaf
+		   qdisc drops packets in enqueue routine or if someone used
+		   graft operation on the leaf since last dequeue; 
+		   simply deactivate and skip such class */
+		if (unlikely(cl->un.leaf.q->q.qlen == 0)) {
+			struct htb_class *next;
+			htb_deactivate(q,cl);
+
+			/* row/level might become empty */
+			if ((q->row_mask[level] & (1 << prio)) == 0)
+				return NULL; 
+			
+			next = htb_lookup_leaf (q->row[level]+prio,
+					prio,q->ptr[level]+prio);
+			if (cl == start) /* fix start if we just deleted it */
+				start = next;
+			cl = next;
+			goto next;
+		}
 	
 		if (likely((skb = cl->un.leaf.q->dequeue(cl->un.leaf.q)) != NULL)) 
 			break;
@@ -1201,7 +1229,8 @@
 	gopt.direct_pkts = q->direct_pkts;
 
 #ifdef HTB_DEBUG
-	htb_debug_dump(q);
+	if (HTB_DBG_COND(0,2))
+		htb_debug_dump(q);
 #endif
 	gopt.version = HTB_VER;
 	gopt.rate2quantum = q->rate2quantum;
@@ -1282,6 +1311,9 @@
 					return -ENOBUFS;
 		sch_tree_lock(sch);
 		if ((*old = xchg(&cl->un.leaf.q, new)) != NULL) {
+			if (cl->prio_activity)
+				htb_deactivate ((struct htb_sched*)sch->data,cl);
+
 			/* TODO: is it correct ? Why CBQ doesn't do it ? */
 			sch->q.qlen -= (*old)->q.qlen;	
 			qdisc_reset(*old);
